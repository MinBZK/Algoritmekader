urn,titel,maatregel,onderwerp,levenscyclus,rollen,toelichting,risico,bijbehorende-vereisten,bronnen,url
urn:nl:ak:mtr:org-00,Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueel,"Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueel. 
  ","['governance', 'transparantie']","['organisatieverantwoordelijkheden', 'monitoring-en-beheer']",['beleid-en-advies'],"Om grip te krijgen op het gebruik van algoritmes binnen jouw organisatie, heb je allereest overzicht nodig van de algoritmes die in jouw organisatie gebruikt worden. Zorg dat je dit overzicht regelmatig actualiseert. 
Bepaal voor ieder algoritme de [risicogroep en vervolgens welke vereisten daarop van toepassing zijn](2-owp-05-soort-algoritme.md). Hiervoor kan je gebruik maken van de [beslishulp AI-verordening](https://ai-verordening-beslishulp.apps.digilab.network/). 

Bepaal ook of er sprake is van [geautomatiseerde besluitvorming of geautomatiseerde risicoselectie](../vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming.md). 

Inventariseren van de algoritmes die gebruikt worden, helpt bij:

- Inzicht in de risico's en kansen van het gebruik van algoritmes. 
- [Het correct registreren van de algoritmes in het Algoritmeregister](6-imp-04-publiceren-algoritmeregister.md)
- Het opzetten van een goede [algoritmegovernance](../../onderwerpen/governance.md). 
",,"['urn:nl:ak:ver:aia-00', 'urn:nl:ak:ver:aia-02', 'urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:bzk-01', 'urn:nl:ak:ver:avg-10']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/index.html
urn:nl:ak:mtr:org-01,Bepaal of er genoeg experts beschikbaar zijn,"
Bepaal welke expertise en capaciteit noodzakelijk is voor het ontwikkelen, inkopen en gebruiken van algoritmes en stel vast of er voldoende expertise en capaciteit beschikbaar is.
  ",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","- Bepaal welke expertise en capaciteit binnen de organisatie noodzakelijk is voor het ontwikkelen, inkopen en gebruiken van algoritmes.
- Dit is sterk afhankelijk van de specifieke toepassing en de inzichten die voortkomen uit risicoanalyses. Hoe complexer en risicovoller de toepassing, des te meer expertise en capaciteit noodzakelijk is. 
- Indien is vastgesteld dat er onvoldoende expertise aanwezig is, investeer dan in [bewustwording en voldoende opleidingen](0-org-16-bewustwording-en-opleiding.md) over de kansen en risico's van algoritmes en AI. 
- Interne en externe actoren die betrokken zijn bij het ontwikkelen, inkopen en gebruik moeten over voldoende expertise en capaciteit beschikken om hun taken naar behoren uit te voeren.
- Stel vast of er afhankelijkheden van externe aanbieders ontstaan.  
- Bepaal voorafgaand aan het (laten) ontwikkelen of inkopen van algoritmes of voldoende expertise en capaciteit beschikbaar is om tot een verantwoorde inzet ervan te komen.
- Leg vast of er voldoende expertise en capaciteit beschikbaar is en onderbouw dit in projectdocumentatie.
- Om menselijke controle te kunnen uitoefenen in verschillende fases van de ontwikkeling (of inkoop) van algortimes moet de mens bepaalde kennis, tijd en vaardigheden hebben. Alleen met de juiste kennis, tijd en vaardigheden kunnen risico’s op tijd geïdentificeerd en afgedekt worden. Deze kennis en expertise kan ook buiten de organisatie liggen, maar dan is het belangrijk om verantwoordelijkheden goed vast te leggen.
","Zonder voldoende expertise en capaciteit kan het zijn dat het ontwikkelen, inkopen, en gebruiken van algoritmes niet goed verloopt binnen de organisatie doordat de middelen hiervoor ontbreken. 

","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-01']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-01-benodigde-expertise-en-capaciteit/index.html
urn:nl:ak:mtr:org-02,Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatie,"
Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatie. 
","['governance', 'transparantie']",['organisatieverantwoordelijkheden'],['beleid-en-advies'],"Een duidelijk beleid over de inzet van algoritmes helpt organisaties te voldoen aan de vereisten voor het verantwoord gebruik ervan. Hierin worden zaken beschreven als:

- Hoe de inzet van algoritmes gaat bijdragen aan het realiseren van de organisatiedoelstellingen. 
- Het beschrijven van de stappen die moeten worden gezet om algoritmes op een verantwoorde wijze in te gaan zetten. Dit is afhankelijk en verschilt per [type algoritme en de bijbehorende risicoclassificatie](2-owp-05-soort-algoritme.md).
- Het beschrijven van welke hulpmiddelen in welke gevallen moeten worden ingezet om te voldoen aan de vereisten die gelden voor algoritmes. Hierbij kan worden gedacht aan:

    - Een [Impact Assessment Mensenrechten en Algoritmes](../hulpmiddelen/IAMA.md).
    - Een [Data Protection Impact Assessment](../hulpmiddelen/DPIA.md).
    - Het hanteren van [inkoopvoorwaarden](../hulpmiddelen/inkoopvoorwaarden.md).
    - Het uitvoeren van een [biasanalyse](5-ver-03-biasanalyse.md).
  
- Hoe burgers worden geïnformeerd over de inzet van algoritmes door de organisatie (communicatiestrategie) en welke kanalen hiervoor kunnen worden gebruikt. Hierbij kan worden gedacht aan:

    - Het [Algoritmeregister](../hulpmiddelen/algoritmeregister.md) voor het publiceren van hoog risico AI-systemen of impactvolle algoritmes. 
    - Een algemene pagina op de website met informatie over de inzet van algoritmes.
    - Het [verwerkingsregister](6-imp-07-vermelding-in-verwerkingsregister.md).
    - Een intern registratiesysteem, bijvoorbeeld voor het registreren van laag risico of niet-impactvolle algoritmes zodat deze informatie voor medewerkers beschikbaar is.
    - In welke gevallen een [(openbaar) besluit](6-imp-08-politiek-bestuurlijk-besluit.md) wordt genomen door het bestuur over de inzet van een algoritme. 

- Of algoritmes zelf worden ontwikkeld, of dat algoritmes of systemen worden [ingekocht](../../onderwerpen/publieke-inkoop.md). Dit vraagt om een andere governacnestructuur en aanpak. 

- Er is beschreven welke informatie over welke typen algoritmes wordt gecommuniceerd met betrokkenen bij de ontwikkeling of gebruik ervan door de organisatie. 
- Stel dit beleid op voor zowel:

    - nieuw te ontwikkelen algoritmes
    - gedurende de ontwikkeling van algoritmes
    - bestaande algoritmes

- Bepaal in welke gevallen het nodig is om een externe audit of validatie uit te voeren op het algoritme. 
- Bepaal of het wenselijk is om gebruik te maken van een (externe) ethische commissie en hoe dit onderdeel kan zijn van je processen. 
- Er is beschreven welke stappen worden gezetten in het geval dat er incidenten ontstaan rondom de inzet van algoritmes, denk hierbij aan een [discriminatieprotocol](0-org-15-discriminatieprotocol.md).
- Betrek een brede groep met verschillende disciplines bij de ontwikkeling van governance. 
- Dit beleidsdocument is beschikbaar en toegankelijk voor geïnteresseerden. 
","Zonder duidelijk beleid over de inzet van algoritmes kan het gebeuren dat algoritmes worden ontwikkeld of gebruikt die niet passend zijn binnen de organisatie. 
",['urn:nl:ak:ver:awb-01'],"
Geen beschikbare bron voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-02-beleid-opstellen-inzet-algoritmes/index.html
urn:nl:ak:mtr:org-03,Maak een plan voor het omgaan met risico’s,"
Pas risicobeheer gestructureerd toe voorafgaand en gedurende de ontwikkeling en gebruik van algoritmes.
  ",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","- Bepaal tijdig, bijvoorbeeld in de ontwerpfase om [wat voor toepassing het gaat](2-owp-05-soort-algoritme.md) (algoritme of AI-systeem) en bepaal welke risicoclassificatie hierbij hoort.
- Bepaal op basis van de toepassing en de risicoclassificatie, welke aspecten van risicobeheer moeten worden toegepast.
- Inventariseer tijdig, bijvoorbeeld in de probleemanalayse- of ontwerpfase, bij betrokken experts welke beleidskaders en hulpmiddelen binnen de organisatie moeten worden ingezet om risicobeheer toe te passen.
- Bepaal op basis van de [levenscyclus van een algoritme of AI-systeem](0-org-08-beslismoment-levenscyclus.md) wanneer welke aspecten van risicobeheer moeten worden toegepast. 
- Maak inzichtelijk op welke niveaus risicobeheer kan en moet worden belegd bij het ontwikkelen en gebruiken van algoritmes.
- Daarbij gaat het om het identificeren, analyseren, evalueren (afhankelijk van de risicobereidheid), behandelen (risicoreactie, o.a. maatregelen), monitoren & beoordelen en communiceren & rapporteren van risico's.
- Gedurende de levenscyclus van een algoritme of AI-systemen kunnen nieuwe risico's ontstaan waar mogelijk nieuwe maatregelen voor moeten worden getroffen. Het is van belang dat iteratief wordt gewerkt aan mitigerende maatregelen en dat risicobeheer periodiek wordt toegepast.

Let op! Sommige maatregelen in het Algoritmekader gaan dieper in op het uitvoeren van risicoanalyses. 
   ","Risico's worden niet (tijdig) vastgesteld en adequaat geadresseerd en behandeld.  
","['urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:awb-01']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/index.html
urn:nl:ak:mtr:org-04,"Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheid","Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid en verantwoordelijkheid. 
","['governance', 'transparantie']",['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","Voor een passende algoritmegovernance is politiek-bestuurlijk bewustzijn, betrokkenheid en verantwoordelijkheid essentieel. 
Het maken van verantwoorde keuzes rond de inzet van specifieke algoritmen en AI en het vinden van balans tussen voordelen en risico's, juridische vereisten en ethische principes vraagt om een bestuurlijke afweging. Daarmee is ook het opstellen van een goede governancestructuur een bestuurlijke verantwoordelijkheid. 
Zorg ervoor dat bestuurders bewust zijn van de voor- en nadelen van de inzet van algoritmes en daarnaar kunnen handelen.
Het opstellen van een juiste governancestructuur helpt teams bij het maken van de juiste overwegingen bij de ontwikkeling en gebruik van algoritmes. Het geeft ook inzicht wanneer de politiek of bestuurlijk verantwoordelijke(n) moeten worden betrokken bij het project om beslissingen te nemen, bijvoorbeeld of de mate van onbewuste vooringenomenheid (bias) binnen acceptabele grenzen ligt. 

De kernvraag voor publieke organisaties bij de inzet van algoritmen is altijd: Hoe wegen we (als publieke organisatie of samenleving) de voordelen en nadelen van de inzet van algoritmen? 
Dit gaat niet alleen over direct opbrengsten maar ook over lange termijn en indirecte effecten, de mate waarin de inzet van technologie bijdraagt aan de legitimiteit van publieke organisatie en hoe burgers met deze technologie worden bejegend. 

Om te zorgen voor politiek-bestuurlijke betrokkenheid kan het helpen om een [meerjarige visie/strategie rondom verantwoorde inzet](0-org-02-beleid-opstellen-inzet-algoritmes.md) te formuleren waar een communicatiestrategie richting burgers onderdeel van is.
Het doorlopen van een concrete casus voor de ontwikkeling en gebruik van een algoritme, inclusief het uitvoeren van een IAMA, kan waardevolle informatiegeven om een meerjarige visie of strategie op te stellen. 

","Het verwaarlozen van politiek-bestuurlijk bewustzijn, betrokkenheid en verantwoordelijkheid kan leiden tot een het ontwikkelen van algoritmegovernance dat op de lange termijn niet effectief inzetbaar is. 
",[],"[Kleur bekennen - vervolgonderzoek algoritmes](https://rekenkamer.rotterdam.nl/onderzoeken/kleur-bekennen/)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-04-politiek-bestuurlijke-verantwoordelijkheid/index.html
urn:nl:ak:mtr:org-05,Sluit algoritmegovernance aan op bestaande governancestructuren binnen de organisatie,"
Sluit algoritmegovernance aan op bestaande governancestructuren binnen de organisatie.
",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","Zoek bij het opstellen van een algoritmegovernance van een organisatie aansluiting en samenwerking met huidige governancestructuren. Dit kan op drie manieren: aansluiting bij bestaande governance binnen je organisatie, governance van andere sectoren en governance van andere overheidsorganisaties. 

### Aansluiting met bestaande governancestructuren binnen je eigen organisatie
Zoek aansluiting met bestaande governance binnen je organsatie, zoals:

- IT governance
- [datagovernance](../../onderwerpen/data.md#goed-databeheer-datagovernance-en-datamanagement)
- informatiebeveiliging zoals governance rondom de [NIS2 richtlijn](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/nis2-richtlijn/)
- [privacygovernance](https://www.cip-overheid.nl/media/eeqkauey/20200814-handleiding-privacy-governance-v3_2.pdf)

Deze governancestructuren kunnen waardevolle aanknopingspunten bieden voor algoritmegovernance, omdat hierin vaak al duidelijke afspraken zijn gemaakt en processen zijn geschreven om bijvoorbeeld risico's zo goed mogelijk te managen.
In veel organisaties werken bijvoorbeeld privacy- en informatiebeveiliging en informatiebeheerders nauw samen van strategisch organisatieniveau tot operationeel, omdat deze onderwerpen raken aan beide domeinen. 
Voor een verantwoorde inzet van algoritmes zullen deze expertise moeten gaan samengewerkt met andere expertise, zoals die van data science en ethiek.
Het is van belang dat deze expertises tijdig en voldoende ruimte krijgen om samen te werken, zodat de functionele en niet functionele requirements kunnen worden gedefinieerd voor een verantwoorde inzet van algoritmes.  
Stel vast waar deze expertises elkaar nodig hebben en waar deze zelfstandige taken en verantwoordelijkheden hebben. 
Voorgaande geeft inzichten om te bepalen in hoeverre algoritmegovernance, naast de bestaande governancestructuren, moet worden ingericht.

De volgende vragen kunnen bedragen om bovenstaande inzichtelijk te krijgen:

- Welke lessen zijn geleerd met de implementatie van de AVG of de toepassing van de BIO?
- Is er iemand intern verantwoordelijk gemaakt voor (toezicht op) algoritmes?
- Hoe werken experts vanuit verschillende onderwerpen zoals privacy, informatiebeheer, informatiebeveiliging en data op dit moment samen als het gaat om de inzet van algoritmes?


### Governance van andere sectoren
Andere sectoren hebben in veel gevallen al governancestructuren met vergelijkbare elementen. Denk aan governancestructuren uit de verzekeringssector of de bankensector. 

### Aansluiting met andere overheidsorganisaties
Probeer aansluiting te zoeken met vergelijkbare overheidsorganisaties. 
","Als er bij de bestaande governancestructuren geen rekening wordt gehouden met het invoeren van algoritmegovernance is er een risico dat verantwoord gebruik van algoritmes niet genoeg wordt overwogen binnen de organisatie.
",[],"Geen beschikbare bron voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/index.html
urn:nl:ak:mtr:org-06,Gebruik een algoritme volwassenheidsmodel om te weten waar de organisatie staat,"
Breng de volwassenheid van je organisatie op het gebied van algoritmes in kaart.
",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","-   Om tot een passende algoritmegovernance voor een organisatie te komen, moet eerst worden vastgesteld wat op dit moment al is ingericht binnen een organisatie op het gebied van algoritmes.
-   Hiervoor kan een volwassenheidsmodel worden toegepast.
-   Op basis hiervan kunnen vervolgstappen worden gedefinieerd, zodat je een handelingsperspectief hebt om je organisatie te organiseren. Ook kunnen deze uitkomsten helpen bewustzijn over de uitdagingen te vergroten.
-   Het is denkbaar dat het realiseren van algoritmegovernance vraagt om een organisatieverandering. De noodzaak voor implementatie van de AI-Verordening kan hier een katalysator voor zijn. Pas daarom verandermanagementtechnieken toe.
-   Deel deze informatie met het bestuur en zorg dat hier bewustzijn ontstaat. Bepaal vervolgens hoe algoritmegovernance moet worden ingericht.
-   Het is aan te raden om verantwoordelijkheden te beleggen voor het realiseren van algoritmegovernance.

","Als je niet een goed beeld hebt van waar de organisatie staat, is het moeilijk te peilen welke richting gekozen moet worden en kan dit leiden tot het doen van dubbel werk.
",[],"Geen beschikbare bron voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-06-volwassenheidsmodel/index.html
urn:nl:ak:mtr:org-07,Richt een algoritmegovernance in met three lines of defence,"
Richt een algoritmegovernance in met three lines of defence.
",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","Een inrichting van algoritmegovernance die vaak wordt toegepast is het three lines of defence model:

- De eerste linie gaat over eigenaarschap, ontwikkeling, gebruik en risicobeheersing van algoritmes.
- De tweede linie identificeert, beoordeelt en rapporteert over risico’s en het uitgevoerde gebruik algoritmes.
- De derde verdedigingslinie controleert de werking van de governance en betreft interne advisering en toetsing. 

Schuett (2022) presenteert het three lines of defence model als volgt:

![Three Lines of Defence Model](https://github.com/user-attachments/assets/4974f07d-9810-44e0-a0bb-56f1b1061732)

Het toepassen van een 'three lines of defence' is slechts één aspect van het toepassen van algoritmegoverance. 
","Een risico van het vermijden van het three lines of defence model is dat er stappen worden overgeslagen bij het ontwikkelen van een algoritmegovernance. 
",[],"Geen beschikbare bron voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/index.html
urn:nl:ak:mtr:org-08,Richt vaste beslismomenten en controlepunten in in de algoritmelevenscyclus,"
Richt vaste beslismomenten en controlepunten in in de algoritmelevenscyclus.
",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","- Algoritmegovernance kan op de levenscyclus aansluiten door 'gates' of controlepunten in te voeren. Deze gates bevatten belangrijke mijlpalen om te beoordelen of de juiste taken zijn uitgevoerd, of ethische afwegingen zijn gemaakt, of documentatie heeft plaatsgevonden en of akkoord is ingewonnen (go/no-go moment) bij de verantwoordelijke(n) om naar de volgende fase te mogen. 
- Het is belangrijk om te weten dat toepassing van deze ‘gates’ niet altijd hetzelfde is. Dit kan namelijk verschillen afhankelijk van het type algoritme. 
- Een hoog-risico-AI systeem moet aan meer vereisten voldoen dan een niet impactvol algoritme. Een hoog-risico AI-systeem moet daarom binnen de gates worden getoetst op meer onderdelen dan een niet impactvol algoritme.
","Als er geen controlepunten aanwezig zijn in de levenscyclus van een algoritmegovernance kan het moeilijk zijn om te traceren waar sommige problemen ontstaan en kunnen simpele wijzigingen in het proces over het hoofd worden gezien.
",[],"- [Hulpmiddel handelingsruimte waardevolle AI in de zorg](https://nlaic.com/wp-content/uploads/2022/06/04a)
- [Hulpmiddel-Handelingsruimte-Waardevolle-AI-voor-gezondheid-en-zorg.pdf](https://nlaic.com/wp-content/uploads/2022/08/NLAIC_AI-Lifecycle-management-in-de-zorg-samenvatting_V1.2.pdf)
- UWV Beleidsdocument model risico management, Modellevenscyclus (blz 21), 29 september 2021
- [Toetsingskader Algemene Rekenkamer, 1.07](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-08-beslismoment-levenscyclus/index.html
urn:nl:ak:mtr:org-09,Richt algoritmegovernance in op basis van de risicoclassificatie van algoritmes,"Richt algoritmegovernance in op basis van de risicoclassificatie van algoritmes.
",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","- Er is een verschil in de vereisten die van toepassing zijn op type algoritmes. Dit is mede afhankelijk van de risioclassificatie en de impact van het algoritme op betrokkenen.
- Zo zullen op basis van de AI-verordening meer vereisten moeten worden nageleefd bij hoog-risico AI-systemen, dan voor een AI-systeem met een beperkt risico. 
- Dit betekent dat algoritmegovernance uitgebreider moet zijn voor de risicovollere, complexere toepassingen dan voor de eenvoudige, niet-risicovolle toepassingen.
- [Stel daarom tijdig vast om welk type algoritme het gaat](2-owp-05-soort-algoritme.md) en welke vereisten hiervoor gelden. Dat draagt eraan bij dan alleen wordt gefocust op het realiseren van de vereisten waar daadwerkelijk aan moet worden voldaan. Dit zorgt ervoor dat projecten sneller kunnen worden gerealiseerd.
- Let op dat niet enkel naar de AI-verordening wordt gekeken. Ook op impactvolle algoritmes die niet vallen onder het bereik van de AI-verordening zijn vereisten van toepassing, en moet algoritmegovernance op worden toegepast.
- Is algoritmegovernance nieuw bij jouw organisatie, dan kan het helpen om een use-case met beperkt risico grondig te doorlopen om hiervan te leren.
","Een risico dat kan voortkomen uit het niet hanteren van de verschillende risicoclassificaties is dat er aan meer vereisten wordt voldaan dan nodig is bij sommige types algoritmes, wat kan leiden tot onnodig werk.
",[],"Geen beschikbare bron voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-09-governance-per-risicocategorie/index.html
urn:nl:ak:mtr:org-10,Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance,"
Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance.
",['governance'],['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","- Bij het vormgeven van een doeltreffende algoritmegovernance is het beleggen van expliciete taken en verantwoordelijkheden cruciaal.
- Het beleggen van deze taken en verantwoordelijkheden zorgt voor een actiegerichte structuur waarin duidelijkheid bestaat over wie wanneer aan zet is.
- Denk hierbij aan het opstellen van een RACI-matrix en pas dit binnen de organisatie toe per risicoclassificatie voor algoritmes. 
- Rollen en verantwoordelijkheden kunnen worden gekoppeld aan de [vereisten](../vereisten/index.md) en [maatregelen](../maatregelen/index.md) die moeten worden gerealiseerd in de verschillende [fasen van de levenscyclus](../../levenscyclus/over-de-levenscyclus.md) van een algoritme.
- Organisaties zullen zelf moeten beoordelen welke taken en verantwoordelijkheden ze willen koppelen aan de beschikbare (of nieuwe) rollen binnen hun organisaties.  
- Zie hieronder een mogelijk voorbeeld van hoe dit eruit kan zien. 

![Format](https://github.com/user-attachments/assets/3debe7b6-0c42-40f5-a366-9cc5cc90cd3e)

De rollen en verantwoordelijkheden voor reguliere algoritmes en AI kunnen anders zijn dan voor generatieve AI. Waar het gebruik van reguliere algoritme en Al-toepassingen duidelijk onder de verantwoordelijkheid van het management valt, wordt er bij hulpmiddelen die gebruik maken van generatieve AI meer verantwoordelijkheid gevraagd van betrokken medewerkers. Hier wordt vaak ingezet om te zorgen voor bewustwording van verantwoord gebruik van deze technologie bij verschillende medewerkers. 
","Een risico dat kan worden gemitigeerd met behulp van deze maatregel is dat het werkproces rondom algoritmegovernance niet efficiënt is ingedeeld en bijvoorbeeld kan leiden tot dubbele werkzaamheden of overzicht verliezen.

",[],"- [Onderzoekskader Auditdienst Rijk, SV.9](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-10-inrichten-taken-en-verantwoordelijkheden-algoritmegovernance/index.html
urn:nl:ak:mtr:org-11,Maak afspraken over het beheer van gebruikers,"
Richt gebruikersbeheer in, waarmee bepaald wordt wie toegang heeft tot wat, en wat er bijvoorbeeld gebeurt bij indiensttreding, functiewijziging en uitdiensttreding.
","['technische-robuustheid-en-veiligheid', 'governance']",['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","Gebruikersbeheer zorgt ervoor dat accounts en autorisaties beheerst worden aangevraagd, geautoriseerd, gewijzigd en ingetrokken bij indiensttreding, functiewijziging en uitdiensttreding. Ook wordt functievermenging voorkomen bij toegang en gebruik van het algoritme, de data of de uitkomsten van een algoritme.

Bij het inrichten van gebruikersbeheer moeten aan de volgende elementen worden gedacht:

- Gebruikers en beheerders krijgen slechts toegang tot functionaliteit die zij uit hoofde van hun functie nodig hebben (need to know, need to use). Daartoe is een beschrijving beschikbaar welke rollen en rechten per applicatie bij een functie horen (BIO 6.1.2, 9.2.2 en 9.4).
- Het verlenen en muteren van accounts en toegangsrechten vindt plaats na goedkeuring door een bevoegde functionaris. Dit aan de hand van een actueel mandaatregister waaruit blijkt welke personen beslissende bevoegdheden hebben voor het verlenen van een bepaald type (niveau) toegangsrechten danwel functieprofielen (BIO 9.2.1.2, 9.2.2.1, 9.4).
- Er bestaat functiescheiding tussen het aanvragen, autoriseren en doorvoeren van wijzigingen in gebruikersaccounts en toegangsrechten (BIO 9.2.1.2, 9.2.2.1, 9.2.3).
- Functiewijzigingen en uitdiensttredingen worden bewaakt voor aanpassen van de toegangsrechten en voor intrekken van de identiteits- en authenticatiemiddelen (BIO 9.2.2, 9.2.6).
- Het aantal accounts met verhoogde rechten is beperkt en verklaard, en staat in logische verhouding tot de beheerders en of ICT-afdeling (BIO 9.1.2.(1), 9.2.3, 9.2.4).
- Gebruikersaccounts en beheeraccounts dienen altijd persoonsgebonden en verklaard te zijn, zodat handelingen altijd te herleiden zijn naar één verantwoordelijke (BIO 9.1, 9.4.2).
- Eindgebruikers hebben geen directe toegang tot de onderliggende componenten (zoals de database) (BIO 9.2.3, 13.1.3).
- Toegangsrechten op onderliggende componenten dienen periodiek, minimaal jaarlijks, geëvalueerd te worden. Dit interval dient te zijn beschreven in het toegangsbeleid en zijn bepaald op basis van het risiconiveau. De uitkomsten van de evaluatie en de opvolging daarvan worden vastgelegd (BIO 9.2.5).

Voor deze maatregelen is het van belang om aandacht te hebben voor de volgende zaken:

- Autorisatiematrix en beschrijving rollen/rechten per systeem(laag)
- Lijst met wijzigingen rollen en bijbehorende goedkeuringen
- Overzicht aantallen en rechten per (systeem)laag
","Er bestaan meerdere risico's wanneer er geen gebruikersbeheer is:

- Toegangsrechten kunnen niet meer up-to-date zijn, bijvoorbeeld wanneer er geen rekening wordt gehouden met het IDU-proces. Er bestaat dan het risico dat gebruikers toegang tot de omgeving van het algoritme, de data of de uitkomsten van het algoritme hebben die zij niet zouden mogen hebben.
- Wanneer functievermenging niet wordt voorkomen bij toegang en gebruik van het algoritme, bestaat het risico dat er ongeautoriseerde wijzigingen worden doorgevoerd aan het algoritme, de data of de uitkomsten van het algoritme.
- Wanneer gebruik wordt gemaakt van generieke-, groeps- of onpersoonlijke accounts, bestaat het risico dat handelingen niet te herleiden zijn naar een verantwoordelijke persoon.

",['urn:nl:ak:ver:bio-01'],"
- [Baseline Informatiebeveiliging Overheid](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.10 t/m IB.17](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 4.01, 4.02, 4.04, 4.05](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-11-gebruikersbeheer/index.html
urn:nl:ak:mtr:org-12,Controleer en verbeter regelmatig de kwaliteit van het algoritme," Richt een proces in voor een periodieke evaluatie van de kwaliteit van het algoritme.
  ","['governance', 'menselijke-controle']","['organisatieverantwoordelijkheden', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies']","- Het is van belang dat een proces wordt ingericht waarmee periodiek de kwaliteit van algoritmes wordt geëvalueerd.
-	Bij kwaliteit van een algoritme kan worden gedacht aan doeltreffenheid, doelmatigheid, betrouwbaarheid en accuraatheid (geschiktheid), non-discriminatie en menselijke controle.
-	Hieronder vallen het analyseren en evalueren van ingediende klachten en incidenten.
-	Hieronder vallen ook het analyseren en evalueren van besluiten door of aan de hand van het algoritme.
- Na verloop van tijd kan de accuraatheid van machine learning modellen bijvoorbeeld wijzigen of kan het gebeuren dat bepaalde groepen (indien van toepassing) anders worden behandeld.
- Het is van belang dat monitoringsactiviteiten worden ingericht om deze kwaliteitsaspecten tijdig te beoordelen.
- Als er ongewenste wijzigingen plaatsvinden met betrekking tot de kwaliteit, moeten die worden geëvalueerd en zullen maatregelen moeten worden getroffen om deze te herstellen.
- Het proces moet er voor zorgen dat de juiste experts of stakeholders worden betrokken bij het proces van evaluatie en het treffen van passende maatregelen.

Let op! Sommige maatregelen in het Algoritmekader gaan dieper in op het uitvoeren van risicoanalyses. 
   ","Zonder evaluatie van de kwaliteit van het algoritme is er geen goede sturing, beheersing en verantwoording mogelijk als er ongewenste wijzigingen plaatsvinden in het algoritme of AI-systeem. 
","['urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-27']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/index.html
urn:nl:ak:mtr:org-13,Maak afspraken over het beheer van wachtwoorden,"
Richt wachtwoordbeheer in, waarmee bepaald wordt hoe wachtwoorden worden opgeslagen, wanneer wijzigingen moeten plaatsvinden en waaraan wachtwoorden moeten voldoen. Hiermee wordt de toegang tot bijvoorbeeld ontwikkelomgevingen geregeld op een veilige manier.

","['technische-robuustheid-en-veiligheid', 'governance']",['organisatieverantwoordelijkheden'],"['projectleider', 'ontwikkelaar']","Bij het inrichten van wachtwoordbeheer moeten de volgende zaken worden toegepast:

- Alle wachtwoorden van gebruikers en beheerders dienen periodiek te worden gewijzigd, met een maximum van 1 jaar (BIO 9.4.3). Initiële wachtwoorden en wachtwoorden die gereset zijn, hebben een maximale geldigheidsduur van 24 uur en moeten bij het eerste gebruik worden gewijzigd.
- Voor toegang vanuit een onvertrouwde omgeving dient twee-factor authenticatie te worden gebruikt (BIO 9.4.2.1). Als er geen gebruik wordt gemaakt van twee-factor authenticatie, is de wachtwoordlengte minimaal 8 posities en complex van samenstelling. In situaties waar geen twee-factor authenticatie mogelijk is, wordt minimaal halfjaarlijks het wachtwoord vernieuwd.
- Na een periode van maximaal 15 minuten inactiviteit dient de toegang tot de applicatie te worden vergrendeld en na 10 foutieve inlogpogingen dient het account geblokkeerd te worden (BIO 11.2.9, BIO 9.4.3). De tijdsduur dat een account wordt geblokkeerd na overschrijding van het aantal keer foutief inloggen is vastgelegd.
- Wachtwoorden mogen niet in originele vorm (plaintext) worden opgeslagen, maar dienen versleuteld te worden (NIST 5.1.1.2).
- De eisen aan wachtwoorden moeten geautomatiseerd worden afgedwongen.

","Als het wachtwoordbeheer van onvoldoende kwaliteit is, kan oneigenlijke toegang plaatsvinden tot het algoritme of uitkomsten van het algoritme, bijvoorbeeld doordat het wachtwoord te eenvoudig is.
",['urn:nl:ak:ver:bio-01'],"
- [Baseline Informatiebeveiliging Overheid](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.6 t/m IB.9](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 4.03](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [NIST 5.1.1.2](https://pages.nist.gov/800-63-3/sp800-63b.html#sec5)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-13-wachtwoordbeheer/index.html
urn:nl:ak:mtr:org-14,Maak afspraken over het wijzigen van de code,"
Richt een wijzigingenproces in, waarmee bepaald wordt hoe codewijzigingen plaatsvinden.

","['technische-robuustheid-en-veiligheid', 'governance']",['organisatieverantwoordelijkheden'],"['projectleider', 'ontwikkelaar']","Bij het inrichten van een proces om wijzigingen aan de code te mogen aanbrengen, kunnen aan de volgende elementen worden gedacht:

- Wijzigingen dienen van te voren te worden geautoriseerd door de systeemeigenaar of product owner. (BIO 12.1.2)
- Wijzigingen worden getest in een andere omgeving dan de productieomgeving. (BIO 12.1.4, 14.2.3, 14.2.9, 14.3.1)
- Wijzigingen worden door de systeemeigenaar of product owner goedgekeurd op basis van gedocumenteerde testresultaten en pas daarna doorgevoerd in de productieomgeving. (BIO 12.1.2, 14.2.2, 14.2.9)
- Er dient functiescheiding te zijn ingericht tussen het aanvragen, goedkeuren en doorvoeren van wijzigingen om onbevoegde en onbedoelde wijzigingen te beperken. (BIO 6.1.2, 14.2.2)
- Er dient periodiek controle plaats te vinden op wijzigingen aan het systeem, zodanig dat oneigenlijke wijzigingen worden gesignaleerd. (BIO 9.4.4, 12.4.1)
","Als een formeel wijzigingenproces ontbreekt bestaat het risico van ongeautoriseerde toegang, wijziging of beschadiging van de code van het algoritme, of de uitkomsten van het algoritme.
",['urn:nl:ak:ver:bio-01'],"
- [Baseline Informatiebeveiliging Overheid](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.1 t/m IB.5](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 4.07](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag) 
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-14-wijzigingenproces/index.html
urn:nl:ak:mtr:org-15,Stel een protocol vast voor de situatie dat er (een vermoeden van) discriminatie door een algoritme is geconstateerd en pas dit wanneer nodig toe,"Stel een protocol vast voor de situatie dat er (een vermoeden van) discriminatie door een algoritme is geconstateerd en pas dit wanneer nodig toe.
",['bias-en-non-discriminatie'],"['organisatieverantwoordelijkheden', 'implementatie']","['projectleider', 'beleid-en-advies']","De inzet van algoritmes kan onbedoeld leiden tot discriminerende effecten. 
Het is van belang om als organisatie een protocol te hebben vastgesteld waarin is uitgewerkt hoe wordt omgegaan met situaties waarin (een vermoeden van) discriminatie door een algoritme is geconstateerd.
In een dergelijk protocol kunnen de handelingen worden beschreven die moeten worden uitgevoerd om deze situatie te herstellen.
Het vaststellen van een dergelijk protocol geeft ontwikkelaars en gebruikers (vooraf) duidelijkheid wat van hen wordt verwacht en wat zij kunnen doen om discriminatie door algoritmes te voorkomen.  
Een voorbeeld hiervan is het analyseren van de data op [datakwaliteit en bias in de data](3-dat-01-datakwaliteit.md) en [toets regelmatig je algoritmisch systeem op bias](5-ver-03-biasanalyse.md). 

Het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties heeft een [discriminatieprotocol](https://minbzk.github.io/discriminatieprotocol) opgesteld wat organisaties handvatten biedt.

Een discriminatieprotocol kan de volgende stappen bevatten:

### Stap 1: Vermoeden van onrechtmatigheid

Een vermoeden van bevooroordeeldheid of discriminatie kan vanuit verschillende partijen gemeld worden. 
Signalen hiervoor kunnen worden ontvangen vanuit de interne organisatie, bijvoorbeeld door de betrokken ontwikkelaars, gebruikers of beheerders, of door externe partijen, zoals belanghebbenden, toezichthouder of journalisten. 
  
  - Zorg dat signalen tijdig bij de goede medewerkers terecht komen. 
  - Indien er sprake is van zo'n vermoeden, zorg je dat bijvoorbeeld de uitvoerend directeur, de interne toezichthouder en/of de CIO en CDO hierover worden geïnformeerd. 
  - Maak met de verantwoordelijken een afweging of het betreffende systeem in werking kan blijven of dat bijvoorbeeld [het noodplan voor het stopzetten van het algoritme](4-owk-02-stopzetten-gebruik.md) (tijdelijk) in gang moet worden gezet. 

### Stap 2: Inzicht en overzicht

Het is van belang om inzicht en overzicht te krijgen over de oorzaak en de gevolgen van eventuele discriminerende effecten van het algoritme. 
Daarvoor kan worden gedacht aan het uitvoeren van een bias analyse.

  - Bepaal wie er verantwoordelijk is voor het uitvoeren van het onderzoek.
  - Bepaal of je een onafhankelijk onderzoek wilt doen naar het algoritme.
  - Breng in kaart wat de omvang van het probleem is. Hoe lang doet het probleem zich al voort, en hoeveel mensen betreft het?
  - Ga snel met (vertegenwoordigers van) gedupeerden in gesprek over de gevolgen en de mogelijke schade.
  - Trek een conclusie of er sprake is van discriminatie, of een sterk vermoeden van discriminatie. 
  - Onderzoek en analyseer waarom de genomen maatregelen om discriminatie tegen te gaan, zoals het [uitvoeren van een biasanalyse](5-ver-03-biasanalyse.md) onvoldoende hebben gewerkt. Bekijk hoe de werkwijzen in de organisatie verbeterd kunnen worden zodat dit in de toekomst voorkomen kan worden. 

### Stap 3: Beperken schade

Bepaal welke mitigerende maatregelen er genomen moeten worden. Als er in het onderzoek is vastgesteld dat er sprake is van discriminatie, dan moet het betreffende systeem worden stopgezet. Hierbij kan je denken aan:

   - Het in werking stellen van het [het noodplan voor het stopzetten van het algoritme](4-owk-02-stopzetten-gebruik.md), indien dat in stap 1 nog niet gebeurd is. 
   - Aanpassingen in het algoritme, de werkinstructies of de bijbehorende processen.
   - Indien het algoritme essentieel is in de uitvoer kan er sprake zijn van een een proportionaliteitsvraagstuk. In dat geval moet er worden bezien wat de alternatieven zijn, en of er delen van het systeem kunnen worden uitgeschakeld.
  
### Stap 4: Melden en informeren

De conclusies van de eerdere stappen moeten, indien nodig, worden gemeld bij de betreffende instanties. De eventuele gedupeerde burgers dienen te worden geïnformeerd over de gevolgen.

   - Als er sprake is van een hoog-risico AI-systeem moeten ernstige incidenten worden gemeld bij de markttoezichtautoriteiten. Zie [artikel 73 van de AI-verordening](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e7117-1-1) en [artikel 3 (49.c) van de AI-verordening](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2093-1-1).
   - Voor alle algoritmes geldt: Informeer de interne toezichthouder, de externe toezichthouder en de politiek, afhankelijk van hoeveel mensen geraakt en gedupeerd zijn en de impact. 
   - Informeer de betrokken burgers over de situatie. Maak indien nodig excuses en geef de mensen die (mogelijk) geraakt zijn uitleg zodat zij:
     
       - begrijpen wat er is gebeurd
       - weten wat de waarschijnlijke gevolgen zijn
       - welke mitigerende maatregelen zijn genomen
       - waar mensen terecht kunnen met vragen
       - op de hoogte zijn van het proces rondom de afhandeling van de schade.
        
### Stap 5: Registratie en afhandeling

  - Registreer het algoritme in het [algoritmeregister](https://algoritmes.overheid.nl/nl), indien dat nog niet gebeurd is.
  - Zorg voor goede klachtenafhandeling en herstelprocedures. 
","Als er geen protocol wordt vastgesteld voor het detecteren van discriminatie door een algoritme is er een risico op discriminatie, waarbij het niet duidelijk is voor werknemers wat de stappen zijn om dit te herkennen en tegen te gaan. 
",['urn:nl:ak:ver:grw-02'],,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/index.html
urn:nl:ak:mtr:org-16,Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AI,"Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AI. 

!!! warning ""Let op!""

    Volgens de AI-verordening moet [AI-geletterdheid](../vereisten/aia-01-ai-geletterdheid.md) per **2 februari 2025** gewaarborgd worden door aanbieders en gebruiksverantwoordelijken van AI-systemen.
",['governance'],['organisatieverantwoordelijkheden'],['beleid-en-advies'],"Om algoritmes op een verantwoorde manier te gebruiken, is het noodzakelijk dat medewerkers hier voldoende kennis over hebben. Dat draagt bij om de kansen die AI biedt zo goed mogelijk te benutten, en tegelijkertijd bewust om te gaan met de risico's. Dit geldt niet alleen voor direct betrokken medewerkers en ontwikkelaars, maar ook voor bestuurders en bijvoorbeeld beleidsmakers. 
Om te komen tot een volwassen niveau van AI-geletterdheid is een structurele, langdurige en op maat gemaakte aanpak nodig, die rekening houdt met de context en rollen waarin mensen met AI-systemen te maken hebben.

Denk bijvoorbeeld aan het borgen voldoende kennis en bewustzijn over:

- risico's op [bias en eventuele discriminerende effecten](../../onderwerpen/bias-en-non-discriminatie.md)
- de werking van een algoritme zodat [betekenisvolle menselijke tussenkomst](../../onderwerpen/menselijke-controle.md) kan plaatsvinden 
  
Maak een meerjarig actieplan om toe te werken naar een volwassen niveau van AI-geletterdheid die past bij jouw organisatie. Stel dit bestuurlijk vast en zorg voor [bestuurlijke verantwoordelijkheid en betrokkenheid](0-org-04-politiek-bestuurlijke-verantwoordelijkheid.md). De [Autoriteit Persoonsgegevens](https://www.autoriteitpersoonsgegevens.nl/documenten/aan-de-slag-met-ai-geletterdheid) heeft een aanzet gedaan voor een passend meerjarenplan om AI-geletterdheid in jouw organsatie te bevorderen: 

![stappenplan meerjarenplan AI-geletterdheid](images/ai-geletterdheid-ap.png)

### Relevante opleidingen
- [E-learning Non-discriminatie in algoritmes en data](https://www.it-academieoverheid.nl/actueel/nieuws/2024/10/29/nieuwe-radio-e-learning-non-discriminatie)
",,"['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-21']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/0-org-16-bewustwording-en-opleiding/index.html
urn:nl:ak:mtr:pba-01,Beschrijf het probleem dat het algoritme moet oplossen,"Formuleer en documenteer wat de aanleiding is om een algoritme in te willen zetten. 
Formuleer duidelijk de probleemdefinitie en probleemafbakening waarvoor het algoritme een oplossing zou moeten vormen. 
","['governance', 'transparantie']",['probleemanalyse'],['projectleider'],"Formuleer de probleemdefinitie en probleemafbakening zo concreet en precies mogelijk. Maak dit waar mogelijk kwantificeerbaar. 
","Het algoritme dient niet het onderliggende probleem. 
Zonder eenduidigheid over het op te lossen probleem is geen sturing op en verantwoording over het algoritme mogelijk. 
",['urn:nl:ak:ver:awb-01'],"
- [Impact Assessment Mensenrechten en Algoritmes, 1.01](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes)
- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.1](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-01-formuleren-probleemdefinitie/index.html
urn:nl:ak:mtr:pba-02,Beschrijf het doel van het algoritme,"
Het doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd. 
Maak de consequenties van het algoritme specifiek en zorg dat het doel van het algoritme formeel is vastgesteld en vastgelegd. 
","['governance', 'transparantie']",['probleemanalyse'],['projectleider'],"- Het doel van de inzet van een algoritme dient zo concreet en specifiek mogelijk gedefinieerd te worden. 
Indien er meerdere doelen zijn, is het belangrijk om een zekere rangorde te maken: wat zijn de belangrijkste doelen? En waarom?
Welke doelen zijn subdoelen, waarvoor het minder belangrijk is om deze te realiseren?

- Indien mogelijk, dienen de doelstellingen gekwantificeerd te worden (SMART).

- Probeer vast te stellen wat de doelpopulatie is, zodat in een later stadium data kan worden gezocht dat [representatief is daarvoor, wat bijdraagt aan de datakwaliteit](3-dat-01-datakwaliteit.md) van een algoritme.

- Om te zorgen voor voldoende draagvlak voor de beoogde doelen, is het noodzaak om [voldoende belanghebbenden te betrekken](1-pba-04-betrek-belanghebbenden.md). 
Hierbij kan het ook helpen om burgers te betrekken bij de totstandkoming van de doelstellingen, bijvoorbeeld door middel van een burgerpanel of het betrekken van belangengroepen.
","Het algoritme dient niet het beoogde doel en onderliggend probleem. 
Zonder eenduidigheid over het doel is geen sturing op en verantwoording over het algoritme mogelijk. 
Er is dan een groter risico op fouten en/of verschillen in interpretatie. 

Wanneer doelstellingen niet meetbaar zijn gemaakt, is het onmogelijk om achteraf te kwantificeren of de doelstellingen zijn behaald. 
Doelstellingen zijn in dat geval moeilijk bespreekbaar.
",['urn:nl:ak:ver:awb-01'],"
- [Toetsingskader Algoritmes Algemene Rekenkamer, 1.01, 1.02](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Impact Assessment Mensenrechten en Algoritmes, 1.2](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes)
- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.3, DM.7](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/index.html
urn:nl:ak:mtr:pba-03,Beschrijf waarom een algoritme het probleem moet oplossen,"Bepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. 
","['governance', 'menselijke-controle']",['probleemanalyse'],['projectleider'],"- Bepaal waarom het gewenst of nodig is om een algoritme in te zetten, en of er ook alternatieven zijn om het probleem op te lossen. 
Documenteer de onderbouwing waarom een algoritme een betere oplossing zou bieden dan een niet-geautomatiseerd of niet-digitaal proces. 

- Maak een bewuste afweging of een algoritme het juiste middel is om [het probleem](1-pba-01-formuleren-probleemdefinitie.md) op doelmatige en doeltreffende wijze op te lossen, en documenteer deze afweging.

- Beoordeel of de gewenste oplossing is [toegestaan op grond van de AI-Verordening](../vereisten/aia-00-verboden-AI-praktijken.md). 
","Het algoritme is niet het juiste middel om het probleem op te lossen. Het risico daarbij bestaat dat het probleem niet wordt opgelost. 
","['urn:nl:ak:ver:aia-00', 'urn:nl:ak:ver:awb-01']","
- [Impact Assessment Mensenrechten en Algoritmes, 1.01](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes)
- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.2](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Handreiking identificatie verboden AI-systemen (Powerpoint-bestand)](https://github.com/user-attachments/files/18179740/Handreiking_Uitvraag_VBSystemen.pptx)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/index.html
urn:nl:ak:mtr:pba-04,Overleg regelmatig met belanghebbenden,"
Breng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.
","['governance', 'fundamentele-rechten']","['probleemanalyse', 'ontwerp', 'implementatie']",['projectleider'],"Het betrekken van belanghebbenden is van belang in bijna alle fasen van de levenscyclus.
Belanghebbenden zijn onder meer eindgebruikers, mensen en rechtspersonen die door het algoritme geraakt kunnen worden en vertegenwoordigende organisaties.

In de fase van de probleemanalyse is het allereerst van belang in kaart te brengen welke stakeholders er zijn.
Wie gaan bijvoorbeeld werken met het algoritme (eindgebruikers)? En welke demografieën worden geraakt door een algoritme?
Bij wie liggen de voordelen en bij wie liggen de nadelen?
Ga in gesprek met deze belanghebbenden - al dan niet vertegenwoordigd door belangenorganisaties zoals burgerrechtenorganisaties - over het te ontwerpen algoritme en de context waarin het gebruikt wordt. Zij kunnen waardevolle inzichten en wensen delen, wat kan bijdragen aan een betere werking van het algoritme. 

Enkele voorbeelden hierbij zijn:

- Het betrekken van burgers bij het ontwerpen van een algoritme in de ontwerpfase. 
- Het bespreken welke definitie en metriek van _fairness_ past bij de context met de proceseigenaar en een ethicus.
- Het betrekken van domeinexperts in de fase van dataverkenning en datapreparatie, om zo in kaart te brengen wat de data features betekenen en waar zij vandaan komen.
- Het betrekken van eindgebruikers bij het ontwikkelen en het implementeren van het algoritme.
- Het betrekken van belanghebbenden bij het monitoren en evalueren van het algoritme.
","Het niet betrekken van belanghebbenden bij de ontwikkeling en het gebruik van algoritmes kan ertoe leiden dat belangrijke inzichten of perspectieven niet worden verwerkt en het algoritme onjuist gaat functioneren. 
",['urn:nl:ak:ver:awb-01'],,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-04-betrek-belanghebbenden/index.html
urn:nl:ak:mtr:pba-05,Beschrijf de wettelijke grondslag voor de inzet van het algoritme,"Beschrijf de wettelijke grondslag voor de inzet van het algoritme en de beoogde besluiten die genomen zullen worden op basis van het algoritme.
","['governance', 'transparantie']",['probleemanalyse'],['jurist'],"- Analyseer of er een concrete wettelijke grondslag is die de inzet van het algoritme mogelijk maakt en deze inzet voldoende voorzienbaar maakt. 
- Als de verwachting is dat een algoritme tot gevolg heeft dat wordt ingegrepen in het leven of de vrijheid van mensen, en zeker als de verwachting is dat er grondrechten worden geraakt, moet er een wettelijke grondslag bestaan voor de inzet van het algoritme.
- Voor het verwerken van persoonsgegevens is een wettelijke grondslag noodzakelijk.
","Het algoritme en beoogde besluiten voldoen niet aan wet- en regelgeving en intern beleid en kaders.

","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:avg-01']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/index.html
urn:nl:ak:mtr:pba-06,Stel een multidisciplinair team samen bij het ontwikkelen of inkopen van algoritmes,"Stel een multidisciplinair team samen bij het ontwikkelen of inkopen van algoritmes.
",['publieke-inkoop'],['ontwerp'],"['projectleider', 'beleid-en-advies']","- Bij een project gericht op het ontwikkelen of inkopen van algoritmes is het belangrijk dat betrokkenen al in een vroeg stadium samenwerken. Dit betekent dat zowel een interne opdrachtgever als het ontwikkelingsteam of de afdeling inkoop tijdig worden aangehaakt om te zorgen voor een goed afgestemd proces.
- Wanneer het gaat om het ontwikkelen of inkopen van algoritmes, is een multidisciplinair team wenselijk. Zo'n team brengt relevante kennis en ervaring samen om de behoeften en specificaties helder te krijgen. Afhankelijk van de aard en complexiteit van het algoritme kunnen de rollen binnen dit team variëren.
- Naast een interne opdrachtgever, materiedeskundige en gebruiker kun je voor het ontwikkelen van algoritmes denken aan een data-engineer, data scientist, IT-architect, ethicus, data- en privacy-officer. Bij een overheidsopdracht gericht op de inkoop van een algoritme, horen daar nog een (aanbestedings)jurist en inkoper bij. Afhankelijk van de complexiteit van de oplossing zijn meer of minder disciplines en dus te beleggen verantwoordelijkheden binnen het team wenselijk.
- Een multidisciplinair team kan ondersteunen bij het [formuleren van de probleemstelling](1-pba-01-formuleren-probleemdefinitie.md) of [formuleren van de doelstellingen](1-pba-02-formuleren-doelstelling.md) van een project, verkennen van de mogelijke oplossingsrichtingen en het vertalen van de gewenste oplossingsrichting naar de concrete behoefte.
","Zonder een multidisciplinair team is het waarschijnlijk dat belangrijke aspecten voor een verantwoorde inzet van algoritmes niet worden geadresseerd en ongewenste algoritmes worden ontwikkeld of ingekocht.
",['urn:nl:ak:ver:awb-01'],,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/1-pba-06-multidisciplinair-inkoopteam/index.html
urn:nl:ak:mtr:owp-01,Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmes,"Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmes. De rollen en verantwoordelijkheden worden vastgesteld door de verantwoordelijke(n).
",['governance'],"['ontwerp', 'implementatie', 'monitoring-en-beheer']",['projectleider'],"Een reëel risico is dat bepaalde groepen en belanghebbenden over het hoofd worden gezien tijdens het ontwikkelproces van een algoritme.
Daarom is het noodzakelijk om al vroeg in kaart te brengen welke groepen allemaal een mening over het beoogde algoritme kunnen hebben.

Duidelijkheid en borging van rollen en verantwoordelijkheden zorgen voor een effectief en verantwoord verloop van het proces rondom de ontwikkeling, inkoop en gebruik van een algoritme. 
Zeker wanneer ongewenste effecten optreden en maatregelen nodig zijn, is duidelijkheid over rollen, verantwoordelijkheden en bijbehorende besluitvormingsstructuren van belang.

Om deze reden kan het handig zijn om een matrix van belanghebbenden op te stellen.  
Deze matrix kan in verdere fases helpen wanneer belanghebbenden betrokken moeten worden. In deze matrix kunnen de volgende onderdelen staan: 

- Per belanghebbende een beschrijving van wie deze groep is 
- Mate van invloed van belanghebbende op het algoritme: wie, wanneer in de levenscyclus zorgt voor passende [menselijke controle](../../onderwerpen/menselijke-controle.md)
- Impact van algoritme op de belanghebbende 
- Risico’s voor belanghebbende (wat zal de belanghebbende merken als het algoritme eventueel niet naar behoren functioneert).  

Een RACI-matrix/VERI-matrix is een passend middel om de verantwoordelijkheden (Responsible/Verantwoordelijk, Accountable/Eindverantwoordelijk, Consulted/Geraadpleegd, Informed/Geïnfomeerd) te bepalen.
Werk specifieke, gevoelige activiteiten nader uit in concrete taken en verantwoordelijkheden, bijvoorbeeld welke stappen moeten worden gezet om data veilig te leveren ten behoeve van een onderzoek naar onbewuste vooringenomenheid.  

### Vaststellen van rollen en verantwoordelijkheden
- Laat de rollen en verantwoordelijkheden vaststellen door de verantwoordelijke(n). Het doel van vaststelling is dat de verantwoordelijke(n) de verantwoordelijkheid neemt en actief een keuze maakt om het algoritme te (laten) ontwikkelen of gebruiken op de beoogde wijze en met de bijbehorende verantwoordelijkheden. Met het vaststellen worden afspraken geformaliseerd. 
- Vaststelling van de verantwoordelijkheden kan plaatsvinden door beleidsdocumenten, werkinstructies, verwerkersovereenkomst of een PIA/DPIA, mits de verantwoordelijkheden voldoende duidelijk zijn beschreven.
- Gedurende de levenscyclus kan het voorkomen dat rollen en verantwoordelijkheden opnieuw moet worden beschreven en vastgesteld.

### Verwerking van persoonsgegevens
- Bij het verwerken van persoonsgegevens moet worden vastgelegd wie de (gezamelijke) verwerkingsverantwoordelijken zijn en wie de verwerkers. Uit deze vaststelling van de rolverdeling volgen onder de AVG verschillende rechten en plichten.
- Bij de ontwikkeling en gebruiken van algoritmes is het denkbaar dat de noodzaak voor het verwerken van persoonsgegevens wijzigt en dat meer of andere verwerkingen moeten plaatsvinden. Het is van belang dat wederom wordt beoordeeld wat dit betekent voor de bijbehorende verantwoordelijkheden. Als er sprake is van een wezenlijke wijziging ten opzichte van de al vastgestelde situatie, bijvoorbeeld doordat er meer persoonsgegevens worden verwerkt door een andere partij, dan zal de verwerkingsverantwoordelijke opnieuw tot vaststelling moeten overgaan om de afspraken te formaliseren.

","De sturing en verantwoording is ontoereikend of niet geborgd, waardoor er onvoldoende betrokkenheid of capaciteit is van verantwoordelijken. Ook kan er dan onvoldoende deskundigheid in de organisatie zijn, wat de kans vergroot op fouten en ongewenste effecten. Zonder het vaststellen van rollen en verantwoordelijkheden kan er geen effectieve sturing plaatsvinden op partijen die betrokken zijn bij het ontwikkelen of gebruiken van algoritmes.
","['urn:nl:ak:ver:avg-06', 'urn:nl:ak:ver:awb-01']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/index.html
urn:nl:ak:mtr:owp-02,"Voer voorafgaand aan een project een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit","
Voer voorafgaand aan een project een data beschikbaarheids- en [datakwaliteitsanalayse](3-dat-01-datakwaliteit.md) uit.
","['publieke-inkoop', 'data']",['ontwerp'],"['projectleider', 'beleid-en-advies']","- Het is van belang om voorafgaand aan een project vast te stellen of de data die noodzakelijk is om een algoritme te ontwikkelen of te kunnen gebruiken beschikbaar is, gaat worden en of de data van voldoende [kwaliteit](3-dat-01-datakwaliteit.md) is.
- Er moet worden onderzocht of en hoe data vanuit de eigen organisatie, die van een eventuele externe aanbieder of elders beschikbaar kan worden gesteld, kan worden opgeslagen en of goedkeuring kan worden gegeven voor het verwerken van de data.
- De infrastructuur van de eigen organisatie en/of die van een eventuele externe aanbieder moet van voldoende niveau zijn om de beoogde verwerkingen uit te kunnen voeren.
- Een dergelijke analyse levert inzichten op welke problemen er eventueel op dit vlak kunnen ontstaan en geeft input voor de verdere ontwikkeling of (in geval van inkoop) de behoeftestelling.
","Het zou kunnen voorkomen dat de data niet beschikbaar is en ook niet gaat worden. Dit betekent dat een algoritme ook niet goed gemaakt of gebruikt kan worden. Ook is het belangrijk om te checken of de data beschikbaar blijft als dat nodig is voor het functioneren van het algoritme (bijv. voor het bijleren). Ook bestaat er een risico dat als de data van onvoldoende kwaliteit is, het algoritme niet goed gaat werken. Wanneer niet vooraf bepaald is of de data beschikbaar is en van voldoende kwaliteit is, kan het gebeuren dat er wel een algoritme gemaakt wordt door een derde partij, maar deze vervolgens niet gebruikt kan worden binnen de organisatie. 
",['urn:nl:ak:ver:aia-05'],,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-02-data-beschikbaarheid/index.html
urn:nl:ak:mtr:owp-03,Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit mag,"
Het doel voor het verwerken van persoonsgegevens met een algoritme is welbepaald en omschreven.
",['privacy-en-gegevensbescherming'],"['ontwerp', 'dataverkenning-en-datapreparatie', 'ontwikkelen', 'verificatie-en-validatie', 'implementatie']","['projectleider', 'jurist']","Persoonsgegevens mogen alleen worden verwerkt voor een ‘welbepaald, uitdrukkelijk omschreven en gerechtvaardigd’ doel. De wettelijke grondslag voor de verwerking van de persoonsgegevens moet zijn beschreven.

De verwerking van persoonsgevens voor het ontwikkelen en gebruiken van een algoritme moet verenigbaar zijn met het oorspronkelijke verwerkingsdoel (doelbinding). Eventuele verdere (subsidiaire) verwerkingen, zoals het verwerken van persoonsgegevens voor een onderzoek naar onbewuste vooringenomenheid, moeten uitdrukkelijk worden omschreven.
  
Stel een overzicht op waarin is beschreven welke persoonsgegevens mogen worden verwerkt.
Bij de persoonsgegevens is aangegeven om wat voor categorie persoonsgegevens het gaat.
Per kenmerk is toegelicht waarom deze noodzakelijk is om te verwerken voor het ontwikkelen en gebruiken van het algoritme.
Het principe van dataminimalisatie is toegepast, wat betekent dat een keuze is gemaakt of een persoonsgegevens al dan niet strikt noodzakelijk is om het doel te bereiken of dat verwerking ervan achterwege kan blijven.

Voor [het beschermen van deze persoonsgegevens](3-dat-04-pseudonimiseren-anonimiseren.md) wordt per kenmerk aangegeven op welke manier deze kan worden beschermd. Denk hierbij aan het anonimiseren, pseudonomiseren en aggregeren van de persoonsgegevens. 

Gebruik een [DPIA](../hulpmiddelen/DPIA.md) om bovenstaande zaken te beschrijven.
","Als het doel voor het verwerken van persoonsgegevens onvoldoende is omschreven en onderbouwd, ontstaat het risico dat onrechtmatig persoonsgegevens worden verwerkt en een inbreuk wordt gemaakt op privacyrechten van betrokkenen.

  ","['urn:nl:ak:ver:avg-01', 'urn:nl:ak:ver:awb-01']","- [Toetsingskader Algoritmes Algemene Rekenkamer, 3.01, 3.05](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Onderzoekskader Algoritmes Auditdienst Rijk, PRI.4](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023) 
- [Onderzoekskader Algoritmes Auditdienst Rijk, PRI.7](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023) 
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/index.html
urn:nl:ak:mtr:owp-04,Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing,"Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing. 
",['technische-robuustheid-en-veiligheid'],['ontwerp'],['ontwikkelaar'],"- Beschrijf wat voor soort algoritme er gebruikt gaat worden voor de beoogde toepassing. 
- Bepaal of je gebruik wilt maken van een:

    - [zelflerend algoritme](../../overhetalgoritmekader/soorten-algoritmes.md#zelflerende-algoritmes)
    - niet-zelflerend algoritme zoals een algoritme gebaseerd op [rekenregels](../../overhetalgoritmekader/soorten-algoritmes.md#rekenregels)

- Beschrijf vervolgens ook:
    
    - waarom er voor dit type algoritme wordt gekozen
    - wat de alternatieven zijn en waarom die minder passend zijn
    - waarom dit algoritme het meest geschikt is om het [beoogde doel](1-pba-02-formuleren-doelstelling.md) van het algoritme te bereiken. 

- De precieze details kunnen in dit stadium van de levenscyclus waarschijnlijk nog niet ingevuld worden. Maak een goede eerste inschatting van de gebruikte techniek. Eventueel kan je er ook voor kiezen om verschillende technieken verder te onderzoeken. Dat betekent dat er meerdere algoritmes ontwikkeld worden (op basis van verschillende technieken), en je later een definitieve keuze maakt. 

- Het is belangrijk om uiteindelijk een passend uitlegbaar algoritme te selecteren voor de context waarin het wordt toegepast. Daarin moet de afweging gemaakt worden of de technische [uitlegbaarheid](2-owp-32-toepassen-uitlegbaarheidstechnieken.md) voldoende is in de context die de inzet van het algoritme vereist. Hierbij kan ook de conclusie worden getrokken dat een simpeler, inzichtelijker algoritme de voorkeur krijgt. 

- Maak hierbij een bewuste afweging tussen [uitlegbaarheid](2-owp-32-toepassen-uitlegbaarheidstechnieken.md) en [prestaties](5-ver-02-evalueer-nauwkeurigheid.md) van het algoritme. Over het algemeen geldt dat complexere maar minder uitlegbare algoritmes nauwkeuriger zijn. 

- Veel (statistische) modellen zijn gebaseerd op (statistische) aannames over bijvoorbeeld eigenschappen van de data. Ga na of er aan deze aannames wordt voldaan. 
","Wanneer je geen zorgvuldige afweging maakt over de techniek die je gebruikt om het doel te bereiken, dan is het niet duidelijk of de meest geschikte techniek wordt gebruikt. Mogelijk zijn er passendere oplossingen om het doel te bereiken. 
","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-10']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-04-gebruikte-techniek/index.html
urn:nl:ak:mtr:owp-05,Stel vast in welke risicogroep het algoritme valt en bepaal vervolgens welke vereisten van toepassing zijn.,"
Stel vast in welke risicogroep het algoritme valt en bepaal vervolgens welke vereisten van toepassing zijn.
","['publieke-inkoop', 'governance']","['ontwerp', 'ontwikkelen']","['projectleider', 'beleid-en-advies']","Het verschilt per type algoritme welke vereisten hierop van toepassing is en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen. 

Dit is mede afhankelijk van de bijbehorende [risicogroepen](../ai-verordening.md#risicogroepen), de [gebruikte techiek](2-owp-04-gebruikte-techniek.md) en of je het algoritme [ontwikkelt of slechts gebruikt](../ai-verordening.md#rollen-uit-de-ai-verordening).  

Gebruik de [beslishulp](https://ai-verordening-beslishulp.apps.digilab.network/) om de risicobepaling van jouw toepassing te bepalen.

Let op dat niet enkel naar de AI-verordening wordt gekeken. Ook op impactvolle algoritmes die niet vallen onder het bereik van de AI-verordening zijn vereisten van toepassing. Zie hiervoor de [Handreiking Algoritmeregister](https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf). 

Deze stap is van groot belang, omdat dit bijvoorbeeld voor ontwikkelteams mede bepalend is waar het te ontwikkelen systeem aan moet voldoen of welke contractuele verplichtingen moeten worden gecreëerd tussen opdrachtgever en aanbieder van algoritmes.

Je kan ook de [Gids AI-verordening](https://www.rijksoverheid.nl/documenten/brochures/2024/10/16/gids-ai-verordening) gebruiken om te bepalen wat de AI-verordening betekent voor jouw organisatie of toepassing. 

!!! tip ""Tip""

    De Europese Commissie publiceerde in februari 2025 [extra guidance over de definitie van een AI-systeem](https://digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-ai-system-definition-facilitate-first-ai-acts-rules-application). De richtlijnen over de definitie van een AI-systeem geven uitleg over de praktische toepassing van het wettelijke concept, zoals verankerd in de AI-verordening. 

","Als de risicogroep waar een algoritme bij hoort niet wordt bepaald is er een risico op het niet naleven van de AI-verordening wat kan leiden tot sancties of boetes. 
","['urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:aia-06']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-05-soort-algoritme/index.html
urn:nl:ak:mtr:owp-06,Leg vast wat de impact van het algoritme is als het niet werkt zoals beoogd,"Leg vast wie er wordt geraakt, welke processen beïnvloed worden door het algoritme en wat de impact is wanneer het systeem niet werkt zoals beoogd. Neem deze informatie proactief mee in het ontwerp en de ontwikkeling van een algoritme. 
","['technische-robuustheid-en-veiligheid', 'fundamentele-rechten']","['probleemanalyse', 'ontwerp']","['projectleider', 'ontwikkelaar']","Er moet een analyse gemaakt worden van de impact van een algoritme dat niet werkt zoals bedoeld. 
Een algoritme dat niet werkt zoals bedoeld kan bijvoorbeeld betekenen dat het algoritme een foutieve beslissing maakt of dat het algoritme is uitgevallen. 
De analyse op wie dit een impact heeft en hoe groot die impact is, is van belang voor de ontwerpkeuzes, de risicoanalyse en de evaluatie. 
Wanneer een foutieve beslissing zwaarwegende gevolgen heeft, moet er in het ontwerp gezorgd worden dat de kans op deze fout verminderd wordt.
In de evaluatie moet er worden bepaald of de resterende risico’s acceptabel zijn. 
Voer de impactanalyse uit met een multidisciplinaire groep en documenteer afwegingen en keuzes hierbij. 
Wanneer een algoritme niet werkt als beoogd, kan dit inbreuk maken op [grondrechten](../../onderwerpen/fundamentele-rechten.md) van eventuele betrokken burgers. 
Onderdeel van de impactanalyse is om te bepalen of je algoritme bepaalde [grondrechten kan raken](2-owp-07-afwegen-grondrechten.md), aantasten of mogelijk schenden. 
Neem in de impactanalyse de volgende stappen.

- Leg vast welke stakeholders worden geraakt.
Denk hierbij aan de directe gebruiker, degene waarover het besluit wordt genomen en derde partijen die input leveren of de resultaten ontvangen. Houd hierbij rekening met [kwetsbare groepen waarbij het nodig is om deze groep extra bescherming te bieden](2-owp-07-afwegen-grondrechten.md). 

- Leg vast welke processen worden geraakt.
Denk hierbij aan werkproces(sen) waarin het algoritme wordt gebruikt, maar ook aan vervolgprocessen of parallelle processen die beïnvloed worden door de resultaten van het algoritme.

- Leg vast wat de impact is van een niet goed werkend algoritme (per stakeholder en proces).
Bepaal per stakeholder en per proces wat het gevolg is van een niet goed werkend systeem. Indien het systeem uitvalt, hoe worden de partijen daardoor geraakt en wat is het gevolg? Zijn er processen die mogelijk stilvallen of moeten worden aangepast?  

    Analyseer ook de gevolgen van foutieve beslissingen. 
    Let op dat verschillende typen fouten een verschillende impact hebben. 
    Bijvoorbeeld in het geval van een ziektedetectie algoritme als voorsortering of een patiënt een uitgebreidere test moet ondergaan is de impact groter als de patiënt ten onrechte als geen-risico wordt geclassificeerd dan als iemand ten onrechte een extra controle moet ondergaan. 

- Bepaal welke factoren van invloed zijn op de kans dat het fout gaat.
Het risico is afhankelijk van de kans dat een fout voorkomt. Voor risicoanalyse en mitigatie is het van belang om de factoren die van invloed zijn op de fouten in kaart te brengen. Deze geven input aan de ontwerpfase en mitigerende maatregelen. Denk hierbij aan factoren in de [data](3-dat-01-datakwaliteit.md), [het soort algoritme](2-owp-05-soort-algoritme.md), het gebruik en externe factoren. 
","Als er geen goede impactanalyse wordt gemaakt, kunnen risico’s over het hoofd worden gezien. Een niet werkend systeem kan dan een grote impact hebben op mensen of de organisatie. 
","['urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:avg-11']","- [Onderzoekskader Auditdienst Rijk, SV.4](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/index.html
urn:nl:ak:mtr:owp-07,Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafweging,"Identificeer welke grondrechten geraakt worden door het in te zetten algoritme en maak een afweging of dit aanvaardbaar is.
",['fundamentele-rechten'],"['probleemanalyse', 'ontwerp', 'verificatie-en-validatie', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies']","Een algoritme kan invloed hebben op grondrechten. Op een aantal grondrechten kan een algoritme sneller invloed hebben, zoals recht op [persoonsgegevensbescherming](../../onderwerpen/privacy-en-gegevensbescherming.md), recht op behoorlijk bestuur en recht op [gelijke behandeling](../../onderwerpen/bias-en-non-discriminatie.md).
Deze veelvoorkomende grondrechten krijgen op andere plekken in het Algoritmekader specifieke aandacht. 
Er zijn echter ook grondrechten die bij minder algoritmes relevant zijn, maar desalniettemin in die gevallen zeer invloedrijk kunnen zijn. 
Het is van belang uiteindelijk een totale afweging te maken van alle grondrechten die (mogelijk) geraakt worden ten opzichte van de voordelen van het in te zetten algoritme. 
Een voorbeeld van een grondrecht dat minder snel geraakt wordt is bijvoorbeeld een algoritme om hate speech te kunnen detecteren. Zo'n algoritme zal van invloed kunnen zijn op de vrijheid van meningsuiting en het recht op informatie.

Doorloop in lijn met deel 4 van het [Impact Assessment Mensenrechten en Algoritmes](../hulpmiddelen/IAMA.md) de volgende stappen:

1. Breng in kaart welke grondrechten geraakt kunnen worden door de inzet van het algoritme. Hiervoor kan [bijlage 1 uit het Impact Assessment Mensenrechten en Algoritmes](../hulpmiddelen/IAMA.md) gebruikt worden.
2. Als dat het geval is, is het allereerst van belang om te controleren of hiervoor specifieke wetgeving is waar de inzet van het algoritme aan moet voldoen.
3. Bepaal hoe zwaar de geindentificeerde grondrechten worden geraakt door het beoogde algoritme.
4. Bepaal hoe [doeltreffend/effectief](5-ver-01-functioneren-in-lijn-met-doeleinden.md) het algoritme in de praktijk is.
5. Bepaal of de inzet van het algoritme noodzakelijk is om het [beoogde doel](1-pba-02-formuleren-doelstelling.md) te bereiken. Zijn er alternatieven? Of zijn er mitigerende maatregelen die genomen kunnen worden waardoor grondrechten niet of minder worden geraakt en eventuele nadelige gevolgen verzacht kunnen worden?
6. Gegeven alle voorgaande stappen, bepaal of de inzet van het algoritme proportioneel is om het [beoogde doel](1-pba-02-formuleren-doelstelling.md) te bereiken. Wegen de voordelen op tegen de nadelen?

Het is van belang voldoende [belanghebbenden te betrekken](1-pba-04-betrek-belanghebbenden.md) bij het doorlopen van deze stappen om te zorgen dat alle eventueel nadelige aspecten van het in te zetten algoritme worden meegenomen. 
Documenteer de te doorlopen stappen en leg de keuzes en afwegingen goed vast. 

!!! note ""Opmerking""

    Zoals vermeld in de [vereiste voor beoordeling van gevolgen voor grondrechten uit de AI-verordening](../vereisten/aia-27-beoordelen-gevolgen-grondrechten.md) moeten sommige hoog-risico AI-systemen een beoordeling doen van de gevolgen voor grondrechten. Het is nog niet bekend welke vorm dit precies moet hebben.
","Het risico is dat er grondrechten, anders dan die expliciet beschermd zijn in andere maatregelen en vereisten, aangetast worden. 
","['urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:aia-27']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/index.html
urn:nl:ak:mtr:owp-08,Maak een lijst van de meest kwetsbare groepen en bescherm hen extra,"Bepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen).
Bepaal vervolgens of er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.
",['fundamentele-rechten'],['ontwerp'],['beleid-en-advies'],"- Verschillende groepen kunnen op een andere manier geraakt worden door het inzetten van een algoritme. Dit is afhankelijk van de context waarin het algoritme wordt ingezet, en dient daardoor bij iedere toepassing opnieuw bekeken te worden. 
- Bedenk wat er met de uitkomsten van het algoritme gedaan wordt, en wat de consequenties daarvan zijn voor burgers. Hierbij kan gedacht worden aan de volgende aspecten:
    - Worden bepaalde groepen sneller gemonitored?
    - Wat als het model het fout heeft? 
    - Wordt het systeem gebruikt om informatie te verkrijgen, om besluiten voor te bereiden of om zelfstandige besluiten te nemen en welke gevolgen heeft dat voor de mate waarin het algoritme bepalend zal zijn in de praktijk? 
    - Worden de gegevens veilig en vertrouwelijk behandeld; welke gevolgen zou een datalek hebben voor groepen of categorieën personen?
    - Worden data gedeeld met andere partijen en wat is het gevaar dat die misbruik maken van de data met negatieve gevolgen voor groepen of categorieën personen?
- Houd hierbij ook rekening met de impact van het in te zetten algoritme op de samenleving (vanuit sociaal, democratisch en milieu/ecologisch perspectief).
- Om de impact op groepen te bepalen, kan het handig zijn een mensenrechtentoets zoals het [Impact Assessment Mensenrechten en Algoritmes](https://open.overheid.nl/documenten/ronl-c3d7fe94-9c62-493f-b858-f56b5e246a94/pdf) toe te passen. 
- Bepaal of er maatregelen genomen kunnen worden om de geïdentificeerde groepen extra bescherming te bieden. Hierbij kan men denken aan de volgende aspecten: Kan de (extra) administratieve druk voor bepaalde groepen worden weggenomen? Worden resultaten van het algoritme naast de resultaten van een expert gelegd? Is het wenselijk om een proces in te richten waarbij zowel algoritme als een expert een uitkomst geven? Kunnen we de betreffende groep extra hulp aanbieden? Is het wenselijk bij negatieve uitkomsten een vier-ogen-principe toe te passen? 
- De impact van het algoritme op de groepen die geïdentificeerd worden in deze stap, kunnen mogelijk onderzocht worden in een [biasanalyse](5-ver-03-biasanalyse.md). Daarbij kan geïdentificeerd worden of bepaalde groepen over- of ondervertegenwoordigd zijn in selecties, of dat het algoritme andere of meer fouten maakt voor bepaalde groepen. 
- Merk op dat het onmogelijk is om de risico's voor alle specifieke groepen af te vangen. Hierbij kan het helpen om te focussen op de meest kwetsbare groepen.
","De impact van het algoritme op de besluitvorming en op personen, doelgroepen en/of de samenleving is niet inzichtelijk, waardoor onvoldoende maatregelen zijn getroffen om ongewenste effecten (zoals bias en discriminatie) te voorkomen. 
","['urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:aia-04']","
- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.4, DM.16](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Kamerstukken II 2023/24, 31066-1374](https://www.tweedekamer.nl/downloads/document?id=2024D15214)
- [Impact Assessment Mensenrechten en Algoritmes, 4.1](https://open.overheid.nl/documenten/ronl-c3d7fe94-9c62-493f-b858-f56b5e246a94/pdf)
- [Handreiking non-discriminatie by design, 1.7 en 1.8 en 1.15](https://open.overheid.nl/documenten/ronl-3f9fa69c-acf4-444d-96e1-5c48df00eb3c/pdf)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/index.html
urn:nl:ak:mtr:owp-09,Bepaal welke documenten voor hoe lang gearchiveerd moeten worden,"
Stel vast welke documenten, (samengesteld geheel van) data, informatie van of in het algoritme gelden als ""archiefbescheiden"" in de zin van [artikel 1c Archiefwet](https://wetten.overheid.nl/jci1.3:c:BWBR0007376&hoofdstuk=I&artikel=1&z=2024-06-19&g=2024-06-19) en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde. Bepaal de bijbehorende bewaartermijnen vast voor de archiefbescheiden.

",['transparantie'],"['ontwerp', 'ontwikkelen']","['ontwikkelaar', 'projectleider', 'jurist']","- Bij archiefbescheiden kan worden gedacht aan de broncode, trainings- en testdata, (technische) documentatie en de output. 
- Deze archiefbescheiden moeten voor een bepaalde tijd worden bewaard (de bewaartermijn).
- Overleg hierover met de verantwoordelijke binnen de organisatie voor het toepassen van de Archiefwet.
- Het is mogelijk dat de selectielijsten nog niet duiden welke informatie of data, specifiek bij de toepassing van algoritmes, moet worden toegepast en hier dus ook nog geen termijnen bij zijn gekoppeld. 
- Stel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld. Er zijn gevallen waarbij het openbaren van archiefbescheiden is uitgesloten. Stem in het begin van het proces (pro-actief) met de opdrachtgever af wat de wenselijkheid is t.a.v.
transparantie en openheid (uitgangspunt zou 'open, tenzij' moeten zijn).
- Stel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt. Het moet mogelijk zijn dat de archiefbescheiden daadwerkelijk overhandigd kunnen worden aan betrokken partijen. Denk hierbij aan burger, onderneming, toezichthouder of rechter. Duurzaam betekent hier met behoud van functie en kwaliteit voor langere tijd. Onderzoek welke voorziening hiervoor beschikbaar is binnen de organisatie.

!!! tip ""Tip"" 

    Formeer hierbij een multi-discipinaire groep (bestaande uit bijvoorbeeld een inkoper, ontwikkelaar, data scientist, proceseigenaar en archiefdeskundige) om deze maatregel toe te passen.
","Bij het niet vaststellen van de archeifbescheiden loop je als organisatie het risico dat je niet voldoet aan de archiefwet, en dat informatie moeilijk te traceren is.
","['urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aia-12']","- [Rekenen en rekenschap. Essay over Algoritmes en de Archiefwet](https://www.inspectie-oe.nl/binaries/inspectie-oe/documenten/publicatie/2021/01/21/rekenen-en-rekenschap/Rekenen+en+rekenschap%2C+Algoritme+en+de+Archiefwet+essay+door+Petra+Helwig+BJu+Tijdschrift+voor+Toezicht++aflevering+1+2020.pdf)
- [Toetsingskader Algemene Rekenkamer 4.06](https://www.rekenkamer.nl/onderwerpen/algoritmes-digitaal-toetsingskader) 
- [Onderzoekskader Auditdienst Rijk, DM.13](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023) 
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-09-archiveren-documenten/index.html
urn:nl:ak:mtr:owp-10,Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmes,"
Voer een Project Startarchitectuur (PSA) uit als algoritmes worden ontwikkeld of ingekocht.
",['technische-robuustheid-en-veiligheid'],"['ontwerp', 'ontwikkelen', 'verificatie-en-validatie', 'implementatie']","['projectleider', 'beleid-en-advies']","- Een Project Startarchitectuur (PSA) is een hulpmiddel dat bij een project wordt ingezet om veranderingen van A naar B beter te faciliteren.
- De PSA richt zich daarbij op de kaders die op een project van toepassing zijn en wat de oplossing bijdraagt aan het realiseren van de gewenste, toekomstige architectuur, wat de implicaties zullen zijn voor bestaande voorzieningen en waar het project zal afwijken van bestaande beelden.
- Met de PSA wordt een concreet en doelgericht ICT-architectuurkader opgesteld, waarbinnen het project moet worden uitgevoerd. 
- De PSA maakt concreet wat architectuur voor een project betekent.
- Door een PSA uit te voeren ontstaan inzichten hoe het betreffende algoritme zo optimaal mogelijk onderdeel kan worden gemaakt van het bestaande applicatielandschap, waarmee bijvoorbeeld kan worden voorkomen dat het algoritme of AI-systeem na verloop van tijd geen input meer kan ontvangen door onverwachte wijzigingen in systemen.
- Onderwerpen als privacy en informatiebeheer worden hierin ook globaal meegenomen. 
  ","Het algoritme kan niet of na verloop van tijd niet meer functioneren, doordat onverwachte of ongewenst wijzigingen in het applicatielandschap plaatsvinden. 
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:avg-11']","
- [Project Startarchitectuur,NORA](https://www.noraonline.nl/wiki/PSA_(Project_Startarchitectuur))
- [PSA Format](https://www.noraonline.nl/images/noraonline/9/96/NORA_PSA_format.odt)
- [PSA Handleiding](https://www.noraonline.nl/images/noraonline/9/93/NORA-handleiding_voor_het_opstellen_van_een_PSA.odt)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-10-projectstartarchitectuur/index.html
urn:nl:ak:mtr:owp-11,Beschrijf welke data gebruikt wordt voor de beoogde toepassing,"Beschrijf welke data gebruikt wordt voor de beoogde toepassing. 
",['data'],"['ontwerp', 'dataverkenning-en-datapreparatie']","['ontwikkelaar', 'beleid-en-advies']","- Maak in een vroege fase van de ontwikkeling een inschatting van welke data er gebruikt gaat worden voor het algoritme.
- Leg na het uitvoeren van een [beschikbaarheids-](2-owp-02-data-beschikbaarheid.md), [kwaliteits-](3-dat-01-datakwaliteit.md) en toegankelijkheidsanalyse vast welke data wordt verwerkt voor het ontwikkelen en gebruiken van het algoritme.
- Beschrijf daarbij om wat voor gegevens het gaat en uit welke bron deze komen.
- Bepaal of het is [toegestaan om deze data](2-owp-03-doel-verwerken-persoonsgegevens.md) te verwerken.
- Het is denkbaar dat het onderzoek van de kwaliteit van de data in een latere fase in de levenscyclus pas grondig kan worden uitgevoerd. 
","Als er niet wordt beschreven welke data wordt gebruikt voor een toepassing wordt het risico gelopen dat bij gebruik van een algoritme er kans is op bias-vorming en mindere transparantie. 

",['urn:nl:ak:ver:aia-05'],,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/index.html
urn:nl:ak:mtr:owp-12,Koop duurzaam algoritmes in,"
Kies softwareoplossingen van aanbieders die duurzaamheid bevorderen, en stel heldere eisen aan energieverbruik, hernieuwbare energiebronnen en transparantie over de milieuprestaties van software.
","['publieke-inkoop', 'duurzaamheid']",['ontwerp'],"['projectleider', 'beleid-en-advies']","Door software duurzaam in te kopen, kun je als organisatie al vroeg in het ontwikkelproces bijdragen aan de verduurzaming van je algoritmes. Kies daarom softwareoplossingen van aanbieders die maatschappelijk verantwoord ondernemen (MVI) en energie-efficiëntie vooropstellen.

### Duurzaamheidscriteria en selectie van aanbieders
Om software duurzaam in te kopen, kun je aanbieders beoordelen op specifieke duurzaamheidscriteria. Enkele belangrijke criteria zijn:

- het energieverbruik van de software
- het gebruik van hernieuwbare energiebronnen in de benodigde datacenters
- het beperken van CO₂-uitstoot tijdens de levenscyclus van de software.

Vraag om inzicht in milieuprestaties en certificeringen, zoals ISO-14001, om de toewijding van aanbieders aan duurzaamheid te toetsen.
De ISO-14001 is een internationaal geaccepteerde standaard met eisen voor een milieumanagementsysteem.

### Inkoopvoorwaarden en contractuele eisen
Stel bij het inkopen duidelijke eisen aan duurzaamheidscriteria, zoals het gebruik van ""groene technologieën"", het aanbieden van Software-as-a-Service (SaaS) en open standaarden. Zo maak je duurzame keuzes die bijdragen aan een langere levensduur en energie-efficiëntie van je algoritmes. Door KPI’s op te nemen voor energie-efficiëntie en CO₂-reductiedoelen kun je de voortgang van deze doelen concreet monitoren. Je kunt deze voorwaarden opnemen als [standaard inkoopvoorwaarden](../hulpmiddelen/inkoopvoorwaarden.md).

### Bonus-malusregeling en monitoring
Om naleving van duurzame doelstellingen te stimuleren, kun je een bonus-malusregeling inzetten. Aanbieders ontvangen een bonus wanneer zij duurzame doelstellingen halen, en kunnen worden aangesproken als beloofde duurzaamheidsnormen niet worden behaald. Monitoring via jaarlijkse rapportages helpt om de voortgang van de duurzaamheidsdoelen te evalueren en, indien nodig, bij te sturen.
","Zonder duurzaamheidscriteria bij het inkopen van software loop je het risico op hogere energie- en kostenlasten en beperk je de mogelijkheden om duurzaamheidsdoelstellingen te halen bij je algoritmes.
",['urn:nl:ak:ver:awb-01'],,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/index.html
urn:nl:ak:mtr:owp-13,Ontwerp algoritmes zo eenvoudig mogelijk,"Ontwerp algoritmes gericht op eenvoud en efficiëntie, zodat het energieverbruik en de benodigde rekenkracht tijdens gebruik minimaal blijven.
",['duurzaamheid'],"['ontwerp', 'ontwikkelen']",['ontwikkelaar'],"Complexe algoritmes vereisen vaak aanzienlijke rekenkracht, wat energie-intensief kan zijn. Door algoritmes minder complex en rekenintensief te ontwerpen, verlaag je de benodigde middelen en energie bij het trainen en uiteindelijk toepassen van deze algoritmes. Een efficiënter ontwerp maakt de algoritmes energiezuiniger in de trainings- en gebruiksfase en draagt zo bij aan duurzaamheid in de gehele levenscyclus.

### Modellen vereenvoudigen en focussen op kernfunctionaliteit
Wanneer je een nieuw algoritme ontwikkelt, kun je de omvang en rekenbelasting beperken door alleen noodzakelijke functionaliteit op te nemen. Focus op de kernfunctionaliteit, zodat je gebruik maakt van een kleiner model dat beter te begrijpen en gemakkelijker te beheren is. Het vermijden van overbodige functionaliteiten maakt het algoritme minder zwaar en verlaagt de milieu-impact aanzienlijk.

### Minder complexiteit door divide-and-conquer en dynamisch programmeren
Een populaire methode om complexiteit te verlagen is het *divide-and-conquer* principe, waarbij je een grote algoritmische berekening opsplitst in kleinere, overzichtelijke deelberekeningen en deze vervolgens oplost (je splitst hierbij het technische probleem in meerdere kleinere problemen). Dit vermindert de rekenlast aanzienlijk en verhoogt de efficiëntie. Ook kun je met *dynamisch programmeren* optimalisaties toevoegen door eerder berekende resultaten op te slaan en te hergebruiken, wat herhaling van berekeningen voorkomt en de rekenkracht vermindert.

### Minder complexiteit door modeloptimalisatie
- Door gebruik te maken van *pruning* kunnen minder relevante verbindingen en nodes in een neuraal netwerk worden verwijderd, waardoor de rekenbelasting vermindert.
- *Quantization* verlaagt de precisie van numerieke waarden in een model, wat opslag en rekenkracht verlaagt zonder de prestaties significant te beïnvloeden.
- *Knowledge distillation* kan verder helpen door de kennis van een groot model over te dragen naar een kleiner, minder complex model, dat vervolgens efficiënter werkt.
","Ontwerpen zonder oog voor efficiëntie kan leiden tot energie-intensieve algoritmes die hoge kosten en milieubelasting met zich meebrengen.
",[],"- [What is knowledge distillation? (IBM)](https://www.ibm.com/topics/knowledge-distillation)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/index.html
urn:nl:ak:mtr:owp-14,Maak het opstellen van een verwerkersovereenkomst onderdeel van de aanbesteding als persoonsgegevens worden verwerkt,"
Het opstellen van een verwerkersovereenkomst met aanbieder is onderdeel van de aanbesteding als persoonsgegevens worden verwerkt of noodzakelijk zijn voor het trainen of genereren van output door algoritmes van de aanbieder.
","['publieke-inkoop', 'privacy-en-gegevensbescherming']","['ontwerp', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies']","Een verwerkersovereenkomst moet worden opgesteld als persoonsgegevens worden verwerkt voor het trainen of het genereren van output door algoritmes van de aanbieder. Met een verwerkersovereenkomst worden een aantal afspraken schriftelijk vastgelegd het bij de verwerking van persoonsgegevens. Het gaat om de volgende zaken:

- Algemene beschrijving. Een omschrijving van het onderwerp, de duur, de aard en het doel van de verwerking, het soort persoonsgegevens, de categorieën van betrokkenen en uw rechten en verplichtingen als verwerkingsverantwoordelijke.

- Instructies voor de verwerking. De verwerking vindt in principe uitsluitend plaats op basis van uw schriftelijke instructies. De verwerker mag de persoonsgegevens niet voor eigen doeleinden gebruiken.

- Geheimhoudingsplicht. Personen in dienst van of werkzaam voor de verwerker hebben een geheimhoudingsplicht.

- Beveiliging. De verwerker treft passende technische en organisatorische maatregelen om de verwerking te beveiligen. Bijvoorbeeld pseudonimisering en versleuteling van persoonsgegevens, permanente informatiebeveiliging, herstel van beschikbaarheid en toegang tot gegevens bij incidenten en regelmatige beveiligingstesten.

- Subverwerkers. De verwerker schakelt geen subverwerker(s) in zonder uw voorafgaande schriftelijke toestemming. De verwerker legt aan een subverwerker in een subverwerkersovereenkomst dezelfde verplichtingen op als de verwerker richting u heeft. In de overeenkomst kunt u ook direct afspreken dat de verwerker subverwerkers mag inschakelen en onder welke voorwaarden. Komt de subverwerker de verplichtingen niet na? Dan blijft de verwerker volledig aansprakelijk richting u voor het nakomen van de verplichtingen van de subverwerker (artikel 28, vierde lid, van de AVG).

- Privacyrechten. De verwerker helpt u om te voldoen aan uw plichten als betrokkenen hun privacyrechten uitoefenen (zoals het recht op inzage, correctie, verwijdering en dataportabiliteit).

- Andere verplichtingen. De verwerker helpt u ook om andere verplichtingen na te komen. Zoals bij het melden van datalekken, het uitvoeren van een data protection impact assessment (DPIA) en bij een voorafgaande raadpleging.

- Gegevens verwijderen. Na afloop van de verwerkingsdiensten verwijdert de verwerker de gegevens. Of bezorgt de verwerker de gegevens aan u terug, als u dat wilt. Ook verwijdert de verwerker kopieën. Tenzij de verwerker wettelijk verplicht is de gegevens te bewaren.

- Audits. De verwerker werkt mee aan uw audits of die van een derde partij. En stelt alle relevante informatie beschikbaar om te kunnen controleren of de verwerker zich houdt aan de hierboven genoemde verplichtingen (artikel 28 AVG).
","Er is sprake van een onrechtmatige verwerking van persoonsgegevens als geen verwerkersovereenkomst is opgesteld tussen de verwerker en de verwerkingsverantwoordelijke. 
",['urn:nl:ak:ver:avg-13'],"
- [Verwerkersovereenkomst](https://www.autoriteitpersoonsgegevens.nl/themas/basis-avg/avg-algemeen/verwerkersovereenkomst)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-14-verwerkersovereenkomst-onderdeel-aanbesteding/index.html
urn:nl:ak:mtr:owp-15,Bespreek de vereisten die gelden voor een verantwoorde inzet van algoritmes met aanbieders,"
Bespreek de vereisten die gelden voor een verantwoorde inzet van algoritmes met een aanbieder.
",['publieke-inkoop'],"['ontwerp', 'ontwikkelen']",['projectleider'],"Ga met een aanbieder in gesprek over in hoeverre zij invulling kunnen geven aan de vereisten die gelden voor een verantwoorde inzet van algoritmes. Dit kan worden gedaan bijvoorbeeld bij een informatiesessie met aanbieders voorafgaand aan een aanbesteding. 

Hiervoor is het van belang om te bepalen om wat voor [type algoritme het gaat en wat de bijbehorende risicoclassificatie](2-owp-05-soort-algoritme.md) is. Maak op basis daarvan inzichtelijk welke vereisten hierop van toepassing zijn. 

Op basis van nieuwe of gewijzigde wet- en regelgeving of de totstandkoming van nieuwe standaarden, is het denkbaar dat aanbieders van algoritmes nog niet of niet meer voldoen aan deze vereisten. Het is van belang dat deze inzichten bijvoorbeeld tijdens een aanbesteding worden verkregen. Indien van toepassing, laat de aanbieder inzichtelijk maken welke stappen deze gaat zetten om hieraan te gaan voldoen. Dit is ook relevant bij reeds afgesloten contracten.
","Door de vereisten voor een verantwoorde inzet van algoritmes niet te bespreken met aanbieders, is het voor hen (deels) onduidelijk aan welke vereisten diens algoritmes moet voldoen om te kunnen contracteren met overheidsorganisaties.
","['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:aia-02', 'urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-04', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-07', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-12', 'urn:nl:ak:ver:aia-13', 'urn:nl:ak:ver:aia-14', 'urn:nl:ak:ver:aia-15', 'urn:nl:ak:ver:aia-16', 'urn:nl:ak:ver:aia-17', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-20', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-23', 'urn:nl:ak:ver:aia-24', 'urn:nl:ak:ver:aia-25', 'urn:nl:ak:ver:aia-26', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-29', 'urn:nl:ak:ver:aia-30', 'urn:nl:ak:ver:aia-31', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:aia-33', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:aia-35', 'urn:nl:ak:ver:aia-36', 'urn:nl:ak:ver:aia-37', 'urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:avg-01', 'urn:nl:ak:ver:avg-02', 'urn:nl:ak:ver:avg-03', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:avg-05', 'urn:nl:ak:ver:avg-06', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:avg-08', 'urn:nl:ak:ver:avg-09', 'urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:avg-11', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:avg-13', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:bzk-01', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:grw-02']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/index.html
urn:nl:ak:mtr:owp-16,Maak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomst,"
Maak vereisten voor algoritmes onderdeel van contractvoorwaarden en de contractovereenkomst.
","['publieke-inkoop', 'transparantie']",['ontwerp'],"['projectleider', 'beleid-en-advies']","- Door vereisten die gelden voor algoritmes onderdeel te maken van contractvoorwaarden, is voor een aanbieder vooraf duidelijk aan welke voorwaarden zij moeten voldoen als zij algoritmes willen aanbieden aan overheidsorganisaties.
- Het is van belang om een afweging te maken welke vereisten voor algoritmes als ['algemene contractvoorwaarden'](../hulpmiddelen/inkoopvoorwaarden.md) kunnen gelden en welke aanvullend in een contractovereenkomst moeten worden opgenomen.
","Door de vereisten voor een verantwoorde inzet van algoritmes niet te communiceren met aanbieders, is het voor hen (deels) onduidelijk aan welke vereisten diens algoritmes moet voldoen om te kunnen contractueren met overheidsorganisaties.
","['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:aia-02', 'urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-04', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-07', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-12', 'urn:nl:ak:ver:aia-13', 'urn:nl:ak:ver:aia-14', 'urn:nl:ak:ver:aia-15', 'urn:nl:ak:ver:aia-16', 'urn:nl:ak:ver:aia-17', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-20', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-23', 'urn:nl:ak:ver:aia-24', 'urn:nl:ak:ver:aia-25', 'urn:nl:ak:ver:aia-26', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-29', 'urn:nl:ak:ver:aia-30', 'urn:nl:ak:ver:aia-31', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:aia-33', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:aia-35', 'urn:nl:ak:ver:aia-36', 'urn:nl:ak:ver:aia-37', 'urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:avg-01', 'urn:nl:ak:ver:avg-02', 'urn:nl:ak:ver:avg-03', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:avg-05', 'urn:nl:ak:ver:avg-06', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:avg-08', 'urn:nl:ak:ver:avg-09', 'urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:avg-11', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:avg-13', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:bzk-01', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:grw-02']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/index.html
urn:nl:ak:mtr:owp-17,Maak het leveren van bewijs voor het voldoen aan de vereisten voor algoritmes onderdeel van de beoordeling van een inschrijving,"
 Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving.
",['publieke-inkoop'],['ontwerp'],"['projectleider', 'beleid-en-advies']","Het leveren van bewijs door aanbieder dat de ontwikkelde algoritmes voldoen aan de vereisten draagt bij aan het kunnen beoordelen of een aanbieder geschikt is om mee te contracteren. Bij het leveren van bewijs kan worden gedacht aan het overhandigen van bijvoorbeeld een certificaat of een EU-conformiteitsverklaring voor hoog risico AI-systemen. 

Daarbij is het relevant om te beoordelen in hoeverre er is voldaan aan geharmoniseerde standaarden. Deze standaarden zijn momenteel in ontwikkeling. In de (nabije) toekomst zal dit naar verwachting op een vergelijkbare manier kunnen worden benaderd als bij het moeten leveren van een NEN-ISO 27001 certificaat (voldoen aan informatiebeveiligingsvereisten) door een leverancier.  
","Er wordt gecontracteerd met een aanbieder die niet voldoet aan de vereisten voor een verantwoorde inzet van algoritmes. 
","['urn:nl:ak:ver:aia-14', 'urn:nl:ak:ver:aia-15', 'urn:nl:ak:ver:aia-16']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-17-leveren-bewijs-voldoen-aan-vereisten-algoritme-aanbieder/index.html
urn:nl:ak:mtr:owp-18,Laat aanbieder(s) bewijs leveren dat de door hen ontwikkelde algoritmes geen inbreuk maken op de auteursrechten van derden met de trainingsdata en de output,"
Maak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden met de trainingsdata en output van diens algoritme van bijvoorbeeld een aanbesteding.
","['publieke-inkoop', 'data']","['dataverkenning-en-datapreparatie', 'verificatie-en-validatie']","['projectleider', 'beleid-en-advies']","### Trainingsdata
- Algoritmes worden veelal getraind aan de hand van een omvangrijke hoeveelheid data. Wanneer grote hoeveelheden data, bijvoorbeeld door deze te scrapen van internet, worden gebruikt is het zeer aannemelijk (of: nagenoeg zeker) dat zich onder de gescrapete inhoud (ook) veel auteursrechtelijk beschermde werken bevinden, zoals bijvoorbeeld e-books en afbeeldingen. De gebruikte auteursrechtelijke werken kunnen soms bijvoorbeeld uit illegale bron verkregen zijn, en ook los daarvan zijn rechthebbenden veelal niet op de hoogte van het feit dat hun auteursrechtelijke werken voor de ontwikkeling van een algoritme of AI gebruikt worden.

- Onder auteursrechtjuristen wordt aangenomen dat het gebruik van auteursrechtelijk beschermde werken ter training van algoritmes (waarschijnlijk) als kopiëren geldt: een handeling die de rechthebbende kan verbieden. Dat betekent dat aanbieders van algoritmes het gebruik van auteursrechtelijk beschermd materiaal in de inputfase steeds moeten kunnen legitimeren op grond van (a) toestemming van de rechthebbende(n) of (b) een in de wet neergelegde exceptie op het auteursrechtelijke verveelvoudigingsrecht.

- Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen op welke manier de trainingsdata is verkregen en of dit rechtmatig was. Laat de aanbieders(s) ook aantonen welke maatregelen er zijn getroffen om dit te voorkomen en ga hier eventueel over in gesprek. Maak een jurist onderdeel van de beoordeling hiervan. 

### Output
Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen op welke manier de trainingsdata is verkregen en of dit rechtmatig was. Laat de aanbieders(s) ook aantonen welke maatregelen er zijn getroffen om dit te voorkomen. Maak een jurist onderdeel van de beoordeling hiervan. Overweeg om een bronvermelding te laten opnemen.

### Risicomanagement
Het is van belang dat de (rest)risico's inzichtelijk zijn gemaakt als er sprake is van een (potentiële) schending van auteursrechten. Laat een aanbieder deze risico's inzichtelijk maken, zodat aanbieder en gebruiksverantwoordelijke maatregelen kunnen treffen en handelen als dit nodig is. Beoordeel of deze rest(risico's) acceptabel zijn. 

### Contractovereenkomst
Neem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de trainingsdata of output van het algoritme en dat aanbieder dit gedurende de ontwikkeling en levensduur actief bewaakt.
","Dat wordt gecontracteerd met een aanbieder waarbij niet kan worden uitgesloten dat auteursrechten worden geschonden. 
",['urn:nl:ak:ver:aut-01'],"
- [Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat](https://www.rijksoverheid.nl/documenten/brieven/2023/10/10/1-advies-landsadvocaat-pels-rijcken)
- ARVODI (24.7) en ARBIT (art 8.5 & 8.6)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/index.html
urn:nl:ak:mtr:owp-19,Aansprakelijkheidsvoorwaarden van een aanbieder worden beoordeeld in de aanbesteding,"
Maak de aansprakelijkheidsvoorwaarden die een aanbieder stelt ten aanzien van auteursrechten een vast onderdeel om te beoordelen in de aanbesteding.
",['publieke-inkoop'],"['ontwerp', 'implementatie']","['jurist', 'beleid-en-advies']","- Eindgebruikers van algoritmes kunnen er niet altijd op vertrouwen, of (eenvoudig) nagaan, of datgene wat zij door middel van een algoritme laten genereren, inbreuk maakt op rechten van anderen. Het is onwenselijk dat een eindgebruiker aansprakelijk wordt gesteld voor het maken van een inbreuk op rechten van derden, als deze gebruik maakt van algoritmes die worden aangeboden door aanbieders. Organisaties moeten daarom afspraken hierover maken met aanbieders.

- Hoe groot de kans is dat eindgebruikers vanwege het gebruik van algoritmes aansprakelijk worden gesteld, is nog onduidelijk. Er zijn wel voorbeelden waarbij eindgebruikers voor een eventuele inbreuk aansprakelijk kunnen worden gesteld.

- Op dit moment zijn (nog) geen gevallen of rechtszaken bekend waarin eindgebruikers (of hun werkgevers) aansprakelijk zijn gesteld voor een inbreuk op het intellectuele eigendomsrecht vanwege het gebruik van op basis van algoritme. Feit is echter wel dat een dergelijke aansprakelijkstelling in voorkomende gevallen dus mogelijk is, te meer nu de aanbieders van algoritmes in hun algemene voorwaarden het risico voor aansprakelijkheid volledig of grotendeels uitsluiten, of zelfs verlangen dat gebruikers hen vrijwaren voor de gevolgen van eventuele aansprakelijkstellingen.

- Het is daarom van belang om een beoordeling te maken in hoeverre de aansprakelijkheidsvoorwaarden van de aanbieder passend zijn. Maak een jurist onderdeel van de beoordeling.
","Er wordt gecontracteerd met een aanbieder die ongewenste aansprakelijkheidsvoorwaarden hanteert. 
",['urn:nl:ak:ver:aut-01'],"
[Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat](https://open.overheid.nl/documenten/16d72572-da6b-422c-8cf8-cdc95a523093/file)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-19-beoordeel-aansprakelijkheidsvoorwaarden-van-aanbieder/index.html
urn:nl:ak:mtr:owp-20,Maak vereisten onderdeel van (sub)gunningscriteria bij een aanbesteding,"
Maak vereisten onderdeel van (sub)gunningscriteria bij een aanbesteding.
",['publieke-inkoop'],['ontwerp'],['ontwikkelaar'],"- Door een vereiste onderdeel te maken van (sub)gunningscriteria, ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden van andere aanbieders.
- Dit kan zorgen voor een extra stimulatie op kwaliteitsaspecten van algoritmes.
- In de context van algoritmes is dit in het bijzonder relevant, bijvoorbeeld in relatie tot vereisten als non-discriminatie, het eerbiedigen van fundamentele rechten of het verbod op schenden auteursrechten. 
- Door vereisten te vertalen naar (sub)gunningscriteria, kan een inhoudelijke beoordeling worden gemaakt in hoeverre een aanbieder voldoet aan deze vereisten.
","Een risico van vereisten geen onderdeel te maken van (sub)gunningscriteria is dat bepaalde vereisten worden overgeslagen of gemist, wat kan leiden tot het niet voldoen aan deze vereisten. 
","['urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-04', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-20', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-24', 'urn:nl:ak:ver:aia-26', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-30', 'urn:nl:ak:ver:aia-33', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:avg-03', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:avg-09', 'urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:avg-11', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:grw-02']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-20-maak-vereisten-onderdeel-van-subgunningscriteria/index.html
urn:nl:ak:mtr:owp-21,Creëer ruimte om met een aanbieder samen te gaan werken om specifieke vereisten te realiseren,"
Creëer ruimte om met een aanbieder samen te gaan werken om specifieke vereisten te realiseren.
",['publieke-inkoop'],"['ontwerp', 'ontwikkelen']",['projectleider'],"- Om op een betekenisvolle manier invulling te geven aan bepaalde vereisten, kan het noodzakelijk zijn dat opdrachtgever en aanbieder (innovatief) moeten gaan samenwerken. Op basis van nieuwe wet- en regelgeving (bv. AI-Verordening) of geharmoniseerde standaarden kunnen aanbieders mogelijk nog niet voldoen aan nieuwe vereisten. Het kan ook onduidelijk zijn hoe moet worden voldaan aan vereisten nu de technologie zich snel ontwikkelt of dat de specifieke omstandigheden van het beoogde gebruik vragen om een samenspel tussen opdrachtgever en aanbieder.

- Bij een verantwoorde inzet van algoritmes kan het bij vereisten zoals [non-discriminatie](../../onderwerpen/bias-en-non-discriminatie.md), [transparantie](../../onderwerpen/transparantie.md), [menselijke controle](../../onderwerpen/menselijke-controle.md) en [grondrechten](../../onderwerpen/fundamentele-rechten.md) van belang zijn om samen te onderzoeken hoe hier invulling aan moet worden gegeven. Het is belangrijk om bij de behoeftestelling al te verkennen om welke onderwerpen dit mogelijk van toepassing is. Bij een marktverkenning of informatiesessie kan worden verkend hoe aanbieders ervoor staan. Op basis hiervan kan worden beoordeeld in hoeverre bijvoorbeeld in een aanbesteding contractuele ruimte moet worden gecreëerd voor opdrachtgever en aanbieder om hieraan te werken. 
","Door niet te kunnen samenwerken aan vereisten kan de situatie ontstaan dat uiteindelijk niet op een betekenisvolle manier wordt voldaan aan deze vereisten voor een verantwoorde inzet van algoritmes.
Gebrek aan samenwerking kan leiden tot onvermogen om de benodigde vereisten voldoende in de praktijk te garanderen. Ook is het belangrijk dat de verantwoordelijke goed genoeg begrijpt hoe het algoritme werkt en welke keuzes er gemaakt zijn tijdens het ontwerp, omdat alleen dan goed beoordeeld kan worden welke vereisten zijn voldaan en welke risico’s nog niet of minder goed zijn afgedekt. 
","['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:aia-02', 'urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-04', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-07', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-12', 'urn:nl:ak:ver:aia-13', 'urn:nl:ak:ver:aia-14', 'urn:nl:ak:ver:aia-15', 'urn:nl:ak:ver:aia-16', 'urn:nl:ak:ver:aia-17', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-20', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-23', 'urn:nl:ak:ver:aia-24', 'urn:nl:ak:ver:aia-25', 'urn:nl:ak:ver:aia-26', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-29', 'urn:nl:ak:ver:aia-30', 'urn:nl:ak:ver:aia-31', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:aia-33', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:aia-35', 'urn:nl:ak:ver:aia-36', 'urn:nl:ak:ver:aia-37', 'urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:avg-01', 'urn:nl:ak:ver:avg-02', 'urn:nl:ak:ver:avg-03', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:avg-05', 'urn:nl:ak:ver:avg-06', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:avg-08', 'urn:nl:ak:ver:avg-09', 'urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:avg-11', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:avg-13', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:bzk-01', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:grw-02']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/index.html
urn:nl:ak:mtr:owp-22,Vul technische documentatie van aanbieder aan met relevante informatie vanuit de gebruiksverantwoordelijke,"
Vul technische documentatie van de aanbieder aan met relevante informatie vanuit de gebruiksverantwoordelijke, zodat alle relevante onderdelen van het algoritme zijn beschreven.
","['publieke-inkoop', 'transparantie']",['ontwerp'],"['projectleider', 'beleid-en-advies', 'ontwikkelaar']","- Het is van belang dat duidelijke afspraken worden gemaakt over het opstellen, aanvullen en actueel houden van technische documentatie van algoritmes. Bij het inkopen van algoritmes moet hier rekening mee worden gehouden. De aanbieder zal een belangrijk deel van de technische documentatie moeten aanleveren, maar bij gebruik door de gebruiksverantwoordelijke zal deze informatie moeten worden aangevuld. 

- Bespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het AI-systeem door welke partij (aanbieder of gebruiksverantwoordelijke) moeten worden ingevuld of aangevuld. 

- Hierbij is het van belang dat de documentatie aansluit bij de verschillende gebruikers van het systeem, waarbij rekening wordt gehouden met verschillende toepassingen of versies. Bespreek met het projectteam welke onderdelen van de technische documentatie voor AI-systemen, als genoemd in de Bijlage 4 AI-verordening, door welke partij (aanbieder of gebruiksverantwoordelijke) moeten worden ingevuld of aangevuld. 
","Door de technische documentatie niet volledig op te stellen, is niet geheel transparant hoe het algoritme functioneert en kan daar geen verantwoording voor worden afgelegd.   
","['urn:nl:ak:ver:aia-02', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02']","Geen beschikbare bron voor deze maatregel.

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-22-vaststellen-aanleveren-informatie-technische-documentatie/index.html
urn:nl:ak:mtr:owp-23,Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst,"
Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst. 
",['publieke-inkoop'],['ontwerp'],"['projectleider', 'beleid-en-advies']","Het is van belang dat de opdrachtgever mogelijkheden heeft om te controleren in hoeverre door de aanbieder of opdrachtnemer wordt voldaan aan naleving van de contractvoorwaarden.
","Er kunnen geen controles of inspecties worden uitgevoerd om te beoordelen of de algoritmes van een aanbieder nog voldoen aan de vereisten voor een verantwoorde inzet van algoritmes. 
","['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:aia-02', 'urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-04', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-07', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-12', 'urn:nl:ak:ver:aia-13', 'urn:nl:ak:ver:aia-14', 'urn:nl:ak:ver:aia-15', 'urn:nl:ak:ver:aia-16', 'urn:nl:ak:ver:aia-17', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-20', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-23', 'urn:nl:ak:ver:aia-24', 'urn:nl:ak:ver:aia-25', 'urn:nl:ak:ver:aia-26', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-29', 'urn:nl:ak:ver:aia-30', 'urn:nl:ak:ver:aia-31', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:aia-33', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:aia-35', 'urn:nl:ak:ver:aia-36', 'urn:nl:ak:ver:aia-37', 'urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:avg-01', 'urn:nl:ak:ver:avg-02', 'urn:nl:ak:ver:avg-03', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:avg-05', 'urn:nl:ak:ver:avg-06', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:avg-08', 'urn:nl:ak:ver:avg-09', 'urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:avg-11', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:avg-13', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:bzk-01', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:grw-02']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/index.html
urn:nl:ak:mtr:owp-24,Bepaal in een aanbesteding of algoritmes van een aanbieder bepalende invloed hebben in een besluit richting personen,"Ga na of algoritmes van een aanbieder een bepalende invloed hebben in een besluit richting personen en laat de aanbieder onderbouwen in hoeverre dit wel of niet het geval is.
","['publieke-inkoop', 'transparantie']",['ontwerp'],"['projectleider', 'beleid-en-advies', 'ontwikkelaar']","- Als overheidsorganisaties algoritmes willen gebruiken van aanbieders, dan zal bijvoorbeeld tijdens een aanbestedingsproces moeten worden beoordeeld in hoeverre deze algoritmes invloed hebben op besluitvormingprocessen van deze organisaties. Algoritmes kunnen namelijk gebruikers ondersteunen bij de totstandkoming van besluiten, maar ook de besluitvorming van gebruikers overnemen. De mate van [menselijke tussenkomst](../../onderwerpen/menselijke-controle.md) speelt daarbij een belangrijk rol. 

- Een opdrachtgever moet zelf bepalen welke algoritmes, gezien de specifieke context, wenselijk en toegestaan zijn. Vervolgens moet worden beoordeeld of de algoritmes die worden aangeboden door de aanbieder daarbij aansluiten.

- Tijdens het aanbestedingsproces moeten daarom inzichten worden verkregen hoe de algoritmes van aanbieders functioneren om tot een beoordeling te kunnen komen. Laat de aanbieder dit toelichten. 
","Algoritmes van aanbieders nemen besluitvormende taken over, zonder dat daar zicht op is of dat dit is beoordeeld.  
","['urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02']","- [Onderzoekskader Auditdienst Rijk, PRI.10](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetingskader Algemene Rekenkamer, 2.10](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-24-invloed-besluitvorming-algoritmes-aanbieders/index.html
urn:nl:ak:mtr:owp-25,Laat de aanbieder aangeven welke mate van opleiding en ondersteuning bij de implementatie nodig is om de beoogde algoritmes verantwoord te gebruiken,"
Laat de aanbieder aangeven welke mate van kennisoverdracht (opleiding en training) en ondersteuning bij de organisatorische implementatie nodig is om de beoogde algoritmes verantwoord te kunnen gebruiken. 
",['publieke-inkoop'],['ontwerp'],"['projectleider', 'beleid-en-advies', 'ontwikkelaar']","Beoordeel of de kennisoverdracht en ondersteuning van aanbieder voldoende is om voor een langere periode zelfstandig op een verantwoorde wijze gebruikt te kunnen maken van de algoritmes.

Laat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren trainingen passend zijn voor het beoogde gebruik, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.
","Zonder kennisoverdracht aan de organisaties en gebruikers ontstaat het risico dat algoritmes onjuist worden toegepast of dat de output onjuist wordt geïnterpreteerd en zo fouten ontstaan bij het uitvoeren van overheidstaken.
","['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:aia-24']","Geen beschikbare bron voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-25-kennisoverdracht-en-ondersteuning-aanbieder/index.html
urn:nl:ak:mtr:owp-26,Voer een risico-analyse met de aanbieder uit op het gebied van informatiebeveiliging bij een uitbestedingstraject,"Voer een risico-analyse met de aanbieder uit op het gebied van informatiebeveiliging bij een uitbestedingstraject.
","['technische-robuustheid-en-veiligheid', 'publieke-inkoop']",['ontwerp'],"['projectleider', 'beleid-en-advies']","- Stel vast of een aanbieder voldoet aan de Baseline Informatiebeveiliging Overheid (BIO).
- Bespreek de informatiebeveiligingseisen met de aanbieder die verband houden met de beschikbaarheid, integriteit en vertrouwelijkheid van de informatie en de informatiesystemen.
- Bepaal of er, gezien de restrisico's, aanvullende beveiligingsmaatregelen (door de aanbieder of opdrachtgever) moeten worden getroffen om deze te beschermen.
","Er is onvoldoende zicht op risico's op het gebied van informatiebeveiliging als gebruik wordt gemaakt van algoritmes van aanbieders. 
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:bio-01']","
- [Baseline Informatiebeveiliging Overheid, BIO 15.1.1.1](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.29](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-26-risico-analyse-informatiebeveiliging-leverancier/index.html
urn:nl:ak:mtr:owp-27,Maak vereisten onderdeel van het programma van eisen bij een aanbesteding,"
Maak vereisten onderdeel van het programma van eisen bij een aanbesteding.
",['publieke-inkoop'],['ontwerp'],"['projectleider', 'beleid-en-advies', 'ontwikkelaar']","- Door vereisten onderdeel te maken van het programma van eisen bij een aanbesteding is het voor aanbieders duidelijk aan welke specifieke eisen een oplossing moet voldoen.
- Op basis hiervan kan een aanbieder een zo goed mogelijke aanbieding doen.
- Afhankelijk van de behoeftestelling kan het relevant zijn om bepaalde vereisten te verfijnen in het Programma van Eisen (PvE) en aan te geven wanneer hieraan voldaan is, bijvoorbeeld met betrekking tot de transparantievereiste. Bepaal met het inkoopteam bij welke vereisten dit noodzakelijk is. 
","Er is niet gespecificeerd en daarmee achteraf niet afdwingbaar dat algoritmes aan bepaalde vereisten moeten voldoen die van belang zijn voor de betreffende overheidsorganisatie. 
","['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:aia-02', 'urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-04', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-07', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-12', 'urn:nl:ak:ver:aia-13', 'urn:nl:ak:ver:aia-14', 'urn:nl:ak:ver:aia-15', 'urn:nl:ak:ver:aia-16', 'urn:nl:ak:ver:aia-17', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-20', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-23', 'urn:nl:ak:ver:aia-24', 'urn:nl:ak:ver:aia-25', 'urn:nl:ak:ver:aia-26', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-29', 'urn:nl:ak:ver:aia-30', 'urn:nl:ak:ver:aia-31', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:aia-33', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:aia-35', 'urn:nl:ak:ver:aia-36', 'urn:nl:ak:ver:aia-37', 'urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:avg-01', 'urn:nl:ak:ver:avg-02', 'urn:nl:ak:ver:avg-03', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:avg-05', 'urn:nl:ak:ver:avg-06', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:avg-08', 'urn:nl:ak:ver:avg-09', 'urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:avg-11', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:avg-13', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:bzk-01', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:grw-02']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/index.html
urn:nl:ak:mtr:owp-28,Maak vereisten voor algoritmes onderdeel van de Service Level Agreement,"
Maak de vereiste onderdeel van Service Level Agreement (SLA).
",['publieke-inkoop'],['ontwerp'],"['projectleider', 'beleid-en-advies', 'ontwikkelaar']","- Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening van de aanbieder.
- Hierbij kan worden gedacht aan onderwerpen als incidentmanagement, servicemanagement, verantwoordelijkheden matrix, hersteltijd, prestatiecriteria, reproduceerbaarheid, versiebeheer van de gebruikte algoritmes en informatiebeveiliging.
- Onderzoek met het inkoopteam welke vereiste voor een verantwoorde inzet van algoritmes onderdeel moeten worden gemaakt van de Service Level Agreement. 
- Laat de aanbieder aangeven welke vormen van onderhoud aan de betreffende algoritmes nodig zijn en de snelheid waarmee signalen vanuit gebruik, ongeacht de bron, kunnen worden verwerkt in het systeem en welke expertise hiervoor beschikbaar is. 
","Zonder concrete afspraken te maken in de SLA ontstaat het risico dat aloritmes (tijdelijk) of te langdurig niet kunnen worden gebruikt, onjuist fuctioneren of dat er geen verantwoording over de output kan worden afgelegd.
","['urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-07', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:aia-35', 'urn:nl:ak:ver:aia-34', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:woo-01']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement/index.html
urn:nl:ak:mtr:owp-29,Maak (contractuele) afspraken over data en artefacten met een aanbieder,"
Maak (contractuele) afspraken met de aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmes.
",['publieke-inkoop'],"['ontwerp', 'implementatie']",['jurist'],"Hier kan worden gedacht aan (initiële) trainingsdatasets, outputdata (richting gebruikers) en nieuwe trainingsdata (vanuit gebruikers). 
","Een risico dat kan ontstaan is dat er onduidelijkheid is over wie de verantwoordelijk heeft voor bepaalde aspecten van het gebruik van een algoritme.
","['urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:avg-01']","
Geen bron beschikbaar voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-29-contractuele-afspraken-data-en-artefacten/index.html
urn:nl:ak:mtr:owp-30,Stel vast welke betrokkenen geïnformeerd moeten worden en welke informatie zij nodig hebben,"
Stel vast welke betrokkenen geïnformeerd moeten worden over de ontwikkeling en het gebruik van algoritmes en welke informatie zij hierover nodig hebben.
",['transparantie'],"['ontwerp', 'ontwikkelen']","['projectleider', 'beleid-en-advies']","Welke informatie over algoritmes relevant is, verschilt per partij. Het is van belang om deze partijen in beeld te brengen en vast te stellen welke informatie voor hen relevant is. Raadpleeg hierbij vastgestelde [beleidskaders](0-org-02-beleid-opstellen-inzet-algoritmes.md), waarin is beschreven welke informatie in welke gevallen moet worden gecommuniceerd.

Stel bijvoorbeeld de volgende vragen:

| Vragen	|Acties die je kan ondernemen |
| :-----------------|---------------|
| Wie heeft informatie nodig over het ontwikkelen en gebruiken van algoritmes? |	Stel vast welke betrokken(en) binnen of buiten de organisatie iets over het algoritme wil of zou moeten weten. |
| Wat voor informatie voor algoritmes heeft deze betrokken partij nodig? | Toets dit ook bij vastgesteld beleid. 	Ga na wat de doelgroep moet weten over de werking of inzet van het algoritme. Bepaal om welk technisch niveau dit gaat. |
| Op wat voor manier informeer je de betrokken partij?	| Pas de juiste methodes toe om de doelgroep te informeren. |
| Wanneer wordt deze informatie gebruikt? | Ga na in welke fase van de levenscyclus de gewenste informatie over de werking of inzet van het algoritme wordt gebruikt. Hoe verschilt de informatiebehoefte in elke fase van de levenscyclus? |
| Wie is er verantwoordelijk voor de informatieverstrekking? | Bepaal wie er informatie over het algoritme moet ophalen, en wie er voor die informatie kan zorgen. |

Maak bij het vaststellen van de informatiebehoefte onderscheid tussen transparantie, [uitlegbaarheid](2-owp-32-toepassen-uitlegbaarheidstechnieken.md) en interpreteerbaarheid. Houd daarbij ook rekening met zaken die moeten worden gecommuniceerd. Denk hierbij aan het kunnen uitleggen hoe een automatisch genomen besluit tot stand is gekomen, of de mogelijkheid om niet [onderworpen te worden aan geautomatiseerde besluitvorming](../vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming.md).

Stel een communicatieplan op over de ontwikkeling en gebruik van het algoritme. Bepaal vervolgens aan de hand van de levenscyclus wanneer welke informatie beschikbaar moet worden gesteld. Stel vast wie verantwoordelijk is voor het opstellen of het leveren van een bijdrage aan deze informatie. In het communicatieplan kunnen verder zaken worden opgenomen als:

  - Het doel van het algoritme.
  - Mogelijkheden van het algoritme.
  - Beperkingen van het algoritme.
  - Context waarin het algoritme wordt toegepast.
  - Wie heeft informatie nodig?
  - Wat voor informatie heeft deze betrokken partij nodig?
  - Op wat voor manier informeer je de betrokken partij?
  - Wanneer wordt deze informatie gebruikt?
  - Wie is er verantwoordelijk voor de informatieverstrekking?
  - Hoe en naar wie communiceer je in het geval van een incident?
  - Wat is de planning voor de communicatieactiviteiten?

Overleg regelmatig met betrokkenen en [belanghebbenden](1-pba-04-betrek-belanghebbenden.md) in hoeverre de informatieverstrekking aansluit bij de (nieuwe) behoeften.
","Het risico is dat partijen niet of onvolledig worden geïnformeerd over de ontwikkeling en gebruik van algoritmes en hierdoor hun rechten niet kunnen effectueren of belangen kenbaar kunnen maken.
","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:avg-10']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-30-informeer-betrokkenen/index.html
urn:nl:ak:mtr:owp-31,"Pas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmes","
Pas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmes.
","['governance', 'transparantie']",['organisatieverantwoordelijkheden'],"['projectleider', 'beleid-en-advies']","- Vastgestelde (interne) beleidskaders, zoals [specifiek beleid voor de inzet van algoritmes](0-org-02-beleid-opstellen-inzet-algoritmes.md), moeten worden toegepast bij het ontwikkelen, inkopen of gebruiken van algoritmes.
- Het is van belang dat tijdig, bijvoorbeeld in de [probleemanalyse fase](../../levenscyclus/probleemanalyse.md), inzichtelijk wordt gemaakt welke interne beleidskaders moeten worden toegepast.
- Hierbij kan worden gedacht aan definities die moeten worden gehanteerd, het naleven van inkoopbeleid, strategisch beleid volgen met betrekking tot het mogen inzetten van algoritmes binnen de organisaties of het doorlopen van processen en protocollen die moeten worden toegepast.
- Vraag de [betrokken experts](1-pba-04-betrek-belanghebbenden.md) welke beleidskaders van toepassing zijn vanuit diens specifieke expertise. 
- Ten behoeve van controles en audits is het van belang dat aantoonbaar wordt gemaakt dat de vastgestelde beleidskaders zijn nageleefd. 
","De in te zetten algoritmes voldoen niet aan vastgestelde beleidskaders. 
","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-37', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:avg-11', 'urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-09', 'urn:nl:ak:ver:grw-02', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-20']","
- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.8](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-31-pas-vastgestelde-beleidskaders-zijn-nageleefd/index.html
urn:nl:ak:mtr:owp-32,Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze,"Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze.
",['transparantie'],['ontwerp'],"['projectleider', 'beleid-en-advies', 'ontwikkelaar']","Uitlegbaarheidstechnieken helpen om de werking van een algoritme transparant te maken.
De keuze voor het type algoritme bepaalt hoe transparant je kunt zijn. Van rekenregels kun je namelijk precies uitleggen hoe deze tot een beslissing komen. Aan de andere kant kunnen complexe AI-systemen een black box zijn. Het is dan onduidelijk hoe deze systemen beslissingen maken. 

Afhankelijk van het type algoritme zijn er uitlegbaarheidstechnieken beschikbaar om de werking en keuzes van een algoritme bloot te leggen. Er moet eerst een keuze worden gemaakt welk type algoritme geschikt is gezien de [informatiebehoefte](2-owp-30-informeer-betrokkenen.md). Het is belangrijk om samen met de betrokken partijen vast te leggen welke uitlegbaarheidstechnieken moeten worden toegepast. Bij bronnen kan informatie worden geraadpleegd die helpen bij het vinden van de juiste methodiek.

### Gebruik uitlegbaarheid bij besluiten

Onderzoek hoe uitlegbaarheidstechnieken kunnen bijdragen aan het motiveren van besluiten. Dit kan bijvoorbeeld door:
	
- De output van het algoritme te koppelen aan het zaakdossier, met een toelichting op de interpretatie van die output.
- De output of een samenvatting hiervan op te nemen in de beschikking.
 
### Beperkingen en veiligheid

Vanuit veiligheidsoverwegingen kan bij specifieke algoritmes besloten worden om bepaalde informatie over de werking van een algoritme niet aan iedereen vrij te geven. Denk hierbij aan de beperkingen die de [Wet Open Overheid](../vereisten/woo-01-recht-op-toegang-tot-publieke-informatie.md) oplegt. Houd ook rekening met mogelijke risico’s op aanvallen die kunnen ontstaan door het gebruik van uitlegbaarheidstechnieken, zoals omschreven in: A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures. 

### Evaluatie en validatie

Evalueer de uitlegbaarheid van het systeem op functionele, operationele, bruikbaarheids- en veiligheidsvereisten in samenwerking met betrokkenen zoals gebruikers. Valideer of de uitkomst van het algoritme begrijpelijk genoeg is voor een gebruiker om hier op een verantwoorde wijze mee te werken.
","Als er geen rekening wordt gehouden met de uitlegbaarheid van een algoritme binnen een bepaalde context ontstaat het risico dat de output van het algoritme niet wordt begrepen of verkeerd wordt geïnterpreteerd, wat kan leiden tot onjuist gebruik.
","['urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:aia-26', 'urn:nl:ak:ver:awb-02']","
- [Onderzoekskader Auditdienst Rijk, DM.11](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes, Algemene Rekenkamder, 2.04](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Toolkit voor implementatie](https://xaitk.org/)
- [An introduction to explainable AI with Shapley values](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)
- [Paper over (de evaluatie van) toolkits](https://www.ijcai.org/proceedings/2023/0747.pdf)
- [UXAI: Design Strategy](https://www.uxai.design/design-strategy)
- [Overzicht (evaluatie van) metrieken XAI](https://dl.acm.org/doi/pdf/10.1145/3583558)
- [Part 2: Explaining AI in practice | ICO](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/part-2-explaining-ai-in-practice/)
- [A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures](https://arxiv.org/pdf/2404.00673)
- [Towards Transparency by Design for Artificial Intelligence | Science and Engineering Ethics](https://link.springer.com/content/pdf/10.1007/s11948-020-00276-4.pdf).
- [From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI](https://dl.acm.org/doi/pdf/10.1145/3583558)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/index.html
urn:nl:ak:mtr:owp-33,Identificeer en implementeer technische interventies die robuustheid vergroten,"Bepaal in het ontwerp welke technische interventies bijdragen aan de [robuustheid](../../onderwerpen/technische-robuustheid-en-veiligheid.md#wat-is-technisch-robuust-en-veilig) van het algoritme. Deze keuzes moeten in lijn zijn met het [beoogde doel](1-pba-02-formuleren-doelstelling.md) en de context. 
",['technische-robuustheid-en-veiligheid'],"['ontwerp', 'ontwikkelen']",['ontwikkelaar'],"Maak in de ontwerpfase de volgende afwegingen:

- **Identificeer en implementeer technische interventies die de robuustheid vergroten**

    In het ontwerp en in de training kunnen extra interventies worden genomen die de robuustheid vergroten. Dit kan op verschillende niveaus. Denk bijvoorbeeld aan: 
    
    - *Data Augmentation*: op data niveau kan de dataset uitgebreid worden met variaties op de oorspronkelijke data, bijvoorbeeld door het toevoegen van extra ruis aan de dataset; 
    - *Regularisatie*: tijdens training kunnen interventies worden gebruikt die overfitting voorkomen zoals *dropout* of *weight decay*. 
    - *[Cross-validation](3-dat-07-training-validatie-en-testdata.md#k-fold-cross-validation)*: tijdens training kunnen meerdere combinaties van train- en testsets gebruikt worden om generalisatie te waarborgen.
    - *Model ensembles*: er kunnen meerdere modellen gecombineerd worden om samen een beslissing te maken, dit minimaliseert de impact van een fout van één model. 
    - *[Adversarial training](#)*: het trainen met speciale voorbeelden die bedoeld zijn om het model te misleiden.  
    - Ook zijn er andere methoden die generalisatie kunnen verbeteren, zoals *invariant risk minimization*, *robust optimization*, *transfer learning* en *causal learning*. 

- **Bepaal de factoren waarop je interventies voor robuustheid beoordeelt**
    Afhankelijk van de context, verschillen de factoren waarop je deze afwegingen maakt. 
    Denk aan complexiteit van de data, invoerdata en resultaten, [risico en impact als het fout gaat](2-owp-06-impactanalyse.md), belang van [betrouwbaarheid versus nauwkeurigheid](../../onderwerpen/technische-robuustheid-en-veiligheid.md#wat-is-technisch-robuust-en-veilig), of belang van robuustheid versus transparantie. 

- **Leg de beargumenteerde keuze vast**
    Leg vast welke keuzes er gemaakt zijn en waarom deze keuzes zijn gemaakt. 
","Wanneer robuustheid niet in het ontwerp wordt meegenomen, kan er voor een model worden gekozen waar het niet mogelijk is robuustheid voldoende te waarborgen.
Het model wordt dan ofwel ingezet met de risico’s van dien of de innovatie moet later stop gezet worden. 
",['urn:nl:ak:ver:aia-06'],"- [Kenniscentrum Data & Maatschappij, Ethisch principe 2: technische robuustheid en veiligheid](https://data-en-maatschappij.ai/publicaties/ethisch-principe-2-technische-robuustheid-en-veiligheid)
- [Europese Commissie, Ethische richtsnoeren voor betrouwbare KI](https://digital-strategy.ec.europa.eu/nl/library/ethics-guidelines-trustworthy-ai)
- [A. Tocchetti et al., A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities](https://arxiv.org/abs/2210.08906)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/index.html
urn:nl:ak:mtr:owp-34,Voorkom kwetsbaarheden die geïntroduceerd worden in de supply-chain van het algoritme,"Het in gebruik nemen van algoritmes die door anderen zijn ontwikkeld brengt risico’s met zich mee waar je je tegen moet beschermen. 
Deze risico’s moeten adequaat afgedekt worden door afhankelijkheden te analyseren en afspraken te maken met leveranciers en controles uit te voeren.
","['publieke-inkoop', 'data', 'technische-robuustheid-en-veiligheid']",['ontwerp'],"['ontwikkelaar', 'beleid-en-advies', 'jurist']","Veel algoritmes zullen niet zelf ontwikkeld worden, maar bijvoorbeeld compleet [ingekocht](../../onderwerpen/publieke-inkoop.md) worden of op een externe server getraind worden. 
Redenen om dit te doen zijn het reeds beschikbaar zijn van een voorgetraind algoritme of bijvoorbeeld een gebrek aan technische kennis, een gebrek aan voldoende trainingsdata en een gebrek aan rekenkracht binnen de eigen organisatie. 

Echter is het een stuk lastiger om deze modellen te beschermen tegen aanvallen zoals [backdoors] omdat er geen (directe) controle is op het correct uitvoeren van een trainingsproces. 

Een eerste stap is om in kaart te brengen welke afhankelijkheden er zijn en te onderzoeken of deze beheersbaar zijn. 
Er moeten duidelijke afspraken gemaakt worden met leveranciers, bijvoorbeeld in de vorm van een [Service Level Agreement (SLA)](2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement.md). 
Op deze manier kan bijvoorbeeld afgesproken worden wie er verantwoordelijk is voor bijvoorbeeld het correct trainen en functioneren van het algoritme en hoe incidenten afgehandeld moeten worden.

Tot slot kunnen extra maatregelen genomen worden om te verifiëren dat het model inderdaad functioneert zoals afgesproken. Zo kunnen er formele methodes gebruikt worden om het algoritme te verifiëren en kan het gedrag van het algoritme getest worden tegen bekende, foutieve invoerwaarden. 
","Als onvoldoende duidelijk is hoe een algoritme werkt en tot stand is gekomen kan deze onverwachts gedrag vertonen tijdens het gebruik.
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12']","- [TNO, Ministerie van Justitie en Veiligheid, Verkenning van het raakvlak van cybersecurity en AI](https://www.rijksoverheid.nl/onderwerpen/terrorismebestrijding/documenten/rapporten/2024/10/28/tk-bijlage-4-tno-2024-r10768-verkenning-van-het-raakvlak-van-cybersecurity-en-ai)
- [AIVD, AI-systemen: ontwikkel ze veilig](https://www.aivd.nl/documenten/publicaties/2023/02/15/ai-systemen-ontwikkel-ze-veilig#:~:text=Steeds%20meer%20computersystemen%20maken%20gebruik,organisaties%20zich%20hiertegen%20kunnen%20verdedigen )
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-34-voorkom-kwetsbaarheden-supplychain/index.html
urn:nl:ak:mtr:owp-35,Maak gebruik van een algoritme dat bronvermelding kan genereren bij de output,"Maak gebruik van een algoritme dat bronvermelding kan genereren bij de output.
","['transparantie', 'publieke-inkoop']","['ontwerp', 'verificatie-en-validatie']","['projectleider', 'beleid-en-advies']","Bij het gebruik van generatieve AI (bijvoorbeeld LLM’s) is bronvermelding van belang.
Hiermee kan tot op zekere hoogte een beoordeling worden gegeven in hoeverre bij het trainen van het AI-model [rechtmatig](../vereisten/aut-01-auteursrechten.md) [gebruik](../vereisten/dat-01-databankenwet.md) is gemaakt van bronnen.
Bronvermelding is daarnaast essentieel om de output van het AI-model [inhoudelijk te kunnen controleren](../../levenscyclus/verificatie-en-validatie.md), wat ook informatie geeft in hoeverre het AI-model bijvoorbeeld al dan niet hallucineert of manipuleert. 

Voor het ontwikkelen van een AI-model is bronvermelding noodzakelijk, omdat het voor ontwikkelaars de enige manier is om te kunnen controleren of het model goed werkt. Dit geldt ook voor ontwikkelaars die pre-trained modellen gebruiken. 

Neem het kunnen generenen van een bronvermelding mee als een 'requirement' voor het te ontwikkelen AI-model in de ontwerpfase of maakt het onderdeel van de behoeftestelling en [specificeer deze behoefte](2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen.md) in het inkoopproces.
","Het niet vermelden van een bron bij het gebruik van generatieve AI kan leiden tot sancties aangezien er niet wordt voldaan aan de AI-verordening. Hiernaast kan het voor onduidelijkheden zorgen bij het gebruik van een algoritme wat verantwoord gebruik in de weg kan zitten. 
","['urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-09']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-35-genereren-bronvermelding/index.html
urn:nl:ak:mtr:owp-36,Bepaal of een algoritme moet worden ontwikkeld of ingekocht,"Bepaal of een algoritme moet worden ontwikkeld of ingekocht
",['publieke-inkoop'],['ontwerp'],['projectleider'],"Als in de [probleemanalyse fase](../../levenscyclus/probleemanalyse.md) duidelijk is geworden welke doelstellingen en behoeften gerealiseerd moeten worden, dan moet in de ontwerpfase worden bepaald of het beoogde algoritme zelf moet worden ontwikkeld of moet worden ingekocht.
Er zijn grofweg vier oplossingsrichtingen:

- Een kant-en-klare oplossing inkopen (""off the shelf"") bij een aanbieder.
- Een kant-en-klare oplossing inkopen bij een aanbieder waar nog enig maatwerk bij nodig is.
- Een nieuwe oplossing laten ontwikkelen door een aanbieder.
- Een nieuwe oplossing binnen de eigen organisatie ontwikkelen.

Het is van belang dat een analyse wordt gedaan welke oplossingsrichting het meest wenselijk is. PIANOo heeft een bruikbaar (algemeen) afwegingskader en stappenplan opgesteld om deze analyse grondig uit te voeren. Denk hierbij aan maken van:

- Een kwantitatieve kostenanalyse
- Kwalitatieve productiecriteria
- Kwalitatieve uitbestedingscriteria

Met een grondige analyse kan worden voorkomen dat bijvoorbeeld een algoritme dat al bestaat zelfstandig wordt ontwikkeld of dat de ontwikkeling van een algoritme onbeheersbaar wordt. Er is bij zo'n analyse een betere inschatting gemaakt van de voor en nadelen en bijbehorende kosten.
","Al ontwikkelde algoritmes die aansluiten bij de behoeftestelling worden onnodig opnieuw ontwikkeld of het zelfstandig ontwikkelen is verkeerd ingeschat waardoor de ontwikkeling te duur of onbeheersbaar wordt.
 ",['urn:nl:ak:ver:awb-01'],"
- [Maak of koopbeslissing (PIANOo)](https://www.pianoo.nl/nl/inkoopproces/fase-1-voorbereiden-inkoopopdracht/aanbestedingsplicht/maak-of-koopbeslissing)
- [Afwegingskader en stappenplan maak/koopbeslissing (PIANOo)](https://www.pianoo.nl/nl/inkoopproces/economische-afwegingen-bij-aanbesteding/maak-of-koopbeslissing/afwegingskader-stappenplan-maakkoopbeslissing)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/2-owp-36-maak-of-koopbeslissing/index.html
urn:nl:ak:mtr:dat-01,Controleer de datakwaliteit,"Stel vast of de gebruikte data van voldoende kwaliteit is voor de beoogde toepassing.
",['data'],['dataverkenning-en-datapreparatie'],['ontwikkelaar'],"- Stel functionele eisen voor de datakwaliteit vast en [analyseer structureel of er aan deze eisen wordt voldaan](7-mon-05-evalueer-bij-veranderingen-in-data.md). 
- De kwaliteit van de data die als input voor het algoritme wordt gebruikt is bepalend voor de uitkomsten van het algoritme. Hier wordt soms ook naar gerefereerd als *garbage in = garbage out*. 
- Een vraag die gesteld dient te worden: beschrijft de data het fenomeen dat onderzocht dient te worden? Oftewel: is de data _representatief_ voor de [doelpopulatie](1-pba-02-formuleren-doelstelling.md)?
- Het [Raamwerk gegevenskwaliteit](https://www.noraonline.nl/wiki/Raamwerk_gegevenskwaliteit) bevat een breed toepasbare set van kwaliteitsdimensies:

    - juistheid
    - compleetheid
    - validiteit
    - consistentie
    - actualiteit
    - precisie
    - plausibiliteit
    - traceerbaarheid
    - begrijpelijkheid

    Deze dimensies zijn aangevuld met [kwaliteitsattributen](https://www.noraonline.nl/wiki/Raamwerk_gegevenskwaliteit/Kwaliteitsattributen) welke gebruikt kunnen worden om de verschillende dimensies meetbaar te maken. 

- De vraag of de data kwaliteit voldoende is, hangt sterk samen met de vraag of er bias in de onderliggende data zit. Analyseer daarom ook welke bias en aannames er besloten zijn in de onderliggende data. Denk hierbij onder andere aan de volgende vormen van bias:

    - [historische bias](../../onderwerpen/bias-en-non-discriminatie.md#herken-bias)
    - [meetbias](../../onderwerpen/bias-en-non-discriminatie.md#herken-bias)
    - [representatie bias](../../onderwerpen/bias-en-non-discriminatie.md#herken-bias)

- Zorg dat je data [vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR)](3-dat-12-fair-data.md) is.

- Bepaal of de data voldoende representatief is voor de doelpopulatie en of de data voldoende representatief is voor eventuele relevante subgroepen uit de productiedata. 

!!! note ""Let op!""

    Wanneer je een algoritme inkoopt en de ontwikkeling van het algoritme uitbesteedt aan een derde partij, houdt er dan dan rekening mee dat data traceerbaar en reproduceerbaar moet zijn. Maak hier heldere afspraken over met de aanbieder. 
","- Door onjuiste beslissingen van gegevens kunnen verkeerde beslissingen genomen worden. 
- Het model creëert onwenselijke systematische afwijking voor specifieke personen, groepen of andere eenheden. Dit kan leiden tot ongelijke behandeling en discriminerende effecten met eventuele schade voor betrokkenen.

","['urn:nl:ak:ver:avg-05', 'urn:nl:ak:ver:aia-05']","- [Onderzoekskader Algoritmes Auditdienst Rijk, DM.7, DM.9, DM.19](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes, Algemene Rekenkamder, 2.18](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [NORA, Raamwerk gegevenskwaliteit](https://www.noraonline.nl/wiki/Raamwerk_gegevenskwaliteit)
- [Impact Assessment Mensenrechten en Algoritmes, 2A.2.2](../hulpmiddelen/IAMA.md)
- [Handreiking non-discriminatie by design](https://www.rijksoverheid.nl/documenten/rapporten/2021/06/10/handreiking-non-discriminatie-by-design)
- Norm: [""Artificial intelligence - Data quality for analytics and machine learning (ML) - Part 2: Data quality measures""](https://www.nen.nl/iso-iec-5259-2-2024-en-331171)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-01-datakwaliteit/index.html
urn:nl:ak:mtr:dat-02,Toets en analyseer of de inputvariabelen of risicoindicatoren geschikt zijn voor het beoogde algoritme,"Toets en analyseer of de inputvariabelen of risicoindicatoren geschikt zijn voor de beoogde toepassing.
","['data', 'bias-en-non-discriminatie']","['dataverkenning-en-datapreparatie', 'verificatie-en-validatie']","['ontwikkelaar', 'beleid-en-advies', 'privacy-en-gegevensbescherming']","Analyseer welke variabelen en risicoindicatoren geschikt en wenselijk zijn om te gebruiken als inputdata voor het beoogde algoritme. 

!!! note ""Opmerking""

    Deze maatregel is specifiek relevant voor de situatie van risicoprofilering. Maar ook voor andere toepassingen zijn deze stappen aanbevolen. 

Doorloop voor iedere potentiële indicator de volgende stappen:

1. Ga na of het wettelijk gezien is toegestaan om de variabele te gebruiken voor de beoogde toepassing:

    - De [Algemene Wet Gelijke Behandeling](https://wetten.overheid.nl/BWBR0006502/2020-01-01) verbiedt het directe onderscheid op basis van verschillende kenmerken die bijvoorbeeld relatie hebben met ras of nationaliteit.
    - De [Algemene Verordening Gegevensbescherming](https://www.autoriteitpersoonsgegevens.nl/themas/basis-avg/avg-algemeen/de-avg-in-het-kort) verbiedt het onrechtmatig verwerking van persoonsgegevens. 

2. Ga na of de variabele of indicator een proxy is voor [kwetsbare groepen](2-owp-08-kwetsbare-groepen.md). Controleer bijvoorbeeld of er een correlatie bestaat tussen de variabele en nationaliteit of ras, of maak gebruik van bestaande (wetenschappelijke) inzichten uit bijvoorbeeld openbare data. Wanneer je data wilt verwerken om deze proxy's te onderzoeken, houdt dan rekening met geldende wet- en regelgeving. Het verzamelen en verwerken van data over kwetsbare groepen kan in strijd zijn met privacy vereisten uit bijvoorbeeld de Algemene Verordening Gegevensbescherming. Het is daarom van belang om duidelijk afwegingen te maken tussen privacy en het analyseren van proxy's die rekening houdt met de juridische en ethische vereisten.

3. Bepaal of de [datakwaliteit](3-dat-01-datakwaliteit.md) van de variabele of indicator voldoende is. Bepaal of de beschikbare data voldoende representatief is voor het fenomeen dat bedoeld wordt.   

4. Ga na of de variabele of indicator een *statistisch* verband heeft met het [beoogde doel](1-pba-02-formuleren-doelstelling.md). Maak hiervoor gebruik van een [aselecte steekproef](6-imp-02-aselecte-steekproeven.md) uit de relevante populatie om de hypothese dat de variabele verband heeft met het beoogde doel statistisch te toetsen. Toets of dit verband significant is.

5. Ga na of de variabele of indicator een *inhoudelijk* verband heeft met het [beoogde doel](1-pba-02-formuleren-doelstelling.md). Naast een statistisch verband kan ook een inhoudelijk verband bijdragen om het gebruik van de indicator te rechtvaardigen. 
","Indien de variabelen niet voldoende worden getoetst op geschikheid bestaat het risico dat deze variabelen onrechtmatig worden gebruikt, of dat het gebruik van deze variabelen leidt tot nadelige effecten. Dit kan leiden tot discriminerende effecten van het algoritme. 
","['urn:nl:ak:ver:grw-02', 'urn:nl:ak:ver:avg-01', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:avg-10']","- [Toetsingskader risicoprofilering – Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens](../hulpmiddelen/toetsingskader-risicoprofilering.md)
- [Advies geautomatiseerde besluitvorming, Autoriteit Persoonsgegevens](https://www.autoriteitpersoonsgegevens.nl/documenten/advies-geautomatiseerde-besluitvorming)
  ",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-02-toetsen-geschiktheid-variabelen/index.html
urn:nl:ak:mtr:dat-03,Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedure,"
Bepaal de bewaartermijnen en richt een vernietigingsprocesdure in voor de verwerkte (persoons)gegevens.
","['technische-robuustheid-en-veiligheid', 'privacy-en-gegevensbescherming']","['ontwikkelen', 'monitoring-en-beheer']","['jurist', 'projectleider']","- (Persoons)gegevens die het algoritme verwerkt worden niet langer bewaard dan voor de verwezenlijking van de 
verwerkingsdoeleinden noodzakelijk is.
- Beschrijf de bewaartermijnen voor de gegevens, bijvoorbeeld in een DPIA.
- Beschrijf hoe de (persoons)gegevens moeten worden vernietigd.
- Zorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme en de onderliggende (zaak)systemen.
- Controleer of deze maatregelen voor de bewaartermijnen en vernietiging van de (persoons)gegevens (in de onderliggende systemen) zijn getroffen en zorg dat dit aantoonbaar is, bijvoorbeeld met logbestanden.
- Maak aantoonbaar dat persoonsgegevens zijn vernietigd, bijvoorbeeld met logbestanden.  
","Een risico dat kan voorkomen bij deze maatregel is dat bewaartermijnen van (persoons)gegevens kunnen worden overschreden zonder dat dit op tijd kenbaar wordt doordat er geen (volledige) vernietigingsprocedure is vastgesteld. 
","['urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aia-12', 'urn:nl:ak:ver:avg-02']","
- [Onderzoekskader Algoritmes Auditdienst Rijk, PRI.11](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 3.17](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/index.html
urn:nl:ak:mtr:dat-04,"Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregeren","
Pas maatregelen toe als pseudonimiseren, anonimiseren of aggregeren van persoonsgegevens toe bij het verwerken van de data. 
",['privacy-en-gegevensbescherming'],"['dataverkenning-en-datapreparatie', 'ontwikkelen']","['ontwikkelaar', 'jurist']","- Als is vastgesteld welke persoonsgegevens mogen worden verwerkt voor het ontwikkelen en gebruiken van algoritmes, moet worden nagegaan of er maatregelen kunnen worden getroffen om deze te beschermen.
- Het algoritme verwerkt niet meer persoonsgegevens dan noodzakelijk; de verwerkte gegevens zijn proportioneel en substantieel.
- Hierbij kan worden gedacht aan het pseudonomiseren, anonimiseren of aggregeren van persoonsgegevens.
- Het bepalen of persoonsgegevens mogen worden verwerkt voor algoritmes moet worden bekeken in samenhang met maatregelen die kunnen worden getroffen om deze gegevens te beschermen. 
","Het niet goed pseudonimiseren, anonimiseren of aggregeren van persoonsgegevens kan leiden tot onterecht gebruik van deze gegevens en kan daarbij een inbreuk op privacy veroorzaken. 
","['urn:nl:ak:ver:avg-03', 'urn:nl:ak:ver:avg-12']","- [Onderzoekskader Auditdienst Rijk, PRI.5](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 2.20, 3.06](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-04-pseudonimiseren-anonimiseren/index.html
urn:nl:ak:mtr:dat-05,Controleer de auteursrechten van eigen data,"
Controleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen.
Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.
",['data'],"['ontwerp', 'dataverkenning-en-datapreparatie']",['jurist'],"Het is van belang om te controleren of de te verwerken data waar overheidsorganisaties zelf over beschikken rechtmatig zijn verkregen en geen inbreuken maken op auteursrechten.
Hier kan worden gedacht aan data die is gescraped van het internet en zou kunnen worden gebruikt voor de ontwikkeling van een algoritme.
","Onrechtmatig gebruik van data dat niet toegeëigend is aan de organisatie die de data gebruikt voor ontwikkeling van algoritmes. 
",['urn:nl:ak:ver:aut-01'],"- [Onderzoekskader Auditdienst Rijk, SV.11](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-05-schending-auteursrechten/index.html
urn:nl:ak:mtr:dat-06,Gebruik duurzame datacenters,"Maak gebruik van datacenters die gebruik maken van duurzame energiebronnen en energie-efficiënte technologieën voor de opslag en verwerking van data.
",['duurzaamheid'],"['ontwerp', 'dataverkenning-en-datapreparatie', 'ontwikkelen', 'implementatie', 'monitoring-en-beheer']","['ontwikkelaar', 'projectleider', 'beleid-en-advies']","Door data op te slaan en algoritmes te laten draaien in datacenters die hernieuwbare energiebronnen inzetten en bijvoorbeeld de ontstane restwarmte recyclen, kan je de ecologische voetafdruk van de algoritmes aanzienlijk verkleinen.
Datacenters die zich op duurzaamheid richten, verlagen de CO₂-uitstoot van hun infrastructuur en bieden mogelijk duurzaamheidsrapportages. Let bij het kiezen van een aanbieder op mogelijke greenwashing; dit gebeurt wanneer bedrijven beweren groen te zijn zonder dit met concrete maatregelen te onderbouwen.

### Technologieën voor energie-efficiënte datacenters
Om datacenters energie-efficiënt te maken, zijn er verschillende benaderingen:

- **Gebruik van groene energiebronnen**: kies voor datacenters/aanbieders die hernieuwbare energie gebruiken. Maak bijvoorbeeld afspraken over [een doel, zoals een DCie-score van minimaal 50%](https://www.denkdoeduurzaam.nl/themas/ict/doelen), gewogen over een heel jaar. De DCie score van elk Overheids Datacenter (ODC) [kun je hier bekijken](https://rijksictdashboard.nl/duurzaamheid).
Je kunt ook kijken of naast duurzame stroom ook restwarmte van servers wordt benut om bijvoorbeeld nabijgelegen gebouwen te verwarmen.
- **Koeling en energiebeheer optimaliseren**: adiabatische koeling, waarbij water en lucht worden gebruikt in plaats van elektriciteit, verlaagt het energieverbruik. Efficiënte stroomverdeling en warmteterugwinning dragen verder bij aan een lagere ecologische voetafdruk.
- **Monitoren**: Blijf controleren op duurzame prestaties door te letten op certificeringen, zoals [ISO 14001](https://www.nen.nl/milieu/milieumanagement), [ISO 50001](https://www.nen.nl/energie/energiemanagement) en [BREEAM](https://www.breeam.nl/certificeren-in-5-stappen), en vraag naar energierapportages en details over het energieverbruik en de herkomst van stroom. Dit helpt om claims van duurzaamheid te toetsen en te voorkomen dat je in greenwashing trapt.
","Door geen gebruik te maken van duurzame datacenters loop je het risico op een hogere CO₂-uitstoot en wordt je daardoor niet aangesloten bij Rijksbreed beleid. Ook loop je risico op hogere energiekosten.
",[],"- [Rijks ICT Dashboard - Duurzaamheid](https://www.rijksictdashboard.nl/duurzaamheid)
- [Denk Doe Duurzaam - Doelen voor ICT](https://www.denkdoeduurzaam.nl/themas/ict/doelen)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/index.html
urn:nl:ak:mtr:dat-07,"Gebruik bij machine learning technieken gescheiden train-, test- en validatiedata en houd rekening met underfitting en overfitting","Indien je gebruik maakt van machine learning technieken, maak een passende keuze voor gescheiden train-, test- en validatiedata en houd hierbij rekening met underfitting en overfitting. 
","['data', 'technische-robuustheid-en-veiligheid', 'bias-en-non-discriminatie']","['dataverkenning-en-datapreparatie', 'ontwikkelen']",['ontwikkelaar'],"Verdeel je dataset in drie delen:

1. **De trainingset**

    Deze dataset wordt gebruikt om het model te trainen. Uit deze dataset worden de onderliggende patronen of relaties geleerd die later gebruikt kunnen worden om voorspellingen mee te doen.

    De [kwaliteit](3-dat-01-datakwaliteit.md) van deze dataset moet goed zijn en zo representatief mogelijk van de doelpopulatie. Eventuele [bias](../../onderwerpen/bias-en-non-discriminatie.md#herken-bias) of vooroordelen in deze dataset kunnen door het trainen in het model sluipen.

   Let bij het samenstellen van de traningset op dat de data waarop het model gebaseerd is, niet beschikbaar is voordat de uitkomsten zijn geobserveerd. Met andere woorden, zorg ervoor de de voorspellingen geen onderdeel kunnen zijn van de inputvariabelen. 

3. **De validatieset**

    De validatieset fungeert als een onafhankelijke, onbevooroordeelde dataset voor het vergelijken van de prestaties van verschillende algoritmes die zijn getraind op de trainingset.

    Verschillende modellen kunnen getraind worden op de trainingset. Zo kan je bijvoorbeeld variëren in de (hyper)parameters of de inputvariabelen. Dit leidt tot verschillende varianten van het model. Om de prestaties van de verschillende modellen te vergelijken, moeten we een nieuwe dataset gebruiken: de validatieset. Zou je hiervoor de trainingset gebruiken, kan dat leiden tot [overfitting](https://hastie.su.domains/ISLP/ISLP_website.pdf.download.html), omdat het model te specifiek afgestemd is op 1 dataset. Het model kan dan niet voldoende generaliseren voor nieuwe situaties.

4. **De testset**

    Nadat er met behulp van de validatieset een keuze is gemaakt voor een passend model en bijbehorende (hyper)parameters, moet je het model nog testen op nieuwe data. Dit geeft een beeld van de werkelijke prestaties van het model in nieuwe omstandigheden. 

    Let op dat je pas naar deze resultaten kijkt als laatste stap. Inzichten uit deze testdataset mogen niet worden meegenomen in de ontwikkeling, omdat dit kan leiden tot overfitting. Het model zal dan in productie mogelijk minder goed presteren. 

### Grootte van de drie datasets

Er is geen optimale verdeling van de drie datsets. Veelvoorkomende verhoudingen om data te splitten zijn:

- 80% trainingsset, 10% validatieset, 10% testset
- 70% trainingsset, 15% validatieset, 15% testset
- 60% trainingsset, 20% validatieset, 20% testset

Afhankelijk van de hoeveelheid beschikbare data en de context maak je hierin een keuze. Houdt hierbij rekening met:

- Hoe minder trainingdata, hoe groter de variatie van het model tijdens het trainen. De patronen en relaties die ontdekt zijn bevatten dan een grotere onzekerheid. 
- Hoe minder validatie- en testdata je gebruikt, hoe groter de variatie en de onzekerheid in de verwachte prestaties van het algoritme. 
- Hoe complexer het model en hoe meer (hyper)parameters er zijn om te optimaliseren, hoe groter de validatieset moet zijn om het model met optimale presetaties te vinden. Wanneer er weinig hyperparameters zijn, is een relatief kleine validatieset vaak voldoende.

### K-fold cross validation

Naast dat je de datasets willekeurig kan verdelen in drie delen (aselect), kan je ook meer geavanceerde technieken gebruiken. Een robuuste en veelgebruikte techniek is [k-fold cross validation](https://hastie.su.domains/ISLP/ISLP_website.pdf.download.html), waarbij het model *k* keer wordt getraind op verschillende delen van de data. 
","Door onjuiste training van het model presteert het model in de praktijk minder goed dan bij de tests. Als training-, validatie- en testdata door elkaar lopen (""data leakage""), kan dit leiden tot overfitting waardoor het model beter lijkt te presteren dan in werkelijkheid het geval is.
",['urn:nl:ak:ver:aia-10'],"
- [Onderzoekskader Auditdienst Rijk, DM.5, DM.6](https://open.overheid.nl/documenten/61b54381-d331-40ed-8fce-b2883b195f25/file)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 2.15, 2.21](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag) 

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/index.html
urn:nl:ak:mtr:dat-08,Zorg dat je controle of eigenaarschap hebt over de data,"De organisatie heeft volledige controle of eigenaarschap over de data. Wanneer dit niet mogelijk is, zijn afspraken gemaakt om de functionele eisen te waarborgen.
","['data', 'publieke-inkoop']",['dataverkenning-en-datapreparatie'],['projectleider'],"Wanneer een algoritme ontwikkeld of ingekocht wordt, is het belangrijk om [toegang tot de gebruikte data](3-dat-12-fair-data.md) goed te regelen.
Maak bijvoorbeeld afspraken over wie ervoor zorgt dat de data:

- Op een centrale plek beschikbaar wordt gesteld.
- Van voldoende [kwaliteit](3-dat-01-datakwaliteit.md) is.
- Goed beveiligd is.

Wanneer een algoritme wordt ontwikkeld door een derde partij en dus niet wordt beheerd door de eigen organisatie, maak je duidelijke afspraken over eigenaarschap van de data. Dat geldt zowel voor de inputdata als de outputdata. 
Zorg dat de inputdata tot je beschikking blijft, zodat resultaten altijd reproduceerbaar zijn. 
","De organisatie is afhankelijk van de data of het model afhankelijk van derden en kan daardoor reproduceerbaarheid en prestatie niet garanderen.
","['urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:aut-01']","- [Onderzoekskader Auditdienst Rijk, DM.23](https://open.overheid.nl/documenten/61b54381-d331-40ed-8fce-b2883b195f25/file)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-08-eigenaarschap-data/index.html
urn:nl:ak:mtr:dat-09,Beperk de omvang van datasets voor energie-efficiëntie,"Houd datasets beperkt tot het noodzakelijke en voldoende specifiek om onnodige energieconsumptie te voorkomen tijdens de verwerking en opslag van data voor algoritmes. We noemen dit ook wel dataminimalisatie.
","['data', 'duurzaamheid']","['dataverkenning-en-datapreparatie', 'ontwikkelen']","['ontwikkelaar', 'projectleider']","Hoe meer je bewaart, hoe meer ruimte dat kost om op te slaan. Bovendien verbruikt elk apparaat dat nodig is om data op te slaan stroom. Dat heeft grote invloed op de CO₂-uitstoot van een datacentrum.
Grote datasets brengen daarom hoge energie- en opslagkosten met zich mee. Door de dataset bewust te beperken tot relevante gegevens, kun je ook de energie-efficiëntie van algoritmes aanzienlijk verbeteren. Vooral bij de ontwikkeling van AI-systemen kan het verminderen van data bijdragen aan lagere energiebehoeften en CO₂-uitstoot.

### Technieken voor dataminimalisatie
- **Slimme selectie van trainingdata**: Gebruik methoden die irrelevante data uit de dataset filteren, zoals dataselectie-algoritmes en sampling-technieken. Door te focussen op relevante data, beperk je de omvang zonder de prestaties van het model te beïnvloeden.
- **Verwijderen van redundante en dubbele data**: Deduplicatie van data minimaliseert onnodige verwerkingskracht. Door alleen unieke en relevante gegevens op te slaan, wordt de opslagbehoefte verder beperkt.
- **Opschonen en archiveren van verouderde data**: [Regelmatige archivering](2-owp-09-archiveren-documenten.md) of verwijdering van verouderde data in je dataset zorgt voor een verminderde voetafdruk en verhoogt ook de efficiëntie.
","Zonder dataminimalisatie loopt je organisatie het risico op onnodig hoge energie- en opslagkosten, en een grotere ecologische impact.
",[],"- [Onderzoekskader Auditdienst Rijk, PRI.5](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 2.20](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Rijks ICT-dashboard](https://www.rijksictdashboard.nl/duurzaamheid)
- [Sustainable artificial intelligence – TU Delft](https://www.tudelft.nl/en/stories/articles/sustainable-artificial-intelligence-from-chatgpt-to-green-ai)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/index.html
urn:nl:ak:mtr:dat-10,Controleer de data op manipulatie en ongewenste afhankelijkheden,"De dataset die gebruikt wordt om een model te (her)trainen moet periodiek gecontroleerd worden op manipulatie (data poisoning). Voorkom ongewenste afhankelijkheden.
","['data', 'technische-robuustheid-en-veiligheid']","['dataverkenning-en-datapreparatie', 'monitoring-en-beheer']","['ontwikkelaar', 'beleid-en-advies']","Manipulatie van data wordt een “data poisoning” aanval genoemd [^1] [^2] [^3]. Een kwaadwillende kan op verschillende manieren te werk gaan:

- Bewust verkeerde informatie aan de dataset toevoegen. Dit is bijvoorbeeld mogelijk door als aanvaller zelf een foutieve dataset beschikbaar te stellen. Controleer daarom goed of een afgenomen dataset de kenmerken heeft die je verwacht. Daarnaast kun je ook nog verifiëren of bijvoorbeeld het proces waarmee de dataset vergaard is op de juiste manier is uitgevoerd. Tot slot is het verstandig om te voorkomen dat de dataset afhankelijk is van een enkele bron.
- Een aanvaller kan een bestaande dataset aanpassen, door bijvoorbeeld labels om te draaien. In dit geval moet een aanvaller toegang krijgen tot de locatie van de dataset. Bescherming hiertegen begint met algemene beveiligingsmaatregelen, bijvoorbeeld zoals beschreven in de [BIO](../hulpmiddelen/BIO.md). Daarnaast moet er ook gekeken worden naar het voorkomen van een insider aanval. Dit kan door selectief te zijn in het verlenen van toegang tot de locatie van de data en bijvoorbeeld het toepassen van een vier-ogen principe.
- In lijn met het aanpassen van de dataset kan een aanvaller ook een deel van de dataset verwijderen. Dit is naar verwachting makkelijker te realiseren dan het selectief aanpassen van de data. Door bijvoorbeeld alle data over een bepaalde groep personen uit de dataset te verwijderen functioneert het model minder goed voor die groep. Controleer daarom of de dataset waarmee uiteindelijk getraind wordt precies hetzelfde is als de origineel bedoelde data. Dit kan bijvoorbeeld door middel van een handtekening die geverifieerd moet worden. 

Op deze manieren kan een aanvaller een model slecht laten functioneren, of alleen fouten laten maken op specifiek gekozen invoerwaarden. Een aanvaller kan de trainingsdata zo beïnvloeden dat nummerborden met een stip altijd foutief gelezen worden, waardoor criminelen kentekencontroles kunnen ontwijken. In dit geval wordt ook wel gesproken over een [“backdoor” aanval](4-owk-09-adversarial-aanvallen.md#backdoor).

### Adversarial training
Daarnaast kan het principe van [adversarial training](https://arxiv.org/abs/1611.01236) worden toegepast door zelf bewust foutieve invoerwaarden aan de trainingsdata toe te voegen. 
Door een algoritme hierop te laten trainen kan deze beter bestand gemaakt worden tegen aanvallen tijdens het gebruik.
","Een aanvaller kan proberen om de trainingset te manipuleren om het uiteindelijke model doelbewust fouten te laten maken. Dit kan leiden tot verkeerde antwoorden, vooroordelen of zelfs kwetsbaarheden in het model.
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12']","- [Crowdstrike, Data Poisoning: The Exploitation of Generative AI](https://www.crowdstrike.com/en-us/cybersecurity-101/cyberattacks/data-poisoning/)
- [TNO, Ministerie van Justitie en Veiligheid, Verkenning van het raakvlak van cybersecurity en AI](https://www.rijksoverheid.nl/onderwerpen/terrorismebestrijding/documenten/rapporten/2024/10/28/tk-bijlage-4-tno-2024-r10768-verkenning-van-het-raakvlak-van-cybersecurity-en-ai)
- [AIVD, AI-systemen: ontwikkel ze veilig](https://www.aivd.nl/documenten/publicaties/2023/02/15/ai-systemen-ontwikkel-ze-veilig#:~:text=Steeds%20meer%20computersystemen%20maken%20gebruik,organisaties%20zich%20hiertegen%20kunnen%20verdedigen )
- [Kurakin, et al., Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/index.html
urn:nl:ak:mtr:dat-11,Controleer de input van gebruikers op misleiding,"Controleer de inputdata van gebruikers op misleiding.
","['data', 'technische-robuustheid-en-veiligheid']","['dataverkenning-en-datapreparatie', 'monitoring-en-beheer']",['ontwikkelaar'],"Een algemeen belangrijke stap in cyberveiligheid is het valideren of de inputdata voldoet aan de verwachting. 
Zo moet gecontroleerd worden of de [input valide, compleet en consistent](3-dat-01-datakwaliteit.md) is. 
Bijvoorbeeld door te verifiëren of een leeftijd niet negatief is en of er geen tegenstrijdige informatie gegeven wordt. 
Dit wordt typisch “*input sanitization*” genoemd. 
Veel programmeertalen en software bibliotheken bieden standaard oplossingen voor input sanitization.

In de context van algoritmes is het raadzaam om ook nog specifieker te monitoren wat voor inputs er gegeven worden aan bijvoorbeeld een AI-systeem. 
Zo kan het herhaaldelijk gebruiken van dezelfde input waarden met minimale aanpassingen wijzen op een poging tot een model engineering of een model inversion aanval. 

### Generatieve AI
In het specifieke geval van generatieve AI moet er rekening gehouden worden met [*prompt injection attacks*](https://www.ibm.com/topics/prompt-injection). 
Dit zijn aanvallen waarbij aanvallers een kwaadaardige opdracht dusdanig verhullen dat standaard checks het niet doorhebben en het model bijvoorbeeld gemanipuleerd wordt om desinformatie te verspreiden, gevoelige data te lekken of zelfs kwaadaardige software uit te voeren. 
Op dit moment is nog weinig bekend over hoe dit over het algemeen effectief gemodereerd kan worden. 
Echter kunnen in bepaalde situaties bepaalde opdrachten uitgesloten worden. Een ontwikkelaar zal dus moeten onderzoeken om wat voor opdrachten het gaat.
Zo hoeft een AI-systeem dat een klantenservice ondersteunt waarschijnlijk nooit een stuk code uit te voeren. 
","Als inputdata gemanipuleerd wordt dan kan dit leiden tot verkeerd gebruik van het algoritme. Een aanvaller kan bijvoorbeeld doelbewust een afwijkende input kiezen om ervoor te zorgen dat het algoritme op een andere manier gebruikt kan worden. 
Daarnaast kunnen onbewuste fouten ertoe leiden dat het model niet meer goed functioneert.
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12']","- [IBM, What is a prompt injection attack?](https://www.ibm.com/topics/prompt-injection)
- [Onderzoekskader Auditdienst Rijk, DM.9](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algemene Rekenkamer, 2.08](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/index.html
urn:nl:ak:mtr:dat-12,"Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie","
Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.
",['data'],['dataverkenning-en-datapreparatie'],['ontwikkelaar'],"De internationale [FAIR-principes](https://www.gofair.foundation/) zijn richtlijnen voor de manier van beschrijven, opslag en publicatie van data. 

- **Findable** (vindbaar): metadata moet gemakkelijk te vinden zijn voor zowel mensen als computers.
- **Accessible** (toegankelijk): gebruikers moeten weten hoe toegang tot de data verkregen kan worden (autorisatie en authenticatie).
- **Interoperable** (uitwisselbaar): data moet meestal geïntegreerd worden met andere data en bijbehorende applicaties, opslag en processen.
- **Reusable** (herbruikbaar): het uiteindelijke doel van FAIR is om hergebruik van data te optimaliseren.

Wanneer je voldoet aan de 15 principes is je data 'machine actionable'. Dit maakt het mogelijk dat de data effectief gebruikt kan worden voor verschillende algoritmes.

FAIR data betekent niet per definitie dat data open data is. Juist ook voor (privacy) gevoelige data (gesloten data) kan het heel zinvol zijn om te voldoen aan de principes voor FAIR data, om juist daarmee specifieke geautoriseerde toegang tot gevoelige data mogelijk te kunnen maken.

### 15 principes voor FAIR data

Er zijn 15 principes voor FAIR data geformuleerd:

#### Findable (vindbaar)
- [F1: Aan (meta)data wordt een wereldwijd unieke en permanente identifier toegevoegd](https://www.gofair.foundation/f1)

    !!! example ""Voorbeeld""

        Met behulp van [Persistent Identifiers (PID)](https://www.surf.nl/diensten/persistent-identifiers) zorg je ervoor dat jouw data (bijvoorbeeld onderzoeksdata) altijd vindbaar blijft. 
        PID's kun je vergelijken met het ISBN-nummer bij boeken. Het idee is dat ook als de locatie of de onderliggende infrastructuur verandert, de verwijzing intact blijft. 

- [F2: Data wordt beschreven met rijke metadata](https://www.gofair.foundation/f2)

    !!! example ""Voorbeeld""

        Het team van [data.overheid.nl](https://data.overheid.nl/) heeft de metadata standaard [DCAT-AP-DONL](https://docs.datacommunities.nl/data-overheid-nl-documentatie/dcat/dcat-ap-donl) ontwikkeld die speciaal voor de uitwisseling van dataset informatie voor de Nederlandse situatie is ingericht. Dit is gebaseerd op de [Data Catalog Vocabulary (DCAT) versie](https://www.w3.org/TR/vocab-dcat/) die de Europese Unie heeft opgesteld. Je kan hierover meer lezen op de site van [data.overheid.nl](https://data.overheid.nl/ondersteuning/open-data/dcat).

- [F3: Metadata bevat duidelijk en expliciet de identificatie van de data die ze beschrijven](https://www.gofair.foundation/f3)
- [F4: (Meta)data worden geregistreerd of geïndexeerd in een doorzoekbare bron](https://www.gofair.foundation/f4) 

#### Accessible (toegankelijk)
- [A1: (Meta)data zijn opvraagbaar op basis van hun identificatiecode met behulp van een gestandaardiseerd communicatieprotocol](https://www.gofair.foundation/a1) 
- [A1.1: Het protocol is open, vrij en universeel implementeerbaar](https://www.gofair.foundation/a1-1) 
- [A1.2: Het protocol maakt waar nodig een authenticatie- en autorisatieprocedure mogelijk](https://www.gofair.foundation/a1-2) 
- [A2: Metadata zijn toegankelijk, ook als de data niet meer beschikbaar zijn](https://www.gofair.foundation/a2) 

#### Interoperable (uitwisselbaar)
- [I1: (Meta)data gebruikt een formele, toegankelijke, gedeelde en breed toepasbare taal voor kennisrepresentatie](https://www.gofair.foundation/i1) 
- [I2: (Meta)data gebruikt gegevenswoordenboeken of vocabulaires die FAIR-principes volgen](https://www.gofair.foundation/i2) 

    !!! example ""Voorbeeld woordenboek""

        In het [woordenboek Hitte](https://woordenboek.klimaatadaptatienederland.nl/hitte/nl/) staan ongeveer 230 definities van termen rond het thema hitte die gebruikt worden in het klimaatadaptatieveld. Dit woordenboek is ontwikkeld in opdracht van het ministerie van Infrastructuur en Waterstaat door overheidsstichting Geonovum.

- [I3: (Meta)data bevat gekwalificeerde verwijzingen naar andere (meta)data](https://www.gofair.foundation/i3) 

#### Reusable (herbruikbaar)
- [R1: (Meta)data wordt rijkelijk beschreven met een veelheid aan nauwkeurige en relevante attributen](https://www.gofair.foundation/r1) 
- [R1.1: (Meta)data wordt vrijgegeven met een duidelijke en toegankelijke licentie voor datagebruik](https://www.gofair.foundation/r1-1) 
- [R1.2: (Meta)data wordt geassocieerd met gedetailleerde herkomst](https://www.gofair.foundation/r1-1) 

    !!! example ""Voorbeeld""

        [PROV-DM](https://www.w3.org/TR/prov-dm/) is een conceptueel datamodel dat gebruikt kan worden voor de herkomstinformatie (provenance) van data. 
        
- [R1.3: (Meta)data voldoet aan domein-relevante normen](https://www.gofair.foundation/r1-3)
","Data is niet gebruiksvriendelijk en het is onduidelijk hoe de data hergebruikt kan worden wat kan leiden tot inefficiënt datagebruik. 
",[],"
- [GO FAIR Foundation](https://www.gofair.foundation/interpretation)
- [3-point FAIRification framework 3PFF](https://www.go-fair.org/how-to-go-fair/)
- [Toolbox verantwoord datagebruik, 2b](https://realisatieibds.nl/page/view/ff607c02-9f09-440a-a0e7-9bbb6c7ceb09/3-data-verzamelen)
- [NORA online](https://www.noraonline.nl/wiki/FAIR-principes)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/index.html
urn:nl:ak:mtr:owk-01,Ontwerp en ontwikkel het algoritme volgens de principes van ‘security by design’,"
Hanteer principes van ‘security by design’ (informatiebeveiligingsmaatregelen) als uitgangspunten bij de ontwikkeling van het algoritme.
Stel vast welke principes horen bij security by design en welke relevant zijn voor het ontwerp of de ontwikkeling van het algoritme.
Mogelijke documenten waarin deze principes kunnen worden opgenomen zijn het security beleid of ontwikkelbeleid. Bij het bepalen en vaststellen van de juiste principes kunnen interviews met de ontwikkelaar en software-architecten helpen.
",['technische-robuustheid-en-veiligheid'],['ontwikkelen'],"['projectleider', 'ontwikkelaar']","Security by design is gehanteerd en terug te zien als uitgangspunt. (BIO 14.2.1.1) 

Security by design benadrukt het belang van het in een vroeg stadium integreren van securitymaatregelen. Op die manier kan worden voldaan aan regelgeving, maar wordt de weerbaarheid tegen bijvoorbeeld cyberaanvallen verhoogd. In een vroeg stadium nadenken over security betekent dat vroeg al de [benodigde expertise wordt betrokken](1-pba-04-betrek-belanghebbenden.md), zoals een security officer.
","Wanneer tijdens het ontwerp en de inrichting van het algoritmisch systeem niet voldoende rekening wordt gehouden met vastgestelde security-by-design principes kan dit leiden tot een onvoldoende veilige (software-)omgeving. Dit kan tot gevolg hebben: oneigenlijke toegang, wijzigingen of vernietigingen van het algoritme, de data of uitkomsten van het algoritme.

","['urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:aia-07']","
- [Baseline Informatiebeveiliging Overheid, (BIO 14.2.1.1)](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.28](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 4.09](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/index.html
urn:nl:ak:mtr:owk-02,Maak een noodplan voor het stoppen van het algoritme,"
Stel een duidelijk proces in voor situaties waarin het algoritme niet meer werkt zoals beoogd. Dit moet bevatten welke personen welke acties moeten doen en hoe er gewerkt wordt zonder het algoritme.
  ","['governance', 'menselijke-controle', 'technische-robuustheid-en-veiligheid']","['ontwikkelen', 'implementatie']","['projectleider', 'ontwikkelaar']","Er moet gezorgd worden dat er een alternatief plan is voor als het algoritme niet meer werkt zoals beoogd. Dit kan betekenen dat het hele systeem (tijdelijk) wordt stopgezet, dat delen van het systeem (tijdelijk) worden uitgeschakeld of dat er een alternatief systeem gebruikt wordt. 

Dit proces bevat in ieder geval de volgende stappen:

### Leg vast wanneer het algoritme niet meer werkt zoals beoogd
- Leg vast wat de [beoogde werking van het algoritme](1-pba-02-formuleren-doelstelling.md) is.
- Bepaal of [de geïmplementeerde werking overeenkomt met de vastgelegde beoogde werking](5-ver-01-functioneren-in-lijn-met-doeleinden.md) en wanneer het algoritme gestopt moet worden. Dit gebeurt tijdens een [evaluatie](7-mon-04-evaluatieplan.md) of door de [continue monitoring](7-mon-07-plan-continue-monitoring.md). 

### Zorg dat beslissingen kunnen worden herzien
- Leg vast hoe het mogelijk is na te gaan op welk moment het algoritme stopte met werken zoals beoogd. 
Wanneer de melding vanuit continue monitoring komt is het vaak duidelijk wanneer deze waarde wordt overschreden. 
Bij vaste evaluatiemomenten moet dit worden herleid. 
Zorg dat door middel van het [loggen](4-owk-04-logging.md) van de juiste informatie het mogelijk is te herleiden wanneer het algoritme stopte met werken zoals beoogd. 
- Zorg dat beslissingen die zijn genomen vanaf het moment dat het algoritme stopte met werken zoals beoogd kunnen worden herzien. Indien het algoritme niet direct is gestopt zodra het niet meer werkte zoals beoogd, moet er opnieuw gekeken worden naar de beslissingen die daarna zijn genomen. Leg vast op welke manier deze beslissingen herzien worden. 

### Leg vast wat de vervolgacties zijn
- Leg in een proces vast hoe het gebruik van het algoritme moet worden stopgezet. 
- Leg vast hoe er gewerkt worden zonder het algoritme en wat de impact daarvan is op het werkproces.  
- Leg vast wie er binnen en buiten de organisatie geïnformeerd moeten worden. 
- Het is van belang dat bij het ontwerp van algoritmes er rekening wordt gehouden met dat het werkproces ook zonder het algoritme kan worden uitgevoerd.
- In het geval van risicoselectie kan er bijvoorbeeld worden teruggevallen op het enkel uitvoeren van een [aselecte steekproef](6-imp-02-aselecte-steekproeven.md) als selectieinstrument. 
- Als blijkt dat het algoritme ongewenst functioneert moeten (technische) maatregelen zijn getroffen waarmee het gebruik daadwerkelijk kan worden stopgezet. Denk hierbij aan een stopknop en [werkinstructies](6-imp-01-werkinstructies-gebruikers.md) hoe het gebruik kan worden beëindigd.
- Maak aantoonbaar dat deze maatregelen zijn getroffen.
- De proceseigenaar of een menselijk toezichthouder moet in staat zijn om het algoritme op elk moment te kunnen beëindigen.
- Het stopzetten van het gebruik van een algoritme mag niet tot gevolg hebben dat betrokkenen niet meer kunnen achterhalen hoe besluiten tot stand zijn gekomen of dat gevolgen niet meer kunnen worden gecorrigeerd als dat noodzakelijk is. 

Indien er sprake is van discriminerende effecten van een algoritme, kan je gebruik maken van het [discriminatieprotocol](0-org-15-discriminatieprotocol.md). 
   ","Als er geen duidelijke acties zijn gedefinieerd, kan dat bijvoorbeeld leiden tot de volgende risico’s: het werkproces komt stil te liggen door een niet-werkend algoritme, er worden verkeerde beslissingen genomen doordat het algoritme nog wordt gebruikt terwijl het niet goed meer werkt of kwaadwillenden hebben langer toegang tot het algoritme en/of organisatiedata. 
","['urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:grw-02', 'urn:nl:ak:ver:aia-19', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:avg-04', 'urn:nl:ak:ver:aia-22']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/index.html
urn:nl:ak:mtr:owk-03,Analyseer de privacy-risico’s en neem maatregelen om deze risico’s laag te houden,"Uitvoeren risicoanalyse en formuleren mitigerende maatregelen voor privacyrisico.
",['privacy-en-gegevensbescherming'],"['ontwerp', 'ontwikkelen', 'monitoring-en-beheer']","['projectleider', 'jurist']","- Verifieer of een [DPIA](../hulpmiddelen/DPIA.md) is uitgevoerd over het werkproces dat wordt of zal worden ondersteund met een algoritme. Zo nee, voer een risico analyse (DPIA) uit om de risico's voor de rechten en vrijheden van betrokkenen met de inzet van algoritmes in beeld te brengen.
- Organisatorische en technische maatregelen moeten worden getroffen om persoonsgegevens bij de ontwikkeling en het gebruik van het algoritme te beschermen.
- Beleg de mitigerende maatregelen bij betrokken actoren. Denk bijvoorbeeld aan het toekennen van de maatregelen als [anonimiseren en pseudonimiseren van persoonsgegevens](3-dat-04-pseudonimiseren-anonimiseren.md) aan een data engineer, voordat deze kunnen worden gebruikt ten behoeve van het ontwikkelen of controleren van het algoritme.
- Bepaal welke maatregelen moeten zijn gerealiseerd voordat mag worden gestart met de verwerking van de persoonsgegevens en welke moeten worden gemonitord.  
- Bepaal of er sprake is van geautomatiseerde besluitvorming. Indien dat het geval is dient er beargumenteerd te worden of dat is toegestaan volgens de AVG. 
- Monitor de voortgang op het realiseren van de maatregelen en zorg voor bewijsstuken als deze zijn gerealiseerd. Deze bewijsstukken kunnen onderdeel worden van een audit.
- Als er een noodzaak is om na verloop van tijd meer persoonsgegevens te verwerken of om andere verwerkingen uit te voeren, zal opnieuw een beoordeling moeten plaatsvinden of er privacyrisico's ontstaan en hoe deze kunnen worden gemitigeerd. Gedurende de levenscyclus van het algoritme moet aandacht blijven voor het uitvoeren van de risicoanalyse voor privacyrisico's.
- Bij hoge risico's voor het verwerken van persoonsgegevens is een voorafgaande raadpleging bij de Autoriteit Persoonsgegevens onder artikel 36 AVG verplicht. Bepaal of raadpleging noodzakelijk is. 
","Privacyrisico's met de inzet van algoritmes worden niet gemitigeerd, waardoor privacyrechten van betrokkenen worden geschonden. 
","['urn:nl:ak:ver:avg-13', 'urn:nl:ak:ver:avg-10']","- [Onderzoekskader Algoritmes Auditdienst Rijk, PRI.2, PRI.3, PRI.10](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 3.03, 3.06, 3.10](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Besluit inzake lijst van verwerkingen van persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens](https://www.autoriteitpersoonsgegevens.nl/uploads/imported/stcrt-2019-64418.pdf)
- [Model DPIA Rijksdienst](https://www.kcbr.nl/sites/default/files/2023-09/Model%20DPIA%20Rijksdienst%20v3.0.pdf)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/index.html
urn:nl:ak:mtr:owk-04,Maak logbestanden waarin staat wie wanneer toegang had tot de data en de code,"Zorg ervoor dat logbestanden worden gecreëerd waarin informatie wordt geregistreerd over gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen.
Door goede logging is te achterhalen wanneer en door wie er toegang is geweest tot code en data (audit trail).
Er kan loginformatie gegenereerd, bewaard, toegankelijk gemaakt en gemonitord worden. Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren.
Bedenk wat deze informatie betekent in de context van de werking van het algoritme.
",['technische-robuustheid-en-veiligheid'],"['ontwikkelen', 'monitoring-en-beheer']",['ontwikkelaar'],"- Met logbestanden is te achterhalen wanneer en door wie er (ongewenste) aanpassingen zijn gedaan (audit trail).
- Loginformatie moet worden gegenereerd, bewaard, gemonitord en toegankelijk worden gemaakt.
- Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren.
- Bedenk wat deze informatie betekent in de context van de werking van het algoritme. loginformatie gegenereerd, bewaard, toegankelijk gemaakt en gemonitord worden. Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren.
- Stel vast welke informatie bij het ontwikkelen en gebruiken van algoritmes relevant is om te loggen. 
- Log behalve het aanpassen van gegevens ook het uitlezen van gegevens waar dat relevant is. Bijvoorbeeld als persoonsgegevens worden opgevraagd.
- Logs dienen periodiek (of doorlopend) gecontroleerd to worden op relevante incidenten. Dat betekent dat wat er gelogd wordt geschikt moet zijn om relevante beveiligingsincidenten op te merken. 
","Wanneer loginformatie ontbreekt, is niet te achterhalen wanneer er (eventueel ongewenste) aanpassingen zijn gedaan (audit trail) op (de code van) het algoritme, of door wie.
","['urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:aia-07', 'urn:nl:ak:ver:aia-13']","
- [Baseline Informatiebeveiliging Overheid, BIO 12.3.1.1, 12.3.1.4, 12.3.1.5, 12.4.1.1, 12.4.2.2](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.27](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 4.06](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-04-logging/index.html
urn:nl:ak:mtr:owk-05,Kies energiezuinige programmeermethoden,"Gebruik energie-efficiënte programmeertechnieken en methoden die de benodigde rekenkracht minimaliseren.
",['duurzaamheid'],['ontwikkelen'],['ontwikkelaar'],"Energiezuinig programmeren maakt het mogelijk om de voetafdruk van algoritmes te verkleinen door minder energie en middelen te verbruiken. Door specifieke technieken toe te passen, zoals optimalisatie van processen en efficiënte geheugenbeheerstrategieën, kun je als ontwikkelaar bijdragen aan het verduurzamen van algoritmes.

### Technieken voor energiezuinige softwareontwikkeling
1. **Lean coding en minimalisatie van code bloat**  
   Lean coding richt zich op het gebruik van alleen de benodigde code zonder overbodige complexiteit of libraries, wat resulteert in lagere energieconsumptie. Door “code bloat” te vermijden, zorg je ervoor dat het algoritme minder verwerkingskracht en geheugen verbruikt.

2. **Gebruik van energiezuinige programmeertalen en frameworks**  
   Programmeren in talen zoals Rust, Go en Elixir draagt bij aan energie-efficiëntie doordat deze ontworpen zijn voor lage resource-omvang en hoge efficiëntie. Ook frameworks die lichtgewicht en modulair zijn, ondersteunen energiezuinige processen.

3. **Parallel processing en multi-core optimalisaties**  
   Door parallelle verwerking en multi-core optimalisaties toe te passen, wordt rekenwerk verdeeld over meerdere cores. Dit reduceert de totale verwerkingstijd, bespaart energie en verhoogt de prestaties van je code op het vlak van duurzaamheid.

4. **Microservices en modulaire architecturen**  
   Een modulaire architectuur, zoals microservices, zorgt ervoor dat je onderdelen van de applicatie alleen activeert wanneer dat nodig is. Dit voorkomt onnodige belasting en beperkt energieverbruik behoorlijk.

5. **Geoptimaliseerd geheugenbeheer**  
   Door efficiënt geheugenbeheer, zoals caching en lazy loading, voorkom je onnodige data-opslag en bewerkingen. Dit verlaagt de energievraag en verbetert de snelheid van het algoritme aanzienlijk.
","Zonder energie-efficiënte methoden kan het algoritme onnodig veel energie verbruiken, wat leidt tot hogere operationele kosten en een grotere milieu-impact.
",[],"Geen beschikbare bron voor deze maatregel.
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/index.html
urn:nl:ak:mtr:owk-06,Optimaliseer AI-trainingsprocessen voor energie-efficiëntie,"Streef naar energiezuinige methoden voor AI-training, zoals het beperken van trainingscycli en het gebruik van energie-efficiënte hardware.
",['duurzaamheid'],['ontwikkelen'],['ontwikkelaar'],"Het trainen van AI, vooral generatieve AI-modellen, vergt aanzienlijke energie en heeft daardoor een grote ecologische voetafdruk. Een enkele trainingsronde kan al een enorme hoeveelheid CO₂ uitstoten. Door enkele concrete methoden toe te passen, kun je deze impact beperken.

### Energie-optimalisatie door hardwarekeuze en serverbeheer
- Gebruik energie-efficiënte hardware zoals specifiek afgestemde GPU's, die geschikt zijn voor de trainingsbehoeften van het model. Door bijvoorbeeld te kiezen voor GPU’s die optimaal bij je model passen in plaats van de krachtigste beschikbare hardware, kan het energieverbruik drastisch worden verminderd. Houd hiermee rekening in je keuze voor een trainingsomgeving.
- Verder kan servergebruik geoptimaliseerd worden door onnodige trainingsomgevingen tijdig te stoppen of voor andere trainingsomgevingen of testomgevingen te kiezen. Ook kun je servers dynamisch schalen met tools zoals Kubernetes of autoscaling technologie.

### Slimme data- en trainingsoptimalisatie
Niet alle beschikbare data dragen bij aan de modelprestaties. Door een dataselectiestrategie toe te passen, [gebruik je enkel relevante datasets (dataminimalisatie)](3-dat-09-dataminimalisatie.md), wat zorgt voor minder intensieve rekenbelasting tijdens het trainingsproces. Daarnaast kan slimme caching helpen om repetitieve data-opvragingen te beperken, wat bijdraagt aan een lagere energievraag. Bovendien kun je hertrainingscycli van AI beperken door enkel updates te doen wanneer nieuwe data dit echt vereist. Dit voorkomt overbodige trainingscycli en bespaart energie.
","Zonder energie-efficiënte methoden kan AI-training leiden tot hoge operationele kosten en een aanzienlijke ecologische impact, met name door overmatig gebruik van rekenkracht en energie-intensieve hardware.
",[],"- [How to Make Generative AI Greener - Harvard Business Review](https://hbr.org/2023/07/how-to-make-generative-ai-greener)
- [GreenOps: 4 Tips om AI-training duurzamer te maken - AG Connect](https://www.agconnect.nl/partner/leafcloud/greenops-4-tips-om-ai-training-duurzamer-te-maken)
- [Duurzame kunstmatige intelligentie - TU Delft](https://www.tudelft.nl/en/stories/articles/sustainable-artificial-intelligence-from-chatgpt-to-green-ai)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/index.html
urn:nl:ak:mtr:owk-07,Zorg voor reproduceerbaarheid van de uitkomsten,"Zorg ervoor dat uitkomsten van het algoritme herhaald of herleid kunnen worden.
","['technische-robuustheid-en-veiligheid', 'transparantie']",['ontwikkelen'],['ontwikkelaar'],"De reproduceerbaarheid omschrijft of de resultaten van een algoritme herhaald of herleid kunnen worden. 
Het betekent dat dezelfde input leidt tot dezelfde output in alle situaties. In ieder geval moet het algoritme dezelfde werking vertonen. 

Reproduceerbaarheid is sterk gelinkt aan herleidbaarheid en traceerbaarheid. 
Uitkomsten moeten altijd herleid kunnen worden aan de hand van het model en de data. 

Om te zorgen voor reproduceerbaarheid van de uitkomsten, kan je de volgende stappen nemen:

1. [Bepaal welke mate van reproduceerbaarheid nodig is](#bepaal-welke-mate-van-reproduceerbaarheid-nodig-is)
2. [Implementeer verschillende stappen die bijdragen aan reproduceerbaarheid](#implementeer-verschillende-stappen-die-bijdragen-aan-reproduceerbaarheid)
3. [Test of het algoritme het gewenste niveau van reproduceerbaarheid heeft](#test-of-het-algoritme-het-gewenste-niveau-van-reproduceerbaarheid-heeft)

### Bepaal welke mate van reproduceerbaarheid nodig is
Afhankelijk van de toepassing moeten de resultaten van het algoritme precies te reproduceren zijn. 
Wanneer er gebruik wordt gemaakt van generatieve AI hoeft de output niet altijd exact hetzelfde te zijn. 

### Implementeer verschillende stappen die bijdragen aan reproduceerbaarheid
Om te zorgen dat uitkomsten reproduceerbaar zijn, implementeer je het volgende in je processen en systemen:

- Zorg voor versiebeheer op de code en de bijbehorende systemen. Dit geldt zowel tijdens ontwikkeling als tijdens operatie. Tools als [GitHub](https://github.com/) of [GitLab](https://about.gitlab.com/) kunnen ondersteunen bij versiebeheer van code. 
- Zorg dat de data (trainings- en testdata) kan worden gereproduceerd. Maak gebruik van versiebeheer op de data, maak backups van de data, sla snapshots van de data op en maak gebruik van timestamps. 
- Documenteer wijzigingen aan het algoritme of de systemen daaromheen.
- Beheer afhankelijkheden van software bibliotheken en de beschikbare versies. Verschillende versies van veelgebruikte open-source software bibliotheken kunnen leiden tot verschillende resultaten. Gebruik bijvoorbeeld tools als [Docker](https://www.docker.com/) om deze versies te beheren.  
- Logging van tussenresultaten, eindresultaten, parameters en andere benodigde informatie. 
- Houd de documentatie compleet en compact. 

### Test of het algoritme het gewenste niveau van reproduceerbaarheid heeft
Het is belangrijk om het algoritme te testen op de mate van reproduceerbaarheid. Dit kan je doen door:

- Experimenten meerdere keren te herhalen. 
- Te testen of kan worden achterhaald hoe een bepaald resultaat tot stand is gekomen. Is het duidelijk welke data is gebruikt, en welke versie van het algoritme is gebruikt? Test of het resultaat op basis van deze informatie opnieuw kan worden gegenereerd.
- Rekening te houden met willekeur in het systeem. Dit is bijvoorbeeld relevant wanneer er gebruikt wordt gemaakt van *seeds* en/ of *random number generators*. Experimenteer wat de invloed is van verschillende seeds op de uitkomsten, en analyseer of het systeem dezelfde resultaten geeft voor een vaste seed. Indien van belang, documenteer de seed die gebruikt wordt. 
- Test of een versie van het algoritme opnieuw gereconstrueerd kan worden op basis van de gedocumenteerde informatie: 

    - trainingsdata
    - parameters
    - versies van gebruikte software (softwarebibliotheken)
    - etc.

- Indien er gebruik wordt gemaakt van generatieve AI kan er getest worden wat de uitkomsten zijn voor dezelfde of heel vergelijkbare prompts. 
","Wanneer uitkomsten niet herhaald kunnen worden, kan er niet worden gegarandeerd dat vergelijkbare casussen tot vergelijkbare uitkomsten komen. 
Dit maakt de uitkomsten van het algoritme mogelijk oneerlijk. 
Wanneer een herhaald experiment niet tot dezelfde uitkomsten leidt, kan het experiment niet vertrouwd worden. 
Als uitkomsten niet herleid kunnen worden, kan er geen uitleg worden gegeven waarom een bepaalde beslissing tot stand is gekomen. 
Hierdoor kan geen verantwoording worden geboden. 
",['urn:nl:ak:ver:aia-10'],"- [Onderzoekskader Auditdienst Rijk, DM.14](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [MLOps Principles: Reproducability](https://ml-ops.org/content/mlops-principles#reproducibility)
- [Ministerie van Infrastructuur en Waterstaat, AI Impact Assessment](https://www.rijksoverheid.nl/documenten/rapporten/2022/11/30/ai-impact-assessment-ministerie-van-infrastructuur-en-waterstaat)
- [Harald Semmelrock, et al., Reproducibility in Machine Learning-Driven Research](https://arxiv.org/pdf/2307.10320)
- [Odd Erik Gundersen, et al., Do machine learning platforms provide out-of-the-box reproducibility?](https://www.sciencedirect.com/science/article/pii/S0167739X21002090)
- [Odd Erik Gundersen, et al., State of the Art: Reproducibility in Artificial Intelligence ](https://ojs.aaai.org/index.php/AAAI/article/view/11503)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/index.html
urn:nl:ak:mtr:owk-08,Bepaal welke feedbackloops van invloed zijn op het algoritme,"Stel vast op welke manier de uitkomst of de inzet van het algoritme van invloed kan zijn op het proces en de werking in een latere fase. 
Probeer deze ‘feedbackloops’ in kaart te brengen zodat ze mogelijk voorkomen kunnen worden of gemonitored kunnen worden op mogelijke negatieve effecten. 
","['technische-robuustheid-en-veiligheid', 'bias-en-non-discriminatie']","['ontwerp', 'ontwikkelen']","['projectleider', 'ontwikkelaar']","Een feedbackloop kan zich voordoen wanneer de uitkomst van een algoritme wordt gebruikt als nieuwe input voor het algoritme. 
Deze feedbackloops kunnen een vertekend beeld van de werkelijkheid geven en de robuustheid van het algoritme over tijd in gevaar brengen. Dit is met name van belang wanneer algoritmes bijleren (continue of periodiek). 

!!! note ""Opmerking""

    Merk op dat feedbackloops ook een positief effect kunnen hebben, wanneer bijvoorbeeld gebruikerservaring wordt meegenomen in de doorontwikkeling van het algoritme. 

Er zijn verschillende vormen van feedbackloops:

- *Sampling feedbackloop*: wanneer de beslissing die volgt uit het algoritme effect heeft op de kans dat bepaalde groepen in een volgende selectie terechtkomen. 

- *Individual feedbackloop*: wanneer de mening of visie van een beoordelaar verandert door [het gebruiken van het algoritme](../../onderwerpen/bias-en-non-discriminatie.md#bias-in-menselijk-denken)(het overnemen van de ‘vooroordelen van een systeem’). 

- *Feature feedbackloop*: bijvoorbeeld wanneer de uitkomst dat een subsidie niet verstrekt wordt, ook als kenmerk ‘eerdere weigering van subsidie’ wordt gebruikt door het algoritme. 

- *Outcome feedbackloop*: wanneer burgers of bedrijven op basis van de uitkomst ander gedrag gaan vertonen. In het voorbeeld van de subsidie betekent dit bijvoorbeeld dat burgers hun uitgavepatroon veranderen. 

- *Machine-learning model feedbackloop*: wanneer nieuwe data die beschikbaar komt is beïnvloed door de beslissing van het algoritme zelf en deze data wordt gebruikt om een machine-learning model mee te (her)trainen. Een ander voorbeeld is wanneer alleen data wordt gebruikt van de personen die daadwerkelijk subsidie ontvangen om het algoritme op te (her)trainen. De groep die geen subsidie ontvangt ontbreekt dan in de dataset. 

### Adversarial feedbackloops
Soms kunnen feedbackloops opzettelijk ingezet worden als ‘aanval’ op het systeem. 
Dit hoeft niet per se vijandig te zijn, maar het kan gaan om het opzettelijk reageren op of aanpassen van de beslissingen die uit een algoritme volgen. 
Bijvoorbeeld wanneer mensen liegen bij het invullen van een vragenlijst van de GGD wanneer ze een soa-test willen doen, omdat ze weten dat ze dan gekwalificeerd worden voor een gratis test [^1]. 
Wanneer de belanghebbende het gedrag aanpast zonder dat zijn of haar kenmerken daadwerkelijk veranderen, omdat het heeft geleerd hoe het algoritme oordeelt, is dat voorbeeld van een adversarial feature feedbackloop. 
Deze feedbackloops wil je het liefste voorzien en mitigeren.  

[^1]: Zie https://nos.nl/op3/artikel/2143511-soa-sjoemelaars-liegen-voor-gratis-test

### Monitoring en ophalen informatie
Feedbackloops kunnen ook een positieve werking hebben op het algoritme. Het is verstandig om feedback op te halen om in te zien wat de reactie is van mensen op (beslissingen van) een algoritme. 
Dit kan bijvoorbeeld door gebruikers of belanghebbende burgers vragenlijsten te laten invullen met vragen over hun gedrag en de ontwikkelingen hierin te monitoren. 
Daarnaast kan het ophalen van ervaringen met het algoritme worden gebruikt voor doorontwikkeling en verbetering van het algoritme waarbij de gewenste en ongewenste effecten meegenomen worden. 

Ten slotte verdient [bias](../../onderwerpen/bias-en-non-discriminatie.md) specifieke aandacht. Houd goed in de gaten hoe het algoritme gebruikmaakt van de kenmerken van gevoelige groepen en wat de effecten van de uitkomsten zijn op hun gedrag en de datadistributie.
","Feedbackloops kunnen invloed hebben op verschillende onderdelen van het systeem waarin een algoritme zit. Als dit onopgemerkt gebeurt kan dit een negatief effect hebben op de accuraatheid en betrouwbaarheid van het algoritme, of ongewenste bias ontwikkelen. 
",[],"- [Lucía Vicente, et al., Humans inherit artificial intelligence biases](https://www.nature.com/articles/s41598-023-42384-8)
- [Nicolò Pagan, et al., A Classification of Feedback Loops and Their Relation to Biases in Automated Decision-Making Systems](https://arxiv.org/abs/2305.06055)
- [Jonathan Stray, The AI Learns to Lie to Please You: Preventing Biased Feedback Loops in Machine-Assisted Intelligence Analysis](https://www.mdpi.com/2813-2203/2/2/20)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/index.html
urn:nl:ak:mtr:owk-09,Ontwerp en train het algoritme om bestand te zijn tegen (cyber)aanvallen,"Ontwerp en train het algoritme om bestand te zijn tegen adversarial aanvallen.
",['technische-robuustheid-en-veiligheid'],['ontwikkelen'],"['beleid-en-advies', 'ontwikkelaar']","De impact van een adversarial AI-aanval hangt af van de [mate van autonomie](../ai-verordening.md#ai-systeem) waarmee een algoritme wordt ingezet. 
Een algemene impact-beperkende maatregel is daarom om menselijke gebruikers duidelijke instructies mee te geven om de uitkomsten van de algoritmes te controleren.

Voor de verschillende types adversarial AI-aanvallen zijn specifieke maatregelen mogelijk: 

### Poisoning aanval
Bij een poisoning aanval wordt het AI-systeem vergiftigd doordat een aanvaller aanpassingen aan de trainingsdata doet, waardoor het AI-systeem fouten gaat maken. 
Bijvoorbeeld een spamfilter die getraind is op gemanipuleerde data en zo bepaalde spam e-mails doorlaat. 
Maatregelen gericht op het [behoud van de integriteit van de trainingsdata](3-dat-10-datamanipulatie.md) kunnen hiertegen worden ingezet.

### Input- of evasion aanval
Bij een input- of evasion aanval voegt een aanvaller hele kleine bewerkingen toe aan input zodat een AI-systeem wordt misleid: het trekt een foute conclusie. 
Een voorbeeld hiervan is het plakken van een gele post-it op een stopbord, waardoor een auto met AI gebaseerde omgevingsherkenning het bord niet meer goed kan herkennen en zijn snelheid aanpast. 
Op evasion aanvallen kan geanticipeerd worden bij het testen van de [robuustheid](2-owp-33-technische-interventies-robuustheid.md) van algoritmes. Bijvoorbeeld door als onderdeel van een [representatieve testomgeving](5-ver-04-representatieve-testomgeving.md) ook rekening te houden met moedwillig, subtiel aangepaste input.

### Backdoor
Een backdoor in een algoritme geeft een aanvaller toegang en/ of de mogelijkheid om deze te manipuleren. 
Een voorbeeld hiervan is een nummerbord herkenningsalgoritme dat tijdens de ontwikkelfase van een backdoor voorzien is van een aanvaller, waardoor via een speciale toevoeging aan een nummerbord deze niet meer herkend wordt. 
Maatregelen gericht op controle van verwerking van trainingsdata, gebruik van ontwikkeltools en halffabricaten en het trainingsproces beperken de mogelijkheid om aanvallers backdoors te laten injecteren.

### Model stealing
Bij *model stealing* of *model reverse engineering* brengt een aanvaller in kaart hoe een algoritme in elkaar zit. 
Hierdoor kan een aanvaller het algoritme voor andere doeleinden misbruiken, zoals het vinden van kwetsbaarheden of van *evasion tactieken* voor het algoritme.

### Inversion of inference aanval
Met *inversion of inference* aanvallen kan een aanvaller achterhalen wat voor (mogelijk vertrouwelijke) trainingsdata is gebruikt. 
Zo kunnen gevoelige informatie worden blootgelegd, waaronder privacygevoelige gegevens en intellectueel eigendom.
","Adversarial AI-aanvallen kunnen leiden tot ongewenste misleiding, manipulatie of uitschakeling van de werking van een algoritme of tot verlies van gevoelige gegevens.
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12']","- [TNO, Adversarial AI in het cyberdomein](https://publications.tno.nl/publication/34640579/Mf1Fda/TNO-2023-R10292.pdf)
- [OWASP Top 10 for Large Language Model Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/index.html
urn:nl:ak:mtr:owk-10,Zorg dat (gevoelige) informatie niet kan lekken op basis van de output van het algoritme,"Zorg dat (gevoelige) informatie niet kan lekken op basis van de output van het algoritme.
",['technische-robuustheid-en-veiligheid'],"['ontwikkelen', 'implementatie', 'monitoring-en-beheer']",['ontwikkelaar'],"Een aanvaller kan aan de hand van de uitkomsten van een model proberen om bepaalde eigenschappen over het model of de dataset te achterhalen. In de [brochure van de AIVD](https://www.aivd.nl/documenten/publicaties/2023/02/15/ai-systemen-ontwikkel-ze-veilig) wordt specifiek gewaarschuwd voor “*model engineering*”, “*model inversion*” en “*inference*” aanvallen.

- **Model engineering** refereert naar aanvallen die als bedoeling hebben om te achterhalen hoe het model werkt. Dit kan bijvoorbeeld als doel hebben om intellectueel eigendom te stelen of om effectiever zwakheden in het model te kunnen onderzoeken.

- **Model inversion** beschrijft aanvallen waarbij het doel is om de trainingsdata te reconstrueren. Dit kan wederom interessant zijn voor het stelen van intellectueel eigendom, maar ook het achterhalen van privé gegevens als het bijvoorbeeld om een medische dataset gaat.

- **Inference** aanvallen zijn ook gericht op het achterhalen van informatie over de trainingsdata. In tegenstelling tot model inversion is het doel niet om de gehele trainingsdata terug te krijgen, maar specifieke informatie. Zo kan het doel bijvoorbeeld zijn om te achterhalen of een bepaald persoon onderdeel was van de trainingsdata of kan met een deel van de informatie over een persoon geprobeerd worden om missende informatie te achterhalen. Dit type aanvallen is vaak makkelijker uit te voeren van een volledige model inversion.

### Technieken voor voorkomen van lekken

### Statistical Disclosure Control
Statistical Disclosure Control (SDC) is een veelgebruikte techniek om ervoor te zorgen dat er geen gevoelige informatie lekt uit de uitkomst van een datagedreven onderzoek.
Alhoewel SDC vooral gericht is op traditionele data-analyses kan het ook gebruikt worden in de context van algoritmes. 
Er zijn verschillende voorbeelden hoe SDC kan worden toegevoegd aan een AI-systeem, zoals [The SACRO-ML package](https://arxiv.org/abs/2212.01233).

### k-anonimity
Daarnaast bestaan er ook nieuwere technieken die kunnen helpen bij het onherkenbaar maken van mogelijk gevoelige informatie in de outputs van algoritmes. Zo zijn er technieken gebaseerd op het generaliseren van data om individuen onherkenbaar te maken, zoals [k-anonimity](https://dl.acm.org/doi/10.1142/s0218488502001648). 

### Differential privacy
Ook bestaan er technieken die ruis toevoegen aan de uitkomst, met wiskundige garanties van de veiligheid. De meest populaire techniek voor het toevoegen van ruis is [differential privacy](https://dl.acm.org/doi/10.1007/11787006_1).

### Rate limiting
De hierboven benoemde oplossingen focussen op het beveiligen van één output van het algoritme. Veel aanvallen berusten echter ook op het veelvuldig aanroepen van een algoritme. Een andere oplossing die dit tegen kan gaan is het limiteren van het aantal interacties dat een gebruiker mag hebben met een algoritme, ook wel bekend als *rate limiting*. 
","Als een gebruiker teveel informatie te zien krijgt kan dit bijvoorbeeld leiden tot het lekken van trainingsdata of eigenschappen van het algoritme.
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12']","- [Smith, et al., Safe machine learning model release from Trusted Research Environments: The SACRO-ML package](https://arxiv.org/abs/2212.01233)
- [Sweeney, et al., k-anonymity: a model for protecting privacy](https://dl.acm.org/doi/10.1142/s0218488502001648)
- [Dwork, et al., Differential privacy](https://dl.acm.org/doi/10.1007/11787006_1)
- [Nguyen, et al., A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures](https://arxiv.org/abs/2404.00673)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/index.html
urn:nl:ak:mtr:owk-11,Documenteer en beargumenteer de keuze voor gebruikte modellen en parameters,"Documenteer en beargumenteer de keuze voor gebruikte modellen en parameters. 
",['technische-robuustheid-en-veiligheid'],"['ontwikkelen', 'implementatie']",['ontwikkelaar'],"Documenteer en beargumenteer tijdens de ontwikkeling van een algoritme de technische keuzes die gemaakt worden voor het betreffende model. 

Dit houdt in dat ten minste het volgende wordt gedocumenteerd en beargumenteer:

- Keuzes voor (hyper)parameters.
- Keuzes voor het gebruikte model.
- Of wordt er voldaan aan onderliggende (statistische) aannames van het model?

Onderbouw deze keuzes van parameters en verschillende modellen bijvoorbeeld op basis van de gemeten [nauwkeurigheid](5-ver-02-evalueer-nauwkeurigheid.md). 

Goede documentatie zorgt er voor dat opgebouwde kennis door kan worden gegeven. 
","Wanneer keuzes niet goed worden gedocumenteerd en onderbouwd is later niet te herleiden waarom welke keuzes zijn gemaakt in ontwerp en implementatie, waardoor transparantie en verantwoording niet mogelijk is. 
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:awb-02']","- [Onderzoekskader Auditdienst Rijk, DM.2](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetinskader Algemene Rekenkamer, 2.02, 2.03, 2.16, 2.17](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag) 
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-11-documenteer-parameters/index.html
urn:nl:ak:mtr:owk-12,Gebruik een passende licentie bij publicatie of gebruik van (open) data,"Gebruik bij het publiceren of gebruiken van data een passende licentie die aansluit bij het beoogde doel en de bescherming van burgers. Overweeg hierbij zorgvuldig welke voorwaarden nodig zijn, zoals bronvermelding of het delen onder gelijke voorwaarden.
",['data'],"['ontwikkelen', 'dataverkenning-en-datapreparatie', 'monitoring-en-beheer']","['ontwikkelaar', 'jurist']","Het kiezen van de juiste licentie is belangrijk bij het publiceren en gebruiken van datasets en algoritmes. Dit zorgt voor [betere datakwaliteit (zie o.a. R1.1 uit FAIR)](3-dat-02-fair-data.md). In de huidige digitale samenleving, met name door de opkomst van generatieve AI, is het belangrijk om de balans te vinden tussen openheid en traceerbaarheid.
Overweeg bij het kiezen van een licentie de volgende aspecten:

- Bronvermelding: wil je gebruikers van bijvoorbeeld de dataset verplichten om de oorspronkelijke bron te vermelden?
- Share-alike: wil je gebruikers verplichten om *afgeleide werken* van hetgeen zij gebruiken, onder dezelfde voorwaarden / licentie te delen?
- Commercieel gebruik: bepaal of en onder welke voorwaarden commercieel gebruik is toegestaan.
- Herroepbaarheid: houd rekening met toekomstige aanpassingen van de licentie.

Voorbeelden van licenties zijn:

- Creative Commons BY-SA: vereist bronvermelding en het delen onder gelijke voorwaarden.
- Creative Commons BY: vereist alleen bronvermelding.
- Publiek Domein met bronvermeldingsplicht: voor maximale openheid met behoud van traceerbaarheid.

### Licenties voor software en code
Voor software en algoritmes zijn er specifieke licenties beschikbaar die beter aansluiten bij het publiceren van broncode. [Creative Commons (CC) raadt het gebruik van CC-licenties voor software expliciet af](https://creativecommons.org/faq/#can-i-apply-a-creative-commons-license-to-software).

Voor Nederlandse overheidssoftware wordt de European Union Public License (EUPL) als standaard aanbevolen, zoals [beschreven in de bijlage van ""Overwegingen bij Open tenzij en Aanpak open source""](https://open.overheid.nl/documenten/ronl-8746885c-59bd-4b0e-a86b-c6fa85d63c9a/pdf). Voor een overzicht en vergelijking van softwarelicenties kan bovendien de website [choosealicense.com geraadpleegd](https://choosealicense.com/licenses/) worden.
","Enkele risico's bij het niet vermelden van de passende licentie:

- Onduidelijke licentievoorwaarden kunnen leiden tot onbedoeld gebruik van de dataset.
- Te restrictieve licenties kunnen hergebruik onnodig beperken.
- Te open licenties (zoals CC0) kunnen leiden tot oncontroleerbare mis- en desinformatie.
- Onherroepelijke licenties bieden geen flexibiliteit voor toekomstige aanpassingen.
","['urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aut-01', 'urn:nl:ak:ver:dat-01', 'urn:nl:ak:ver:aia-05']","- [Toetsingskader Algemene Rekenkamer, 2.13](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Licentiewijzer voor overheden - voor licenties bij software](https://opensourcewerken.nl/news/view/84367829-63bb-4039-8528-e9b0041c7067/met-zes-vragen-de-juiste-licentiecategorie-kiezen)
- [Licensing Assistant - tool van de Europese commissie, ook voor licenties bij software](https://interoperable-europe.ec.europa.eu/collection/eupl/solution/licensing-assistant)
- [FAIR Data Principles - R1.1](https://www.gofair.foundation/r1-1)
- [Creative Commons licenties](https://creativecommons.org/licenses/)
- [Open Data Handboek](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/nieuwe-technologieen-data-en-ethiek/open-data/)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/index.html
urn:nl:ak:mtr:ver-01,Controleer regelmatig of het algoritme werkt zoals het bedoeld is,"Stel vast dat het algoritme voortdurend functioneert in lijn met de [vastgestelde doelstelling](1-pba-02-formuleren-doelstelling.md). 
","['technische-robuustheid-en-veiligheid', 'bias-en-non-discriminatie']","['ontwikkelen', 'verificatie-en-validatie', 'monitoring-en-beheer']","['projectleider', 'ontwikkelaar']","- Vertaal de [vastgestelde doelstelling](1-pba-02-formuleren-doelstelling.md) naar functionele eisen voor het algoritme. Werk het vastgestelde doel uit in een beschrijving in logische taal/ pseudo code of documentatie die handvatten biedt aan de ontwikkelaar. 
- Monitor de mate waarin aan deze eisen wordt voldaan door het algoritme. 
- Bepaal en leg vast hoe eventuele parameters, business rules en indicatoren bepaald worden. Zorg dat dit breed wordt afgestemd in de organisatie (ontwikkelteam, opdrachtgevers en beheer).
- Houd hier rekening met eventuele [(statistische) bias](../../onderwerpen/bias-en-non-discriminatie.md#bias-in-statistiek-en-berekeningen): meten we daadwerkelijk wat we denken te meten? 
- Wanneer het algoritme meerdere doelen dient, is het belangrijk ook te evalueren op meerdere functionele eisen. 
- Wanneer er sprake is van een (handmatige) behandeling, bepaal dan wanneer deze behandeling als 'succesvol' gezien kan worden. 
","Het algoritme functioneert niet in lijn met geformuleerde doelstellingen. 

","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-10']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/index.html
urn:nl:ak:mtr:ver-02,Evalueer de nauwkeurigheid van het algoritme,"Test en evalueer de nauwkeurigheid van het algoritme om te zorgen dat deze accurate uitkomsten geeft. 
","['technische-robuustheid-en-veiligheid', 'bias-en-non-discriminatie']","['ontwikkelen', 'verificatie-en-validatie', 'monitoring-en-beheer']","['ontwikkelaar', 'projectleider']","De nauwkeurigheid van het algoritme wil zeggen: geeft het algoritme de juiste uitkomst voor [het gewenste doel](1-pba-02-formuleren-doelstelling.md); maakt het correcte berekeningen, voorspellingen, aanbevelingen, beslissingen of classificeringen. 

Voor het evalueren van de nauwkeurigheid zijn de volgende stappen essentieel:

- Bepaal met welke methoden en [metriek(en)](#metrieken) je de nauwkeurigheid wilt gaan meten. Pas dit aan op de [ontwerpkeuzes](../../levenscyclus/ontwerp.md), [het beoogde doel](1-pba-02-formuleren-doelstelling.md) en [de bepaalde risico’s](2-owp-06-impactanalyse.md). 
- [Controleer of de data volledig en actueel is](3-dat-01-datakwaliteit.md) om de metrieken te kunnen meten.
- Bepaal welke foutmarge acceptabel is:

    - Bepaal hoe vaak het algoritme een bepaalde fout maakt. Houd rekening met verschillende fouten die gemaakt kunnen worden, zoals *false positives* en *false negatives*. Welke fouten zijn erger om te maken? 
    - De foutmarge is afhankelijk van [welke schade wordt veroorzaakt](2-owp-06-impactanalyse.md) bij onnauwkeurige of foutieve voorspellingen.
    - Heb hierbij aandacht voor de afweging tussen nauwkeurigheid en [betrouwbaarheid](5-ver-06-evalueer-betrouwbaarheid.md). Een model met hoge nauwkeurigheid op de testset kan vaak slechter generaliseren naar situaties net buiten de test set (overfitting).
    - Bepaal interventies voor als het restrisico hoger is dan acceptabel.

    - Wanneer de nauwkeurigheid niet voldoende is tijdens de ontwikkelfase kan er besloten worden door te ontwikkelen, andere maatregelen te treffen (bijvoorbeeld in [menselijke interventies](../../onderwerpen/menselijke-controle.md)) om het restrisico acceptabel te maken of door [te stoppen met de ontwikkeling van het systeem](../../levenscyclus/uitfaseren.md). 
    - Wanneer monitoring aangeeft dat de nauwkeurigheid onvoldoende is, moet er een passende afweging worden gemaakt om het systeem te verbeteren dan wel over te gaan op het [stoppen van het systeem](4-owk-02-stopzetten-gebruik.md).

### Metrieken
Afhankelijk van het type algoritme zijn er verschillende metrieken waarmee je de nauwkeurigheid kan meten. Veelgebruikte metrieken/methoden zijn:

- accuraatheid *(accuracy)*
- precisie *(precision)*
- *recall*
- *F1-score*
- *mean-squared-error*
- *mean-absolute-error*
- *ROC-curve*

Leg vast welke keuze je maakt voor bepaalde metrieken en waarom. In verschillende omgevingen en onder verschillende datasets moeten de relevante metrieken voor jouw toepassing worden geëvalueerd.
","Een onnauwkeurig algoritme geeft de verkeerde uitkomsten waardoor situaties of mogelijk personen verkeerd beoordeeld kunnen worden. 
","['urn:nl:ak:ver:aia-06', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:awb-01']","- [Europese Commissie, Ethische richtsnoeren voor betrouwbare KI](https://digital-strategy.ec.europa.eu/nl/library/ethics-guidelines-trustworthy-ai)
- [Toetingskader Algemene Rekenkamer, 2.03](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Onderzoekskader Auditdienst Rijk, DM.1, DM.4](https://open.overheid.nl/documenten/61b54381-d331-40ed-8fce-b2883b195f25/file)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/index.html
urn:nl:ak:mtr:ver-03,Toets het algoritme op bias en voer een rechtvaardigingstoets uit,"Analyseer regelmatig of het gebruik van het algoritme of het proces daaromheen leidt tot onwenselijke of onrechtmatige verschillen in de behandeling van individuen en/of groepen.  
",['bias-en-non-discriminatie'],"['ontwerp', 'verificatie-en-validatie', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies', 'ontwikkelaar', 'jurist']","Het uitvoeren van een analyse over onwenselijke of onrechtmatige verschillen bestaat grofweg uit 3 stappen:

- [Stap 1](#stap-1-analyseer-of-er-sprake-is-van-bias): analyseer of er sprake is van bias: *systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen.*
- [Stap 2](#stap-2-voer-een-rechtvaardigingstoets-uit): voer een rechtvaardigingstoets uit om te bepalen of het geconstateerde verschil uit stap 1 te rechtvaardigen is. 
- [Stap 3](#stap-3-voer-een-ethische-wenselijkheidstoets-uit): voer een ethische wenselijkheidstoets uit om te bepalen of het geconstateerde verschil uit stap 1 ethisch wenselijk is. 

Voor alle stappen geldt dat het belangrijk is om de gemaakte keuzes en afwegingen zorgvuldig te onderbouwen en te documenteren. De 3 stappen worden hieronder verder toegelicht. 

!!! note ""Opmerking"" 

    Deze maatregel is in ieder geval van toepassing op natuurlijke personen. Voor andere rechtspersonen zoals bedrijven kan dit ook van toepassing zijn. Denk bijvoorbeeld aan een gelijke behandeling tussen eenmanszaken en grotere bedrijven. 

### Stap 1: Analyseer of er sprake is van bias
In deze stap is het doel om te bepalen in welke mate er sprake is van een systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen. 
Dit verschil kan zowel op een [directe als een indirecte manier](../../onderwerpen/bias-en-non-discriminatie.md#herken-bias) ontstaan. 

#### Toetsen op direct onderscheid
Toetsen op direct onderscheid is in vergelijking tot toetsen op indirect onderscheid relatief eenvoudig. 

:material-arrow-right: Bepaal of de inputvariabelen die gebruikt worden leiden tot een direct onderscheid op basis van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid[^1] of burgelijke staat. 

Het is niet mogelijk om een uitputtend overzicht te geven van alle selectiecriteria die mogelijk tot direct onderscheid op één van deze gronden leiden. 
Wel is duidelijk dat verschillende criteria verband houden met bijvoorbeeld nationaliteit of ras. Gebruik van deze factoren wordt dan gezien als direct onderscheid en is verboden. De volgende criteria duiden in ieder geval (niet limitatief) op een onderscheid op ras[^2]: huidskleur, eventueel andere geracialiseerde uiterlijke kenmerken zoals gezicht of haar, etniciteit, etnische achtergrond, allochtoon/autochtoon, migratieachtergrond, buitenlandse afkomst of nationale oorsprong, specifiek benoemde afkomst (bijv. Marokkaans, Antilliaans etc.), ‘niet-Westers’ klinkende naam, ‘Roma’ of ‘woonwagenbewoners’.

Wel zijn in de jurisprudentie verschillende voorbeelden en aanknopingspunten te vinden. 
Zo staat vast dat selectie op basis van fysieke etnische kenmerken, zoals huidskleur, direct onderscheid op grond van ras oplevert[^2].
Een ander voorbeeld is dat onderscheid op grond van een niet-westers klinkende naam direct onderscheid op grond van afkomst (en dus ras) oplevert[^2].

[^1]: Er is een wetsvoorstel om de term 'hetero- of homoseksuele gerichtheid' in de Algmemene wet gelijke behandeling (Awgb) te wijzigingen in 'seksuele gerichtheid'. Met deze wijziging sluit de Awgb aan bij een eerdere wijziging van artikel 1 van de Grondwet. 

[^2]: Zie voor meer informatie het [Toetsingskader Risicoprofilering](https://publicaties.mensenrechten.nl/publicatie/4093c026-ae41-4c1d-aa78-4ce0e205b5de) van het College voor de Rechten van de Mens. 

#### Toetsen op indirect onderscheid
Ook selectiecriteria die op het eerste gezicht geen enkele link lijken te hebben met een discriminatiegrond kunnen leiden tot indirect onderscheid op grond van een discriminatiegrond. 
Enkele voorbeelden van zulke 'ogenschijnlijk neutrale' selectiecriteria die verband hebben met ras of nationaliteit zijn: postcode, hoogte van het inkomen, kenteken, familielid in het buitenland, laaggeletterdheid. 
Indirect onderscheid is in vergelijking met direct onderscheid lastiger te signaleren en te voorkomen. 
Daarom is het belangrijk jouw algoritmische toepassing [regelmatig te analyseren](7-mon-07-plan-continue-monitoring.md) op eventueel indirect onderscheid. 
Het toetsen op indirect onderscheid bestaat uit 5 stappen:

1. **Bepaal wat de [kwetsbare groepen](2-owp-07-afwegen-grondrechten.md) zijn.**
Eventueel kan dit aangevuld worden op basis van de discriminatiegronden uit non-discriminatie wetgeving. Of andere groepen waarvoor verschillen in behandeling ethisch onwenselijk zijn.

2. **Bepaal wat ""verschillen in behandeling"" betekent in de context van het algoritme.**
In deze stap is het belangrijk om voorafgaand aan de daadwerkelijke analyse met een [brede groep stakeholders](1-pba-04-betrek-belanghebbenden.md) te bepalen wat 'eerlijk' en 'rechtvaardig' wordt bevonden in de context van het betreffende algoritme. 
Er zijn veel verschillende manieren waarop je kan kijken naar onderscheid bij het gebruik van algoritmes. Voorbeelden van manieren waarop je naar onderscheid kan kijken zijn:

    - **Onderscheid op basis van gelijke uitkomsten (representatie)**. 
    De belangrijkste vraag die hier mee beantwoord wordt is: hebben personen uit verschillende groepen gelijke kans om geselecteerd te worden door het algoritme? Of is er sprake van een over- of ondervertegenwoording van bepaalde groepen in de selectie ten opzichte van de betreffende populatie?
    - **Onderscheid op basis van gelijke prestaties (fouten)**. 
    De belangrijkste vraag die hier mee beantwoord wordt is: presteert het algoritme gelijk voor personen uit verschillende groepen? Met andere woorden: maakt het algoritme vaker fouten bij bepaalde groepen? Dat kan er eventueel toe leiden dat bepaalde groepen vaker onterecht wel of niet geselecteerd worden door het algoritme. 

    Om te toetsen of er sprake is van onderscheid op basis van gelijke prestaties, is het noodzakelijk om [de prestaties van het algoritme goed te analyseren](5-ver-01-functioneren-in-lijn-met-doeleinden.md). 
    In het geval van classificatie is het daarvoor nodig om een zogeheten *confusion matrix* op te stellen. 
    Een confusion matrix is een tabel waarin de voorspellingen van het algoritme worden vergeleken met de werkelijke waarden (de *ground truth*). 

    De verschillende maten/metrieken waarop gekeken kan worden naar onderscheid, worden in de (wetenschappelijke) literatuur ook wel *fairness metrieken* genoemd. 
    Veel van deze metrieken kunnen op basis van de confusion matrix berekend worden. 
    Een hulpmiddel om de meest passende metrieken te kiezen in jouw situatie is de [Fairness tree](https://openresearch.amsterdam/en/media/inline/2022/7/14/fairness_handbook.pdf). 

    Door te denken vanuit verschillende perspectieven, zullen er in de praktijk meerdere metrieken van belang zijn. 
    Het kan echter voorkomen dat deze metrieken elkaar tegenspreken. 
    Maak een duidelijke prioritering van de verschillende metrieken om afwegingen te maken tussen de verschillende opvattingen van eerlijkheid. 

3. **Verzamel de benodigde data die nodig is om bovenstaande groepen te bepalen.**
Bepaal welke data nodig is om te analyseren of er verschillen zijn tussen bepaalde groepen. 
In veel gevallen zal data nodig zijn die demografische en beschermde kenmerken van groepen omschrijft. 
Het verzamelen en verwerken van deze data kan in strijd zijn met privacy vereisten uit bijvoorbeeld de [Algemene Verordening Gegevensbescherming](../vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt.md).
Het is daarom van belang om duidelijk afwegingen te maken tussen privacy en het analyseren van bias die rekening houdt met de juridische en ethische vereisten.

    !!! info ""Uitzondering voor hoog risico AI-systemen""

        De AI-verordening biedt een uitzondering voor het verwerken van bijzondere categorieën persoonsgegevens voor het monitoren, opsporen en corrigeren van bias bij AI-systemen met een hoog risico. Zie [artikel 10.5, AI-verordening](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3348-1-1). 

    Om de data op een veilige en rechtmatige manier te gebruiken voor een biasanalyse dient de data van voldoende kwaliteit te zijn. 
    Denk hier goed na of de data eventuele bias bevat die kan duiden op een bepaalde vooringenomenheid in de biasanalyse zelf (historische bias of representatie bias). 
    De data dient bijvoorbeeld voldoende actueel en volledig te zijn.

    Voor sommige groepen zal het onmogelijk zijn om te beschikken over data van voldoende kwaliteit om zorgvuldig te toetsen op bias. 
    De laaggeletterdheid van burgers of personen is bijvoorbeeld lastig meetbaar en in veel gevallen niet beschikbaar. 
    Bepaal in zo'n situatie [of er andere mogelijkheden zijn deze groepen te helpen](2-owp-07-afwegen-grondrechten.md), of er andere mogelijkheden zijn om eventuele ongelijke behandeling bij deze groepen te constateren. 
    Bijvoorbeeld door hierop te monitoren in de klacht- en bezwarenprocedure. 

4. **Bereken de verschillen in behandeling en/of uitkomsten van het algoritme**.
Bepaal of er sprake is van een onderscheid en of dit significant is. Er zijn verschillende open source softwarepakketten die je hierbij kunnen ondersteunen, zoals [fairlearn](https://fairlearn.org/), [Aequitas](https://github.com/dssg/aequitas), [fairml](https://cran.r-project.org/web/packages/fairml/index.html), [fairness](https://cran.r-project.org/web/packages/fairness/index.html) of [AI Fairness 360](https://github.com/Trusted-AI/AIF360).

5. **Probeer te verklaren hoe het geconstateerde onderscheid is ontstaan**.
Als er in de vorige stap een significant onderscheid is geconstateerd, is het belangrijk om na te gaan hoe en waar in het proces dit onderscheid is ontstaan. 
Dit kan bijvoorbeeld ontstaan door:
    - Een vorm van bias in de onderliggende inputdata. Je kan hierbij denken aan: 
        - Historische bias: in hoeverre beschrijft de data de huidige situatie?
        - Representatie bias: is de data waarop getraind wordt representatief voor de bijbehorende populatie? Zijn trends uit de gebruikte data generaliseerbaar naar de totale populatie?
        - Meetbias: beschrijven de inputvariabelen wel wat ze moeten beschrijven? In hoeverre zijn dit benaderingen waarbij eventuele factoren worden weggelaten?
    - Een vorm van bias in het proces na afloop van het algoritme:
        - Is er sprake van automatiseringsbias of bevestigingsbias in de (handmatige) beoordeling?

:material-arrow-right: Wanneer duidelijker is hoe de geconstateerde bias is ontstaan, is het goed om te verkennen of er mogelijkheden zijn om dit (in de toekomst) te voorkomen. 

Het is belangrijk hier [een brede groep aan belanghebbenden bij te betrekken](1-pba-04-betrek-belanghebbenden.md). 
De oorzaken van bias komen in veel gevallen uit de 'echte wereld', waarbij patronen in datasets historische, demografische en sociale verschillen weerspiegielen. 
Het verklaren en voorkomen van bias vraagt daarmee niet alleen om technische oplossingen, maar het is belangrijk de hele socio-technische omgeving waarin het algoritme wordt ingezet mee te nemen. 

### Stap 2: Voer een rechtvaardigingstoets uit
Wanneer er in [Stap 1](#stap-1-analyseer-of-er-sprake-is-van-bias) is geconstateerd dat er sprake is van een onderscheid, dient de volgende vraag beantwoord te worden:

> Valt dit onderscheid te rechtvaardigen?

Een geconstateerd systematisch onderscheid is niet altijd fout en is niet altijd verboden, maar het vraagt wel altijd om aandacht en zorgvuldigheid. 
Het geconstateerde onderscheid kan in bepaalde situaties en onder bepaalde strikte voorwaarden gerechtvaardigd zijn:

- Voor **direct onderscheid** kan er bijvoorbeeld sprake zijn van een wettelijke uitzondering die het gemaakte onderscheid toelaat. 
- Voor **indirect onderscheid** geldt dat behalve een wettelijke uitzondering er ook een **objectieve rechtvaardiging** kan bestaan, waarmee het geconstateerde onderscheid in bepaalde gevallen toelaatbaar kan zijn. 

Vier subvragen die hierbij beantwoord moeten worden zijn:

- Streeft het in te zetten algoritme een legitiem doel na?
- Is het in te zetten algoritme geschikt om het doel te bereiken?
- Is het algoritme noodzakelijk? Zijn er geen redelijke, minder bezwaarlijke alternatieven?
- Is het algoritme alles afwegend proportioneel?

Wanneer er geen rechtvaardiging is voor het gemaakte onderscheid, spreken we van een verboden direct of indirect onderscheid, ofwel discriminatie. 
Het algoritme mag in dat geval niet gebruikt worden.

Voor meer toelichting over het uitvoeren van een rechtvaardigingstoets, verwijzen we naar het [Toetsingskader Risicoprofilering](https://publicaties.mensenrechten.nl/publicatie/4093c026-ae41-4c1d-aa78-4ce0e205b5de) van het College voor de Rechten van de Mens. 

### Stap 3: Voer een ethische wenselijkheidstoets uit
Bepaal of het geconstateerde onderscheid uit [Stap 1](#stap-1-analyseer-of-er-sprake-is-van-bias) ethisch wenselijk is. Dit hangt samen met de algemene wenselijkheid van de inzet van het algoritme.  


In sommige gevallen kan het zo zijn dat ondanks dat er een objectieve rechtvaardiging bestaat voor het gemaakte onderscheid, dit vanuit ethisch perspectief toch onwenselijk is. 
Bepaal [met een grote groep belanghebbenden](1-pba-04-betrek-belanghebbenden.md) wat eventuele (nadelige) effecten van het gemaakte onderscheid kunnen zijn, of jullie dit eerlijk vinden en of er eventuele alternatieven zijn. 

!!! note ""Opmerking""

    De bepaling over wat eerlijk is en wat ethisch wenselijk is kan in sommige gevallen ook politiek bevonden worden. Houd hier rekening met de politiek-bestuurlijke verantwoordelijkheden en zorg indien nodig dat de [politiek-bestuurlijke verantwoordelijkhden](0-org-04-politiek-bestuurlijke-verantwoordelijkheid.md) duidelijk zijn. 
","Wanneer er geen zorgvuldige analyse naar (onwenselijke) bias is uitgevoerd bestaat het risico dat het gebruik van het algoritme discriminerende effecten met zich meebrengt. 
Dit kan leiden tot een ongelijke behandeling van burgers met eventuele schade voor betrokkenen.
","['urn:nl:ak:ver:grw-02', 'urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-06']","- [Toetsingskader Algoritmes Algemene Rekenkamer, 2.18, 2.19, 3.08, 3.09](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Onderzoekskader Algoritmes Auditdienst Rijk, DM.16, DM.17, DM.18, DM.20, DM.21, DM.22](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023) 
- [Toetsingskader risicoprofilering – Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens](https://publicaties.mensenrechten.nl/publicatie/4093c026-ae41-4c1d-aa78-4ce0e205b5de)
- [Handreiking non-discriminatie by design](https://www.rijksoverheid.nl/documenten/rapporten/2021/06/10/handreiking-non-discriminatie-by-design)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/index.html
urn:nl:ak:mtr:ver-04,Zorg voor een representatieve testomgeving,"Test het algoritme in verschillende scenario’s en omstandigheden die zoveel mogelijk overeenkomen met de operationele context. 
",['technische-robuustheid-en-veiligheid'],['verificatie-en-validatie'],"['ontwikkelaar', 'projectleider']","Representatieve testomstandigheden zijn essentieel om een goed onderbouwd vertrouwen te krijgen in de prestaties en de toegevoegde waarde van het algoritme. 
Houd daarbij bijvoorbeeld rekening met voldoende variatie en ruis die voorkomt tijdens het operationeel gebruik of de verschillende type gebruikers die interacteren met het algoritme. 
Neem bij het inrichten van een testomgeving de volgende aspecten mee:

- De factoren uit [de impactanalyse](2-owp-06-impactanalyse.md).
- Zorg voor een testomgeving waarin je betrouwbaarheid, nauwkeurigheid en reproduceerbaarheid kan evalueren.
- Analyseer de verschillen tussen de dataset en operationeel gebruik.
- Wanneer een gebruikerstest wordt gedaan, zorg voor een representatieve groep gebruikers. Denk bijvoorbeeld aan verschillend enthousiasme en verschillend niveau van digitale/ AI-vaardigheden. 
- Neem verschillende typen (cyber)aanvallen mee.
- Valideer dat de testomgeving de risicoanalyse en het beslissingsproces ondersteunt. 

Voorbeelden om bij te dragen aan een representatieve testomgeving:

- Voeg extra ruis toe aan de testdata.
- Test op gevallen die niet passen in de verdeling van variabelen waarop een classificatiemodel is getraind (de *out-of-distribution* scenario’s). 
- [Test op uitzonderlijke gevallen (*outliers*) en minderheidsgroepen](5-ver-03-biasanalyse.md)
- Stel specifieke testscenario’s op. Dit kan bijvoorbeeld met de [‘What if tool’ van Google](https://ieeexplore.ieee.org/abstract/document/8807255), om specifieke data scenario’s voor een machinelearning model te onderzoeken.
","Als het algoritme niet getest wordt, of getest wordt in niet-representatieve omstandigheden, kan er een onterecht vertrouwen in het algoritme ontstaan. 
De evaluatie geeft dan goede resultaten, maar het model zal minder presteren in de operationele context waar meer variatie aanwezig is. 
","['urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-33']","- [Bo Li, et al., Trustworthy AI: From Principles to Practices](https://arxiv.org/abs/2110.01167)
- [Onderzoekskader Auditdienst Rijk, DM.7](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/index.html
urn:nl:ak:mtr:ver-05,Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid,"Stel regelmatig vast dat wetgeving en (lokaal) beleid correct is vertaald naar de uitvoering van het te ondersteunen werkproces en de onderliggende systemen. 
 ","['governance', 'transparantie']","['verificatie-en-validatie', 'monitoring-en-beheer']",['jurist'],"- Systemen die overheidsorganisaties inzetten voor bijvoorbeeld het verlenen van subsidies, vergunningen of bijstandsuitkeringen moeten de regels en processtappen volgen die in wetgeving zijn voorgeschreven.
- Er is een vertaling nodig van deze regels en processtappen naar de uitvoering van het werkproces, het datagebruik en onderliggende systemen.
- Algoritmes moeten ook voldoen aan deze regels en processtappen.
- Als algoritmes worden ontwikkeld, moet worden onderzocht wat deze regels zijn en hoe deze moeten worden toegepast bij het ontwikkelen van algoritmes.
- Het moeten voldoen aan wetgeving en beleid kan dus in zekere zin 'begrenzend' werken op wat mag worden gedaan met algoritmes. Dit is mede afhankelijk van de risico classificatie van de specifieke toepassing. 
- Voor algoritmes, bijvoorbeeld regelgebaseerde rekenregels, moet bijvoorbeeld nauwkeurig worden geprogrammeerd in welke gevallen welke bedragen moeten worden uitgekeerd voor een bijstandsuitkering.
- Voor machine learning algoritmes moet bijvoorbeeld worden vastgesteld of de trainingsdata wel tot stand is gekomen in lijn met wetgeving en vastgesteld beleid (datakwaliteit) en welke verbanden en patronen (inputvariabelen) al dan niet passend zijn bij het ondersteunen van wettelijke taken.
 
- Er is een multidisciplinaire samenwerking nodig tussen de proceseigenaar, gebruikers, juristen, informatieanalisten en ontwikkelaar om deze vertaling zorgvuldig en doorlopend te maken.
- Voorafgaand aan het (laten) ontwikkelen van een algoritme moet dit zijn uitgevoerd.
- De toegepaste 'business rules' en de verwerkte data voor de uitvoering van het te ondersteunen werkproces met algoritmes moeten worden onderzocht en beoordeeld.
- Diepgaande procesanalyses (bijv. BPMN niveau Analytisch) en procesbeschrijvingen kunnen hierbij ondersteunen. 
- Als blijkt dat een werkproces niet (meer) conform (gewijzigde) wetgeving of beleid wordt uitgevoerd, dan moet worden beoordeeld of de verworven data of welke deel van de data geschikt is voor het ontwikkelen een algoritme.
- Het is dan raadzaam om de uitvoering van het betreffende werkproces en de werking van onderliggende systemen eerst te 'herstellen' en om hiermee een nieuw datafundament te creëeren (eerst een groot aantal zaken behandelen) die later als trainingsdata kan worden gebruikt. 
","Een beslissing of besluit wordt niet conform wetgeving genomen en is daarmee onrechtmatig als er geen goede vertaling wordt gemaakt van wetgeving naar het algoritme. 
","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:aia-05']","- [Wetsanalyse](https://wendbarewetsuitvoering.pleio.nl/page/view/918f9a63-4383-410e-b526-4b8fb67b1c40/het-boek-wetsanalyse)
- [Onderzoekskader Auditdienst Rijk, DM.15](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 2.05](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-05-vertaling-wetgeving-naar-systeem/index.html
urn:nl:ak:mtr:ver-06,Evalueer de betrouwbaarheid van het algoritme,"Evalueer de betrouwbaarheid van het algoritme door het algoritme te testen op verschillende input en in verschillende situaties. 
",['technische-robuustheid-en-veiligheid'],"['ontwikkelen', 'verificatie-en-validatie', 'monitoring-en-beheer']",['ontwikkelaar'],"De betrouwbaarheid van een algoritme omschrijft of het algoritme in staat is om onder verschillende omstandigheden en met alle mogelijke input tot een correcte uitkomst te komen. 
In sommige gevallen is het wenselijk om duidelijk aan te geven wat de onzekerheid is van een uitkomst, dat het juiste antwoord niet bepaald kan worden of dat er kans is op fouten.  

Om de betrouwbaarheid te evalueren kan je de volgende stappen doorlopen:

1. [Bepaal methodes en metrieken](#bepaal-methodes-en-metrieken).
2. [Zorg voor een representatieve testset](#zorg-voor-een-representatieve-testset).
3. [Bepaal welke mate van betrouwbaarheid noodzakelijk is](#bepaal-welke-mate-van-betrouwbaarheid-noodzakelijk-is).
4. [Bepaal interventies voor als het restrisico hoger is dan acceptabel](#bepaal-interventies-voor-als-het-restrisico-hoger-is-dan-acceptabel).
5. [Zorg en controleer of de betrouwbaarheid van een uitkomst wordt meegegeven in de output](#zorg-en-controleer-of-de-betrouwbaarheid-van-een-uitkomst-wordt-meegegeven-in-de-output).

### Bepaal methodes en metrieken
Bepaal met welke methodes je betrouwbaarheid wil evalueren en welke metrieken je daarvoor wilt gebruiken.
De metrieken voor prestatie kunnen gelijk zijn aan die van [nauwkeurigheid](5-ver-02-evalueer-nauwkeurigheid.md#metrieken), alleen gaat het om de score hierop in een onbekende situatie. 
Het testen van betrouwbaarheid kan bijvoorbeeld door precisie of recall te meten onder extreme omstandigheden of met ruis in de data. 

!!! info ""Methodes om te testen op betrouwbaarheid""

    Afhankelijk van het type algoritme zijn er verschillende methodes om betrouwbaarheid te testen. 
    In de literatuur gaat het ook over generalisatie wanneer we spreken over het correct presteren op nieuwe of minder voorkomende inputs en omstandigheden. 
    Hieronder enkele voorbeelden van methoden die gebruikt kunnen worden:

    - De *monkey test* is een manier om voor willekeurige, invalide of onverwachte inputs de werking van het algoritme te testen. Het idee is om een onvoorspelbare gebruiker (of een script) willekeurige acties te laten uitvoeren om te kijken hoe het systeem erop reageert. 
    - Door een *out-of-sample test* kan worden getest hoe een machine-learning algoritme presteert bij een dataset verdeling die niet in de training is meegegeven. 
    - Door *stresstesten* test je de prestatie van het algoritme onder extreme omstandigheden of ruis in de data. 
    - Met synthetische data kunnen goed uitlegbare en controleerbare distributieshifts worden gesimuleerd om te testen of het algoritme in een onbekende situatie, waar geen data van bruikbaar of beschikbaar is, presteert. 
    - De [AI Blindspots kaartenset](https://data-en-maatschappij.ai/tools/ai-blindspots-2.0) kan helpen om risico’s voor betrouwbaarheid (en specifiek [bias](../../onderwerpen/bias-en-non-discriminatie.md)) te identificeren. 

Pas de methodes en metrieken aan op de ontwerpkeuzes, zoals de context waarin het algoritme gebruikt wordt en het [soort algoritme](2-owp-05-soort-algoritme.md). 
Onderzoek of er specifieke situaties of omstandigheden zijn waarvan bekend is dat deze kunnen variëren. 

!!! example ""Voorbeeld""

    Analyseer welke veranderingen of wisselingen in de [inputdata](2-owp-11-gebruikte-data.md) er kunnen plaatsvinden. Bijvoorbeeld door economische schommelingen of door veranderingen in gebruikersgedrag. Test of het algoritme goed blijft presteren onder deze omstandigheden. 

!!! example ""Voorbeeld""

    De verdeling van de inputdata kan invloed hebben op de prestaties van een machine-learning algoritme (distributieshift). Test hoe het algoritme presteert onder andere verdelingen van de inputdata. 

### Zorg voor een representatieve testset
Zorg dat er een [representatieve testset](5-ver-04-representatieve-testomgeving.md) beschikbaar is waarin het algoritme kan worden getest in verschillende scenario's. Test het algoritme in verschillende omstandigheden:

- gebruikers
- omgeving
- interface
- verschillende datasets

Test je algoritme op generaliseerbaarheid van de uitkomsten buiten de standaard omgeving. 

### Bepaal welke mate van betrouwbaarheid noodzakelijk is
- Bedenk onder welke variaties het systeem betrouwbaar moet werken en hoe goed het moet kunnen werken onder rand- of uitzonderlijke gevallen. 
- Afhankelijk van de toepassing moeten resultaten altijd dezelfde uitkomst geven of niet ([reproduceerbaarheid](4-owk-07-reproduceerbaarheid.md)). In het geval van generatieve AI hoeft het antwoord bijvoorbeeld niet altijd exact hetzelfde te zijn. 
- Houd hierbij aandacht voor de afweging tussen [nauwkeurigheid](5-ver-02-evalueer-nauwkeurigheid.md) en betrouwbaarheid. Een model met hoge nauwkeurigheid op de testset kan vaak slechter generaliseren naar situaties net buiten de test set (overfitting). 

### Bepaal interventies voor als het restrisico hoger is dan acceptabel
Bepaal wat er moet gebeuren wanneer de betrouwbaarheid niet voldoende is. Hiervoor zijn verschillende mogelijkheden:

- Verder ontwikkelen aan het algoritme en andere maatregelen treffen om het restrisico acceptabel te maken. Bijvoorbeeld door:

    - meer [menselijke controle](../../onderwerpen/menselijke-controle.md) toe te voegen 
    - een ander [soort algoritme](2-owp-05-soort-algoritme.md) of [techniek](2-owp-04-gebruikte-techniek.md) te gebruiken. 
    - bij machinelearning algoritmes kan je overfitting voorkomen door [verschillende trainingsdatasets en testdatasets te gebruiken](3-dat-07-training-validatie-en-testdata.md), zoals bij [k-fold-cross-validation](3-dat-07-training-validatie-en-testdata.md#k-fold-cross-validation). 
    - door (hyper)parameters aan te passen kan het algoritme worden aangepast zodat het beter presteert in verschillende testsituaties. 

- [Te stoppen met de ontwikkeling en/of het gebruik van het systeem](../../levenscyclus/uitfaseren.md). 

### Zorg en controleer of de betrouwbaarheid van een uitkomst wordt meegegeven in de output
Voorspellingen of uitkomsten van een algoritme kunnen onzeker zijn. Zorg dat de (on)zekerheid van een uitkomst wordt meegegeven in de output van een algoritme. 
Dat kan bijvoorbeeld door een foutmarge mee te geven. 
In veel gevallen kan het wenselijk zijn dat het systeem aangeeft wanneer een uitkomst te onzeker is of soms zelfs geen antwoord geeft vanwege de onzekerheid. 
Dit kan bijdragen aan het vertrouwen in het algoritme. 

### Zorg voor continue monitoring op betrouwbaarheid
Zorg dat het algoritme continu wordt [gemonitored](../../levenscyclus/monitoring-en-beheer.md) op de betrouwbaarheid en de prestaties van het systeem. Maak gebruik van periodieke updates en [valideer regelmatig de kwaliteit van de gebruikte data](3-dat-01-datakwaliteit.md). 
","Een onbetrouwbaar algoritme kan in een nieuwe of onverwachte situatie de verkeerde uitkomsten geven. 
",['urn:nl:ak:ver:aia-10'],"- [Bo Li, et al., Trustworthy AI: From Principles to Practices](https://arxiv.org/abs/2110.01167)
- [Pablo Soldati, et al., Design Principles for Model Generalization and Scalable AI Integration in Radio Access Networks](https://arxiv.org/abs/2306.06251v2)
- [Jiashuo Liu, et al., Towards Out-Of-Distribution Generalization: A Survey](https://arxiv.org/abs/2108.13624)
- [Kenniscentrum Data & Maatschappij - Tool: AI Blindspots 2.0](https://data-en-maatschappij.ai/tools/ai-blindspots-2.0)
- [Kaiyang Zhou, et al., Domain Generalization: A Survey](https://ieeexplore.ieee.org/abstract/document/9847099)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/index.html
urn:nl:ak:mtr:imp-01,Stel een werkinstructie op voor gebruikers,"Stel een werkinstructie op voor gebruikers zodat zij weten hoe het algoritme correct gebruikt kan worden en hoe ze om kunnen gaan met de (veiligheids)risico's. 
","['menselijke-controle', 'transparantie', 'governance']",['implementatie'],"['projectleider', 'beleid-en-advies']","Het is belangrijk dat gebruikers een werkinstructie ontvangen met informatie over hoe zij met het algoritme kunnen en moeten werken. Hierin worden zaken beschreven als:

- Op wat voor manier het algoritme ondersteunt bij het uitvoeren van (wettelijke) taken en hoe het past in de werkwijze. Maak hierbij een duidelijke keuze rondom de rol van het systeem/algoritme bij de werkwijze van medewerkers. 
- Wat de mogelijkheden en beperkingen zijn bij het gebruik van het algoritme. Op welke manieren mag het algoritme gebruikt worden? En op welke manieren niet? Wat zijn de grenzen van toepasbaarheid? En wat zijn de voorwaarden waaronder het model gebruikt kan worden en waaronder niet?
- Maak duidelijke werkinstructies en protocollen om te voorkomen dat beslissingen, gebaseerd op de output van het systeem, door (automation) bias worden beïnvloed.
- Welke informatie mag er worden ingevoerd in het systeem? En welke informatie niet?
- Wat de impact is van het gebruik van het algoritme op de samenleving en individuen (denk aan [fundamentele rechten](../../onderwerpen/fundamentele-rechten.md) en [energieverbruik](7-mon-06-meten-milieu-impact.md) of dat een besluit met rechtsgevolgen wordt genomen).
- Zorg dat medewerkers weten waar ze eventuele problemen met het systeem kunnen melden. Bespreek regelmatig met de betrokken medewerkers welke uitdagingen of verbeteringen zij zien bij het gebruik van het systeem.
- Wat de risico's zijn die aan het gebruik verbonden zijn. Denk aan:

    - verschillende vormen van [bias](../../onderwerpen/bias-en-non-discriminatie.md), zoals automation bias, 
    - foutieve beslissingen
    - veiligheidsrisico's.

- Welke maatregelen zijn getroffen om deze risico's te beperken (bijv. [bias analyse](5-ver-03-biasanalyse.md), ['stopknop' ingebouwd](4-owk-02-stopzetten-gebruik.md), transparantie over de output).
- Hoe de output van het algoritme moet worden geïnterpreteerd en hoe het algoritme tot deze beslissing is gekomen. Zorg dat de output op een eenduidige manier kan worden geïnterpreteerd. 
- Hoe het werkproces kan worden uitgevoerd, zonder ondersteuning van het algoritme.
- Hoe kan je weten dat het systeem niet (meer) goed werkt? 
- Welke protocollen er zijn als incidenten zich voordoen.
- Waar je op moet letten om veiligheidsrisico's te verminderen. 
- Welke waarschuwingen het systeem kan en zou moeten geven op basis van [continue monitoring](7-mon-07-plan-continue-monitoring.md). Hoe er omgegaan moet worden bij deze waarschuwingen. 
	
Denk hierbij na over het eventueel bijscholen van medewerkers als het kennisniveau nog onvoldoende is om de werkinstructies goed te begrijpen. 
","Het algoritme wordt onjuist gebruikt of verkeerd geïnterpreteerd door gebruikers waardoor onjuiste belissingen of besluiten worden genomen. Als gebruikers niet weten hoe ze veilig moeten werken, kunnen ze (onbewust) toegang bieden aan kwaadwillenden. 
","['urn:nl:ak:ver:aia-01', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-28', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:grw-02', 'urn:nl:ak:ver:aia-21']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/index.html
urn:nl:ak:mtr:imp-02,Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie’ te controleren,"Uitvoeren van aselecte steekproeven als aanvulling wanneer gebruik gemaakt wordt van risicogestuurde selectie.
","['bias-en-non-discriminatie', 'technische-robuustheid-en-veiligheid']","['dataverkenning-en-datapreparatie', 'implementatie', 'monitoring-en-beheer']",['ontwikkelaar'],"Aselecte steekproeven kunnen een waardevolle toevoeging zijn bij risicogestuurde selectie.

Het toevoegen van aselecte steekproeven maakt het mogelijk om over tijd te beoordelen of het algoritme nog voldoende effectief is.
Populaties veranderen immers over tijd. Een selectie die het meest effectief was bij ingebruikname kan over tijd dat niet meer zijn.
Door alleen risicogestuurd te selecteren wordt dit niet inzichtelijk, omdat bepaalde groepen zelden tot nooit gecontroleerd worden.
Door de aanvullende mogelijkheid van monitoring, kan over tijd beoordeeld worden of er nog steeds sprake is van de meest proportionele vorm.
Als dat niet zo is, kan bijvoorbeeld gekozen worden voor aanpassing van de risicogestuurde selectie of overgaan op volledig aselect.

De maatregel gaat daarmee niet direct discriminatie tegen, omdat er sprake kan zijn van discriminatie ongeacht de effectiviteit van de risicogestuurde selectie.
Een lagere effectiviteit maakt het echter lastiger het gemaakte onderscheid te rechtvaardigen.

Het gebruik van een aselecte steekproef is in veel gevallen essentieel om het systeem te kunnen toetsen op vooringenomenheid. 
Een aselecte steekproef geeft ook inzicht in een deel van de populatie dat doorgaans niet geselecteerd en behandeld wordt door het betreffende risicogestuurde algoritme. 
Dit maakt het mogelijk om te toetsen of er sprake is van een over- of ondervertegenwoordiging van bepaalde groepen, of om te bepalen of bepaalde typen fouten vaker gemaakt worden in bepaalde groepen.

Bij AI-systemen die verder leren op basis van verkregen data kan daarnaast sprake zijn van een reinforcing feedbackloop, omdat zij geen representatieve data krijgen.
Het toevoegen van aselecte steekproeven kan deze feedbackloop doorbreken.

Het is aan te bevelen om, waar mogelijk, behandelaars niet in te lichten of een casus toegewezen is op basis van een risicogestuurd of aselecte selectie.
Daardoor wordt beperkt dat een behandelaar met tunnelvisie een zaak bekijkt.
De behandelaar weet immers dat er tussen de selecties zaken zitten waar niet sprake is van verhoogd risico.
Op die manier kan automation bias beperkt te worden.
Niet in alle gevallen zal dit mogelijk zijn, omdat de behandelaar ook uit andere aangeleverde gegevens kan halen op basis waarvan een casus geselecteerd is.
Het is dan van belang om op andere wijze de tunnelvisie tegen te gaan.

De precieze inzet van aselecte steekproeven zal afhangen van de context.
Zo verschilt het per context hoeveel zaken aselect geselecteerd moeten worden.
Bepaal welke groepen er precies vergeleken dienen te worden en bepaal aan de hand daarvan een passende steekproefgrootte zodanig dat er gesproken kan worden over statistische significantie. 

In sommige gevallen zal de impact van een selectie ook dusdanig zijn dat het zich niet leent voor aselecte steekproef.
Zo kan een aselecte steekproef wel de basis zijn voor bureauonderzoek, maar mogelijk niet als enige basis voor een huisbezoek.
Deze belangenenafweging moet per context gemaakt worden.
","* Historical bias
* Representation bias
* Automation bias en Reinforcing Feedback Loop
","['urn:nl:ak:ver:aia-27', 'urn:nl:ak:ver:grw-02', 'urn:nl:ak:ver:aia-10']",,https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-02-aselecte-steekproeven/index.html
urn:nl:ak:mtr:imp-03,Richt de juiste menselijke controle in van het algoritme,"Richt (technische) controlemechanismen in voor menselijke tussenkomst (of: menselijke controle) waarmee de output van een algoritme kan worden gecontroleerd.

","['menselijke-controle', 'governance']","['ontwerp', 'implementatie', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies']","Algoritmes ondersteunen vaak beslissingen en besluitvorming van overheidsorganisaties. Deze beslissingen of besluiten kunnen betrokkenen in [aanmerkelijke mate raken of zelfs rechtsgevolgen](../vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming.md) hebben. Omdat algoritmes niet foutloos zijn, is het belangrijk dat een mens controleert wat een algoritme doet en, waar nodig, corrigeert. Dit proces heet 'menselijke tussenkomst' en moet betekenisvol zijn, niet slechts symbolisch.

Het inrichten, monitoren en evalueren van menselijke controle is cruciaal om te voorkomen dat algoritmes negatieve effecten veroorzaken of de menselijke autonomie ondermijnen.

Betekenisvolle menselijke controle houdt in dat:

- Het toezicht wordt uitgevoerd door iemand die bevoegd en bekwaam is om een beslissing of besluit te wijzigen.
- Automatische aanbevelingen niet klakkeloos worden overgenomen. Bijvoorbeeld: een systeem dat standaard een suggestie accepteert door een enkele klik voldoet hier niet aan.
- De vormen van menselijke tussenkomst al in een vroeg stadium, bijvoorbeeld in de ontwerpfase, worden vastgesteld op basis van risicoanalyses.
- Gebruikers voldoende kennis, tijd en verantwoordelijkheid hebben om weloverwogen beslissingen te nemen over het functioneren van algoritmes. Dit betekent ook dat externe factoren, zoals tijdsdruk of onvoldoende informatie, de beoordeling van de output niet mogen beïnvloeden. (zie ook het [onderzoekskader van de ADR, SV.6](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023))

Soms is menselijke tussenkomst minder relevant, zoals bij ‘gebonden bevoegdheden’. Hierbij is weinig tot geen ruimte om een beslissing of besluit aan te passen. Voorbeelden zijn:

- Het opleggen van verkeersboetes onder de Wet administratiefrechtelijke handhaving verkeersvoorschriften (Wahv).
- Het automatisch aanpassen van studiefinanciering op basis van inkomenswijzigingen.

Om menselijke tussenkomst goed te organiseren, zijn technische en organisatorische maatregelen nodig. Dit geldt ook wanneer een externe aanbieder de algoritmes levert. In dat geval moet de verantwoordelijke organisatie (gebruiksverantwoordelijke) samen met de aanbieder bepalen hoe menselijke tussenkomst zinvol kan worden ingericht.

### Inrichten van menselijke controle

Er zijn verschillende manieren om menselijke tussenkomst in te richten, afhankelijk van de specifieke toepassing van een algoritme. Hieronder worden vier mogelijkheden beschreven die kunnen worden ingezet, los of in combinatie:

#### 1. Human in the loop
Bij dit model speelt de mens een actieve rol in elke fase van het algoritme. Deze variant geeft de meeste controle en invloed, maar kan leiden tot vertraagde of minder efficiënte besluitvorming, vooral bij real-time of zeer complexe taken waarbij snelheid cruciaal is.
Een voorbeeld van toepassen van human-in-the-loop is het nakijken en beoordelen van de output van een algoritme door een mens, telkens voordat een beslissing wordt genomen. Het verwerken van data gebeurt alleen in opdracht van de mens en verder neemt het algoritme of AI model geen autonome beslissingen. 

#### 2. Human on the loop
Hier behoudt de mens toezicht en kan ingrijpen wanneer dat nodig is om te garanderen dat een model veilig en ethisch opereert. Dit model biedt daardoor een balans tussen autonome besluitvorming en menselijke controle. Het is vooral nuttig in situaties waarin afwijkende keuzes of acties van het algoritme grote gevolgen kunnen hebben. De menselijke operator houdt de werking van het algoritme in de gaten en staat klaar om in te grijpen of beslissingen terug te draaien wanneer nodig.

#### 3. Human above the loop
In dit model houdt de mens toezicht op een hoger niveau, met een focus op strategische en ethische keuzes, in plaats van dat de menselijke operator zich bezighoudt met directe operationele beslissingen. Dit stelt de mens in staat in te grijpen wanneer kritieke morele, juridische of sociale zorgen ontstaan om het model op de langere termijn bij te sturen.  De menselijke tussenkomst is gericht op het bepalen van beleid en de richtlijnen voor algoritmes. Het gaat daarbij niet alleen over het definiëren van operationele procedures maar ook het maken van bepaalde ethische overwegingen, het zorgen voor naleving van regelgeving en het overwegen van de implicaties van de inzet van algoritmes op de lange termijn. 

#### 4. Human before the loop
Hier maakt de mens vooraf ethische en morele afwegingen die in het algoritme zelf worden ingebouwd. Hoewel het model in productie autonoom opereert, zal de menselijke input gedurende de ontwikkeling ervoor zorgen dat het model ook in complexe situaties volgens de juiste (ethische) afwegingen keuzes en acties onderneemt.

Dit model is essentieel in situaties waar menselijk ingrijpen tijdens de uitvoering niet mogelijk is (wanneer er bijvoorbeeld weinig of helemaal geen tijd is om als mens te interveniëren), maar waar ethische keuzes cruciaal blijven. Denk aan bestrijding van zeemijnen of situaties met zelfrijdende auto’s in onvoorspelbare verkeerssituaties (bron: [TNO visiestuk 2022](https://publications.tno.nl/publication/34640024/a05DMs/TNO-2022-visiestuk.pdf)). Deze variant kan ook worden ingezet voor situaties waarin wel nog menselijk ingrijpen mogelijk is. 
","Het niet inrichten van passende menselijke controle leidt tot onverantwoorde inzet van algoritmen en het niet voldoen aan wettelijke vereisten. 
","['urn:nl:ak:ver:avg-10', 'urn:nl:ak:ver:grw-01', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-09', 'urn:nl:ak:ver:aia-21']","
- [Toetsingskader Algoritmes Algemene Rekenkamer, 3.11](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Menselijke tussenkomst | Algoritmes | Algemene Rekenkamer](https://www.rekenkamer.nl/onderwerpen/algoritmes/toetsingskader/ethiek/menselijke-tussenkomst)
- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.5, SV.6](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023) 
- [Advies over geautomatiseerde selectietechniek Pels Rijcken, p.9](https://open.overheid.nl/documenten/6b5b5d5b-fdc1-4333-a11e-f89d3627a0f5/file)
- [Recht op een menselijke blik bij besluiten | Autoriteit Persoonsgegevens](https://www.autoriteitpersoonsgegevens.nl/themas/basis-avg/privacyrechten-avg/recht-op-een-menselijke-blik-bij-besluiten#:~:text=Reactie%20op%20verzoek-,Geautomatiseerd%20besluit,noemen%20dit%20een%20geautomatiseerd%20besluit.)
- Kamerstukken IT 2017-2018, 34 851, nr. (MvT UAVG), p. 120-121
- [Ethics guidelines for trustworthy AI | Shaping Europe’s digital future](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai), deel (64)
- [""Towards Digital Life: Een toekomstvisie op AI anno 2032"" - TNO, 2022](https://publications.tno.nl/publication/34640024/a05DMs/TNO-2022-visiestuk.pdf)
- [Algoritmes afwegen | Rathenau Instituut](https://www.rathenau.nl/nl/digitalisering/algoritmes-afwegen)
-	[Managing supplier delivery reliability risk under limited information: Foundations for a human-in-the-loop DSS - ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S0167923612002886)
-	[Human control of AI systems: from supervision to teaming | AI and Ethics (springer.com)](https://link.springer.com/article/10.1007/s43681-024-00489-4)
-	[Zijn er beperkingen op het gebruik van geautomatiseerde besluitvorming? - Europese Commissie](https://commission.europa.eu/law/law-topic/data-protection/rules-business-and-organisations/dealing-citizens/are-there-restrictions-use-automated-decision-making_nl#:~:text=Example-,Antwoord,is%20of%20hen%20aanzienlijk%20be%C3%AFnvloedt.)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/index.html
urn:nl:ak:mtr:imp-04,Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregister,"
Publiceer het algoritme  in het [Nederlandse Algoritmeregister](../hulpmiddelen/algoritmeregister.md).  
",['transparantie'],"['implementatie', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies']","- De regering wil dat de overheid algoritmes verantwoord gebruikt. Mensen moeten erop kunnen vertrouwen dat algoritmes voldoen aan de waarden en normen van de samenleving.
- Wanneer de overheid open is over algoritmes en hun toepassing kunnen burgers, organisaties en media haar kritisch volgen.
- Impactvolle algoritmes en hoog-risico AI-systemen moeten daarom worden gepubliceerd in het Algoritmeregister.
- In het Algoritmeregister moet uitleg zijn over hoe algoritmes of het proces wat hiermee wordt ondersteund werkt.
- Er is een [Handreiking Algoritmeregister](https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf) opgesteld met informatie over het publiceren van algoritmes in het Algoritmeregister.
- De [Algoritmeregister Publicatiestandaard](https://regels.overheid.nl/standaarden/algoritmeregister-publicatiestandaard) kan overheidsorganisaties ondersteunen bij het helpen invullen van het Algoritmeregister.
- Sommige overheidsorganisaties publiceren hun algoritmes ook in een eigen Algoritmeregister, zodat burgers dit makkelijker kunnen vinden. Bijvoorbeeld het [Algoritmeregister van de Gemeente Rotterdam](https://algoritmeregister.rotterdam.nl/p/Onzealgoritmes), het [Algoritmeregister van de Gemeente Amsterdam](https://algoritmeregister.amsterdam.nl/) of het [Algoritmeregister van het UWV](https://www.uwv.nl/nl/over-uwv/organisatie/algoritmeregister-uwv). 
- Zorg na publicatie dat de informatie in het Algoritmeregister up-to-date blijft en indien nodig regelmatig wordt aangepast. 
- Eventueel kan je meer informatie over het algoritme openbaar beschikbaar stellen. Bijvoorbeeld door het publiceren van de modelcode op een site zoals GitHub of GitLab. 
","Betrokkenen zijn niet op de hoogte dat hun persoonsgegevens worden verwerkt met een algoritme, waardoor zij hier geen controle over hebben. 
","['urn:nl:ak:ver:bzk-01', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:avg-07', 'urn:nl:ak:ver:awb-01']","- [Handreiking Algoritmeregister](https://www.digitaleoverheid.nl/wp-content/uploads/sites/8/2023/12/Handreiking-Algoritmeregister-versie-1.0.pdf)
- [Algoritmeregister Publicatiestandaard](https://regels.overheid.nl/standaarden/algoritmeregister-publicatiestandaard)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 2.11, 3.12, 3.14, 3.16](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag) 
- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.14, PRI.8](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023) 

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/index.html
urn:nl:ak:mtr:imp-05,Vermeld het gebruik van persoonsgegevens in een privacyverklaring,"
 Neem het gebruik van een algoritme op in de privacyverklaring als hierbij persoonsgegevens worden verwerkt.  
","['privacy-en-gegevensbescherming', 'transparantie']",['implementatie'],"['projectleider', 'jurist']","- Door in een privacyverklaring te vermelden welke persoonsgegevens worden verwerkt voor het gebruik van een algoritme wordt een betrokkene geïnformeerd over de verwerking van diens persoonsgegevens.
- Een privacyverklaring kan op organistieniveau worden opgesteld en ook voor specifieke verwerkingen.
- In een privacyverklaring wordt in ieder geval het volgende opgenomen:
  
  -  De identiteit en contactgegevens van uw organisatie. En ook die van vertegenwoordigers in de Europese Unie (EU), als deze er zijn.
  -  De contactgegevens van de functionaris gegevensbescherming (FG), als een organistie deze heeft.
  -  De doeleinden van de verwerking en de AVG-grondslag. 
  -  De (categorieën van) ontvangers van de persoonsgegevens.
  -  De persoonsgegevens die worden gegeven buiten de EER of aan een internationale organisatie. En zo ja, op welke juridische grond.
  -  De bewaartermijn van de gegevens.
  -  De privacyrechten van de betrokkenen, zoals het recht op inzage, rectificatie en gegevens verwijderen.
  -  Het recht van de betrokkenen om de toestemming die zij voor een bepaalde verwerking hebben gegeven, altijd weer te mogen intrekken.
  -  Dat de betrokkenen een klacht kunnen indienen bij de privacytoezichthouder. In Nederland is dat de Autoriteit Persoonsgegevens (AP).
  -  Of de betrokkenen verplicht zijn de persoonsgegevens te verstrekken. En zo ja, waarom. Vermeld dan ook wat de gevolgen zijn als zij de gegevens niet verstrekken.
  -  Of er sprake is van geautomatiseerde besluitvorming, inclusief profilering. En zo ja, hoe deze beslissing wordt genomen.
  -  Als persoonsgegevens van een andere organisatie zijn ontvangen: de bron waar de persoonsgegevens vandaan komen. En of de gegevens afkomstig zijn van openbare bronnen.

- Het is denkbaar dat in een specifieke privacyverklaring informatie over onderliggende logica van het algoritme, alsmede het belang en de verwachte gevolgen van die verwerking voor de betrokkene wordt opgenomen. Het is ook denkbaar dat deze informatie in het algoritmeregister wordt opgenomen.
- Als ervoor wordt gekozen om het algoritme uit te faseren, dan moet informatie in het algoriteregister hierop worden aangepast. 
","Betrokkenen zijn niet op de hoogte dat hun persoonsgegevens worden verwerkt met een algoritme, waardoor zij hier geen controle over hebben en zich niet kunnen beroepen op hun privacyrechten.
  ",['urn:nl:ak:ver:avg-07'],"- [Onderzoekskader Algoritmes Auditdienst Rijk, PRI.8](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Autoriteit Persoonsgegevens](https://www.autoriteitpersoonsgegevens.nl/themas/basis-avg/privacyrechten-avg/recht-op-informatie) 
- [Toetsingskader Algoritmes Algemene Rekenkamer, 3.12](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-05-vermelding-in-privacyverklaring/index.html
urn:nl:ak:mtr:imp-06,"Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces","Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme. Zorg voor goede monitoring van dit proces zodat het projectteam op de hoogte is van klachten, bezwaren en beroepen over het systeem. 
",['governance'],"['implementatie', 'monitoring-en-beheer']","['projectleider', 'ontwikkelaar']","- Een goede datahuishouding van de binnengekomen bezwaren, klachten en beroepen is essentieel om de informatie rondom de klachten, bezwaren en beroepen vanuit datagedreven perspectief te kunnen monitoren.
- Goede monitoring kan ervoor zorgen dat eventuele patronen in bezwaar, klacht en beroep snel gesignaleerd worden. Eventuele patronen in klacht, bezwaar en beroep kunnen duiden op problemen in het functioneren van het algoritme. Dit kan bijvoorbeeld duiden op discriminerende effecten van het algoritme, waardoor nader onderzoek wenselijk is. 
","Een risico van het niet gebruik maken van een proces voor het indienen van klachten, bezwaren of beroepen is dat dit kan leiden tot het niet overzichtelijk hebben van eventuele problemen bij het functioneren van een algoritme, en hierdoor niet de correcte maatregelen kunnen nemen. 
",['urn:nl:ak:ver:avg-09'],"- [Onderzoekskader Auditdienst Rijk, SV.17, PRI.9](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 1.08](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Onderzoek misbruik uitwonendenbeurs, PricewaterhouseCoopers](https://open.overheid.nl/documenten/dpc-97a155051e66b292ef3cc5799cb4aef61dcbf46b/pdf#page=48)
- [Intern onderzoek controle uitwonendenbeurs, DUO](https://open.overheid.nl/documenten/dpc-486d1370ee92580b07ae27198a636c73fc28b87d/pdf)
- [Toetsingskader risicoprofilering – Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens](https://publicaties.mensenrechten.nl/publicatie/4093c026-ae41-4c1d-aa78-4ce0e205b5de)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-06-klacht-bezwaar-beroep/index.html
urn:nl:ak:mtr:imp-07,Vermeld het gebruik van persoonsgegevens in het verwerkingsregister,"
 Neem de ontwikkeling en gebruik van een algoritme op in het verwerkingsregister als persoonsgegevens worden verwerkt.  
","['transparantie', 'privacy-en-gegevensbescherming']",['implementatie'],"['projectleider', 'jurist']","- Door in het verwerkingsregister te vermelden welke persoonsgegevens worden verwerkt voor het gebruik van een algoritme wordt een betrokkene geïnformeerd over de verwerking van diens persoonsgegevens.
- Hiermee is ook voor de organisatie intern inzichtelijk welke persoonsgegevens voor welke toepassingen worden verwerkt.
- Het is van belang dat vanaf het moment dat persoonsgegevens worden verwerkt, meteen een vermelding hiervan wordt gemaakt in het verwerkingsregister.
- Dat betekent dat als persoonsgegevens worden verwerkt bij het ontwikkelen en trainen van het algoritme en deze nog niet in gebruik zijn genomen, al een vermelding moet worden gedaan in het verwerkingsregister.
- Bij beëindiging van het gebruik van het algoritme moet het verwerkingsregister worden aangepast. 
","Betrokkenen en de interne organisatie zijn niet op de hoogte welke persoonsgegevens worden verwerkt met een algoritme, waardoor zij hier geen controle over hebben. 

",['urn:nl:ak:ver:avg-07'],"
- [Onderzoekskader Algoritmes Auditdienst Rijk, PRI.8](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Autoriteit Persoonsgegevens](https://www.autoriteitpersoonsgegevens.nl/themas/basis-avg/privacyrechten-avg/recht-op-informatie)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 3.04](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-07-vermelding-in-verwerkingsregister/index.html
urn:nl:ak:mtr:imp-08,Maak een openbaar besluit over de inzet van het algoritme,"Een politieke-bestuurlijk besluit wordt genomen over de inzet van een impactvol algoritme. 
","['governance', 'transparantie']","['organisatieverantwoordelijkheden', 'implementatie']",['projectleider'],"- Door een politiek-bestuurlijk besluit te nemen over de inzet of beëindiging van een impactvol algoritme wordt een afweging en keuze gemaakt over de wenselijkheid, haalbaarheid, transparantie, invulling van menselijke controle en eventueel de mate van onbewuste vooringenomenheid van het betreffende algoritme.
- Impactvolle algoritmes bevatten aspecten die vragen om politieke afwegingen en niet enkel door de ambtelijke organistie mogen worden beoordeeld.
- Een voorbeeld van een politiek afweging is wanneer er wel of geen sprake is van een gerechtvaardigd onderscheid wat wordt gemaakt door een algoritme. 
- Het is van belang dat overheidsorganisaties een politiek-bestuurlijk kader opstellen waarin wordt beschreven hoe wordt omgegaan met dergelijke gevallen. 
- Een openbaar besluit draagt bij aan de legitimiteit van de inzet van het algoritme en de controleerbaarheid van de overheidsorganisatie. 
","De ambtelijke organisatie maakt politieke-bestuurlijke afwegingen en beslissingen bij de inzet of beëindiging van het gebruik van impactvolle algoritmes, terwijl deze daar niet toe bevoegd is.
","['urn:nl:ak:ver:awb-01', 'urn:nl:ak:ver:aia-08', 'urn:nl:ak:ver:awb-02', 'urn:nl:ak:ver:aia-21', 'urn:nl:ak:ver:aia-22']","
[Kleur bekennen, Algemene Rekenkamer Rotterdam](https://rekenkamer.rotterdam.nl/wp-content/uploads/2024/05/RO2205-kleur-bekennen-vervolgonderzoek-algoritmes-rekenkamer-rotterdam.pdf)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-08-politiek-bestuurlijk-besluit/index.html
urn:nl:ak:mtr:imp-09,Neem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomen,"Neem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomen.
","['technische-robuustheid-en-veiligheid', 'menselijke-controle']","['implementatie', 'ontwikkelen']","['ontwikkelaar', 'projectleider', 'beleid-en-advies']","Een algoritme wat volledig correcte uitkomsten geeft maar vervolgens verkeerd wordt gebruikt kan leiden tot problemen. 
Neem bijvoorbeeld een algoritme wat een tekstdocument controleert en voorstelt aan de gebruiker of het compleet is, of nog onderdelen mist.
Wanneer je dan een ‘goedgekeurd’ knop rood maakt, en een ‘afgekeurd’ knop groen, is er een kans dat de gebruiker uit gewoonte op de verkeerde klikt en daarmee alsnog een onjuiste beslissing neemt. 
Als deze keuze vervolgens als feedback ook weer wordt doorgevoerd in het systeem kan het algoritme ook nog verkeerd gedrag aanleren. 

Werk bijvoorbeeld aan de hand van [User Centered Design principes](https://www.interaction-design.org/literature/topics/user-centered-design) om de gebruiker centraal te stellen. 

### Evaluatie
Breng risico’s in kaart door het goed testen van het systeem in een praktijksetting. Evalueer hier het gedrag van de gebruiker in het grotere systeem.  

Onderdelen hiervan zijn:

#### Aandacht van de gebruiker 
Oog en muisbewegingen kunnen inzicht geven waar de aandacht van de gebruiker naartoe gaat. 
Als er bijvoorbeeld een controle gedaan moet worden over de uitkomst van het algoritme voor het maken van een definitieve beslissing wil je inzicht krijgen of de gebruiker naar de juiste elementen kijkt om die beslissing te maken. 

#### Interactiegedrag van de gebruiker 
Clicks, scrollen, of het gebruik van het algoritme op zich (in plaats van zelf tot een beslissing komen) horen bij het gedrag van de gebruiker. 
Dit kan inzicht geven of het systeem correct wordt gebruikt, maar ook waar gebruikers mogelijk juist blijven hangen. 

#### Feedback mechanismes 
- Zijn er manieren waarop de gebruiker feedback kan geven over de uitkomsten wanneer deze naar vermoeden niet kloppen?
- Zijn er manieren waarop de gebruiker om hulp kan vragen en wat voor vragen zijn dit?
- Op wat voor manier worden errors in het systeem doorgegeven aan de gebruiker? 

#### Transparantie en uitlegbaarheid
Een correct gebruik begint bij een [duidelijke instructie en inzicht hoe een algoritme werkt](6-imp-01-werkinstructies-gebruikers.md) en hoe daar mee om te gaan. 
Evalueer of de gebruikte methodes hiervoor hun doel bereiken.

#### Toegankelijkheid
Het is belangrijk om te controleren of het algoritme toegankelijk in gebruik is voor iedereen, inclusief personen met een beperking. 

#### Beveiliging en controle
Het onjuist gebruik waarvoor specifiek gedrag opgemerkt kan worden bij bovenstaande evaluaties moet worden gemonitored.
Vervolgens kunnen er beveiligingen (denk aan een melding ‘weet je het zeker?’) ingebouwd worden als zulk gedrag wordt geregistreerd. 
Kijk vervolgens of deze interventies effectief zijn om fouten te voorkomen. 
","Een gebruikersinterface die verkeerd gebruik door gebruikers mogelijk maakt, kan ervoor zorgen dat gebruikers verkeerde invoerwaarden geven, zich niet aan de beoogde werkwijze houden of per ongeluk toegang geven aan kwaadwillenden.
",['urn:nl:ak:ver:aia-10'],"- [Valid Useful User Experience Measurement ](https://www.academia.edu/28475349/Valid_Useful_User_Experience_Measurement)
- [7 fundamental user experience (UX) design principles all designers should know (2024) - UX Design Institute](https://www.uxdesigninstitute.com/blog/ux-design-principles/)
- [Web Content Accessibility Guidelines (WCAG) 2.2](https://www.w3.org/TR/WCAG22/)
- [User Centered Design (UCD)](https://www.interaction-design.org/literature/topics/user-centered-design)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/index.html
urn:nl:ak:mtr:imp-10,Spreek af hoe de organisatie omgaat met privacy-verzoeken,"
Richt een proces in waarmee betrokkenen hun privacyrechten kunnen inroepen als algoritmes worden ontwikkeld of gebruikt.
","['privacy-en-gegevensbescherming', 'governance', 'data']","['organisatieverantwoordelijkheden', 'ontwikkelen']","['projectleider', 'beleid-en-advies', 'jurist']","- Betrokkenen moeten hun persoonsgegevens kunnen inzien, rectificeren, laten verwijderen of het gebruik ervan beperken bij het toepassen van algoritmes.
- Betrokkenen moeten hun verzoek kunnen indienen bij de betreffende organisatie. Denk hierbij aan het inrichten van een privacyloket.
- Er zullen afspraken moeten worden gemaakt door servicemanagement om in te richten hoe deze verzoeken effectief kunnen worden behandeld door bijvoorbeeld het ontwikkel- of beheerteam (aanbieder).
- Bij het inrichten van servicemanagement moet zijn nagedacht over hoe een verzoek tot het inzien, rectificeren, verwijderen of beperken van de verwerking van persoonsgegevens op een betekenisvolle manier kan of moet worden behandeld.
","Betrokkenen hebben geen controle over hun persoonsgegevens doordat ze geen beroep kunnen doen op hun privacyrechten. 
",['urn:nl:ak:ver:avg-09'],"[Onderzoekskader Algoritmes Auditdienst Rijk, PRI.9](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023) 
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/6-imp-10-proces-privacyrechten/index.html
urn:nl:ak:mtr:mon-01,Maak back-ups van algoritmes,"
Back-up kopieën van informatie, software en systeemafbeeldingen dienen regelmatig te worden gemaakt en getest. Idealiter gebeurt dit in overeenstemming met een afgesproken back-up beleid.
Maak back-ups van de omgeving van het algoritme en zorg ervoor dat het algoritme en de data hersteld kunnen worden.
",['technische-robuustheid-en-veiligheid'],"['ontwikkelen', 'monitoring-en-beheer']","['ontwikkelaar', 'beleid-en-advies']","Er is een back-up beleid waarin de eisen voor het bewaren en beschermen zijn gedefinieerd en vastgesteld. Dit beleid moet vervolgens worden vertaald naar (technische) maatregelen om het kunnen maken van back-ups te realiseren.
","Als er geen regelmatige back-ups worden gemaakt en de restore-procedure niet regelmatig wordt getest, bestaat het risico dat er geen hersteloptie is en er een mogelijkheid van gegevensverlies is.
",['urn:nl:ak:ver:bio-01'],"
- [Baseline Informatiebeveiliging Overheid, 12.3.1.1, 12.3.1.4, 12.3.1.5.](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.26](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 4.08](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag) 
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-01-backups-maken/index.html
urn:nl:ak:mtr:mon-02,Beveilig de software,"Zorg voor een goede beveiliging van de verschillende softwarecomponenten van een algoritme.
Bepaal of de data voldoende is beveiligd en maak hierin onderscheid tussen de inputdata en de outputdata.
",['technische-robuustheid-en-veiligheid'],"['dataverkenning-en-datapreparatie', 'ontwikkelen', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies', 'ontwikkelaar']","Er zijn beheersmaatregelen die kunnen helpen bij het zorgen voor een goede beveiliging van verschillende (software-)componenten van een algoritme. Hierbij kan worden gedacht aan:
Het toepassen van wachtwoordbeheer, [Baseline Informatiebeveiliging Overheid](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/), de [NCSC Handreiking voor implementatie van detectieoplossingen](https://www.ncsc.nl/documenten/publicaties/2019/mei/01/handreiking-voor-implementatie-van-detectie-oplossingen) en het [Impact Assessment Mensenrechten en Algoritmes](../hulpmiddelen/IAMA.md).

- Inzicht creëren in de beoogde opzet van de IT-infrastructuur (de architectuur) en de werkelijk geconfigureerde hard- en software. (CIS Control 1, BIO 8.1.1).
- Inrichten van een formeel proces voor het beheer van technische kwetsbaarheden. Dit omvat minimaal periodieke (geautomatiseerde) controle op de aanwezigheid van kwetsbaarheden in de te toetsen systemen, een risicoafweging en navolgbare afwerking daarvan of risicoacceptatie (BIO 12.6).
- Beoordelen, patchen en updaten van kwetsbaarheden in IT-systemen als deze bekend zijn. (BIO 12.6.1)
- Verwijderen of deactiveren van softwarecomponenten en services die niet noodzakelijk zijn voor het functioneren van het algoritme om beveiligingsrisico’s te beperken. (BIO 12.6.1)
- Er vindt zonering plaats binnen de technische infrastructuur conform de uitgangspunten die zijn vastgelegd in een operationeel beleidsdocument, waarbij minimaal sprake is van scheiding tussen vertrouwde en onvertrouwde netwerken (BIO 9.4.2). Denk ook aan het scheiden in netwerken (BIO 13.1.3).
- Actieve monitoring van de algoritmedata vindt plaats zodat beveiligingsincidenten en -gebeurtenissen in een vroeg stadium worden gedetecteerd. (BIO 12.4.1, NCSC Handreiking voor implementatie van detectieoplossingen).
- Netwerkverkeer en componenten worden actief gemonitord (BIO 12.4.1).
- Beoordeel of de data ten behoeve van het ontwikkelen en gebruiken van het algoritme voldoende is beveiligd. Maak hierin onderscheid tussen de trainingsdata, inputdata en de outputdata.
","Oneigenlijke toegang van buitenaf kan plaatsvinden via zwakheden in het systeem.
","['urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12', 'urn:nl:ak:ver:aia-10']","
- [Baseline Informatiebeveiliging Overheid](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.18 t/m IB.25](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [NCSC Handreiking voor implementatie van detectieoplossingen](https://www.ncsc.nl/documenten/publicaties/2019/mei/01/handreiking-voor-implementatie-van-detectie-oplossingen)
- [Handleiding Quickscan Information Security](https://www.cip-overheid.nl/media/xhxglzi0/20180220-quickscan-bir2017.pdf)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/index.html
urn:nl:ak:mtr:mon-03,Maak een noodplan voor beveiligingsincidenten,"Richt een proces in waarmee beveiligingsincidenten met betrekking tot algoritmes en data zo spoedig mogelijk worden opgelost.

","['technische-robuustheid-en-veiligheid', 'governance']","['organisatieverantwoordelijkheden', 'monitoring-en-beheer']","['projectleider', 'beleid-en-advies', 'jurist']","Er zijn procedures aanwezig die borgen dat beveiligingsincidenten met betrekking tot algoritmes en data zo spoedig mogelijk, afhankelijk van de kwalificatie van het incident, worden opgepakt.

","Te late reactie op incidenten kan ervoor zorgen dat de BIV (beschikbaarheid, integriteit en vertrouwelijkheid) van het algoritme of data kan worden aangetast.
","['urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:avg-12']","
- [Baseline Informatiebeveiliging Overheid, BIO 12.3.1.1, 12.3.1.4, 12.3.1.5](https://www.digitaleoverheid.nl/overzicht-van-alle-onderwerpen/cybersecurity/bio-en-ensia/baseline-informatiebeveiliging-overheid/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, IB.30](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 4.06](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)

",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-03-informatiebeveiligingsincidenten/index.html
urn:nl:ak:mtr:mon-04,Maak een evaluatieplan voor tijdens het gebruik van het algoritme,"Maak een evaluatieplan voor wanneer het algoritme in gebruik is. 
Dit plan bevat wanneer, wat en hoe er geëvalueerd dient te worden om te valideren of het model nog in lijn is met de [vastgestelde doelstelling](1-pba-02-formuleren-doelstelling.md). 
",['technische-robuustheid-en-veiligheid'],['monitoring-en-beheer'],['projectleider'],"Het evaluatieplan moet aangeven op welke momenten er wordt geëvalueerd, wat er opnieuw wordt geëvalueerd en hoe dat wordt gedaan. 

Voor het opstellen van het evaluatieplan zijn de volgende stappen nodig:

1. [Bepaal of periodieke controle noodzakelijk is](#bepaal-of-periodieke-controle-noodzakelijk-is)
2. [Bepaal bij welke gebeurtenissen het algoritme geëvalueerd moet worden](#bepaal-bij-welke-gebeurtenissen-het-algoritme-geevalueerd-moet-worden)
3. [Bepaal wat er geëvalueerd moet worden](#bepaal-wat-er-geevalueerd-moet-worden)

### Bepaal of periodieke controle noodzakelijk is
Stel vast of er periodieke momenten zijn vanuit bijvoorbeeld wetgeving, organisatiebeleid of risicomanagement waarop het wenselijk is dat het algoritme geëvalueerd wordt. 

### Bepaal bij welke gebeurtenissen het algoritme geëvalueerd moet worden
Wat zijn gebeurtenissen die om een nieuwe evaluatie vragen? Denk bijvoorbeeld aan momenten waarop het bijtrainen van het model noodzakelijk is, zoals:

- Een wijziging in de data of het algoritme.
- Aangepaste wetgeving.
- Andere context of tijd waarin het algoritme gebruikt wordt.
- Een nieuwe werkwijze.
- Het optreden van een incident.
- Gebruikersfeedback. 
- Een verandering in de gebruikscontext (bijv. een situatie als COVID-19).  

### Bepaal wat er geëvalueerd moet worden
Bepaal welke onderdelen van het algoritme geëvalueerd dienen te worden bij een periodieke controle of wanneer er een gebeurtenis plaatsvindt waardoor evaluatie wenselijk is.

Wat minimaal periodiek geëvalueerd moet worden is:

- [nauwkeurigheid](5-ver-02-evalueer-nauwkeurigheid.md)
- [betrouwbaarheid](5-ver-06-evalueer-betrouwbaarheid.md)
- [reproduceerbaarheid](4-owk-07-reproduceerbaarheid.md)
- [bias](5-ver-03-biasanalyse.md)
- [veiligheid](7-mon-08-test-weerbaarheid-tegen-aanvallen.md)
- [grondrechten](2-owp-07-afwegen-grondrechten.md)
- [privacy](4-owk-03-privacyrisico.md).

Bij een evaluatie hoeft niet altijd alles weer geëvalueerd te worden. Dit hangt af van het type wijzigingen die er zijn geweest en van de aspecten die continu worden gemonitored. Leg vast wat er wanneer geëvalueerd dient te worden. 

### Documenteer voor en tijdens iedere evaluatie
Zorg dat de benodigde informatie voor de evaluatie wordt opgeslagen en beschikbaar is voor de evaluatiemomenten. Denk aan invoerwaarden, resultaten en gebruikersstatistieken. 

Betrek bij het opstellen van dit plan een [diverse groep van belanghebbenden](1-pba-04-betrek-belanghebbenden.md) met o.a. ontwikkelaars, gebruikers en ethisch adviseurs. Zorg dat het evaluatieplan periodiek wordt herzien of deze nog voldoet.  
","Er zullen veranderingen plaatsvinden in de gebruikscontext, de data en in het algoritme zelf (bijv. door bijtrainen). Wanneer niet wordt geëvalueerd tijdens het gebruik is het onbekend of het algoritme nog steeds werkt zoals beoogd en voldoet aan de acceptatiecriteria. 
","['urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-34']","- [Toetsingskader Algemene Rekenkamer, 2.14](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/index.html
urn:nl:ak:mtr:mon-05,Monitor regelmatig op veranderingen in de data. Bij veranderingen evalueer je de prestaties en output van het algoritme.,"Monitor regelmatig op veranderingen in de inputdata. Bij geconstateerde veranderingen evalueer je de prestaties en de output van het algoritme.
","['data', 'technische-robuustheid-en-veiligheid']",['monitoring-en-beheer'],['ontwikkelaar'],"De inputdata kan voortdurend veranderen. 
Dat kan komen doordat de context waarin het algoritme wordt gebruikt verandert, of door een technische fout wanneer de data bijvoorbeeld niet goed is ingelezen of aangeleverd. 
Het te laat opmerken van zo'n verandering kan grote gevolgen hebben. 
Daarom is het belangrijk om regelmatig te controleren en evalueren of:

- De data van [voldoende kwaliteit is voor de beoogde toepassing](3-dat-01-datakwaliteit.md).
- Het algoritme nog [presteert in lijn met de vastgestelde doelen](5-ver-01-functioneren-in-lijn-met-doeleinden.md).
- De gegevens op de juiste en volledige manier worden verwerkt. 

Zeker wanneer er gebruikt wordt gemaakt van informatie van derden is het belangrijk om regelmatig te controleren of er veranderingen in de data zijn. Goede monitoring op datakwaliteit zorgt ervoor dat je voldoende controle hebt over de kwaliteit van de data, zelfs als je hiervoor afhankelijk bent van andere partijen. 
","Door veranderingen in de data presteert het model niet meer zoals verwacht.
","['urn:nl:ak:ver:aia-05', 'urn:nl:ak:ver:aia-11', 'urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:avg-05']","- [Onderzoekskader Auditdienst Rijk, DM.8](https://open.overheid.nl/documenten/61b54381-d331-40ed-8fce-b2883b195f25/file)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 1.02, 1.08, 2.06, 2.08, 2.13](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- Norm: [""Information technology - Artificial intelligence - Data life cycle framework""](https://www.nen.nl/nen-en-iso-iec-8183-2024-en-325716)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-05-evalueer-bij-veranderingen-in-data/index.html
urn:nl:ak:mtr:mon-06,"Meten, monitoren en rapporteren van milieu-impact van algoritmes","Inventariseer en monitor de milieu-impact van algoritmes (bijvoorbeeld door het doen van een impact-assessment) zowel tijdens [ontwerp](../../levenscyclus/ontwerp.md) als bij het gebruik en rapporteer deze om duurzame keuzes mogelijk te maken.
",['duurzaamheid'],"['ontwerp', 'monitoring-en-beheer']","['ontwikkelaar', 'beleid-en-advies', 'projectleider']","Tref bijvoorbeeld de volgende maatregelen, wanneer je de milieu-impact van algoritmes gaat inventariseren of monitoren:

### Digital Product Passports
De milieu-impact van algoritmes kan worden gemeten en geoptimaliseerd door een [Digital Product Passport (DPP)](https://coalitieduurzamedigitalisering.nl/nieuws/digital-product-passport-samen-aan-de-slag/) te overwegen.
DPP's bieden een platform voor duurzame rapportage door middel van real-time informatie over onder andere CO₂-uitstoot, herkomst en energiegebruik, wat kan helpen om de ecologische voetafdruk van een algoritme transparant te maken.
Door deze gegevens structureel te verzamelen en te delen, kunnen gebruikers en bedrijven inzicht krijgen in de duurzaamheidsprestaties.
De milieu-impact van verschillende algoritmes/ modellen kan een rol spelen bij het kiezen van een model in de ontwerpfase. Ook kan het ervoor zorgen dat je later kiest om een ander model te gebruiken of ervoor kiest om het gebruik van een model of systeem zelfs te beëindigen.

### Milieu-impact assessments
Wanneer de milieu-impact (in bepaalde mate) inzichtelijk is, kan er een milieu-impact assessment worden gedaan. Ga na of je organisatie er een heeft of overweeg deze te ontwikkelen.

### Periodieke monitoring
Probeer ook periodieke monitoringsrapporten op te stellen waarin de milieu-impact van algoritmes wordt bijgehouden.
Hiermee vergroot je de duurzaamheid door [tijdig verbeteringen te signaleren en door te voeren](../../levenscyclus/monitoring-en-beheer.md). Hierbij kan ook een onderscheid worden gemaakt in de impact tijdens de trainingsfase van het algoritme en de gebruiksfase. 
","Wanneer in de ontwerpfase niet wordt nagedacht over milieu-impact kan onbewust voor een algoritme of model worden gekozen dat meer energie verbruikt (en wellicht hogere kosten met zich mee brengt) dan een model dat misschien even goed presteert voor het [gekozen doel](1-pba-02-formuleren-doelstelling.md).
Zonder structurele monitoring van de milieu-impact kan de organisatie onbewust bijdragen aan een hoge CO₂-uitstoot en hoge energieverbruikskosten.
",[],"- [Coalitie Duurzame Digitalisering - Digital Product Passport](https://coalitieduurzamedigitalisering.nl/nieuws/digital-product-passport-samen-aan-de-slag/)
- [Onderzoekskader Algoritmes Auditdienst Rijk, DM.24](https://open.overheid.nl/documenten/61b54381-d331-40ed-8fce-b2883b195f25/file)
- [Ethische richtsnoeren voor betrouwbare KI, Hoofdstuk II 1.6: Maatschappelijk en milieuwelzijn](https://digital-strategy.ec.europa.eu/nl/library/ethics-guidelines-trustworthy-ai)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/index.html
urn:nl:ak:mtr:mon-07,Stel een plan op voor continue monitoring,"Maak een plan voor wat er continu gemonitored moet worden tijdens het gebruik van het algoritme. Dit plan bevat niet alleen wat en hoe er gemonitored wordt, maar ook bij welke overschrijdingen actie moet worden ondernomen.
",['technische-robuustheid-en-veiligheid'],['monitoring-en-beheer'],['projectleider'],"Het plan voor monitoring moet aangeven wat er continu moet worden gemonitored en op welke manier dit moet gebeuren. 
Daarnaast bevat het plan in welke situaties er actie moet worden ondernomen, en wie daarbij betrokken moet zijn. 

Voor het opstellen van het plan voor monitoring zijn de volgende stappen nodig:

### Bepaal waar je continu op wilt monitoren
Denk hierbij aan:

- [Bias en discriminerende effecten](5-ver-03-biasanalyse.md).
- Toegankelijkheid van het model (uitvallen of haperingen).
- Foutmeldingen.
- Prestaties: [werkt het model nog zoals beoogd](5-ver-01-functioneren-in-lijn-met-doeleinden.md).
- [Datakwaliteit](3-dat-01-datakwaliteit.md) en data drift (de data die in het systeem wordt ingevoerd kan veranderen over tijd).
- Invoerwaarden (probeert een gebruiker het systeem te manipuleren).

### Bepaal hoe je het gaat meten en welke informatie je hiervoor nodig hebt
Welke metrieken worden er gebruikt om de vastgelegde aspecten te meten? 
Welke informatie moet er opgeslagen worden om deze metrieken te kunnen meten? Analyseer ook of er aspecten zijn die niet met metrieken gemeten kunnen worden en hoe je die aspecten kan monitoren.   

### Bepaal de grenswaarden: bij welke overschrijding moet er actie worden genomen?
Voor een effectieve monitoring is het van belang dat duidelijk is wanneer er actie moet worden ondernomen op de resultaten. Leg vast voor elk van de aspecten die gemonitored worden bij welke waarden er actie moet worden genomen. Hiervoor is het noodzakelijk om een duidelijke omschrijving te hebben wat de beoogde werking van het systeem is. Het is ook mogelijk om meerdere waarden per monitor te bepalen, waarbij bij een eerste overschrijding alleen een waarschuwing wordt gegeven en bij een tweede bij het algoritme bijvoorbeeld wordt overgegaan tot het [noodplan](4-owk-02-stopzetten-gebruik.md). 

### Bepaal welke acties genomen moeten worden bij een overschrijding
Je legt hier in eerste instantie vast of het algoritme moet worden stopgezet, beperkt moet worden in de inzet of in gebruik kan blijven. Ten tweede bepaal je wat voor andere acties er moeten worden genomen, bijvoorbeeld of er een nieuwe uitgebreide evaluatie moet plaatsvinden, moet het algoritme worden bijgewerkt, moet er nieuwe data verzameld worden, moet de beveiliging verbeterd worden of moet er worden overgestapt op plan B. 

### Leg vast hoe en aan wie er een waarschuwing wordt gegeven wanneer een waarde wordt overschreden
Om effectief te kunnen ingrijpen is het van belang dat wordt vastgelegd in het monitoringsplan op welke manier er een waarschuwing wordt gegeven, aan wie deze waarschuwing wordt gegeven en welke informatie deze persoon nodig heeft. Bepaal bijvoorbeeld ook of een systeem automatisch wordt uitgeschakeld of dat een mens die keuze moet maken. 

Betrek bij het opstellen van dit plan een [diverse groep van belanghebbenden](1-pba-04-betrek-belanghebbenden.md) met onder andere ontwikkelaars, gebruikers en ethisch adviseurs. Zorg dat het evaluatieplan periodiek wordt herzien of deze nog voldoet.  
","Tijdens dagelijks gebruik wil je continu monitoren of het systeem nog werkt zoals beoogd. Wanneer dit niet gebeurt worden mogelijke fouten en veiligheidsrisico’s niet opgemerkt. 
","['urn:nl:ak:ver:aia-03', 'urn:nl:ak:ver:aia-18', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-34']","- [Toetsingskader Algemene Rekenkamer, 2.14](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Toetsingskader risicoprofilering – Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens](https://publicaties.mensenrechten.nl/publicatie/4093c026-ae41-4c1d-aa78-4ce0e205b5de)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/index.html
urn:nl:ak:mtr:mon-08,Controleer regelmatig of een algoritme voldoende weerbaar is tegen bekende aanvallen,"Controleer regelmatig of je algoritme bestand is tegen aanvallen. 
",['technische-robuustheid-en-veiligheid'],"['ontwikkelen', 'verificatie-en-validatie', 'monitoring-en-beheer']",['ontwikkelaar'],"Veel algoritmes veranderen in de loop van tijd. 
Daarom is het belangrijk om periodiek te blijven testen of de ingebouwde defensiemechanismen goed werken.
In traditionele cyber security wordt hiervoor de term [*red teaming*](https://www.nightfall.ai/ai-security-101/ai-model-red-teaming) of *pentesting* gebruikt. 

### Pentesting
Met pentesting wordt in feite een interactie tussen een aanvaller en het algoritme nagebootst.  
Verschillende bedrijven die gespecialiseerd zijn in traditionele pentesting van IT systemen bieden nu ook specifiek pentesting van AI aan. 
Indien er voldoende kennis aanwezig is, is het mogelijk  dit zelf te implementeren. 
Dit kan bijvoorbeeld met behulp van de open-source ontwikkelde [Adversarial Robustness Toolbox (ART)](https://research.ibm.com/projects/adversarial-robustness-toolbox) ontwikkeld door IBM (en nu in beheer door de Linux Foundation).

### Top-10 security risico’s van LLM’s
Het is lastig in te schatten met wat voor aanvallen er rekening gehouden moet worden voor een AI-systeem. 
Hiervoor heeft OWASP een [top 10 opgesteld van security risico’s van LLM’s](https://owasp.org/www-project-top-10-for-large-language-model-applications/). Veel risico's zijn waarschijnlijk ook van toepassing op andere soorten AI-systemen.
","Als niet periodiek getest wordt of een algoritme nog bestand is tegen aanvallen, wordt de kans groter dat een aanvaller succesvol is.
","['urn:nl:ak:ver:aia-10', 'urn:nl:ak:ver:aia-22', 'urn:nl:ak:ver:aia-32', 'urn:nl:ak:ver:bio-01', 'urn:nl:ak:ver:avg-12']","- [Nightfall, AI Model Red Teaming](https://www.nightfall.ai/ai-security-101/ai-model-red-teaming)
- [IBM, Adversarial Robustness Toolbox](https://research.ibm.com/projects/adversarial-robustness-toolbox)
- [OWASP Top 10 for Large Language Model Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/index.html
urn:nl:ak:mtr:uit-01,Bij uitfaseren en doorontwikkeling wordt correct omgegaan met data en modelinformatie,"Verwijder bij [uitfasering](../../levenscyclus/uitfaseren.md) van je algoritme gevoelige gegevens in het kader van [privacy en gegevensbescherming](../../onderwerpen/privacy-en-gegevensbescherming.md), maar behoud essentiële modelinformatie.
","['technische-robuustheid-en-veiligheid', 'privacy-en-gegevensbescherming', 'transparantie']","['uitfaseren', 'ontwerp']",['ontwikkelaar'],"Als het doel van het algoritme niet langer bestaat, kan een algoritme (zowel data als model) uitgeschakeld of verwijderd worden. 
Tegelijkertijd kan dit voor door het algoritme gemaakte beslissingen betekenen dat niet meer te achterhalen is welke data is gebruikt en waarom het model deze zo beoordeeld heeft. 
In de ontwerpfase van het algoritme wordt daarom [vastgelegd welke elementen bewaard dienen te worden en waarom](2-owp-09-archiveren-documenten.md).

Door op een juiste manier om te gaan met uitfaseren kan worden voorkomen dat de potentiële latere effecten van algoritmes worden geadresseerd.
De werking van een algoritme en de manier waarop beslissingen in het verleden zijn genomen, blijven behouden. Dit zorgt voor transparantie en controleerbaarheid of auditeerbaarheid. 
Zo kan worden vastgesteld of de uitkomsten zijn aangepast, waardoor bijvoorbeeld fraude onzichtbaar zou worden in geval van verwijdering. 
Ook in geval een organisatie later juridisch aansprakelijk wordt gesteld, is inzicht in hoe beslissingen tot stand zijn gekomen belangrijk. 
Tegelijkertijd kan data die niet essentieel is worden verwijderd, om zo de kans op misbruik en lekken van data te voorkomen.
","Het niet correct uitfaseren van een algoritme heeft mogelijk negatieve effecten op het gebied van uitlegbaarheid, transparantie en verantwoording. 
","['urn:nl:ak:ver:arc-01', 'urn:nl:ak:ver:aia-12', 'urn:nl:ak:ver:avg-02']","- [Onderzoekskader Algoritmes Auditdienst Rijk, PRI.11](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
",https://minbzk.github.io/Algoritmekader/voldoen-aan-wetten-en-regels/maatregelen/8-uit-01-archiveren/index.html
