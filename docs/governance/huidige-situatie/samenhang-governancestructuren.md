---
title: Samenhang en samenwerking bestaande governance
---

Bij de vormgeving van een algoritme- en AI-governance van een organisatie is het van belang om aansluiting en samenwerking te bewerkstelligen met huidige governance structuren binnen de organisatie, zoals IT, data, informatiebeveiliging en privacy governance waar dit onlosmakelijk mee verbonden is. 

In veel organisaties werken privacy- en informatiebeveiliging nauw samen van strategisch organisatieniveau tot operationeel omdat deze onderwerpen raken en beide domeinen. Dit geldt in nog grotere mate voor AI-vraagstukken die vragen om samenwerking en expertise vanuit veel verschillende invalshoeken.

Communicatie en vindbaarheid tussen de verschillende domeinen is hierin essentieel. De eindverantwoordelijkheid voor AI en algoritmes moet bij één entiteit belegd worden, die let op het betrekken van de juiste (interne) partijen. 

Bij algoritme governance moet rekening worden gehouden met mogelijk conflicterende belangen. Bijvoorbeeld, het kan voorkomen dat de business of IT-teams innovatie willen nastreven, terwijl compliance teams juist vragen om het afremmen van innovatie. Een algortime-eindverantwoordelijke dient hierin de afwegingen te maken, in samenspraak. Een strategie of visie zoals vastgelegd in een meerjarenbeleidsplan sturing geven en bestuurlijke steun opleveren in het maken van afwegingen.

Mocht een visie op AI ontbreken, dan kan iets als de IAMA (die zich ook richt op het afwegen van fundamentele rechten) een keer grondig doorlopen voor een AI-toepassing input geven voor de organisatievisie. 

Een concreet voorbeeld van samen optrekken is [deze handreiking](https://www.cip-overheid.nl/media/av0dmahv/20230614-gezamenlijk-gebruik-iama-en-model-dpia-rijksdienst-v1-0.pdf) om de IAMA en DPIA gezamelijk uit te voeren.



### Normen 

Normen en standaarden kunnen op twee manieren van belang zijn in deze fase van het werken naar een algortime governance. 
1) Er zijn normen in de maak die kunnen ondersteunen bij het inrichten van AI-governance.
  * De ISO/IEC 42001:2023 voor AI risk management framework (helaas zijn ISO-normen niet vrij beschikbaar).
      * Deze norm richt zich op ethiek, transparantie, verantwoordelijkheid en veiligheid bij de ontwikkeling en inzet van AI-systemen.
      * Later uitgebrachte normen zullen worden gelinkt aan deze norm om meer invulling te geven aan onderdelen ervan.
  * Ook is er een oproep vanuit de EU om standaarden te ontwikkelen die direct aansluiten bij de AI-verordening. Deze worden verwacht april 2025, meer informatie [hier](https://artificialintelligenceact.eu/standard-setting/).
2) Aan AI-verwante thema's, zoals privacy en data, hebben ook te maken met normen, standaarden, en wetgeving. 
  * De inzet van algoritmes raakt aan deze thema's, dus passende samenwerking is vereist.
  * Vanuit de (implementatie van de) AVG en bijbehorende privacy governance kunnen lessen zijn geleerd die zich vertalen naar algoritme governance. Een belangrijke standaard m.b.t. de AVG is de ISO-27001.


## Aandachts- en actiepunten
* Welke lessen zijn geleerd met de implementatie van de AVG?
* Is er iemand intern verantwoordelijk gemaakt voor (toezicht op) AI & algoritmes?
* Hoe communiceren verschillende groepen die aan AI-thema’s raken, zoals privacy of data, op dit moment?
* Hoe worden afwegingen gemaakt in de organisatie tussen innovatie en compliance?
* Welke normen en standaarden zijn nu al in gebruik, of kunnen helpen met het vormgeven van AI-governance?

## Bronnen
