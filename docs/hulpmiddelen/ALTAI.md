---
title: Assessment List for Trustworthy Artificial Intelligence (ALTAI)
toelichting: De ALTAI helpt ontwikkelaars en organisaties hun AI-systemen te beoordelen op basis van ethische richtlijnen voor betrouwbare AI, ontwikkeld in de EU. De ethische richtlijnen zijn gebaseerd op zeven hoofdcriteria. 
categorie: 
- toetsingskader 
vereiste:
- aia-14-conformiteitsbeoordeling
- awb-01-zorgvuldigheidsbeginsel
maatregel:
- afwegen_grondrechten
levenscyclus:
- ontwerp
- implementatie 
onderwerp:
- privacy-en-gegevensbescherming 
- duurzaamheid 
- fundamentele-rechten 
- technische-robuustheid-en-veiligheid 
- transparantie 
- menselijke-controle 
- data 
rollen:
- jurist 
- ontwikkelaar 
- projectleider 
- beleid-en-advies 
hide: navigation
---

<!-- tags -->

[Direct naar de ALTAI](https://digital-strategy.ec.europa.eu/en/library/assessment-list-trustworthy-artificial-intelligence-altai-self-assessment){ .md-button }
## Hulpmiddel 

In 2019 publiceerde de High-Level Expert Group on Artificial Intelligence (AI HLEG), opgericht door de Europese Commissie, de Ethics Guidelines for Trustworthy Artificial Intelligence. De ALTAI is een hulpmiddel dat ontwikkelaars en organisaties helpt hun AI-systemen te beoordelen, gebaseerd op deze Ethics Guidelines for Trustworthy Artificial Intelligence. Het helpt te bepalen of het AI-systeem dat wordt ontwikkeld, ingezet, aangeschaft of gebruikt, voldoet aan zeven vereisten van betrouwbare AI;

- Menselijke tussenkomst en toezicht;
- Technische robuustheid en veiligheid;
- Privacy en gegevensbeheer;
- Transparantie;
- Diversiteit, non-discriminatie en eerlijkheid;
- Maatschappelijk en ecologisch welzijn;
- Verantwoordelijkheid

De ALTAI is bedoeld voor zelfevaluatie. Het hulpmiddel is verankerd in de bescherming van de fundamentele rechten van mensen, de term die in de Europese Unie wordt gebruikt om te verwijzen naar de mensenrechten die zijn vastgelegd in de EU-verdragen, het Handvest van de Grondrechten, en het internationale mensenrechtenrecht. 

De ALTAI is bedoeld voor flexibele inzet: organisaties kunnen gebruikmaken van de relevante onderdelen van dit hulpmiddel voor een specifiek AI-systeem of er elementen aan toevoegen die zij passend achten, rekening houdend met de sector waarin zij opereren. Het helpt organisaties te begrijpen wat betrouwbare AI inhoudt, in het bijzonder welke risico's een AI-systeem zou kunnen meebrengen en hoe deze risico's kunnen worden geminimaliseerd terwijl de kansen van AI worden gemaximaliseerd. Organisaties halen het meeste waarde uit de ALTAI door de gestelde vragen uitgebreid te beantwoorden, die zijn bedoeld om zorgvuldige reflectie te stimuleren en passende vervolgacties aan te formuleren, en een organisatiecultuur te bevorderen die zich inzet voor de ontwikkeling van betrouwbare AI-systemen. Het vergroot het bewustzijn van de mogelijke impact van AI op de samenleving, het milieu, consumenten, werknemers en burgers (in het bijzonder kinderen en mensen die tot gemarginaliseerde groepen behoren). 

## Relevantie
De ALTAI biedt houvast bij het evalueren van in hoeverre een betreffend AI-systeem voldoet aan de zeven vereisten van betrouwbare AI, zoals geformuleerd door de EU. Deze zeven vereisten en de ALTAI hebben samen de basis gevormd voor de AI-verordening. 


## Auteur
De ALTAI is ontwikkeld door de High-Level Expert Group on Artificial Intelligence van de Europese Commissie. 

## Bijbehorende vereisten

<!-- list_vereisten_on_maatregelen_page -->

## Bijbehorende maatregelen

<!-- list_maatregelen_on_hulpmiddelen_page -->
