---
title: The Fairness Handbook
toelichting: toelichting volgt
categorie: 
- handreiking
levenscyclus:
- probleemanalyse
- ontwerp
onderwerp:
- bias-en-non-discriminatie
- fundamentele-rechten
rollen:
- projectleider
vereiste:
- grw-01-fundamentele-rechten
- grw-02-non-discriminatie
- aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren
maatregel:
- 3-dat-01-datakwaliteit
- 5-ver-02-biasanalyse
- 6-imp-02-aselecte-steekproeven
hide: navigation
---

<!-- tags -->

[Direct naar het Fairness Handbook](https://openresearch.amsterdam/en/page/87589/the-fairness-handbook){ .md-button }
## Hulpmiddel
Het Fairness Handbook biedt overheidsorganisaties een gedetailleerde richtlijn om eerlijkheid in algoritmen te waarborgen en schadelijke vooroordelen binnen AI-systemen te verminderen. Het handboek, dat origineel is ontwikkeld voor de Gemeente Amsterdam, richt zich op het voorkomen en mitigeren van vooroordelen en oneerlijke uitkomsten (bias) door middel van een gestructureerde _Fairness Pipeline_. Deze pipeline behandelt alle fasen van het ontwikkelproces, van het [formuleren van het probleem](../levenscyclus/probleemanalyse.md) tot de uiteindelijke [implementatie](../levenscyclus/implementatie.md) en [monitoring](../levenscyclus/monitoring-en-beheer.md). Dit hulpmiddel biedt inzicht in de soorten schadelijke effecten van AI (zoals representatiebias en denigratieschade) en introduceert specifieke technieken, zoals het uitvoeren van een bias-analyse en het gebruik van contra-feitelijke scenario's (_counterfactual fairness_), om te controleren of de algoritmen rechtvaardige resultaten opleveren.

Naast praktische technieken voor het meten en mitigeren van vooroordelen, definieert het Fairness Handbook verschillende eerlijkheidsprincipes en bijbehorende statistische metrics. Deze metrics helpen [ontwikkelaars](../rollen/ontwikkelaar.md) en [beleidsmakers](../rollen/beleid-en-advies.md) om de prestaties van modellen te analyseren en verschillen in modelprestaties tussen verschillende groepen te detecteren. Door de nadruk te leggen op transparantie, zowel in de keuze van datasets als in de manier waarop het model beslissingen neemt, helpt het handboek om het vertrouwen in AI-systemen te vergroten en discriminerend gedrag in algoritmen te verminderen.

## Relevantie
Het Fairness Handbook beidt ondersteuning voor overheden die streven naar verantwoorde, niet-discriminerende algoritmische besluitvorming. Het handboek ondersteunt overheidsinstanties bij het identificeren en corrigeren van vooroordelen in datasets en algoritmes, waardoor het risico op schadelijke effecten, zoals ongelijke verdeling van kansen of kwaliteit van dienstverlening, wordt geminimaliseerd. Het hulpmiddel sluit nauw aan bij andere hulpmiddelen, zoals de [IAMA](IAMA.md), door richtlijnen te geven voor het beoordelen van specifieke eerlijkheidsaspecten in de context van datagebruik en algoritmeontwikkeling.

Door de combinatie van technische en niet-technische benaderingen bevordert het Fairness Handbook een holistische benadering van algoritmische eerlijkheid. Er wordt rekening gehouden met zowel de technische als de sociale en ethische dimensies. Dit maakt het een bruikbaar hulpmiddel voor diverse overheidsprojecten, waaronder de ontwikkeling van AI-toepassingen in het sociaal domein en besluitvormingsprocessen waarbij kansengelijkheid van groot belang is.

## Auteurs en Ontwikkeling
Het Fairness Handbook is ontwikkeld in 2022 door de Gemeente Amsterdam, met als doel de eerlijkheid en transparantie van haar AI-systemen te verbeteren. Het project is tot stand gekomen in samenwerking met diverse stakeholders, waaronder datawetenschappers, ethici en [beleidsmakers](../rollen/beleid-en-advies.md), om ervoor te zorgen dat het handboek aansluit bij de bredere maatschappelijke behoeften en regelgeving. Door deze samenwerking biedt het Fairness Handbook een gebalanceerd perspectief, met aandacht voor zowel technische oplossingen als ethische en [juridische](../rollen/jurist.md) overwegingen die nodig zijn voor verantwoorde AI-toepassingen.

## Bijbehorende vereisten

<!-- list_vereisten_on_maatregelen_page -->

## Bijbehorende maatregelen

<!-- list_maatregelen_on_hulpmiddelen_page -->


## Bronnen
[The Fairness Handbook](https://openresearch.amsterdam/en/page/87589/the-fairness-handbook)

## Voorbeeld

Heb jij een goed voorbeeld van het gebruik van het Fairness Handbook op het gebied van algoritmen? Laat het ons weten!
