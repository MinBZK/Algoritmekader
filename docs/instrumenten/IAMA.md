---
title: Impact Assessment Mensenrechten en Algoritmes
toelichting: Het Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen. 
vereiste:
- beoordelen_gevolgen_voor_grondrechten
levenscyclus:
- ontwerp
bouwblok:
- fundamentele-rechten
rollen:
- projectleider
- aanbieder
- data-engineer
- data-scientist
- ethicus
- gemandateerd-verantwoordelijke
- jurist
- privacy-officer
- proceseigenaar
- security-officer
---

<!-- tags -->
## Instrument

Het Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen. Het IAMA stelt een reeks vragen die moeten worden besproken en beantwoord om een zorgvuldige afweging van de inzet van algoritmen te waarborgen. Dit proces is onderverdeeld in drie fasen: voorbereiding, input en throughput, en output en toezicht, waarbij steeds aandacht wordt besteed aan de impact op mensenrechten. Het IAMA fungeert als naslagwerk voor de besluitvorming en is gekoppeld aan andere relevante richtlijnen en instrumenten, zoals de gegevensbeschermingseffectbeoordeling (GEB). Hierdoor biedt het een overkoepelend kader dat helpt om algoritmen verantwoord te implementeren en mogelijke risico’s, zoals inbreuken op grondrechten, te identificeren en te mitigeren.


## Relevantie
Het IAMA kan op dit moment op veel politieke belangstelling rekenen. In zowel de Eerste als Tweede Kamer zijn hierover moties ingediend en vragen gesteld. Er is in de Tweede Kamer een [motie ingediend](https://www.tweedekamer.nl/kamerstukken/moties/detail?id=2022D12329&did=2022D12329) om mensenrechten assessments (zoals het IAMA) te verplichten voorafgaand aan het gebruik van algoritmes wanneer deze worden ingezet om evaluaties van, of beslissingen over mensen te maken (i.e. impactvolle algoritmes).   In een andere motie wordt bovendien gevraagd om de uitkomsten van deze assessments te publiceren in het algoritmeregister.  De Eerste Kamer heeft daarbij verzocht om mensenrechtentoetsen met betrekking tot AI-gebruik uit te voeren en te herhalen, en dat deze toetsen moeten worden gepubliceerd.  


Dit instrument hoort bij het bouwblok [Fundamentele Rechten](../bouwblokken/fundamentele-rechten/index.md).
Aanvullen in welke levenscyclus dit isntrument relevant is.

## Auteur
Het IAMA is ontwikkeld door de [Utrecht Data School](https://dataschool.nl/iama/). De auteurs van het IAMA zijn prof. mr. Janneke Gerards, dr. Mirko Tobias Schäfer, Arthur Vankan en Iris Muis, allen werkzaam aan de Universiteit Utrecht. Opdrachtgever voor de ontwikkeling is het Ministerie van Binnenlandse Zaken.

## Bijbehorende vereisten

<!-- list_vereisten_on_maatregelen_page -->

## Bronnen

| Bron                        |
|-----------------------------|
|[Impact Assessment Mensenrechten en Algoritmes](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes)|

## Voorbeeld

Heb jij een goed voorbeeld? Laat het ons weten!
