--- 
title: Dataverkenning en datapreparatie
---

In deze fase worden relevante datasets ge√Ødentificeerd, wanneer nodig verzameld, en geanalyseerd. Ook worden de gegevens opgeschoond en geschikt gemaakt. 

Het is van belang dat dataverzameling op de juiste manier gebeurd, en dat bestaande datasets die gebruikt gaan worden van goede kwaliteit zijn. Daarbij is het van belang dat opschoning van datasets (een standaard stap in het proces data science) geen nieuwe onvoorziene effecten met zich meebrengt. 

In de _gehele_ AI-levenscyclus is van belang:
- (Ethische) risico's zijn in kaart gebracht.
- De AI governance is duidelijk. (Wie in de organisatie gaat over naleven van AI-wetgeving.)
- Transparantie en navolgbaarheid van modellen en processen.

Hieronder komen vereisten en maatregelen die relevant zijn tijdens deze fase in de levenscyclus:

## Vereisten 

## Maatregelen

<!-- list levenscyclus/dataverkenning-en-datapreparatie -->


!!! info "Disclaimer"

    Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via [GitHub](https://github.com/MinBZK/Algoritmekader).
