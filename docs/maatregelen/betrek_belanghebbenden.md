---
# vul hier een titel in voor deze maatregel
title: Betrek belanghebbenden
# geef hier een korte toelichting van deze maatregel
toelichting: Breng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.
vereiste:
- 
# vul hier de fasen van de levenscyclus in die horen bij deze maatregel
levenscyclus: 
- probleemanalyse
- ontwerp
- dataverkenning-en-datapreparatie
- ontwikkelen
- verificatie-en-validatie
- implementatie
- monitoring-en-beheer
# vul hier de bouwblokken in die horen bij deze maatregel
bouwblok: 
- fundamentele-rechten
---

<!-- Let op! onderstaande regel met 'tags' niet weghalen! Deze maakt automatisch de knopjes op basis van de metadata  -->
<!-- tags -->

## Maatregel
<!-- Vul hier een omschrijving in van wat deze maatregel inhoudt. -->
Breng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.
Belanghebbenden zijn onder meer eindgebruikers, mensen en rechtspersonen die door het algoritme geraakt kunnen worden en vertegenwoordigende organisaties.

## Toelichting 
<!-- Geef hier een toelichting van deze maatregel -->
Algoritmes worden vaak gebruikt binnen een (specifieke) context waar deze invloed op uitoefenen.
Medewerkers moeten bijvoorbeeld werken met de uitkomsten of anderen zijn onderwerp van het algoritme.
Om te voorkomen dat er een mismatch ontstaat met de realiteit, is het van belang om specifieke domeinkennis te betrekken.

Het betrekken van belanghebbenden is van belang in bijna alle fasen van de levenscyclus.

In de fase van de probleemanalyse is het allereerst van belang in kaart te brengen welke stakeholders er zijn.
Wie gaan bijvoorbeeld werken met het algoritme (eindgebruikers)? En welke demografieÃ«n worden geraakt door een algoritme?
Bij wie liggen de voordelen en bij wie liggen de nadelen?
Ga vervolgens in gesprek met belanghebbenden - al dan niet vertegenwoordigd door belangenorganisaties zoals burgerrechtenorganisaties - over het te ontwerpen algoritme en de context waarin het gebruikt wordt.
Bespreek daarbij welke definitie en metriek van _fairness_ past bij de context.

In de fase van dataverkenning en datapreparatie is het van belang om domeinexpertise te betrekken, om zo in kaart te brengen wat de data features betekenen en waar zij vandaan komen.
Op basis daarvan kan in kaart gebracht worden of er sprake is van bias en/of links met beschermde persoonskenmerken.

In de fase van implementatie is het van belang de eindgebruikers te betrekken.
Het is dan vooral van belang om maatregelen te nemen om automation bias, deployment bias en reinforcing feedback loop te voorkomen of te beperken.

In de fase van monitoren is het van belang belanghebbenden te betrekken bij de evaluatie.
Dit kan bijvoorbeeld in de vorm van een survey of focusgroep.
Zij kunnen problemen in de praktijk naar voren brengen, die niet altijd terug te vinden zijn in de data.

Terugkoppelen aan buitenwereld.

## Bijbehorende vereiste(n)
<!-- Hier volgt een lijst met vereisten op basis van de in de metadata ingevulde vereiste -->

<!-- Let op! onderstaande regel met 'list_vereisten_on_maatregelen_page' niet weghalen! Deze maakt automatisch een lijst van bijbehorende verseisten op basis van de metadata  -->
<!-- list_vereisten_on_maatregelen_page -->

## Bronnen 
<!-- Vul hier de relevante bronnen in voor deze maatregel -->

| Bron                                                                                                                                                                                 |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Toetsingskader Algemene Rekenkamer 2.12](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)                         |
| [The Fairness Handbook](https://openresearch.amsterdam/nl/media/inline/2022/7/14/fairness_handbook.pdf)                                                                              |
| [Handreiking non-discriminatie by design](https://open.overheid.nl/repository/ronl-3f9fa69c-acf4-444d-96e1-5c48df00eb3c/1/pdf/bijlage-1-handreiking-non-discriminatie-by-design.pdf) |
| Ethics Guidelines for Trustworthy AI                                                                                                                                                 |
| [Onderzoekskader Algoritmes Auditdienst Rijk, SV.10](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)                               |




## Risico 
<!-- vul hier het specifieke risico in dat kan worden gemitigeerd met behulp van deze maatregel -->
De mismatch kan nadelige gevolgen hebben voor de effectiviteit van het algoritme binnen een context.
Het kan daarnaast ook ongerechtvaardigde discriminatie in de hand werken.
Ontwikkelaars kunnen bijvoorbeeld missen dat in de context van het algoritme een variabele een proxy is voor een discriminatiegrond.

## Voorbeeld
<!-- Voeg hier een voorbeeld toe, door er bijvoorbeeld naar te verwijzen -->
Richt een burgerpanel in.

Methodologie van Waag, Civic AI lab, Stakeholder escalation ladder.
Heb je een voorbeeld of best practice, laat het ons weten via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl)


