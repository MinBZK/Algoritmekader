---
# vul hier een titel in voor deze maatregel
title: Configuratie met de mens

# geef hier een korte toelichting van deze maatregel
toelichting: Zorg voor complementariteit tussen algoritmische systeem en de mensen die ermee moeten werken. 

# vul hier de bestandsnamen in van de vereisten die horen bij deze maatregel
vereiste:
- grw-02-non_discriminatie
- aia-09-menselijk-toezicht

# vul hier de fasen van de levenscyclus in die horen bij deze maatregel
levenscyclus: 
- implementatie

# vul hier de bouwblokken in die horen bij deze maatregel
onderwerp: 
- governance
- menselijke-controle
hide:
- navigation
---

<!-- Let op! onderstaande regel met 'tags' niet weghalen! Deze maakt automatisch de knopjes op basis van de metadata  -->
<!-- tags -->

## Maatregel
<!-- Vul hier een omschrijving in van wat deze maatregel inhoudt. -->

-	Maak keuzes rondom de rol van het systeem in de werkwijze van medewerkers.
-	Gebruik duidelijke werkinstructies en protocollen om te voorkomen dat beslissingen, gebaseerd op de output van het systeem, door (automation) bias worden beïnvloed.
-	Stel een structuur op voor het melden van mogelijke problemen met het systeem.
-	Opleiding van medewerkers over:
	-	AI en algoritmes;

	-	het systeem waarmee ze gaan werken;

	-	de rol van het systeem in hun werkwijze;

	-	de risico's die aan het gebruik van een systeem verbonden zijn (bijv. (automation) bias, false positives/negatives);

	-	de maatregelen die genomen zijn om deze risico’s te beperken (bijv. Willekeurige of fictieve casussen, transparantie over de output).

-	Bespreek regelmatig de uitdagingen die medewerkers ondervinden bij het werken met het systeem (bijv. tijdsdruk).
-	Documenteer alle keuzes en de onderliggende redenen/afwegingen rondom  menselijke tussenkomst en overzicht, bijvoorbeeld in een Algoritme Impact Assessment. Evalueer en pas gemaakte keuzes waar nodig aan.


## Toelichting 
<!-- Geef hier een toelichting van deze maatregel -->
Zorg voor complementariteit tussen medewerkers en systemen. Dit helpt bij het voorkomen van (automation) bias en discriminatie, het signaleren van algoritmische problemen, en het vermijden van de facto automatische besluitvorming.

## Bijbehorende vereiste(n)
<!-- Hier volgt een lijst met vereisten op basis van de in de metadata ingevulde vereiste -->

<!-- Let op! onderstaande regel met 'list_vereisten_on_maatregelen_page' niet weghalen! Deze maakt automatisch een lijst van bijbehorende verseisten op basis van de metadata  -->
<!-- list_vereisten_on_maatregelen_page -->

## Bronnen 
<!-- Vul hier de relevante bronnen in voor deze maatregel -->

| Bron                        |
|-----------------------------|
| [Handreiking non-discriminatie by design](https://open.overheid.nl/documenten/ronl-3f9fa69c-acf4-444d-96e1-5c48df00eb3c/pdf) | 
| [Impact Assessment Mensenrechten en Algoritmes](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes) | 
| [Ethics Guidelines of Trustworthy AI](https://op.europa.eu/en/publication-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1)|


## Risico 
<!-- vul hier het specifieke risico in dat kan worden gemitigeerd met behulp van deze maatregel -->

Bias, discriminatie, de facto automatische besluitvorming.

## Voorbeeld
<!-- Voeg hier een voorbeeld toe, door er bijvoorbeeld naar te verwijzen -->

Heb je een voorbeeld of best practice, laat het ons weten via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl)

