---
title: Richt (technische) controlemechanismen in voor menselijk tussenkomst waarmee de output van een algoritme of AI-systeem kan worden gecontroleerd.
toelichting: Als algoritmes of AI-systemen worden ingezet om te ondersteunen bij het nemen van beslissingen en besluiten door overheidsorganisaties, kan het noodzakelijk zijn om menselijke tussenkomst in te richten om foutieve output te signaleren en te corrigeren. 
vereiste:
- recht_op_niet_geautomatiseerd_besluitvorming
- fundamentele_rechten
- gebruiksverantwoordelijken_monitoren_werking_ hoog_risico_AI-systeem
- zorgvuldigheidsbeginsel
- toezichtmogelijkheden_voor_gebruikers
  
levenscyclus:
- ontwerp
- ontwikkelen
- verificatie-en-validatie
- implementatie
- monitoring-en-beheer
onderwerp:
- menselijke-controle
- governance
rollen:
- proceseigenaar
- gebruiker
- aanbieder
hide:
- navigation
- toc
---

<!-- tags -->
## Maatregel
Richt (technische) controlemechanismen in voor menselijk tussenkomst waarmee de output van een algoritme of AI-systeem kan worden gecontroleerd.


## Toelichting

- Algoritmes en AI-systemen worden vaak ingezet om beslissingen of besluitvorming van overheidsorganisaties te ondersteunen.
- Als overheidsorganisaties beslissingen of besluiten nemen, kan dit rechtsgevolgen hebben voor een betrokkene of deze op een andere manier in aanmerkelijke mate treffen. 
- Algoritmes en AI-systemen zijn in de meeste gevallen niet foutloos. 
- Daarom is het van belang dat deze output wordt gecontroleerd door een mens, zodat dit kan worden gecorrigeerd. Dit wordt 'menselijke tussenkomst' genoemd. 
- Er is sprake van menselijke tussenkomst wanneer het menselijke toezicht op beslissingen of besluitvorming betekenisvol of zinvol is, en niet slechts symbolisch is.
- Menselijke tussenkomst moet worden uitgevoerd door iemand die bevoegd en bekwaam is om een beslissing of besluit te veranderen.
- Als een automatisch gegenereerde aanbeveling van een algoritme of AI-systeem (output) praktisch gezien standaard wordt overgenomen (bijvoorbeeld door deze al klikkend te accepteren), is er geen sprake meer van betekenisvolle menselijke tussenkomst. Hier is meer voor nodig.
- Het is van belang dat in een vroeg stadia wordt vastgesteld, bijvoorbeeld in de ontwerpfase, welke vormen van menselijke tussenkomst moeten worden ingezet en passend zijn gezien de specifieke algoritmische toepassing of AI-systeem. Dit kan worden gedaan op basis van uit te voeren risico analyses. 
- In het geval van het uitoefenen van 'gebonden bevoegdheden', waarbij er weinig of geen beoordelingsruimte is om de beslissing of het besluit te wijzigen, kan het zijn dat menselijke tussenkomst geen meerwaarde heeft en kan worden volstaan met de automatisch gegenereerde output.
- Hierbij kan worden gedacht aan het opleggen van een boete in het kader van de Wet administratiefrechtelijke handhaving
verkeersvoorschriften (Wahv) of het bijstellen van de hoogte van het recht op studiefinanciering op basis van veranderingen in het inkomen van een van de ouders.
- Er zullen technische en organisatorische maatregelen moeten worden getroffen om menselijke tussenkomst in te richten.
- Dit is ook het geval als een (externe) aanbieder algorimtes of AI-systemen levert. De gebruiksverantwoordelijke zal dan samen met aanbieder moeten onderzoeken hoe menselijke tussenkomst betekenisvol moet worden ingericht. 


## Bijbehorende vereiste(n)

<!-- list_vereisten_on_maatregelen_page -->

## Bronnen

| Bron                        |
|-----------------------------|
| [Toetsingskader Algoritmes Algemene Rekenkamer, 2.01](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag) |
| [Onderzoekskader Algoritmes Auditdienst Rijk, SV.05](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)                    |
| [Advies over geautomatiseerde selectietechniek Pels Rijcken, p.9](https://open.overheid.nl/documenten/6b5b5d5b-fdc1-4333-a11e-f89d3627a0f5/file) |
| Kamerstukken IT 2017-2018, 34 851, nr. (MvT UAVG), p. 120-121 |
| Algoritmekader | 

## Voorbeeld

[HvJEU december 2023, ECLI:EU:C:2023:957 (SCHUFA Scoring)](https://curia.europa.eu/juris/document/document.jsf?text=&docid=280426&pageIndex=0&doclang=NL&mode=lst&dir=&occ=first&part=1&cid=7436066)



