---
title: Menselijke controle over algoritmes
summary:
icon: material/account-check
---

# Menselijke controle over algoritmes
Algoritmes van de overheid moeten onder controle blijven van mensen. Presteert het algoritme of AI-systeem niet goed, dan moet een mens dit kunnen aanpassen of stoppen.

## Wat is menselijke controle?
Menselijke controle over een algoritme of AI-systeem betekent dat mensen invloed hebben op de uitkomsten. Mensen moeten het ontwerp van het algoritme of AI-systeem kunnen aanpassen. En mensen moeten het algoritme of AI-systeem kunnen stoppen. Zo kun je op tijd ingrijpen als er iets fout gaat.

## Belang van menselijke controle
Algoritmes en AI-systemen van de overheid moeten goed werken. Anders kun je hiermee grote schade veroorzaken in de maatschappij. Daarom moet je steeds op een of andere manier controleren of alles goed werkt.

Vóór gebruik controleren mensen bijvoorbeeld of het algoritme of AI-systeem goed getraind wordt. Is de [trainingsdata van goede kwaliteit](data.md)? Is het algoritme of AI-systeem [vrij van bias en discriminatie](bias-en-non-discriminatie.md), zodat je bepaalde groepen niet benadeelt? En kun je er het doel mee bereiken waarvoor het is ontworpen? 

Tijdens het gebruik moet de mens controles blijven uitvoeren. Zijn de uitkomsten bijvoorbeeld nog steeds [robuust](technische-robuustheid-en-veiligheid.md)? Dit soort controles zijn belangrijk omdat algoritmes en AI-systemen in de loop der tijd op een andere manier kunnen gaan werken:

* Situaties kunnen veranderen, zonder dat het algoritme of AI-systeem dit weet. Hierdoor kan het geen rekening houden met de nieuwe situatie. Een routenavigatiesysteem is bijvoorbeeld niet altijd op de hoogte van werkzaamheden aan de wegen.
* AI-systemen leren soms nog bij. En je weet niet altijd of dit gebeurt op basis van betrouwbare data. Een beeldherkenningssysteem blijkt bijvoorbeeld honden te herkennen op foto’s door naar de achtergrond te kijken, in plaats van naar de hond.
* Nieuwe mogelijkheden ontstaan door technologische ontwikkelingen. Opleidingen moeten bijvoorbeeld leren omgaan met het gebruik van ChatGPT door leerlingen.

Alleen mensen mogen dit soort belangrijke en ethische beslissingen maken. De meeste mensen in de maatschappij vinden dat alleen mensen goede keuzes kunnen maken over het soort controle dat nodig is op welk moment. Daarom kun je menselijke controle niet automatiseren. Mensen mogen zich hierbij wel laten helpen door computers of andere technologie.

## Aanpak menselijke controle
Je kunt op verschillende manieren controle houden over de prestaties van een algoritme of AI-systeem:

* Technische controle: Controle uitoefenen op het algoritme zelf. Je bepaalt bijvoorbeeld dat een AI-systeem alleen mag 'bijleren’ wanneer de data voldoet aan bepaalde voorwaarden voor sociale representativiteit.
* Contextuele controle: Controle van de omgeving van het algoritme. Je verbiedt bijvoorbeeld dat je organisatie het algoritme gebruikt in situaties met een hoog risico op schade.
* Controle door kennis: Je probeert de werking en risico’s van je algoritmes zo goed mogelijk te begrijpen. Gaat het om een AI-systeem, dan heb je ook [voldoende kennis over AI](../vereisten/aia-01-ai-geletterdheid.md) nodig.

Wanneer en hoe je controle uitoefent, hangt af van het [soort algoritme en risico](../overhetalgoritmekader/soorten-algoritmes.md), de [levenscyclusfase](../levenscyclus/index.md) van je project en je [expertise](../rollen/index.md). 

Bepaal in elk geval zo vroeg mogelijk wie in welke levenscyclusfase verantwoordelijk is voor menselijke controle. En [beschrijf dit in een RACI-matrix of VERI-matrix](../maatregelen/beschrijf_rollen_en_verantwoordelijkheden.md). Want menselijke controle is nodig in verschillende fases, door verschillende mensen. Er is nooit 1 persoon verantwoordelijk voor de totale controle. 

Tijdens het gebruik kun je menselijke controle op de volgende manieren uitoefenen:

* _<span lang="en">Human in the loop</span>_: Een mens moet de acties starten van het algoritme of AI-systeem. Het werkt niet uit zichzelf.
* _<span lang="en">Human on the loop</span>_: Mensen kunnen acties stoppen van het algoritme of AI-systeem.
* _<span lang="en">Human above the loop</span>_: Mensen houden overzicht en kunnen ingrijpen bij strategische en ethische beslissingen.
* _<span lang="en">Human before the loop</span>_: Het algoritme of AI-systeem interpreteert morele modellen die mensen vooraf bedenken. Deze oplossing is bedoeld voor volledig autonome algoritmes of AI-systemen. Dit zijn algoritmes die zelf beslissingen moeten nemen, bijvoorbeeld door tijdsdruk.

### Feedback
Na het bepalen van de manier van controleren, bepaal je de manier waarop je feedback krijgt over het algoritme of AI-systeem: Wat voor soort informatie moet bij wie terechtkomen? Aan wie moet een gebruiker bijvoorbeeld rapporteren dat het AI-systeem niet meer goed werkt?

## Vereisten

<!-- list_vereisten onderwerp/menselijke-controle no-search no-onderwerp no-rol no-levenscyclus -->


## Aanbevolen maatregelen

<!-- list_maatregelen onderwerp/menselijke-controle no-search no-onderwerp no-rol no-levenscyclus -->


## Help ons deze pagina te verbeteren
Deel je idee, suggestie of opmerking via [GitHub](https://github.com/MinBZK/Algoritmekader/edit/main/docs/onderwerpen/menselijke-controle/index.md) of mail ons via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl).
