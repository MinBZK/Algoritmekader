---
title: Menselijke controle
summary:
icon: material/account-check
---

# Menselijke controle
Algoritmes van de overheid moeten onder controle blijven van mensen. Presteert het algoritme of AI-systeem niet goed, dan moet een mens dit kunnen aanpassen of stoppen.

## Wat is menselijke controle?
Je hebt menselijke controle over een algoritme of AI-systeem als mensen in staat zijn om de uitkomsten van een algoritme effectief te beïnvloeden. 

Dit betekent dat mensen een algoritme of AI-systeem moeten kunnen aanpassen of stoppen tijdens het ontwerp of gebruik ervan. Zo kun je op tijd ingrijpen als er iets fout gaat.

## Belang van menselijke controle
Algoritmes kunnen schade veroorzaken in de maatschappij. Gebruik je een algoritme of AI-systeem voor een publieke taak, dan moet je dit continu op een of andere manier controleren. 

### Ontwerp
Tijdens het ontwerp van een algoritme of AI-systeem controleer je bijvoorbeeld of het algoritme of AI-systeem op de juiste manier ‘getraind’ wordt. Maakt het bijvoorbeeld gebruik van een goede dataset, zonder bias, die representatief is voor de samenleving? En je controleert of het algoritme bepaalde groepen niet benadeelt. 

Voordat je een algoritme of AI-systeem gaat gebruiken, is het belangrijk om [het doel te bepalen](../../maatregelen/1-pba-02-formuleren-doelstelling.md). 

### Gebruik
Tijdens het gebruik van een algoritme of AI-systeem is menselijke controle belangrijk omdat de werking verandert in de loop der tijd:

- Situaties kunnen veranderen. Het algoritme kan daarvan niet op de hoogte zijn. Een routeplanner kent bijvoorbeeld niet alle werkzaamheden of veranderingen aan de wegen.
- AI-systemen leren soms nog bij. En soms is het niet duidelijk op welke data de uitkomsten gebaseerd zijn. Een beeldherkenningssysteem herkent bijvoorbeeld honden op foto’s op basis van de achtergrond in plaats van de hond zelf.
- Nieuwe mogelijkheden ontstaan door technologische ontwikkelingen. Zo maken leerlingen en studenten massaal gebruik van large language modellen (LLM’s) zoals ChatGPT.

### Mensen
Er is maatschappelijke consensus dat alleen natuurlijke personen in staat zijn om een goede (ethische) afweging te maken over wanneer en welke controle nodig is. Menselijke controle kan je dus niet automatiseren. Mensen mogen zich hierbij wel laten helpen door computers of andere technologie. 

## Aanpak menselijke controle
Je kunt op verschillende manieren controle houden over de prestaties van een algoritme of AI-systeem:

- Technische controle: Controle uitoefenen op het algoritme zelf. Je bepaalt bijvoorbeeld dat een AI-systeem alleen mag 'bijleren’ als de data voldoet aan bepaalde voorwaarden.
- Contextuele controle: Controle van de omgeving van het algoritme. Je verbiedt bijvoorbeeld het gebruik van een bepaald algoritme in een situatie met een hoog risico op schade.
- Controle door kennis: Je probeert de werking en risico’s van je algoritmes zo goed mogelijk te begrijpen. Hiervoor moet de mens voldoende kennis hebben over AI (AI-geletterdheid).

Wanneer en hoe je controle uitoefent, hangt af van het soort algoritme, de situatie (hoog risico of niet), de levenscyclusfase van je project en je rol. 
Bij elke aanpak is er meer dan 1 persoon verantwoordelijk. En je oefent menselijke controle uit in verschillende fases, door verschillende mensen. 

Tijdens het gebruik kun je menselijke controle op de volgende manieren uitoefenen:

- _Human in the loop_: Mensen starten de acties van het algoritme of AI-systeem. Het werkt niet autonoom.
- _Human on the loop_: Mensen kunnen acties stoppen van het algoritme of AI-systeem.
- _Human above the loop_: Mensen houden overzicht en kunnen ingrijpen bij strategische en ethische beslissingen.
- _Human before the loop_: Een volledig autonoom algoritme of AI-systeem interpreteert morele modellen die mensen vooraf bedenken. 

## Vereisten

<!-- list_vereisten onderwerp/menselijke-controle no-search no-onderwerp no-rol no-levenscyclus -->


## Maatregelen

<!-- list_maatregelen onderwerp/menselijke-controle no-search no-onderwerp no-rol no-levenscyclus -->
