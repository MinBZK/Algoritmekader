---
title: Risico van AI-systemen
summary: De AI-verordening deelt AI-systemen op in de 3 risicogroepen 'risico op misleiding', 'hoog-risico-AI-systeem' en 'verboden AI-systeem'.
---

# Risico van AI-systemen
Valt je AI-systeem onder een risicogroep uit de Europese AI-verordening, dan gelden speciale regels. Hoe groter het risico voor de samenleving, hoe strenger de regels. Het hangt ervan af waarvoor je het AI-systeem gebruikt.

## Risico op misleiding
In deze risicogroep vallen AI-systemen die je gebruikt voor:

*  __interactie met mensen__, zoals AI-chatbots
* __genereren van content__, zoals afbeeldingen laten maken door Dall-E

Hiervoor gelden verplichtingen op het gebied van transparantie. Gebruikers mogen niet denken dat zij te maken hebben met echte mensen of originele content.

Zie [AI-verordening, hoofdstuk IV](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e5418-1-1).

## Hoog-risico-AI-systeem
In deze risicogroep vallen AI-systemen die je gebruikt als veiligheidsonderdeel van bepaalde producten, of voor bepaalde diensten of processen.

### Gebruik als veiligheidsonderdeel
'Gebruiken als veiligheidsonderdeel' betekent dat je AI-systeem een belangrijke rol speelt in de veiligheid van een product. En dit product valt onder de harmonisatiewetgeving van de EU, zoals:

* machines
* speelgoed
* liften
* uitrusting en beveiligingssystemen voor plaatsen met ontploffingsgevaar
* radioapparatuur
* drukapparatuur
* pleziervaartuigen
* kabelbaaninstallaties
* gastoestellen
* medische hulpmiddelen
* hulpmiddelen voor het testen van menselijk materiaal (in-vitrodiagnostiek)
* auto-industrie
* luchtvaartindustrie

Zie [AI-verordening, bijlage I](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e38-124-1). 

### Gebruik voor bepaalde diensten of processen
Dit zijn AI-systemen die je gebruikt voor:

* __Biometrie__, zoals het herkennen of indelen van mensen op basis van hun vingerafdruk, gezicht of andere lichamelijke kenmerken.
* __Kritieke infrastructuur__, zoals het veilig houden van digitale netwerken en verkeersnetwerken en het leveren van elektriciteit, water, gas en warmte.
* __Onderwijs en beroepsopleiding__, zoals het bepalen welke studenten je toelaat en het beoordelen van hun prestaties of gedrag.
* __Werkgelegenheid, personeelsbeheer en toegang tot zelfstandige arbeid__, zoals het werven en selecteren van mensen, besluiten nemen die invloed hebben op hun contract en het beoordelen van hun prestaties of gedrag.
* __Essentiële particuliere en openbare diensten__, zoals bepalen wie recht heeft op uitkeringen, gezondheidszorg en andere belangrijke diensten en wie noodhulp krijgt van politie, brandweer en ambulance, het beoordelen van iemands financiële situatie, fraude opsporen en het bepalen van risico’s en prijzen voor levensverzekeringen en ziektekostenverzekeringen.
* __Rechtshandhaving__, zoals iemands kans inschatten om slachtoffer of dader te worden, het gebruik van een leugendetector, het beoordelen van bewijsmateriaal en het opsporen van verdachten.
* __Migratie, asiel en grenzen__, zoals inschatten wat de kans is dat iemand gevaarlijk of illegaal is, het behandelen van aanvragen en klachten en het herkennen of opsporen van mensen.
* __Rechtsbedeling en democratische processen__, zoals het uitleggen van de wet aan een rechtbank, gerechtshof of de Hoge Raad, advies geven bij een geschil of het beïnvloeden van de uitslag van een verkiezing.

Zie [AI-verordening, bijlage III](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e38-127-1).

## Verboden AI
Deze risicogroep bestaat uit soorten AI-praktijken die volgens de AI-verordening verboden zijn. 

Dit zijn AI-systemen die:

* misleiden
* misbruik maken van kwetsbaarheden of gevoelige situaties, zoals het overhalen van mensen met schulden om iets te kopen
* sociale scores bijhouden voor gedrag van mensen en hen hiervoor straffen
* beoordelen hoe groot het risico is dat iemand een strafbaar feit pleegt
* afbeeldingen van gezichten ‘scrapen’ (verzamelen) via internet of bewakingscamera’s en deze opslaan in een databank
* emoties herkennen van mensen op hun werkplek of op school
* biometrisch categoriseren: mensen indelen in gevoelige categorieën zoals ras en geloof, op basis van lichamelijke kenmerken zoals huidskleur
* biometrisch identificeren op afstand voor rechtshandhaving, zoals gezichten herkennen via camera’s op een openbaar plein (hiervoor gelden uitzonderingen in ernstige situaties zoals ontvoeringen en terrorisme)

Zie [AI-verordening, artikel 5](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#d1e2816-1-1).

## Voldoen aan de AI-verordening
Als je AI-systeem onder een risicogroep valt, moet je voldoen aan vereisten uit de [AI-verordening](../voldoen-aan-wetten-en-regels/ai-verordening.md). Bekijk de [tijdlijn met vereisten](../voldoen-aan-wetten-en-regels/tijdlijn-ai-verordening.md) of gebruik de [beslishulp AI-verordening](https://ai-act-decisiontree.apps.digilab.network/).

## Help ons deze pagina te verbeteren
Deel je idee, suggestie of opmerking via [GitHub](https://github.com/MinBZK/Algoritmekader/issues/new/choose) of mail ons via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl).
