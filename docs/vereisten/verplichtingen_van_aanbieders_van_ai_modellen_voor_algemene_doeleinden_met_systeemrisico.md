---
title: Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico 
toelichting: Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico’s in kaart te brengen en te beperken
status_vereiste:
- nog-niet-geldend
levenscyclus:
- ontwikkelen
- verificatie-en-validatie
- implementatie
- monitoring-en-beheer
bouwblok:
- governance
hide:
- navigation
---

<!-- tags -->
## Vereiste

Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico’s in kaart te brengen en te beperken.

## Toelichting

De aanbieders van AI-modellen voor algemene doeleinden die systeemrisico’s inhouden, moeten, naast de verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden, onderworpen worden aan verplichtingen die gericht zijn op het identificeren en beperken van die risico’s en op waarborging van een passend niveau van cyberbeveiliging, ongeacht of het model een op zichzelf staand model is of ingebed in een AI-systeem of in een product.
Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluaties uitvoeren. Dit omvat het testen en documenteren van het model volgens de stand van de techniek, met specifieke aandacht voor het identificeren en beperken van kwetsbaarheden. Deze maatregelen zijn bedoeld om systematische risico's te adresseren en te verminderen. Deze vereiste is een aanvulling op de genoemde verplichtingen in artikel 53 van de AI-verordening.


Systeemrisico betekent: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleienden, die aanzienlijke gevolgen hebben voor de markt van de Uniek vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid.


Systeemrisico’s nemen logischerwijs toe naargelang de capaciteiten en het bereik van een model groter zijn, kunnen zich voordoen gedurende de gehele levenscyclus van het model en worden beïnvloed door elementen als misbruik van het model, de betrouwbaarheid, billijkheid, beveiliging en mate van autonomie ervan. Ook worden ze beïnvloed door de toegang van het model tot instrumenten, nieuwe of gecombineerde modaliteiten, introductie- en distributiestrategieën, en door het potentieel om waarborgen te omzeilen en andere factoren.

## Bronnen

| Bron                        |
|-----------------------------|
|Artikel 55 AI-Verordening |
|Overweging 110 AI-Verordening|

## Wanneer van toepassing?


## Risico

Niet voldoen aan deze verplichtingen kan leiden tot negatieve gevolgen voor de gezondheid, veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel.

## Maatregelen

=== "Allen"
	<!-- list_maatregelen vereiste/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico -->
=== "Governance"
	<!-- list_maatregelen vereiste/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico boubwlok/governance -->
=== "Publieke inkoop"
	<!-- list_maatregelen vereiste/verplichtingen_van_aanbieders_van_ai_modellen_voor_algemene_doeleinden_met_systeemrisico bouwblok/publieke-inkoop -->
