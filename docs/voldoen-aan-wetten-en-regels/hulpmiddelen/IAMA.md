---
title: Impact Assessment Mensenrechten en Algoritmes
toelichting: Het Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen. 
categorie: 
- impact-assessment
vereiste:
- aia-27-beoordelen-gevolgen-grondrechten
- grw-01-fundamentele-rechten
levenscyclus:
- probleemanalyse
- ontwerp
- verificatie-en-validatie
- monitoring-en-beheer
onderwerp:
- fundamentele-rechten
- transparantie
rollen:
- projectleider
- ontwikkelaar
- jurist
- beleid-en-advies
hide: navigation
---

<!-- tags -->

[Direct naar het IAMA](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes){ .md-button }

## Hulpmiddel
Het Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen. 
Het IAMA stelt een reeks vragen die moeten worden besproken en beantwoord om een zorgvuldige afweging van de inzet van algoritmen te waarborgen. 
Dit proces is onderverdeeld in drie fasen: voorbereiding, input en throughput, en output en toezicht, waarbij steeds aandacht wordt besteed aan het vierde onderdeel van het IAMA: de impact op mensenrechten. 
Het IAMA fungeert als naslagwerk voor de besluitvorming en is gekoppeld aan andere relevante richtlijnen en instrumenten, zoals de [gegevensbeschermingseffectbeoordeling (ook wel DPIA)](../vereisten/avg-13-dpia-verplicht.md). 
Hierdoor biedt het een overkoepelend kader dat helpt om algoritmen verantwoord te implementeren en mogelijke risico’s, zoals inbreuken op grondrechten, te identificeren en te mitigeren.


## Relevantie
Het IAMA kan op dit moment op veel politieke en internationale belangstelling rekenen. 
In zowel de Eerste als Tweede Kamer zijn hierover [moties ingediend](https://www.tweedekamer.nl/kamerstukken/moties/detail?id=2022D12329&did=2022D12329) en vragen gesteld. 
Daarbij is het IAMA een van de weinige instrumenten in de EU die een interdisciplinaire discussie rondom (de ontwikkeling, inzet en monitoring van) algoritmes, AI en grondrechten initieert en bevordert. 


## Auteur
Het IAMA is ontwikkeld door de [Utrecht Data School](https://dataschool.nl/iama/). De auteurs van het IAMA zijn prof. mr. Janneke Gerards, dr. Mirko Tobias Schäfer, Arthur Vankan en Iris Muis, allen werkzaam aan de Universiteit Utrecht. Opdrachtgever voor de ontwikkeling is het Ministerie van Binnenlandse Zaken.

## Bijbehorende vereisten

<!-- list_vereisten_on_maatregelen_page -->

## Bijbehorende maatregelen

<!-- list_maatregelen_on_hulpmiddelen_page -->

## Bronnen
[Impact Assessment Mensenrechten en Algoritmes](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes)

## Voorbeeld

Benieuwd naar ervaringen in de praktijk? Bekijk het rapport [IAMA in Actie](https://www.rijksoverheid.nl/documenten/rapporten/2024/06/20/iama-in-actie-lessons-learned-van-15-iama-trajecten-bij-nederlandse-overheidsorganisaties) voor de lessons learned van 15 IAMA-trajecten bij Nederlandse overheidsorganisaties. 


Heb jij een goed voorbeeld? Laat het ons weten!