---
title: Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze.
id: urn:nl:ak:mtr:owp-07
toelichting: Uitlegbaarheidstechnieken dragen bij aan het transparant maken van de werking van een algoritme.
vereiste:
- aia-08-transparantie-aan-gebruiksverantwoordelijken
- aia-26-recht-op-uitleg-ai-besluiten
- awb-02-motiveringsbeginsel
levenscyclus:
- ontwerp
onderwerp:
- transparantie
rollen:
- projectleider
- beleid-en-advies
- ontwikkelaar
hide:
- navigation
- toc
---

<!-- tags -->

## Maatregel
Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze.

## Toelichting
Uitlegbaarheidstechnieken dragen bij aan het transparant maken van de werking van een algoritme.
De keuze voor het type algoritme bepaalt hoe transparant je kunt zijn. Van rekenregels kun je namelijk precies uitleggen hoe deze tot een beslissing komen. Maar complexe AI-systemen kunnen een black box zijn.  Het is dan onduidelijk hoe deze systemen beslissingen maken. 

Er zijn veel technieken vindbaar om de werking en keuzes van een algoritme beter bloot te leggen. De techniek en de mate waarin uitlegbaarheid mogelijk is, is afhankelijk van het type algoritme waarvoor gekozen wordt. Het is belangrijk de betrokken partijen samen vastleggen welke methodiek moet worden toegepast. Onder bronnen kan informatie worden geraadpleegd die helpen bij het vinden van de juiste methodiek. 

**Veiligheid**

Vanuit veiligheidsoverwegingen kan bij specifieke algoritmes besloten worden om bepaalde informatie over de werking van een algoritme niet aan iedereen vrij te geven. Houd rekening met mogelijke risico’s op aanvallen die kunnen ontstaan door het gebruik van uitlegbaarheidstechnieken, zoals omschreven in: A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures. 

**Transparency by design** 

Een manier om transparantie te bewerkstelligen is door het algoritme volgens het transparency-by-design gedachtegoed te ontwikkelen. Dit gedachtegoed is geïnspireerd door het privacy by design raamwerk. Door dit gedachtegoed toe te passen kan je ervoor zorgen dat transparantie in het volledige ontwikkelproces, en dus ook bij het ontwerp, wordt meegenomen. 

**Evaluatie en validatie**
Evalueer de uitlegbaarheid van het systeem op functionele, operationele, bruikbaarheids- en veiligheidsvereisten bij betrokkenen, bijvoorbeeld de gebruikers. Valideer in ieder geval dat de uitkomst van het algoritme begrijpelijk genoeg is voor gebruiker om hier op een verantwoorde wijze mee te werken. 

**Besluitvorming**
Onderzoek in hoeverre de uitlegbaarheidstechnieken kunnen bijdragen aan het formeleren van een motivering bij de totstandkoming van een besluit. Denk bijvoorbeeld aan het koppelen van de output van het algoritme aan het zaakdossier, zodat een belanghebbende deze ontvangen bij het opvragen van diens dossier, of om deze output of informatie hierover een plek te geven in de beschikking. 

## Bijbehorende vereiste(n)

<!-- list_vereisten_on_maatregelen_page -->

## Risico
Als er geen rekening wordt gehouden met de benodigde uitlegbaarheid van een algoritme binnen een bepaalde context, ontstaat het risico dat je het algoritme niet goed kan controleren en ontstaat het risico dat het algoritme op een verkeerde wijze wordt geïnterpreteerd en gebruikt. 

## Bronnen
- [Toolkit voor implementatie](https://xaitk.org/)
- [XAI as a service (IBM)](https://research.ibm.com/blog/ai-explainability-360)
- [Tools voor design (Google)](https://pair.withgoogle.com/)
- [Paper over (evaluatie) toolkits](https://www.ijcai.org/proceedings/2023/0747.pdf)
- [UXAI: Design Strategy](https://www.uxai.design/design-strategy)
- [Overzicht metrieken XAI](https://dl.acm.org/doi/pdf/10.1145/3583558)
- [Part 2: Explaining AI in practice | ICO](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/part-2-explaining-ai-in-practice/)
- [A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures](https://arxiv.org/pdf/2404.00673)
- [Towards Transparency by Design for Artificial Intelligence | Science and Engineering Ethics](https://link.springer.com/article/10.1007/s11948-020-00276-4)

## Voorbeeld

Heb jij een goed voorbeeld? Laat het ons weten!
