---
title: Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze.
id: urn:nl:ak:mtr:owp-07
toelichting: Uitlegbaarheidstechnieken dragen bij aan het transparant maken van de werking van een algoritme.
vereiste:
- aia-08-transparantie-aan-gebruiksverantwoordelijken
- aia-26-recht-op-uitleg-ai-besluiten
- awb-02-motiveringsbeginsel
levenscyclus:
- ontwerp
onderwerp:
- transparantie
rollen:
- projectleider
- beleid-en-advies
- ontwikkelaar
hide:
- navigation
- toc
---

<!-- tags -->

## Maatregel
Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze.

## Toelichting
Uitlegbaarheidstechnieken dragen bij aan het transparant maken van de werking van een algoritme.
De keuze voor het type algoritme bepaalt hoe transparant je kunt zijn. Van rekenregels kun je namelijk precies uitleggen hoe deze tot een beslissing komen. Maar complexe AI-systemen kunnen een black box zijn.  Het is dan onduidelijk hoe deze systemen beslissingen maken. 

Er zijn veel technieken beschikbaar om de werking en keuzes van een algoritme beter bloot te leggen. Er moet een keuze worden gemaakt welke geschikt zijn gezien de [informatiebehoeften](2-owp-29-informeer_betrokkenen.md), de vereisten die gelden en wat technische mogelijk is gezien het type algoritme. Het is belangrijk de betrokken partijen samen vastleggen welke methodiek moet worden toegepast. Onder bronnen kan informatie worden geraadpleegd die helpen bij het vinden van de juiste methodiek. 

**Besluitvorming**
Onderzoek in hoeverre de uitlegbaarheidstechnieken kunnen bijdragen aan het formeleren van een motivering bij de totstandkoming van een besluit. Denk bijvoorbeeld aan het koppelen van de output van het algoritme aan het zaakdossier, zodat een belanghebbende deze ontvangen bij het opvragen van diens dossier, of om deze output of informatie hierover een plek te geven in de beschikking. 

**Veiligheid**

Vanuit veiligheidsoverwegingen kan bij specifieke algoritmes besloten worden om bepaalde informatie over de werking van een algoritme niet aan iedereen vrij te geven. Houd rekening met mogelijke risico’s op aanvallen die kunnen ontstaan door het gebruik van uitlegbaarheidstechnieken, zoals omschreven in: A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures. 

**Evaluatie en validatie**

Evalueer de uitlegbaarheid van het systeem op functionele, operationele, bruikbaarheids- en veiligheidsvereisten bij betrokkenen, bijvoorbeeld de gebruikers. Valideer in ieder geval dat de uitkomst van het algoritme begrijpelijk genoeg is voor gebruiker om hier op een verantwoorde wijze mee te werken. Zorg ervoor dat als het algoritme niet meer naar behoren functioneert, er een procedure is beschreven om dit te herstellen of (tijdelijk) te stoppen met het gebruik maken van het algoritme.

## Bijbehorende vereiste(n)

<!-- list_vereisten_on_maatregelen_page -->

## Risico
Als er geen rekening wordt gehouden met de benodigde uitlegbaarheid van een algoritme binnen een bepaalde context, ontstaat het risico dat je het algoritme niet goed kan controleren en ontstaat het risico dat het algoritme op een verkeerde wijze wordt geïnterpreteerd en gebruikt. 

## Bronnen
- [Toolkit voor implementatie](https://xaitk.org/)
- [An introduction to explainable AI with Shapley values](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html)
- [Paper over (de evaluatie van) toolkits](https://www.ijcai.org/proceedings/2023/0747.pdf)
- [UXAI: Design Strategy](https://www.uxai.design/design-strategy)
- [Overzicht (evaluatie van) metrieken XAI](https://dl.acm.org/doi/pdf/10.1145/3583558)
- [Part 2: Explaining AI in practice | ICO](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/part-2-explaining-ai-in-practice/)
- [A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures](https://arxiv.org/pdf/2404.00673)
- [Towards Transparency by Design for Artificial Intelligence | Science and Engineering Ethics](https://link.springer.com/content/pdf/10.1007/s11948-020-00276-4.pdf).
- [From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI](https://dl.acm.org/doi/pdf/10.1145/3583558)

## Voorbeeld

Heb jij een goed voorbeeld? Laat het ons weten!
