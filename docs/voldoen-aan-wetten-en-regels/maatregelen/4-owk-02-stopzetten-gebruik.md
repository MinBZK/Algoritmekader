---
title: Maak een noodplan voor het stoppen van het algoritme
id: urn:nl:ak:mtr:owk-02
toelichting: Als blijkt dat het algoritme of AI-systeem onjuist functioneert, dan moeten (technische) maatregelen zijn getroffen waarmee het gebruik kan worden stopgezet.
vereiste: 
- aia-18-corrigerende-maatregelen-voor-non-conforme-ai
- awb-01-zorgvuldigheidsbeginsel
- aia-11-systeem-voor-kwaliteitsbeheer
- grw-01-fundamentele-rechten
- aia-27-beoordelen-gevolgen-grondrechten
- grw-02-non-discriminatie
- aia-19-toegankelijkheidseisen
- aia-09-menselijk-toezicht
- avg-04-proportionaliteit-en-subsidiariteit
- aia-22-gebruiksverantwoordelijken-monitoren-werking
levenscyclus: 
- ontwikkelen
- implementatie
onderwerp: 
- governance
- menselijke-controle
rollen:
- projectleider
- ontwikkelaar
hide:
- navigation
- toc
---
<!-- Let op! onderstaande regel met 'tags' niet weghalen! Deze maakt automatisch de knopjes op basis van de metadata  -->
<!-- tags -->

## Maatregel
<!-- Vul hier een omschrijving in van wat deze maatregel inhoudt. -->
 Tref (technische) maatregelen waarmee het gebruik van het algoritme of AI-systeem kan worden stopgezet.
  
## Toelichting
<!-- Geef hier een toelichting van deze maatregel -->
- Er moet in een proces zijn beschreven wanneer en hoe het gebruik van algoritmes moet worden stopgezet.
- Het is van belang dat bij het ontwerp van algoritmes en AI-systemen er rekening wordt gehouden met dat het werkproces ook zonder het algoritme of AI-systeem kan worden uitgevoerd.
- In het geval van risicoselectie kan er bijvoorbeeld worden teruggevallen op het enkel uitvoeren van een [aselecte steekproef](6-imp-02-aselecte-steekproeven.md) als selectieinstrument. 
- Als blijkt dat het algoritme of AI-systeem ongewenst functioneert, dan moeten (technische) maatregelen zijn getroffen waarmee het gebruik daadwerkelijk kan worden stopgezet. Denk hierbij aan een stopknop en werkinstructies hoe het gebruik kan worden beëindigd.
- Maak aantoonbaar dat deze maatregelen zijn getroffen.
- De proceseigenaar of een menselijk toezichthouder moet in staat zijn om het algoritme of AI-systeem op elk moment te kunnen beëindigen.
- Het stopzetten van het gebruik van een algoritme mag niet tot gevolg hebben dat betrokkenen niet meer kunnen achterhalen hoe besluiten tot stand zijn gekomen of dat gevolgen niet meer kunnen worden gecorrigeerd als dat noodzakelijk is. 
   
## Risico
Betrokkenen of belanghebbenden kunnen nadelige gevolgen ondervinden van een algoritme of AI-systeem dat onjuist functioneert en niet tijdig kan worden stopgezet.  

## Bijbehorende vereiste(n)
<!-- Let op! onderstaande regel met 'list_vereisten_on_maatregelen_page' niet weghalen! Deze maakt automatisch een lijst van bijbehorende verseisten op basis van de metadata  -->
??? expander "Bekijk alle vereisten"
    <!-- list_vereisten_on_maatregelen_page -->

## Bronnen 
<!-- Vul hier de relevante bronnen in voor deze maatregel -->

- [Onderzoekskader Algoritmes Auditdienst Rijk, SV.18, SV.17 ](https://www.rijksoverheid.nl/documenten/rapporten/2023/07/11/onderzoekskader-algoritmes-adr-2023)
- [Toetsingskader Algoritmes Algemene Rekenkamer, 1.03](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Impact Assessment Mensenrechten en Algoritmes, 1.5](../hulpmiddelen/IAMA.md)

## Voorbeeld
<!-- Voeg hier een voorbeeld toe, door er bijvoorbeeld naar te verwijzen -->

Heb je een voorbeeld of best practice, laat het ons weten via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl)
