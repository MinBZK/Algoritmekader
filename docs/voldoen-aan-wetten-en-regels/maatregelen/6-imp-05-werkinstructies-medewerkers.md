---
# vul hier een titel in voor deze maatregel
title: Spreek af hoe medewerkers omgaan met het algoritme.
id: urn:nl:ak:mtr:imp-05
# geef hier een korte toelichting van deze maatregel
toelichting: Stel duidelijke werkinstructies op voor de medewerkers die het algoritme gaan gebruiken. 

# vul hier de bestandsnamen in van de vereisten die horen bij deze maatregel
vereiste:
- grw-02-non-discriminatie
- aia-09-menselijk-toezicht
- aia-21-gebruiksverantwoordelijken-menselijk-toezicht
# vul hier de fasen van de levenscyclus in die horen bij deze maatregel
levenscyclus: 
- implementatie
# vul hier de bouwblokken in die horen bij deze maatregel
onderwerp: 
- governance
- menselijke-controle
rollen:
- projectleider
- beleid-en-advies
hide:
- navigation
- toc
---

<!-- Let op! onderstaande regel met 'tags' niet weghalen! Deze maakt automatisch de knopjes op basis van de metadata  -->
<!-- tags -->

## Maatregel
Stel duidelijke werkinstructies op voor de medewerkers die het algoritme gaan gebruiken. 

## Toelichting
-	Maak keuzes rondom de rol van het systeem in de werkwijze van medewerkers.
-	Gebruik duidelijke werkinstructies en protocollen om te voorkomen dat beslissingen, gebaseerd op de output van het systeem, door (automation) bias worden beïnvloed.
-	Stel een structuur op voor het melden van mogelijke problemen die medewerkers ervaren met het systeem.
-	Opleiding van medewerkers over:

	-	Algoritmes, waaronder AI;
	-	het systeem waarmee ze gaan werken;
	-	de rol van het systeem in hun werkwijze;
	-	de risico's die aan het gebruik van een systeem verbonden zijn (bijv. (automation) bias, false positives/negatives);
	-	de maatregelen die genomen zijn om deze risico’s te beperken (bijv. willekeurige of fictieve casussen, transparantie over de output).

-	Bespreek regelmatig de uitdagingen die medewerkers ondervinden bij het werken met het systeem (bijv. tijdsdruk).
-	Documenteer alle keuzes en de onderliggende redenen/afwegingen rondom menselijke tussenkomst en overzicht. Evalueer en pas gemaakte keuzes waar nodig aan.

- Goede samenwerking tussen medewerkers en systemen helpt bij het voorkomen van (automation) bias en discriminatie, het signaleren van algoritmische problemen, en het vermijden van de facto automatische besluitvorming.

## Bijbehorende vereiste(n) { data-search-exclude }
<!-- Hier volgt een lijst met vereisten op basis van de in de metadata ingevulde vereiste -->

<!-- Let op! onderstaande regel met 'list_vereisten_on_maatregelen_page' niet weghalen! Deze maakt automatisch een lijst van bijbehorende verseisten op basis van de metadata  -->
??? expander "Bekijk alle vereisten"
    <!-- list_vereisten_on_maatregelen_page -->
	
## Bronnen 
<!-- Vul hier de relevante bronnen in voor deze maatregel -->

- [Toetsingskader Algoritmes Algemene Rekenkamer, 3.07](https://www.rekenkamer.nl/onderwerpen/algoritmes/documenten/publicaties/2024/05/15/het-toetsingskader-aan-de-slag)
- [Handreiking non-discriminatie by design](https://open.overheid.nl/documenten/ronl-3f9fa69c-acf4-444d-96e1-5c48df00eb3c/pdf) 
- [Impact Assessment Mensenrechten en Algoritmes](https://www.rijksoverheid.nl/documenten/rapporten/2021/02/25/impact-assessment-mensenrechten-en-algoritmes) 
- [Ethics Guidelines of Trustworthy AI](https://op.europa.eu/en/publication-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1)


## Risico 
<!-- vul hier het specifieke risico in dat kan worden gemitigeerd met behulp van deze maatregel -->

Bias, discriminatie, de facto automatische besluitvorming.

## Voorbeeld
<!-- Voeg hier een voorbeeld toe, door er bijvoorbeeld naar te verwijzen -->
!!! example "Gemeente Utrecht: Handleiding Generatieve AI"
 
	De gemeente Utrecht heeft in April 2024 een handleiding gepubliceerd voor Generatieve AI (GenAI), bijvoorbeeld ChatGPT. Hierin wordt uitgelegd hoe het systeem gebruikt kan worden, om zo medewerkers uit te leggen welke risico’s vastzitten aan het gebruik van GenAI. Daarnaast wordt benoemd hoe de beslissingen rondom deze handleiding tot stand zijn gekomen. 

	Deze handleiding is breed opgesteld en zal dus voor een specifiek algoritme binnen een organisatie aangepast moeten worden. De opzet voor een handleiding staat al en kan ter inspiratie gebruikt worden voor andere handleidingen.

	
	Bron: [Handleiding Generatieve AI - Gemeente Utrecht](https://stadszaken.nl/uploads/docs/Handleiding-Generatieve-AI-Gemeente-Utrecht.pdf)

Heb je een ander voorbeeld of best practice, laat het ons weten via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl)

