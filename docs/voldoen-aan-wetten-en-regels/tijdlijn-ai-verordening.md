---
title: Tijdlijn AI-verordening
summary: De AI-verordening gaat in fasen in. Bekijk wanneer je moet voldoen aan welke vereisten.
---

# Tijdlijn AI-verordening
De AI-verordening gaat in fasen in. Bekijk wanneer je moet voldoen aan welke vereisten.

## 2 februari 2025: Stoppen met verboden AI, starten met AI-geletterdheid
Als je aanbieder of gebruiksverantwoordelijke bent van een AI-systeem, moet je vóór 2 februari 2025 voldoen aan de volgende vereisten uit de AI-verordening:

* Verboden AI is uitgefaseerd
* [aia-01 Personeel en gebruikers zijn voldoende AI-geletterd](vereisten/aia-01-ai-geletterdheid.md)

Geldt dit voor jouw organisatie? Gebruik de [beslishulp AI-verordening](https://ai-verordening-beslishulp.apps.digilab.network/).

## 2 augustus 2025: AI-modellen voor algemene doeleinden voldoen aan de vereisten
Als je aanbieder bent van een AI-model voor algemene doeleinden, moet je vóór 2 augustus 2025 voldoen aan de volgende vereisten uit de AI-verordening:
* [aia-01 Personeel en gebruikers zijn voldoende AI-geletterd](vereisten/aia-01-ai-geletterdheid.md)
* [aia-02 Beoordeling als ‘niet-hoog-risico-AI-systeem’ is gedocumenteerd](vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai.md)
* [aia-03 Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteem](vereisten/aia-03-risicobeheersysteem.md)
* [aia-04 Hoog-risico-AI-systemen vormen geen risico voor kwetsbare groepen zoals kinderen](vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren.md)
* [aia-05 Datasets voor hoog-risico-AI-systemen voldoen aan kwaliteitscriteria](vereisten/aia-05-data-kwaliteitscriteria.md)
* [aia-06 Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie](vereisten/aia-06-technische-documentatie.md)
* [aia-07 Hoog-risico-AI-systemen loggen automatisch bepaalde gegevens](vereisten/aia-07-automatische-logregistratie.md)
* [aia-08 Hoog-risico-AI-systemen zijn op een transparante manier ontwikkeld en ontworpen](vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken.md)
* [aia-09 Hoog-risico-AI-systemen staan onder menselijk toezicht](vereisten/aia-09-menselijk-toezicht.md)
* [aia-10 Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig](vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging.md)
* [aia-11 Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteem](vereisten/aia-11-systeem-voor-kwaliteitsbeheer.md)
* [aia-12 Documentatie over hoog-risico-AI-systemen wordt 10 jaar bewaard door de aanbieder](vereisten/aia-12-bewaartermijn-voor-documentatie.md)
* [aia-13 Logs van hoog-risico-AI-systemen worden 6 maanden bewaard door de aanbieder](vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs.md)
* [aia-14 Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedure](vereisten/aia-14-conformiteitsbeoordeling.md)
* [aia-15 Hoog-risico-AI-systemen zijn voorzien van een EU-conformiteitsverklaring](vereisten/aia-15-eu-conformiteitsverklaring.md)
* [aia-16 Hoog-risico-AI-systemen zijn voorzien van een CE-markering](vereisten/aia-16-ce-markering.md)
* [aia-17 Hoog-risico-AI-systemen zijn geregistreerd in de EU-databank](vereisten/aia-17-registratieverplichtingen.md)
* [aia-18 Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder in](vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai.md)
* [aia-19 Hoog-risico-AI-systemen voldoen aan de toegankelijkheidseisen](vereisten/aia-19-toegankelijkheidseisen.md)
* [aia-20 Hoog-risico-AI-systemen worden gebruikt volgens de gebruiksaanwijzing](vereisten/aia-20-gebruiksverantwoordelijken-maatregelen.md)
* [aia-21 Menselijke controle van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkheden](vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht.md)
* [aia-22 De werking van hoog-risico-AI-systemen wordt gemonitord](vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking.md)
* [aia-23 Logs voor hoog-risico-AI-systemen worden bewaard door de gebruiksverantwoordelijke](vereisten/aia-23-gebruiksverantwoordelijken-bewaren-logs.md)
* [aia-24 Werknemers weten dat hun organisatie een hoog-risico-AI-systeem gebruikt](vereisten/aia-24-informeren-werknemers.md)
* [aia-25 Gebruiksverantwoordelijken controleren de registratie van het hoog-risico-AI-systeem in de EU-databank](vereisten/aia-25-gebruiksverantwoordelijken-registratieverplichtingen.md)
* [aia-28 Mensen over wie besluiten worden genomen door hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluiten](vereisten/aia-26-recht-op-uitleg-ai-besluiten.md)
* [aia-29 AI-modellen voor algemene doeleinden zijn voorzien van voldoende technische documentatie en informatie](vereisten/aia-29-ai-modellen-algemene-doeleinden.md)
* [aia-30 Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico treffen extra maatregelen](vereisten/aia-30-ai-modellen-algemene-doeleinden-systeemrisico.md)
* [aia-31 Als AI-modellen voor algemene doeleinden met systeemrisico’s ernstige incidenten veroorzaken, wordt dit gedocumenteerd en gerapporteerd](vereisten/aia-31-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten.md)
* [aia-32 AI-modellen voor algemene doeleinden met systeemrisico’s zijn voldoende beveiligd tegen cyberaanvallen](vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging.md)
* [aia-33 AI-testomgevingen die persoonsgegevens verwerken, voldoen aan strenge voorwaarden](vereisten/aia-33-verwerking-in-testomgeving.md)
* [aia-34 Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem](vereisten/aia-34-monitoring-na-het-in-de-handel-brengen.md)
* [aia-35 Ernstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouder](vereisten/aia-35-melding-ernstige-incidenten.md)
* [aia-36 Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordening](vereisten/aia-36-melding-inbreuk-op-ai-verordening.md)
* [aia-37 Klachtrecht aanbieders verder in waardeketen](vereisten/aia-37-recht-klacht-indienen-bij-ai-bureau.md)

Geldt dit voor jouw organisatie? Gebruik de [beslishulp AI-verordening](https://ai-verordening-beslishulp.apps.digilab.network/).

## 2 augustus 2026: Nieuwe hoog-risico-AI-systemen voldoen aan vereisten
Als je aanbieder of gebruiksverantwoordelijke bent van een hoog-risico-AI-systeem dat nog niet in gebruik is, moet je vóór 2 augustus 2026 voldoen aan de volgende vereisten uit de AI-verordening:

[hier komt een lijst]

Wat betekent dit voor jouw organisatie? Gebruik de [beslishulp AI-verordening](https://ai-verordening-beslishulp.apps.digilab.network/).

## 2 augustus 2027: Hoog-risico-systemen in producten voldoen aan vereisten
Als je aanbieder bent van een product met daarin een hoog-risico-AI-systeem, moet je vóór 2 augustus 2027 voldoen aan de volgende vereisten uit de AI-verordening:

[hier komt een lijst]

### Uitzondering
Een uitzondering geldt voor hoog-risico-AI-systemen die op 2 augustus 2026 al in gebruik zijn bij overheidsorganisaties. Deze systemen hoeven pas in 2030 te voldoen aan de vereisten van de AI-verordening.
Zie [AI-verordening, artikel 26 en artikel 27](https://eur-lex.europa.eu/legal-content/NL/TXT/?uri=CELEX:32024R1689#art_26).

Wat betekent dit voor jouw organisatie? Gebruik de [beslishulp AI-verordening](https://ai-verordening-beslishulp.apps.digilab.network/).

## 2 augustus 2030: Hoog-risico-AI-systemen voldoen aan de overige vereisten
Als je aanbieder of gebruiksverantwoordelijke bent van een hoog-risico-AI-systeem, moet je vóór 2 augustus 2030 voldoen aan de volgende vereisten uit de AI-verordening:

[hier komt een lijst]

Geldt dit voor jouw organisatie? Gebruik de [beslishulp AI-verordening](https://ai-verordening-beslishulp.apps.digilab.network/).

## Help ons deze pagina te verbeteren
Deel je idee, suggestie of opmerking via [GitHub](https://github.com/MinBZK/Algoritmekader/issues/new/choose) of mail ons via [algoritmes@minbzk.nl](mailto:algoritmes@minbzk.nl).
