---
title: Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedure
id: urn:nl:ak:ver:aia-14
toelichting: Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld
levenscyclus:
- verificatie-en-validatie
- implementatie
onderwerp:
- governance
rollen:
- jurist
- projectleider
soort-toepassing:
- ai-systeem
- ai-systeem-voor-algemene-doeleinden
publicatiecategorie:
- hoog-risico-ai-systeem
rol-ai-act:
- aanbieder
hide:
- navigation
---

<!-- tags -->
## Vereiste

Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld

## Toelichting

Conformiteitsbeoordelingen dragen bij aan het kunnen vertrouwen op de kwaliteit van producten en diensten. Aanbieders van AI-systemen met een hoog risico moeten ervoor zorgen dat de conformiteitsbeoordelingsprocedure wordt uitgevoerd vóórdat het systeem op de markt wordt gebracht of in gebruik wordt genomen. Hiervoor moet worden beoordeeld of het ontwikkelde hoog risico AI-systeem voldoet aan de vereisten die gelden voor deze systemen. Denk hierbij aan de vereisten van risicobeheer, technische documentatie, data en datagovernance en transparantie en informatieverstrekking aan gebruiksverantwoordelijken (Afdeling 2, AI-Verordening).  

Een conformiteitbeoordeling kan worden uitgevoerd door middel van 
- een interne controle (als bedoeld in bijlage VI van de AI-verordening)
- of met betrokkenheid van een aangemelde instantie voor de beoordeling van het systeem voor kwaliteitsbeheer en de technische documentatie (als bedoeld in bijlage VII van de AI-verordening). Een conformiteitsbeoordeling door een aangemelde instatie wordt ookwel een conformiteitsbeoordeling door een derden genoemd. 

Als overheidsorganisaties hoog risico AI-systemen gebruiken van aanbieders of deze zelf ontwikkelen, zullen deze systemen veelal de conformiteitsbeoordeling middels een interne controle moeten doorlopen (bijlage VI). Let op! In het geval dat een hoog risico AI-systeem door een rechtshandhavingsinstantie, immigratie- of asielautoriteit wordt ingezet, dan zal de markttoezichtautoriteit als aangemelde instantie optreden die de conformiteitsbeoordeling zal uitvoeren.  

AI-systemen met een hoog risico die al aan een conformiteitsbeoordelingsprocedure zijn onderworpen, ondergaan een nieuwe conformiteitsbeoordelingsprocedure telkens wanneer zij substantieel zijn gewijzigd, ongeacht of het gewijzigde systeem bedoeld is om verder te worden gedistribueerd of door de huidige gebruiksverantwoordelijke gebruikt blijft worden.



![ai_lifecycle_visual_7FC0D14E-A775-A92E-DE5A38FDB7C238EB_75759](https://github.com/user-attachments/assets/47996f0e-d769-4ac5-a504-db12da4d1e21)


## Bronnen

- [Artikel 16(f) Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e3823-1-1)
- [Artikel 43 Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e5074-1-1)
- [Artikel 76 Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/PDF/?uri=OJ:L_202401689)
- [Bijlage VI Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e38-133-1)
- [Bijlage VII Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e38-134-1)
- [Hoe werkt het allemaal in de praktijk voor aanbieders van AI-systemen met een hoog risico](https://digital-strategy.ec.europa.eu/nl/policies/regulatory-framework-ai)
- [Vaststelling autoriteiten voor de bescherming van de grondrechten onder de EU AI-Verordening](https://www.tweedekamer.nl/downloads/document?id=2024D44985).

## Wanneer van toepassing? 
<!-- tags-ai-act -->


## Risico

Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.

## Maatregelen

<!-- list_maatregelen vereiste/aia-14-conformiteitsbeoordeling no-search no-onderwerp no-rol no-levenscyclus -->
