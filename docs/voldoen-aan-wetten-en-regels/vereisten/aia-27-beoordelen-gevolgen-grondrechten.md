---
title: Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechten
id: urn:nl:ak:ver:aia-27
toelichting: Voordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.
levenscyclus:
- ontwerp
- verificatie-en-validatie
onderwerp:
- fundamentele-rechten
rollen:
- projectleider
- beleid-en-advies
soort-toepassing:
- ai-systeem
- ai-systeem-voor-algemene-doeleinden
publicatiecategorie:
- hoog-risico-ai-systeem
rol-ai-act:
- gebruiksverantwoordelijke
hide:
- navigation
---

<!-- tags -->
## Vereiste

Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechten.

## Toelichting
Voordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.

Publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde AI-systemen, moeten dus een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben.

Deze evaluatie is bedoeld om potentiële risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen.

Het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van AI-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiek.

## Bronnen

- [Artikel 27(1) Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e4433-1-1)
- [Artikel 6.2 Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e2986-1-1)
- [Bijlage III.2 en III.5 Verordening Artificiële Intelligentie](https://eur-lex.europa.eu/legal-content/NL/TXT/HTML/?uri=OJ:L_202401689#d1e38-127-1)
- [Impact Assessment Mensenrechten en Algoritmes](https://www.government.nl/documents/reports/2022/03/31/impact-assessment-fundamental-rights-and-algorithms)

## Wanneer van toepassing? 
<!-- tags-ai-act -->


## Risico

Het niet uitvoeren van deze beoordeling kan leiden tot schendingen van de grondrechten, juridische complicaties en verlies van vertrouwen van het publiek in het gebruik van AI-systemen door overheids- en openbare dienstverlenende entiteiten.


## Maatregelen { data-search-exclude }

<!-- list_maatregelen vereiste/aia-27-beoordelen-gevolgen-grondrechten no-search no-onderwerp no-rol no-levenscyclus -->

## Hulpmiddelen

<!-- list_hulpmiddelen vereiste/aia-27-beoordelen-gevolgen-grondrechten no-search no-onderwerp no-rol no-levenscyclus no-id -->
