{"config":{"lang":["nl"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Algoritmekader","text":"Wetten en regels, tips en hulpmiddelen voor verantwoord gebruik van algoritmes en AI.       B\u00e8taversie <p>Deze website is in ontwikkeling. Alle versies ontstaan op een open manier. Iedereen mag opmerkingen of suggesties geven.</p> Over het Algoritmekader Voldoen aan wetten en regels <ul> <li>Vereisten</li> <li>Aanbevolen maatregelen</li> <li>Aanbevolen instrumenten</li> </ul> Informatie per rol <ul> <li>Beleidsmedewerker</li> <li>Data scientist</li> <li>Ethici</li> <li>Jurist</li> <li>Projectleider</li> </ul> Bekijk alle rollen Onderwerpen <ul> <li>Bias en non-discriminatie</li> <li>Governance</li> <li>Transparantie</li> <li>Privacy &amp; gegevensbescherming</li> <li>Publieke inkoop</li> </ul> Bekijk alle onderwerpen Levenscyclus <ul> <li>Probleemanalyse</li> <li>Ontwerpen</li> <li>Dataverkenning &amp; datapreparatie</li> <li>Ontwikkelen</li> <li>Monitoring &amp; beheer</li> </ul> Bekijk de hele levenscyclus <p>Tip</p> <p>Vind snel de betekenis van begrippen als algoritme, AI-systeem, hoog-risico-AI-systeem en impactvolle algoritmes in onze woordenlijst</p> Help ons deze pagina te verbeteren <p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"version/","title":"Version","text":""},{"location":"version/#-","title":"---","text":""},{"location":"version/#huidige-versie","title":"Huidige versie","text":"<p>v1.5.1-45-gb7172d4e</p>"},{"location":"governance/","title":"Governance","text":""},{"location":"governance/#wat-is-governance","title":"Wat is governance","text":"<p>Governance gaat over de inrichting van een organisatie en de daarbij horende processen, regels, gebruiken en bijbehorende verantwoordelijkheden.  Dit onderdeel van het Algoritmekader gaat over de governance van AI en algoritmes en systemen waarin deze verwerkt zijn. </p> <p>Let op!</p> <p>Governance wordt in verschillende contexten anders gebruikt. In dit deel hebben we het over governance over algoritmes en AI.  Omdat het Algoritmekdader uitgaat van de brede definitie van een algoritme, hanteren we voor het gemak de term \u201calgoritmegovernance\u201d als we het hebben over governance over algoritmes en AI. </p> <p>De noodzaak van algoritme governance is om grip te hebben (of krijgen) op algoritmes en AI binnen een organisatie en zaken als (onbedoelde) discriminatie te voorkomen.  Mede gezien de AI-verordening, die 1 augustus 2024 gefaseerd in werking is getreden, is het van belang dat organisaties zich organiseren om deze wet correct te kunnen uitvoeren.  Bewustzijn bij bestuur en organisatie is daarvoor een belangrijk vertrekpunt.</p>"},{"location":"governance/#verschillende-niveaus-van-governance","title":"Verschillende niveau's van governance","text":"<p>Algoritmegovernance bestaat op verschillende niveaus: van (inter)nationaal niveau, naar organisatieniveau naar het niveau van het AI-systeem (zie figuur hieronder). </p> <p>Het Algoritmekader focust op de twee niveaus: </p> <ul> <li>Organisatie</li> <li>Systeem/toepassing (lifecycle).</li> </ul> <p></p> <p>Binnen een organisatie kan algoritme governance niet los worden gezien van de algemene governance, data-governance en IT-governance.  Per organisatie zal verschillen in hoeverre dit is ontwikkeld. De omvang van een organisatie is ook een belangrijk aspect.  Algoritmegovernance moet aansluiten bij de strategie, doelstellingen en publieke waarden van een organisatie, waarbij moet worden voldaan aan wettelijke vereisten en ethische principes (M\u00e4ntym\u00e4ki et al., 2022). Deze aspecten en meer worden in de volgende hoofdstukken behandeld. </p>"},{"location":"governance/#leeswijzer-governance-in-het-algoritmekader","title":"Leeswijzer: Governance in het Algoritmekader","text":"<p>Als je deze sectie over governance leest, ben je waarschijnlijk ge\u00efnteresseerd in het opzetten of verbeteren van algoritmegovernance bij jou organisatie.</p> <p>Een algoritmegovernance ingericht hebben is een randvoorwaarde om de vereisten die het Algoritmekader noemt verantwoord en gestructureerd aan te pakken. In dit onderdeel geven we informatie en voorbeelden om hierheen te werken. We hebben hierin twee fases in onderscheiden, die weer uit verschillende hoofdstukken bestaan:</p> <ol> <li>Huidige situatie en randvoorwaarden algoritmegovernance.</li> <li>Algoritme governance realiseren met best practices en voorbeelden.</li> </ol> <p>Aan het einde van ieder hoofdstuk binnen het onderwerp governance geven we aandachts- en actiepunten om zelf hiermee aan de slag te gaan.</p>"},{"location":"governance/#fase-1-huidige-situatie-algoritmegovernance","title":"Fase 1: Huidige situatie algoritmegovernance","text":"<p>Om een goede algoritmegovernance te realiseren is het van belang eerst de organisatie te kennen. Wat er al is aan governance (processen, rollen, etc.), be\u00efnvloedt hoe algoritmegovernance daaraan opgehangen kan worden. De eerste fase van het in kaart brengen van de huidige situatie algoritmegovernance is ingedeeld in:</p> <ul> <li>Volwassenheid en ontwikkelstappen: Het niveau van volwassenheid verschilt per organisatie. Daarnaast is de grootte van een organisatie van grote invloed. </li> <li>Samenhang verschillende governance structuren: algoritmegovernance kan niet los worden gezien van de algemene governance, datagovernance en IT-governance. </li> <li>Belang bestuurlijke/politiek verantwoordelijkheid: De waarden die de organisatie vanuit (politieke) bestuurlijke top uitzet geven daarbij ook belangrijke kleur aan de inrichting van de algoritmegovernance.</li> </ul>"},{"location":"governance/#fase-2-best-practices-en-voorbeelden-van-algoritme-governance","title":"Fase 2: Best practices en voorbeelden van algoritme governance","text":"<p>De tweede fase gaat over het realiseren van een algoritmegovernance met best practices en voorbeelden van algoritme governance.  De volgende onderwerpen komen hier aan de orde:</p> <ul> <li>Governance structuur: basis in 3 lines of defense</li> <li>Governance per risicogroep</li> <li>Algoritmelevenscyclus(beslis-\u201cgates\u201d)</li> <li>Rollen en verantwoordelijkheden</li> <li>Interactie met burgers en omgeving</li> </ul> <p>Voorbeelden bieden in hoofdlijnen een \u2018blauwdruk\u2019 voor hoe algoritmegovernance kan worden ingericht.  Belangrijk om te realiseren dat altijd moet worden gekeken hoe dit in de eigen organisatie is in te passen.  Het is afhankelijk van onder andere de grootte en inrichting van de organisatie.  Waar mogelijk geven we daarom voorbeelden uit een divers scala aan organisaties. De best practices geven handvatten en lessen om ook zelf aan de slag te gaan.  </p>"},{"location":"governance/#wat-algemene-best-practices","title":"Wat algemene best practices","text":"<ul> <li>Maak iemand verantwoordelijk voor het opstellen van de algoritmegovernance</li> <li>Zorg voor overlegstructuren met keuzemandaat met belangrijke partijen/stakeholders</li> </ul>"},{"location":"governance/#vereisten","title":"Vereisten","text":"idVereistenaia-01Bevorder AI-geletterdheid van personeel en gebruikersaia-02Documentatie beoordeling niet-hoog-risico AIaia-03Verplicht risicobeheersysteem voor hoog-risico AIaia-11Kwaliteitsbeheersysteem voor hoog-risico AIaia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-22Maatregelen van gebruiksverantwoordelijken voor gebruikaia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningaia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemaia-28Recht op uitleg AI-besluitenaia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-37Melden van ernstige incidentenaia-38Veilig melden van inbreuk op AI verordeningaia-39Klachtrecht aanbieders verder in AI-waardeketenarc-01De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01Auteursrechten mogen niet worden geschondenavg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking"},{"location":"governance/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-01Bepaal of er genoeg experts beschikbaar zijnorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesorg-03Maak een plan voor het omgaan met risico\u2019sorg-04Maak afspraken over het wijzigen van de codeorg-05Maak afspraken over het beheer van gebruikersorg-06Maak afspraken over het beheer van wachtwoordenorg-07Controleer en verbeter regelmatig de kwaliteit van het algoritmepba-01Beschrijf het probleem dat het algoritme moet oplossenpba-02Beschrijf het doel van het algoritmepba-03Beschrijf waarom een algoritme het probleem moet oplossenpba-04Overleg regelmatig met belanghebbendenpba-05Beschrijf de wettelijke grondslag voor de inzet van het algoritmeowp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrixowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenowk-02Maak een noodplan voor het stoppen van het algoritmever-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidimp-01Maak een openbaar besluit over de inzet van het algoritmeimp-03Organiseer menselijke controle van het algoritmeimp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeemimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenimp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.mon-03Maak een noodplan voor beveiligingsincidentenMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocument"},{"location":"governance/governance-realiseren/governance-per-risicogroep/","title":"Governance en risio classificatie","text":"<p>Er is verschil in de vereisten en maatregelen die nodig zijn afhankelijk van het type risico en impact van algoritmen. Meer risicovolle AI vraagt om meer uitgebreide processen, en dus een meer uitgebreide governance in de zin dat de processen die doorlopen moeten worden uitgebreider zijn. Bijvoorbeeld vereisten toetsen die alleen gelden voor generatieve AI en bij simpele beslisregels maken de processen niet onnodig complex en zwaar maken.</p> <p>Afgeleid van de term \"minimum viable product\" wordt de processen van compliance doen aansluiten op wat nodig is ook wel \"minimum viable compliance\" genoemd.</p> <p>Als voorbeeld: De gemeente Rotterdam kiest ervoor om de algoritme en AI governance alleen in te zetten bij hoog-risico AI-toepassingen. Deze risicoclassificatie volgt de AI verordening Voor laag-risico toepassingen geldt de standaard governance van de gemeente: de informatiebeveiligings- en privacy governance (Kleur Bekennen, Rekenkamer Rotterdam, 2024, p.71). Tabel 1 geeft inzicht in verschillende typen algoritmen en AI-toepassingen. De afbeelding uit hetzelfde rapport geeft een flowchart van hoe de governance anders is afhankelijk van de risico-categorie. </p> <p></p> <p>Kijk zelf goed wat passend is voor jouw organisatie. </p>"},{"location":"governance/governance-realiseren/governance-per-risicogroep/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten","text":""},{"location":"governance/governance-realiseren/governance-per-risicogroep/#bronnen","title":"Bronnen","text":"<p>Kleur bekennen - vervolgonderzoek algoritmes </p>"},{"location":"governance/governance-realiseren/governance-structuur/","title":"Governance structuur","text":"<p>Een mogelijke inrichting van algoritme en AI governance die vaak wordt toegepast is het three lines of defence model:</p> <ul> <li>De eerste linie gaat over eigenaarschap, ontwikkeling, gebruik en risicobeheersing van algoritme en AI toepassingen.</li> <li>De tweede linie identificeert, beoordeelt en rapporteert over risico\u2019s en het uitgevoerde gebruik algoritmes en AI toepassingen.</li> <li>De derde verdedigingslinie controleert de werking van de governance en betreft interne advisering en toetsing. </li> </ul> <p>Schuett (2022) presenteert het three lines of defence model als volgt: </p> <p>Als voorbeeld: Onder andere UWV en de Gemeente Rotterdam hanteren dit model met drie linies. Rekenkamer Rotterdam rapport vat three lines of defence model als volgt samen: \u201ceerste lijn is verantwoordelijk voor het realiseren van doelen. De tweede lijn is, onafhankelijk van de eerste lijn verantwoordelijk voor kaders en adviezen. De derde lijn controleert of de eerste en tweede lijn gezamenlijk doelmatig, doeltreffend en rechtmatig hebben gefunctioneerd.\u201d </p> <p>Bij de gemeente Rotterdam zijn bijvoorbeeld de drie lijnen ingevuld via de volgende rollen en verantwoordelijkheden: \u201cDe eerste lijn bestaat uit de proceseigenaren en de operationeel verantwoordelijken. Proceseigenaren zijn verantwoordelijk voor de gehele algoritmetoepassing en de operationeel verantwoordelijken voor de ontwikkeling. De tweede lijn is de algoritme expert, die een onafhankelijke toezicht- en adviestaak heeft. De derde lijn wordt volgens de stukken die gaan over de algoritme governance vervuld door Financial audit.\u201d (Rekenkamer Rotterdam, 2024) </p> <p>De algoritmegovernance van de Gemeente Rotterdam bestaat uit de volgende onderdelen: </p> <ol> <li>een visie op de inzet van algoritmes;</li> <li>instrumentarium voor risicobeheersing dat onder andere bestaat uit een risico-assessment en een mensenrechtenassessment; </li> <li>een uiteenzetting van rollen en verantwoordelijkheden en; </li> <li>een omschrijving van de verantwoordelijkheden voor controle en advies.</li> </ol>"},{"location":"governance/governance-realiseren/governance-structuur/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten","text":""},{"location":"governance/governance-realiseren/governance-structuur/#bronnen","title":"Bronnen","text":"<p>Kleur bekennen - vervolgonderzoek algoritmes </p>"},{"location":"governance/governance-realiseren/interactie-burgers-en-omgeving/","title":"Interactie met burgers en omgeving","text":"<p>Bij het vormgeven van de algoritme en AI governance is het van belang om na te denken over de interactie met burgers en andere belangrijke stakeholders, zowel binnen als buiten de organisatie. Er moet worden nagedacht in welke gevallen dit passend is en welke processen, mechanismen en structuren hierbij kunnen helpen. Bijvoorbeeld het instellen van een centraal contactpunt voor vragen, en de wijze waarop een burger in beroep kan gaan op een besluit.</p>"},{"location":"governance/governance-realiseren/interactie-burgers-en-omgeving/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten","text":"<ul> <li>Onderzoek of je burgers en/of omgeving wil betrekken bij de AI-governance in je organisatie, en op welke manier. </li> <li>Dit kan strategisch (in het vaststellen van de waardes van je organisatie) op meer in operationele processen (op een vast punt in de AI-levenscyclus). </li> <li>Zie ter inspiratie Citizen Participation Methods for Artificial Intelligence</li> </ul>"},{"location":"governance/governance-realiseren/interactie-burgers-en-omgeving/#relevante-documenten","title":"Relevante documenten","text":"<ul> <li>Citizen Participation Methods for Artificial Intelligence</li> <li>Framework for Meaningfull Engagement </li> </ul>"},{"location":"governance/governance-realiseren/interactie-burgers-en-omgeving/#voorbeeld","title":"Voorbeeld","text":""},{"location":"governance/governance-realiseren/interactie-met-levenscyclus/","title":"Interactie met de levenscyclus","text":"<p>Voor effectieve governance van algoritmen en AI-modellen is het essentieel om bij de ontwikkeling en gebruik van algoritmen en AI-modellen heldere afspraken te hebben over de interactie en informatie-uitwisseling die vereist is om aan de verantwoording te voldoen. Dit moet gebeuren in iedere fase van de levenscyclus, tussen de direct betrokkenen en de stakeholders binnen en buiten de organisatie. Dit vindt plaats via de rollen en verantwoordelijkheden per levenscyclusstap.</p> <p>Het gaat enerzijds om top-down betrokkenheid en verantwoordelijkheid, waarbij wordt gestuurd op de juiste doelstellingen, waarden en principes. Daarnaast worden passende middelen en randvoorwaarden gealloceerd om verantwoorde inzet te waarborgen. Anderzijds gaat het om bottom-up betrokkenheid van de juiste stakeholders binnen de organisatie. Hierbij wordt de benodigde informatie verschaft en worden afwegingen en uitdagingen voorgelegd om de verantwoorde inzet van algoritmen en AI mogelijk te maken.</p> <p>In elke type levenscyclus vind je een ontwerpfase, een ontwikkelfase en een deployfase (in gebruik nemen).</p> <p>Veel organisaties hebben al een levenscyclus voor AI-ontwikkeling. AI-governance kan hierop aansluiten door 'gates' of controlepunten in te voeren tussen de verschillende stappen in de levenscyclus waar bepaalde processen worden uitgevoerd door verantwoordelijken, zoals het aanleveren van documenten, het uitvoeren van controles en het maken van afwegingen. </p> <p>Houd er rekening mee dat de 'gates' niet altijd hetzelfde hoeven te zijn tussen verschillende projecten. Zo vereist een algoritme met een hoog-risicoclassificatie andere governance dan minder impactvolle algoritmes. Eveneens vraagt het inkoopproces van een off-the-shelf AI-systeem of SaaS om andere procedures dan de inkoop van software die nog verder ontwikkeld wordt.</p> <p>Hieronder volgen twee voorbeelden van hoe governance effectief kan worden ge\u00efntegreerd in de levenscyclus van algoritmen en AI-modellen:</p> <p>Ministerie VWS In de levenscyclus</p> <p>In het hulpmiddel handelingsruimte waardevolle AI in de zorg is tussen elke fase in de levenscyclus een \u2018gate\u2019 geplaatst. Tussen de afronding van een fase en de start van de daaropvolgende fase wordt een formele poort geplaatst. Om door deze poort te gaan, moet de voorgaande fase volledig zijn afgerond: vraagstukken dienen beantwoord te zijn, activiteiten uitgevoerd en aan interne en externe vereisten dient te zijn voldaan. Deze zaken kunnen in de vorm van documentatie aan de organisatie worden opgeleverd, waarna een gesprek of review kan plaatsvinden.</p> <p>Het vormgeven van deze overgangen geeft verantwoordelijke stakeholders binnen de organisatie een structuur om de ontwikkeling en inzet van algoritmen en AI in elke fase te beoordelen en bij te sturen. De gezamenlijke kernvraag voor alle betrokkenen in de gates is: Geloven we dat de voordelen van de inzet (en ontwikkeling) van dit algoritme of AI-model opwegen tegen eventueel te verwachten nadelen? En hoe gaan we om met deze dilemma's? Daarbij kunnen opvolgende fasen in de levenscyclus een eigen accentvraag kennen, zoals \u201cIs het beoogde algoritme wenselijk?\u201d in de probleemanalyse fase tot \u201cLevert het algoritme nog de waarde op die we beogen?\u201d tijdens de monitoring- en beheerfase.</p> <p></p> <p>Voorbeeld: Het UWV</p> <p>In haar modellevenscyclus [^3] maakt het UWV gebruik van een gelaagdheid in de \u201cgates\u201d door gebruik te maken van een zachte en harde knip tussen de opvolgende fasen. Enerzijds is er een zachte knip voorzien door aan het eind van elke fase de mogelijkheid te laten om een stap terug te zetten in de levenscyclus. Mocht het onduidelijk zijn wat de beoogde voordelen zijn ten opzichte van de nadelen, of er onvoldoende invulling gegeven is aan de vereisten/activiteiten, dan kan het algoritme of AI-model ontwikkelproces bij een zachte knip een stap terugnemen in de levenscyclus. Anderzijds zijn er 4 harde grenzen in de levenscyclus aangebracht waarin formele vereisten aan het ontwikkeltraject worden opgelegd.</p> <p></p>"},{"location":"governance/governance-realiseren/interactie-met-levenscyclus/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten","text":"<ul> <li>Introduceer \u2018gates\u2019 tussen fases in de AI-lifecycle; voor de cyclus verder kan gaan moeten handelingen worden uitgevoerd door verantwoordelijken zoals: documenten aanleveren, (ethische) afwegingen, rapportages.</li> <li>De levencyclus bij inkoop is waarschijnlijk anders, maar heeft ook 'gates' en procedures nodig.</li> </ul>"},{"location":"governance/governance-realiseren/interactie-met-levenscyclus/#bronnen","title":"Bronnen","text":"<ul> <li> <p>Hulpmiddel handelingsruimte waardevolle AI in de zorg (presentatie)(samenvatting) is beschikbaar via de NL AI Coalitie en Data voor gezondheid</p> </li> <li> <p>UWV Beleidsdocument model risico management, Modellevenscyclus (blz 21), 29 september 2021</p> </li> </ul>"},{"location":"governance/governance-realiseren/rollen-en-verantwoordelijkheden/","title":"Rollen en verantwoordelijkheden","text":"<p>Binnen het vormgeven van effectieve en efficiente governance van algoritmen/AI zijn het beleggen van expliciete rollen en verantwoordelijkheden cruciaal. Het beleggen van deze rollen zorgt voor een actiegerichte structuur waarin zo weinig mogelijk verwarring/onduidelijkheid bestaat over wie wanneer aan zet is. Informatie-uitwisseling en besluitvorming tussen deze rollen zal effectief plaatsvinden. </p> <p>Binnen het Algoritmekader is idealiter ook een 'blauwdruk' RACI model opgenomen die voor alle vereisten/maatregelen in elke fase van de levenscyclus expliciet maakt waar welke rol ligt: zie hieronder een schets van hoe dit eruit kan zien. </p> <p></p>"},{"location":"governance/governance-realiseren/rollen-en-verantwoordelijkheden/#voorbeelden-van-rollen-en-verantwoordelijkheden-inrichten","title":"Voorbeelden van rollen en verantwoordelijkheden inrichten","text":"<p>Het three lines of defence model dat zowel de gemeente Rotterdam als het UWV hanteert biedt hiervoor handvatten. De essentie van dit model is het scheiden van drie niveau\u2019s in verantwoordelijkheden om effectieve governance mogelijk te maken. Daarnaast wordt in veel governance structuren een RACI model opgesteld om rollen en verantwoordelijkheden expliciet te maken. RACI is de afkorting voor Responsible (Verantwoordelijk \u2013 uitvoerder van de taak), Accountable (Aanspreekbaar \u2013 eigenaar van de taak), Consulted (Geconsulteerd) en Informed (Ge\u00efnformeerd). De gemeente Rotterdam heeft de interactie tussen rollen/verantwoordelijkheden van algoritme/AI governance en de volledige datamanagement structuur in een RACI model vormgegeven: </p> <p></p>"},{"location":"governance/governance-realiseren/rollen-en-verantwoordelijkheden/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten","text":"<ul> <li>RACI matrix Rotterdam interessant ter inspiratie, maar men begint niet bij nul.</li> <li>Onderzoek welke verantwoordlijkheden aanvullend zijn. Passen deze al bij bestaande rollen in de organisatie.</li> <li>Net als in onderdeel bestaande govenrance structuren is het wijs niet opnieuw het wiel uit te vinden.</li> <li>Het koppelen van verantwoordelijkheden aan functies is vaak complex en erg organisatieafhankelijk. Kijk eerst naar welke verantwoordelijkheden bij welke rollen passen. Een individu met een specifieke functie kan afhankelijk van de organisatie (en diens formaat) verschillende rollen vervullen</li> </ul>"},{"location":"governance/governance-realiseren/rollen-en-verantwoordelijkheden/#bronnen","title":"Bronnen","text":""},{"location":"governance/huidige-situatie/politiek-bestuurlijke-verantwoordelijkheden/","title":"Politiek-bestuurlijke verantwoordelijkheden","text":""},{"location":"governance/huidige-situatie/politiek-bestuurlijke-verantwoordelijkheden/#belang-bestuurlijke-en-politiek-verantwoordelijkheid","title":"Belang bestuurlijke en politiek verantwoordelijkheid","text":"<p>Voor een passende algoritmegovernance is politiek-bestuurlijk bewustzijn, betrokkenheid en verantwoordelijkheid essentieel. De kernvraag voor publieke organisaties bij de inzet van algoritmen is altijd: Hoe wegen we (als publieke organisatie of samenleving) de voordelen en nadelen van de inzet van algoritmen? </p> <p>Dit is per definitie een kwalitatieve en politieke vraag. Dit gaat niet alleen over direct opbrengsten maar ook over lange termijn en indirecte effecten, de mate waarin de inzet van technologie bijdraagt aan de legitimiteit van publieke organisatie en hoe burgers met deze technologie worden bejegend. </p> <p>Voorbeeld gemeente Rotterdam</p> <p>Een van de belangrijkste hoofdconclusies van het rapport Kleur Bekennen van de gemeente Rotterdam, opgesteld door de Algemene Rekenkamer, onderstreept het belang van actief bestuur binnen algoritme en AI governance: </p> <p>\"Het ontbreekt aan een politiek-bestuurlijk kader dat duidelijk maakt welke normen en principes leidend zijn bij de ontwikkeling en het gebruik van algoritmes. Dit heeft als effect dat belangrijke besluit over bijvoorbeeld wenselijkheid, haalbaarheid, transparantie en bias bij de ambtelijke organistie komen te liggen. Deze besluiten vragen echt om een politieke afweging\". </p>"},{"location":"governance/huidige-situatie/politiek-bestuurlijke-verantwoordelijkheden/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten","text":"<ul> <li>Een meerjarenbeleidsplan of een strategie- of visedocument kan richting geven in helpen met latere afwegingen maken.</li> </ul>"},{"location":"governance/huidige-situatie/politiek-bestuurlijke-verantwoordelijkheden/#bronnen","title":"Bronnen","text":"<p>Kleur bekennen - vervolgonderzoek algoritmes</p>"},{"location":"governance/huidige-situatie/samenhang-governancestructuren/","title":"Samenhang en samenwerking bestaande governance","text":"<p>Bij de vormgeving van een algoritmegovernance van een organisatie is het van belang om aansluiting en samenwerking te bewerkstelligen met huidige governancestructuren binnen de organisatie, zoals IT, data, informatiebeveiliging en privacy governance waar dit onlosmakelijk mee verbonden is. </p> <p>In veel organisaties werken privacy- en informatiebeveiliging nauw samen van strategisch organisatieniveau tot operationeel omdat deze onderwerpen raken en beide domeinen. Dit geldt in nog grotere mate voor AI-vraagstukken die vragen om samenwerking en expertise vanuit veel verschillende invalshoeken.</p> <p>Communicatie en vindbaarheid tussen de verschillende domeinen is hierin essentieel. De eindverantwoordelijkheid voor algoritmes moet bij \u00e9\u00e9n entiteit belegd worden, die let op het betrekken van de juiste (interne) partijen. </p> <p>Bij algoritme governance moet rekening worden gehouden met mogelijk conflicterende belangen. Bijvoorbeeld, het kan voorkomen dat de business of IT-teams innovatie willen nastreven, terwijl compliance teams juist vragen om het afremmen van innovatie. Een algortime-eindverantwoordelijke dient hierin de afwegingen te maken, in samenspraak. Een strategie of visie zoals vastgelegd in een meerjarenbeleidsplan sturing geven en bestuurlijke steun opleveren in het maken van afwegingen.</p> <p>Mocht een visie op AI ontbreken, dan kan iets als de IAMA (die zich ook richt op het afwegen van fundamentele rechten) een keer grondig doorlopen voor een AI-toepassing input geven voor de organisatievisie. </p> <p>Een concreet voorbeeld van samen optrekken is deze handreiking om de IAMA en DPIA gezamelijk uit te voeren.</p>"},{"location":"governance/huidige-situatie/samenhang-governancestructuren/#normen","title":"Normen","text":"<p>Normen en standaarden kunnen op twee manieren van belang zijn in deze fase van het werken naar een algortime governance.  1) Er zijn normen in de maak die kunnen ondersteunen bij het inrichten van AI-governance.   * De ISO/IEC 42001:2023 voor AI risk management framework (helaas zijn ISO-normen niet vrij beschikbaar).       * Deze norm richt zich op ethiek, transparantie, verantwoordelijkheid en veiligheid bij de ontwikkeling en inzet van AI-systemen.       * Later uitgebrachte normen zullen worden gelinkt aan deze norm om meer invulling te geven aan onderdelen ervan.   * Ook is er een oproep vanuit de EU om standaarden te ontwikkelen die direct aansluiten bij de AI-verordening. Deze worden verwacht april 2025, meer informatie is te vinden op deze website over de AI-Verordening. 2) Aan AI-verwante thema's, zoals privacy en data, hebben ook te maken met normen, standaarden, en wetgeving.    * De inzet van algoritmes raakt aan deze thema's, dus passende samenwerking is vereist.   * Vanuit de (implementatie van de) AVG en bijbehorende privacygovernance kunnen lessen zijn geleerd die zich vertalen naar algoritme governance. Een belangrijke standaard m.b.t. de AVG is de ISO-27001.</p>"},{"location":"governance/huidige-situatie/samenhang-governancestructuren/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten","text":"<ul> <li>Welke lessen zijn geleerd met de implementatie van de AVG?</li> <li>Is er iemand intern verantwoordelijk gemaakt voor (toezicht op) AI &amp; algoritmes?</li> <li>Hoe communiceren verschillende groepen die aan AI-thema\u2019s raken, zoals privacy of data, op dit moment?</li> <li>Een RACI-model kan ook helpen hierbij (zie het hoofdstuk over rollen en verantwoordelijkheden).</li> <li>Hoe worden afwegingen gemaakt in de organisatie tussen innovatie en compliance?</li> <li>Welke normen en standaarden zijn nu al in gebruik, of kunnen helpen met het vormgeven van algoritmegovernance?</li> </ul>"},{"location":"governance/huidige-situatie/samenhang-governancestructuren/#bronnen","title":"Bronnen","text":""},{"location":"governance/huidige-situatie/volwassenheidsniveau/","title":"Volwassenheidsniveau","text":"<p>Om tot een passende algoritmegovernance voor een organisatie te komen, moet eerst worden vastgesteld wat op dit moment al is ingericht op het gebied van AI en algoritmes.  Dit wordt het bepalen van het zogenaamde 'volwassenheidsniveau' genoemd.  Op basis hiervan kunnen vervolgstappen worden gedefinieerd waar een organisatie aan kan gaan werken om zich naar de volgende niveaus voor algoritmegovernance door te ontwikkelen. </p> <p>Er zijn verschillende volwassenheidsmodellen hiervoor te gebruiken. Enkele voorbeelden zijn hieronder beschreven.  Deze modellen richten zich niet altijd expliciet op algoritmegovernance, maar kijken naar algoritmes in de organisatie in brede zin of naar \u201cAI-ethics\u201d.  Governance is echter altijd een onderdeel van deze volwassenheidsmodellen.</p>"},{"location":"governance/huidige-situatie/volwassenheidsniveau/#voorbeelden-van-volwassenheidsmodellen","title":"Voorbeelden van volwassenheidsmodellen","text":""},{"location":"governance/huidige-situatie/volwassenheidsniveau/#ai-ethics-maturity-model-van-krijger-thuis-de-ruiter-ligthart-broekman-2023","title":"AI ethics maturity model van Krijger, Thuis, de Ruiter, Ligthart &amp; Broekman (2023)","text":"<p>Het AI ethics maturity model van Krijger, Thuis, de Ruiter, Ligthart &amp; Broekman (2023) is op basis van zes categorie\u00ebn (awareness &amp; culture, Policy, Governance, Communication &amp; Training, Development Proces, en Tooling) op verschillende niveau\u2019s. </p> <p></p>"},{"location":"governance/huidige-situatie/volwassenheidsniveau/#het-datavolwassenheidsmodel-van-de-ibds","title":"Het Datavolwassenheidsmodel van de IBDS","text":"<p>Richt zich op datavolwassenheid, maar heeft daarin veel raakvlakken met AI waarvoor data een belangrijk component is.  Heeft een eigen beslishulp datavolwassenheid maar ook een meetgids met verschillende methoden.</p>"},{"location":"governance/huidige-situatie/volwassenheidsniveau/#flexible-maturity-model-for-ai-governance-based-on-the-nist-ai-risk-management-framework-van-de-ieee-usa","title":"Flexible Maturity Model for AI Governance Based on the NIST AI Risk Management Framework van de IEEE-USA","text":"<p>De NIST is een veelgebruikte standaard voor cybersecurity (onlangs ge\u00fcpdatet en nu soms NIS2 of NIST2 genoemd).  Het NIST-model bekijkt AI-governance volwassenheid aan de hand van categorie\u00ebn uit de NIST.</p>"},{"location":"governance/huidige-situatie/volwassenheidsniveau/#responsible-ai-maturity-model-van-microsoft-research","title":"Responsible AI Maturity Model van Microsoft Research","text":"<p>Het Responsible AI Maturity Model van Microsoft Research is onderverdeeld in drie onderdelen (organisational foundation, team approach, en RAI practice) waarvan organisational foundation ingaat op AI Governance. </p>"},{"location":"governance/huidige-situatie/volwassenheidsniveau/#innovatie-en-volwassenheid","title":"Innovatie en volwassenheid","text":"<p>Inzet van AI kan vaak worden gezien als innovatie.  Hoe kunnen innovatieve idee\u00ebn worden ondersteund door AI en hoe kan AI worden gebruikt om nieuwe innovatieve toepassingen te vinden?  Ook voor innovatie bestaan er volwassenheidsmodellen.  Een voorbeeld van een volwassenheidsmodel voor innovatie is de Innovatie Maturity Scan van Innoveren met Impact. </p> <p>Om zowel op AI als op innovatie te verbeteren, kunnen volwassenheidsmodellen voor AI en voor innovatie worden ge\u00efntegreerd.  Om dat te doen is het goed om te kijken naar de overlap en de verschillen tussen de twee modellen.  Vul het ene model aan met de nog ontbrekende elementen uit het andere model.  Bepaal het huidige niveau van de organisatie op beide modellen.  Vergelijk voor beide modellen het huidige niveau met het gewenste niveau en ontwikkel een roadmap om de doelen te bereiken. </p>"},{"location":"governance/huidige-situatie/volwassenheidsniveau/#verdere-stappen","title":"Verdere stappen","text":"<p>Nadat een volwassenheidsniveau van de algoritmegovernance is vastgesteld kunnen hier concrete taken aan worden verbonden.  Het realiseren van algoritmegovernance vraagt zeer waarschijnlijk om een organisatieverandering.  Het is aan te raden om verantwoordelijkheid te beleggen voor het realiseren van AI-governance.  Dit is mogelijk te koppelen aan de implementatie van de AI-verordening binnen de organisatie.  Bewustzijn over de noodzaak voor algoritmegovernance moet op bestuurlijk niveau helder zijn.  Een analyse van volwassenheidsniveau kan helpen input te geven waar eerst op te richten.</p>"},{"location":"governance/huidige-situatie/volwassenheidsniveau/#aandachts-en-actiepunten","title":"Aandachts- en actiepunten:","text":"<ul> <li>Breng in kaart wat er al is aan IT-governance met \u00e9\u00e9n van de volwassenheidsmodellen.</li> <li>Is de organisatie volwassen? Vallen AI en algoritmes al ergens onder? </li> <li>Breng deze informatie naar je bestuur met het verzoek duidelijkheid te krijgen hoe AI-governance belegd zou moeten worden. De AI-verordening vraagt om belegde verantwoordelijkheden met betrekking tot AI en algoritmes.</li> <li>Er is verschil in datageletterdheid van ambtenaren. Benodigde skills en expertise (die mogelijk ontbreken) zijn van belang bij het invullen van rollen en verantwoordelijkheden.</li> </ul>"},{"location":"instrumenten/","title":"Instrumenten","text":"<p>Overzicht van aanbevolen instrumenten voor het verantwoord ontwikkelen, gebruiken, beoordelen en monitoren van algoritmes en AI-systemen.</p>"},{"location":"instrumenten/#richtlijnen-en-andere-hulpmiddelen","title":"Richtlijnen en andere hulpmiddelen","text":"<p>Met instrumenten bedoelen we hulpmiddelen voor verantwoord en effectief gebruik van algoritmes en AI-systemen, zoals:</p> <ul> <li>richtlijnen</li> <li>standaarden</li> <li>leidraden</li> <li>handboeken</li> </ul> <p>Deze instrumenten helpen je bij het op een rij zetten, beoordelen en verbeteren van de kenmerken, prestaties, effecten en risico\u2019s van algoritmes en AI.</p>"},{"location":"instrumenten/#hoe-we-instrumenten-selecteren","title":"Hoe we instrumenten selecteren","text":"<p>Instrumenten die we aanbevelen, zijn:</p> <ul> <li>relatief bekend onder ambtenaren</li> <li>in gebruik door overheid, wetenschap of industrie </li> <li>positief beoordeeld door gebruikers</li> <li>geschikt voor algoritmes of AI-systemen van overheden</li> </ul> <p>Staat een instrument niet in onze selectie, dan kan het nog steeds een goed instrument zijn voor jouw organisatie. Er zijn dus meer instrumenten mogelijk. We maken een selectie om 2 redenen:</p> <ul> <li>Een selectie is duidelijker. Als we alle instrumenten aanbieden, is het voor gebruikers moeilijker te bepalen welk instrument of welke combinatie het meest geschikt is. Daarvoor lijken de instrumenten te veel op elkaar.</li> <li>Een selectie kunnen we controleren op kwaliteit. We kunnen niet alle instrumenten controleren.</li> </ul>"},{"location":"instrumenten/#sommige-instrumenten-zijn-verplicht","title":"Sommige instrumenten zijn verplicht","text":"<p>Als een instrument verplicht is, staat dit er duidelijk bij. Een verplicht hulpmiddel is bijvoorbeeld de Data protection impact assessment (DPIA).</p> <p>De meeste instrumenten zijn niet verplicht. Bepaal zelf of je er gebruik van maakt. </p>"},{"location":"instrumenten/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"instrumenten/DPIA/","title":"Data Protection Impact Assessment","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieJuristProjectleiderPrivacy en gegevensbescherming</p> <p>Direct naar de DPIA</p>"},{"location":"instrumenten/DPIA/#instrument","title":"Instrument","text":"<p>Is je organisatie van plan persoonsgegevens te verwerken, maar levert dat waarschijnlijk een hoog privacyrisico op?  Dan is je organisatie verplicht eerst een 'data protection impact assessment' (DPIA) uit te voeren.  Als organisatie moet je zelf bepalen of de gegevensverwerking een hoog privacyrisico oplevert.  En je dus een DPIA moet uitvoeren.  De volgende criteria kunnen hierbij helpen:</p> <ul> <li>Wat er in de Algemene verordening gegevensbescherming (AVG) staat over wanneer je een DPIA moet uitvoeren.</li> <li>De lijst van de Autoriteit Persoonsgegevens (AP) met soorten verwerkingen waarvoor je een DPIA moet uitvoeren.</li> <li>De 9 criteria voor een DPIA van de Europese privacytoezichthouders.</li> </ul> <p>De AVG geeft aan dat je in ieder geval een DPIA moet uitvoeren als je als organisatie:</p> <ul> <li>Systematisch en uitgebreid persoonlijke aspecten van mensen beoordeelt en dit gebeurt op basis van geautomatiseerde verwerking van persoonsgegevens, waaronder profiling. En hierop besluiten baseert die gevolgen hebben voor mensen. Bijvoorbeeld dat zij geen lening kunnen afsluiten. Een voorbeeld hiervan is creditscoring.</li> <li>Op grote schaal bijzondere persoonsgegevens verwerkt.</li> <li>Strafrechtelijke gegevens verwerkt.</li> <li>Op grote schaal en systematisch mensen volgt in een publiek toegankelijk gebied. Bijvoorbeeld met cameratoezicht.</li> </ul> <p>Een DPIA moet in een vroeg stadium van de beleids- of projectontwikkeling worden uitgevoerd.  Op dat moment kan namelijk nog zonder vooroordelen worden nagedacht over de gevolgen en kan het voorstel nog makkelijker worden herzien.  Dit voorkomt ook latere, kostbare aanpassingen in processen, herontwerp van systemen of zelfs stopzetten van een project.  Behalve aan het begin van een project kan een DPIA ook op andere momenten en meermaals worden uitgevoerd en geactualiseerd.  Als het voorstel wijzigt, wordt een DPIA opnieuw uitgevoerd.  Als de gegevensverwerkingen of de gevolgen ervan veranderen, moet de DPIA worden geactualiseerd.  Volgens de European Data Protection Board (EDPB) moet een DPIA iedere drie jaar worden ge\u00ebvalueerd.</p>"},{"location":"instrumenten/DPIA/#relevantie","title":"Relevantie","text":"<p>Een organisatie is bij wet verplicht een DPIA uit te voeren wanneer de verwerking van persoonsgegevens een hoog privacyrisico oplevert. Wanneer hier sprake van is binnen jouw organisatie, dan is de DPIA per definitie relevant voor jou. </p>"},{"location":"instrumenten/DPIA/#auteur","title":"Auteur","text":"<p>De DPIA is ontwikkeld door de Europese Unie in het kader van de AVG. </p>"},{"location":"instrumenten/DPIA/#bijbehorende-vereisten","title":"Bijbehorende vereisten","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieidVereistenRollenLevenscyclusOnderwerpenaia-01Bevorder AI-geletterdheid van personeel en gebruikers                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              aia-02Documentatie beoordeling niet-hoog-risico AI                  projectleider                               ontwerp                               governance                               transparantie              aia-03Verplicht risicobeheersysteem voor hoog-risico AI                  projectleider                               organisatieverantwoordelijkheden                               governance              aia-04Risicobeoordeling voor jongeren en kwetsbaren                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              aia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteria                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              aia-06Technische documentatie voor hoog-risico AI                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie                               technische-robuustheid-en-veiligheid              aia-07Automatische logregistratie voor hoog-risico AI                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               transparantie                               technische-robuustheid-en-veiligheid              aia-08Transparantie in ontwerp voor hoog-risico AI                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-09Toezichtmogelijkheden voor gebruikers                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              aia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-11Kwaliteitsbeheersysteem voor hoog-risico AI                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              aia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-13Bewaartermijn voor gegenereerde logs                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem                  projectleider                               implementatie                               transparantie              aia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico                  projectleider                               implementatie                               governance                               transparantie              aia-18Corrigerende maatregelen voor non-conforme AI                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-22Maatregelen van gebruiksverantwoordelijken voor gebruik                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               implementatie                               governance              aia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              aia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem                  projectleider                               monitoring-en-beheer                               menselijke-controle              aia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-26Informeren werknemers                  projectleider                               implementatie                               transparantie              aia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie                               governance              aia-28Recht op uitleg AI-besluiten                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              aia-29Beoordeling van grondrechten                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              aia-30Transparantieverplichtingen                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              aia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               transparantie              aia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij                  projectleider                               monitoring-en-beheer                               governance                               transparantie              aia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               governance                               technische-robuustheid-en-veiligheid              aia-35Verdere verwerking van persoonsgegevens in AI-testomgevingen                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              aia-36Monitoring na het in handel brengen                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-37Melden van ernstige incidenten                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              aia-38Veilig melden van inbreuk op AI verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              aia-39Klachtrecht aanbieders verder in AI-waardeketen                  projectleider                               organisatieverantwoordelijkheden                               governance                               fundamentele-rechten              arc-01De archiefwet is ook van toepassing op algoritmes en AI-systemen                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               governance                               data              aut-01Auteursrechten mogen niet worden geschonden                  jurist                               dataverkenning-en-datapreparatie                               ontwerp                               data                               governance              avg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvinden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-02Beperkte bewaartermijn van persoonsgegevens                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               uitfaseren                               privacy-en-gegevensbescherming              avg-03Persoonsgegevens verzamelen voor specifieke doeleinden                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              avg-04Proportionaliteit en subsidiariteit                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              avg-05Juistheid en actualiteit van gegevens                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              avg-07Transparantie bij verwerking persoonsgegevens                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              avg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              avg-09Privacyrechten                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              avg-10Recht op niet geautomatiseerde besluitvorming                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming              avg-11Privacy door ontwerp                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-12Beveiliging van de verwerking                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              avg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              awb-01Relevante feiten en belangen zijn bekend                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten              awb-02Een besluit berust op een deugdelijke motivering                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              bio-01Beveiliging informatie en informatiesystemen                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              bzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              dat-01Verbod op schenden databankenrechten                  jurist                               dataverkenning-en-datapreparatie                               data              grw-01Beschermen van fundamentele rechten en vrijheden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              grw-02AI-systemen en algoritmes mogen niet discrimineren                  projectleider                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              woo-01Eenieder heeft recht op toegang tot publieke informatie                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"instrumenten/IAMA/","title":"Impact Assessment Mensenrechten en Algoritmes","text":"<p>ProbleemanalyseOntwerpVerificatie en validatieImplementatieBeleid en adviesJuristProjectleiderFundamentele rechtenTransparantie</p> <p>Direct naar het IAMA</p>"},{"location":"instrumenten/IAMA/#instrument","title":"Instrument","text":"<p>Het Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen.  Het IAMA stelt een reeks vragen die moeten worden besproken en beantwoord om een zorgvuldige afweging van de inzet van algoritmen te waarborgen.  Dit proces is onderverdeeld in drie fasen: voorbereiding, input en throughput, en output en toezicht, waarbij steeds aandacht wordt besteed aan het vierde onderdeel van het IAMA: de impact op mensenrechten.  Het IAMA fungeert als naslagwerk voor de besluitvorming en is gekoppeld aan andere relevante richtlijnen en instrumenten, zoals de gegevensbeschermingseffectbeoordeling (ook wel DPIA).  Hierdoor biedt het een overkoepelend kader dat helpt om algoritmen verantwoord te implementeren en mogelijke risico\u2019s, zoals inbreuken op grondrechten, te identificeren en te mitigeren.</p>"},{"location":"instrumenten/IAMA/#relevantie","title":"Relevantie","text":"<p>Het IAMA kan op dit moment op veel politieke en internationale belangstelling rekenen.  In zowel de Eerste als Tweede Kamer zijn hierover moties ingediend en vragen gesteld.  Daarbij is het IAMA een van de weinige instrumenten in de EU die een interdisciplinaire discussie rondom (de ontwikkeling, inzet en monitoring van) algoritmes, AI en grondrechten initieert en bevordert. </p>"},{"location":"instrumenten/IAMA/#auteur","title":"Auteur","text":"<p>Het IAMA is ontwikkeld door de Utrecht Data School. De auteurs van het IAMA zijn prof. mr. Janneke Gerards, dr. Mirko Tobias Sch\u00e4fer, Arthur Vankan en Iris Muis, allen werkzaam aan de Universiteit Utrecht. Opdrachtgever voor de ontwikkeling is het Ministerie van Binnenlandse Zaken.</p>"},{"location":"instrumenten/IAMA/#bijbehorende-vereisten","title":"Bijbehorende vereisten","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieidVereistenRollenLevenscyclusOnderwerpenaia-01Bevorder AI-geletterdheid van personeel en gebruikers                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              aia-02Documentatie beoordeling niet-hoog-risico AI                  projectleider                               ontwerp                               governance                               transparantie              aia-03Verplicht risicobeheersysteem voor hoog-risico AI                  projectleider                               organisatieverantwoordelijkheden                               governance              aia-04Risicobeoordeling voor jongeren en kwetsbaren                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              aia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteria                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              aia-06Technische documentatie voor hoog-risico AI                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie                               technische-robuustheid-en-veiligheid              aia-07Automatische logregistratie voor hoog-risico AI                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               transparantie                               technische-robuustheid-en-veiligheid              aia-08Transparantie in ontwerp voor hoog-risico AI                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-09Toezichtmogelijkheden voor gebruikers                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              aia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-11Kwaliteitsbeheersysteem voor hoog-risico AI                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              aia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-13Bewaartermijn voor gegenereerde logs                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem                  projectleider                               implementatie                               transparantie              aia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico                  projectleider                               implementatie                               governance                               transparantie              aia-18Corrigerende maatregelen voor non-conforme AI                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-22Maatregelen van gebruiksverantwoordelijken voor gebruik                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               implementatie                               governance              aia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              aia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem                  projectleider                               monitoring-en-beheer                               menselijke-controle              aia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-26Informeren werknemers                  projectleider                               implementatie                               transparantie              aia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie                               governance              aia-28Recht op uitleg AI-besluiten                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              aia-29Beoordeling van grondrechten                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              aia-30Transparantieverplichtingen                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              aia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               transparantie              aia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij                  projectleider                               monitoring-en-beheer                               governance                               transparantie              aia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               governance                               technische-robuustheid-en-veiligheid              aia-35Verdere verwerking van persoonsgegevens in AI-testomgevingen                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              aia-36Monitoring na het in handel brengen                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-37Melden van ernstige incidenten                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              aia-38Veilig melden van inbreuk op AI verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              aia-39Klachtrecht aanbieders verder in AI-waardeketen                  projectleider                               organisatieverantwoordelijkheden                               governance                               fundamentele-rechten              arc-01De archiefwet is ook van toepassing op algoritmes en AI-systemen                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               governance                               data              aut-01Auteursrechten mogen niet worden geschonden                  jurist                               dataverkenning-en-datapreparatie                               ontwerp                               data                               governance              avg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvinden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-02Beperkte bewaartermijn van persoonsgegevens                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               uitfaseren                               privacy-en-gegevensbescherming              avg-03Persoonsgegevens verzamelen voor specifieke doeleinden                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              avg-04Proportionaliteit en subsidiariteit                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              avg-05Juistheid en actualiteit van gegevens                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              avg-07Transparantie bij verwerking persoonsgegevens                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              avg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              avg-09Privacyrechten                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              avg-10Recht op niet geautomatiseerde besluitvorming                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming              avg-11Privacy door ontwerp                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-12Beveiliging van de verwerking                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              avg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              awb-01Relevante feiten en belangen zijn bekend                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten              awb-02Een besluit berust op een deugdelijke motivering                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              bio-01Beveiliging informatie en informatiesystemen                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              bzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              dat-01Verbod op schenden databankenrechten                  jurist                               dataverkenning-en-datapreparatie                               data              grw-01Beschermen van fundamentele rechten en vrijheden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              grw-02AI-systemen en algoritmes mogen niet discrimineren                  projectleider                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              woo-01Eenieder heeft recht op toegang tot publieke informatie                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"instrumenten/IAMA/#bronnen","title":"Bronnen","text":"Bron Impact Assessment Mensenrechten en Algoritmes"},{"location":"instrumenten/IAMA/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"instrumenten/algoritmeregister/","title":"Algoritmeregister","text":"<p>Monitoring en beheerTransparantie</p> <p>Direct naar het Algoritmeregister</p>"},{"location":"instrumenten/algoritmeregister/#instrument","title":"Instrument","text":"<p>De regering wil dat de overheid algoritmes verantwoord gebruikt.  Mensen moeten erop kunnen vertrouwen dat algoritmes voldoen aan de waarden en normen van de samenleving.  En er moet uitleg zijn over hoe algoritmes werken.  Het Algoritmeregister helpt hierbij.  Wanneer overheidsorganisaties open zijn over algoritmes en hun toepassing, kunnen burgers, organisaties en media de overheid kritisch volgen.</p> <p>Je kunt hier meer lezen over de doelen van het Algoritmeregister.</p>"},{"location":"instrumenten/algoritmeregister/#relevantie","title":"Relevantie","text":"<p>In de Handreiking Algoritmeregister staan bruikbare handvatten voor overheidsorganisaties om met publicatie van hun algoritmes aan de slag te gaan.  Hierin wordt bijvoorbeeld duidelijkheid gegeven over welke doelen we ermee bereiken, welke algoritmes erin thuishoren en welke organisaties erin kunnen publiceren.</p>"},{"location":"instrumenten/algoritmeregister/#bijbehorende-vereisten","title":"Bijbehorende vereisten","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieidVereistenRollenLevenscyclusOnderwerpenaia-01Bevorder AI-geletterdheid van personeel en gebruikers                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              aia-02Documentatie beoordeling niet-hoog-risico AI                  projectleider                               ontwerp                               governance                               transparantie              aia-03Verplicht risicobeheersysteem voor hoog-risico AI                  projectleider                               organisatieverantwoordelijkheden                               governance              aia-04Risicobeoordeling voor jongeren en kwetsbaren                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              aia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteria                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              aia-06Technische documentatie voor hoog-risico AI                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie                               technische-robuustheid-en-veiligheid              aia-07Automatische logregistratie voor hoog-risico AI                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               transparantie                               technische-robuustheid-en-veiligheid              aia-08Transparantie in ontwerp voor hoog-risico AI                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-09Toezichtmogelijkheden voor gebruikers                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              aia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-11Kwaliteitsbeheersysteem voor hoog-risico AI                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              aia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-13Bewaartermijn voor gegenereerde logs                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem                  projectleider                               implementatie                               transparantie              aia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico                  projectleider                               implementatie                               governance                               transparantie              aia-18Corrigerende maatregelen voor non-conforme AI                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-22Maatregelen van gebruiksverantwoordelijken voor gebruik                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               implementatie                               governance              aia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              aia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem                  projectleider                               monitoring-en-beheer                               menselijke-controle              aia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-26Informeren werknemers                  projectleider                               implementatie                               transparantie              aia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie                               governance              aia-28Recht op uitleg AI-besluiten                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              aia-29Beoordeling van grondrechten                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              aia-30Transparantieverplichtingen                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              aia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               transparantie              aia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij                  projectleider                               monitoring-en-beheer                               governance                               transparantie              aia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               governance                               technische-robuustheid-en-veiligheid              aia-35Verdere verwerking van persoonsgegevens in AI-testomgevingen                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              aia-36Monitoring na het in handel brengen                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-37Melden van ernstige incidenten                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              aia-38Veilig melden van inbreuk op AI verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              aia-39Klachtrecht aanbieders verder in AI-waardeketen                  projectleider                               organisatieverantwoordelijkheden                               governance                               fundamentele-rechten              arc-01De archiefwet is ook van toepassing op algoritmes en AI-systemen                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               governance                               data              aut-01Auteursrechten mogen niet worden geschonden                  jurist                               dataverkenning-en-datapreparatie                               ontwerp                               data                               governance              avg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvinden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-02Beperkte bewaartermijn van persoonsgegevens                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               uitfaseren                               privacy-en-gegevensbescherming              avg-03Persoonsgegevens verzamelen voor specifieke doeleinden                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              avg-04Proportionaliteit en subsidiariteit                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              avg-05Juistheid en actualiteit van gegevens                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              avg-07Transparantie bij verwerking persoonsgegevens                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              avg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              avg-09Privacyrechten                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              avg-10Recht op niet geautomatiseerde besluitvorming                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming              avg-11Privacy door ontwerp                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-12Beveiliging van de verwerking                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              avg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              awb-01Relevante feiten en belangen zijn bekend                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten              awb-02Een besluit berust op een deugdelijke motivering                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              bio-01Beveiliging informatie en informatiesystemen                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              bzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              dat-01Verbod op schenden databankenrechten                  jurist                               dataverkenning-en-datapreparatie                               data              grw-01Beschermen van fundamentele rechten en vrijheden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              grw-02AI-systemen en algoritmes mogen niet discrimineren                  projectleider                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              woo-01Eenieder heeft recht op toegang tot publieke informatie                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"instrumenten/algoritmeregister/#bronnen","title":"Bronnen","text":"Bron Algoritmeregister"},{"location":"instrumenten/algoritmeregister/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"instrumenten/fairness-handbook/","title":"Fairness handbook","text":"<p>title: The Fairness Handbook toelichting: toelichting volgt levenscyclus: - probleemanalyse - ontwerp onderwerp: - bias-en-non-discriminatie - fundamentele-rechten rollen: - projectleider vereiste: - grw-02-non-discriminatie</p> <p>Direct naar het Fairness Handbook</p>"},{"location":"instrumenten/fairness-handbook/#instrument","title":"Instrument","text":"<p>Informatie volgt</p>"},{"location":"instrumenten/fairness-handbook/#relevantie","title":"Relevantie","text":"<p>Informatie volgt</p>"},{"location":"instrumenten/fairness-handbook/#bijbehorende-vereisten","title":"Bijbehorende vereisten","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieidVereistenRollenLevenscyclusOnderwerpenaia-01Bevorder AI-geletterdheid van personeel en gebruikers                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              aia-02Documentatie beoordeling niet-hoog-risico AI                  projectleider                               ontwerp                               governance                               transparantie              aia-03Verplicht risicobeheersysteem voor hoog-risico AI                  projectleider                               organisatieverantwoordelijkheden                               governance              aia-04Risicobeoordeling voor jongeren en kwetsbaren                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              aia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteria                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              aia-06Technische documentatie voor hoog-risico AI                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie                               technische-robuustheid-en-veiligheid              aia-07Automatische logregistratie voor hoog-risico AI                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               transparantie                               technische-robuustheid-en-veiligheid              aia-08Transparantie in ontwerp voor hoog-risico AI                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-09Toezichtmogelijkheden voor gebruikers                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              aia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-11Kwaliteitsbeheersysteem voor hoog-risico AI                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              aia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-13Bewaartermijn voor gegenereerde logs                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem                  projectleider                               implementatie                               transparantie              aia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico                  projectleider                               implementatie                               governance                               transparantie              aia-18Corrigerende maatregelen voor non-conforme AI                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-22Maatregelen van gebruiksverantwoordelijken voor gebruik                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               implementatie                               governance              aia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              aia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem                  projectleider                               monitoring-en-beheer                               menselijke-controle              aia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-26Informeren werknemers                  projectleider                               implementatie                               transparantie              aia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie                               governance              aia-28Recht op uitleg AI-besluiten                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              aia-29Beoordeling van grondrechten                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              aia-30Transparantieverplichtingen                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              aia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               transparantie              aia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij                  projectleider                               monitoring-en-beheer                               governance                               transparantie              aia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               governance                               technische-robuustheid-en-veiligheid              aia-35Verdere verwerking van persoonsgegevens in AI-testomgevingen                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              aia-36Monitoring na het in handel brengen                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-37Melden van ernstige incidenten                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              aia-38Veilig melden van inbreuk op AI verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              aia-39Klachtrecht aanbieders verder in AI-waardeketen                  projectleider                               organisatieverantwoordelijkheden                               governance                               fundamentele-rechten              arc-01De archiefwet is ook van toepassing op algoritmes en AI-systemen                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               governance                               data              aut-01Auteursrechten mogen niet worden geschonden                  jurist                               dataverkenning-en-datapreparatie                               ontwerp                               data                               governance              avg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvinden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-02Beperkte bewaartermijn van persoonsgegevens                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               uitfaseren                               privacy-en-gegevensbescherming              avg-03Persoonsgegevens verzamelen voor specifieke doeleinden                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              avg-04Proportionaliteit en subsidiariteit                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              avg-05Juistheid en actualiteit van gegevens                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              avg-07Transparantie bij verwerking persoonsgegevens                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              avg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              avg-09Privacyrechten                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              avg-10Recht op niet geautomatiseerde besluitvorming                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming              avg-11Privacy door ontwerp                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-12Beveiliging van de verwerking                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              avg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              awb-01Relevante feiten en belangen zijn bekend                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten              awb-02Een besluit berust op een deugdelijke motivering                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              bio-01Beveiliging informatie en informatiesystemen                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              bzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              dat-01Verbod op schenden databankenrechten                  jurist                               dataverkenning-en-datapreparatie                               data              grw-01Beschermen van fundamentele rechten en vrijheden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              grw-02AI-systemen en algoritmes mogen niet discrimineren                  projectleider                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              woo-01Eenieder heeft recht op toegang tot publieke informatie                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"instrumenten/fairness-handbook/#bronnen","title":"Bronnen","text":"<p>The Fairness Handbook</p>"},{"location":"instrumenten/fairness-handbook/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van het Fairness Handbook op het gebied van algoritmen? Laat het ons weten!</p>"},{"location":"instrumenten/handreiking-non-discriminatie/","title":"Handreiking non-discriminatie by design","text":"<p>ProbleemanalyseOntwerpProjectleiderBias en non discriminatieFundamentele rechten</p> <p>Direct naar de Handreiking non-discriminatie by design</p>"},{"location":"instrumenten/handreiking-non-discriminatie/#instrument","title":"Instrument","text":"<p>Deze handreiking legt uit welke vragen en principes leidend zijn bij het ontwikkelen en implementeren van een AI-systeem met het oog op het discriminatieverbod, vanuit zowel juridisch, technisch, als organisatorisch perspectief. De handreiking is een praktisch toepasbaar ontwerpkader dat ontwikkelaars helpt om al in de ontwikkelfase van een AI-systeem discriminerende patronen zoveel mogelijk te identificeren, te voorkomen en te bestrijden.</p> <p>Er zijn 4 uitgangspunten die leidend zijn in de handreiking:</p> <ol> <li>Diversiteit</li> <li>Context</li> <li>Controleerbaarheid</li> <li>Evaluatie.</li> </ol>"},{"location":"instrumenten/handreiking-non-discriminatie/#relevantie","title":"Relevantie","text":"<p>Stuk over relevantie voor het AK volgt nog. Net als bij het IAMA, is dit document een manier om een multidisciplinaire discussie te faciliteren en stimuleren. Hierbij kunnen verschillende rollen betrokken worden door de projectleider: data-scientists, juristen, de functionaris gegevensbescherming (FG), aangevuld met domeinspecialisten.</p>"},{"location":"instrumenten/handreiking-non-discriminatie/#wanneer-toepassen","title":"Wanneer toepassen?","text":"<p>De handreiking is primair geschreven voor teams die zelf AI-systemen bouwen. Het gaat in op verschillende fases van ontwikkeling: probleemanalyse, dataverkenning en datapreparatie, ontwikkeling, implementatie en evaluatie. Daarnaast kan deze handreiking dienen voor opdrachtgevers van AI-systemen, ofwel om vooraf offrerende partijen te vragen aan te geven hoe zij rekening zullen houden met de diverse punten uit de handreiking, ofwel om tijdens het proces mee te kijken en op relevante punten aanwijzingen te geven, ofwel om achteraf te controleren of een opgeleverd product aan alle relevante voorwaarden voldoet. </p>"},{"location":"instrumenten/handreiking-non-discriminatie/#relatie-tot-iama","title":"Relatie tot IAMA","text":"<p>Gebruikers van zowel de Handreiking non-discriminatie by design als het IAMA geven enkele verschillen tussen de twee instrumenten. Deze bevindingen zijn te vinden in het rapport 'Bekendheid, toepasbaarheid en toegevoegde waarde handreiking \u201cnon-discriminatie by design\"' van de Auditdienst Rijk.</p> <p>Zij geven aan dat het IAMA wordt gezien als instrument voor het nagaan van de impact van grondrechten in algemenere zin, waar de Handreiking zich specifiek richt op discriminatie. De handreiking bevat dan weer meer praktische voorbeelden die kunnen helpen bij begrip en afwegingen, waar de IAMA wat abstracter is.</p>"},{"location":"instrumenten/handreiking-non-discriminatie/#relatie-tot-het-fairness-handbook","title":"Relatie tot het Fairness Handbook","text":"<p>Over het Fairness Handbook werd in het rapport aangegeven dat het een technischere uitwerking bevat dan de Handreiking. Het Handbook biedt wellicht meer houvast voor iemand die analyses maakt om inzicht te geven in de prestaties van het algoritme met het oog op \u2018fairness\u2019 en \u2018bias\u2019. Dit komt doordat het Handbook meer details geeft over de technische stappen die nodig zijn om te komen tot bepaalde analyses.</p>"},{"location":"instrumenten/handreiking-non-discriminatie/#relatie-tot-toetsingskader-risicoprofielen-van-college-voor-de-rechten-van-de-mens","title":"Relatie tot Toetsingskader Risicoprofielen van College voor de Rechten van de Mens","text":"<p>Ook het toetsingskader voor discriminatie door risicoprofielen van het College voor de Rechten van de Mens kan worden gebruikt om te bepalen of er discriminatie plaatsvindt. Dit kader is afkomstig uit 2021 en er wordt gewerkt aan een nieuwe versie, die waarschijnlijk eind 2024 zal verschijnen. De verschillende stappen die daarin gebruikt worden om te bepalen of een risicoprofiel tot discriminatie leidt op grond van ras of nationaliteit, zijn zeer relevant. Daarvoor hebben zij een beslisboom ontwikkeld.</p>"},{"location":"instrumenten/handreiking-non-discriminatie/#bijbehorende-vereisten","title":"Bijbehorende vereisten","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieidVereistenRollenLevenscyclusOnderwerpenaia-01Bevorder AI-geletterdheid van personeel en gebruikers                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              aia-02Documentatie beoordeling niet-hoog-risico AI                  projectleider                               ontwerp                               governance                               transparantie              aia-03Verplicht risicobeheersysteem voor hoog-risico AI                  projectleider                               organisatieverantwoordelijkheden                               governance              aia-04Risicobeoordeling voor jongeren en kwetsbaren                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              aia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteria                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              aia-06Technische documentatie voor hoog-risico AI                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie                               technische-robuustheid-en-veiligheid              aia-07Automatische logregistratie voor hoog-risico AI                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               transparantie                               technische-robuustheid-en-veiligheid              aia-08Transparantie in ontwerp voor hoog-risico AI                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-09Toezichtmogelijkheden voor gebruikers                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              aia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-11Kwaliteitsbeheersysteem voor hoog-risico AI                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              aia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-13Bewaartermijn voor gegenereerde logs                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem                  projectleider                               implementatie                               transparantie              aia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico                  projectleider                               implementatie                               governance                               transparantie              aia-18Corrigerende maatregelen voor non-conforme AI                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-22Maatregelen van gebruiksverantwoordelijken voor gebruik                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               implementatie                               governance              aia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              aia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem                  projectleider                               monitoring-en-beheer                               menselijke-controle              aia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-26Informeren werknemers                  projectleider                               implementatie                               transparantie              aia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie                               governance              aia-28Recht op uitleg AI-besluiten                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              aia-29Beoordeling van grondrechten                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              aia-30Transparantieverplichtingen                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              aia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               transparantie              aia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij                  projectleider                               monitoring-en-beheer                               governance                               transparantie              aia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               governance                               technische-robuustheid-en-veiligheid              aia-35Verdere verwerking van persoonsgegevens in AI-testomgevingen                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              aia-36Monitoring na het in handel brengen                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-37Melden van ernstige incidenten                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              aia-38Veilig melden van inbreuk op AI verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              aia-39Klachtrecht aanbieders verder in AI-waardeketen                  projectleider                               organisatieverantwoordelijkheden                               governance                               fundamentele-rechten              arc-01De archiefwet is ook van toepassing op algoritmes en AI-systemen                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               governance                               data              aut-01Auteursrechten mogen niet worden geschonden                  jurist                               dataverkenning-en-datapreparatie                               ontwerp                               data                               governance              avg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvinden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-02Beperkte bewaartermijn van persoonsgegevens                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               uitfaseren                               privacy-en-gegevensbescherming              avg-03Persoonsgegevens verzamelen voor specifieke doeleinden                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              avg-04Proportionaliteit en subsidiariteit                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              avg-05Juistheid en actualiteit van gegevens                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              avg-07Transparantie bij verwerking persoonsgegevens                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              avg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              avg-09Privacyrechten                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              avg-10Recht op niet geautomatiseerde besluitvorming                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming              avg-11Privacy door ontwerp                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-12Beveiliging van de verwerking                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              avg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              awb-01Relevante feiten en belangen zijn bekend                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten              awb-02Een besluit berust op een deugdelijke motivering                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              bio-01Beveiliging informatie en informatiesystemen                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              bzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              dat-01Verbod op schenden databankenrechten                  jurist                               dataverkenning-en-datapreparatie                               data              grw-01Beschermen van fundamentele rechten en vrijheden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              grw-02AI-systemen en algoritmes mogen niet discrimineren                  projectleider                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              woo-01Eenieder heeft recht op toegang tot publieke informatie                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"instrumenten/handreiking-non-discriminatie/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking non-discriminatie by design</li> <li>Onderzoeksrapport Bekendheid, toepasbaarheid en toegevoegde waarde handreiking 'non-discriminatie by design'</li> <li>Toetsingskader voor discriminatie door risicoprofielen van het College voor de Rechten van de Mens (2021)</li> </ul>"},{"location":"instrumenten/handreiking-non-discriminatie/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van de Handreiking non-discriminatie by design op het gebied van algoritmen? Laat het ons weten!</p>"},{"location":"instrumenten/modelcontractbepalingen/","title":"Modelcontractbepalingen","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieVerificatie en validatieJuristPublieke inkoop</p>"},{"location":"instrumenten/modelcontractbepalingen/#instrument","title":"Instrument","text":"<p>Modelbepalingen kunnen helpen om een contract op te stellen dat een organisatie in staat stelt veilige en verantwoorde algoritmen of AI-systemen in te kopen.  Deze bepalingen (of voorwaarden) kunnen opgenomen worden wanneer er een contract wordt afgesloten met een leverancier van een algoritme of algoritmisch systeem.  Er kunnen dan bijvoorbeeld beperkingen gelden om onaanvaardbare risico's van AI te vermijden, of bepaalde voorwaarden gesteld worden waaraan een algoritme juist moet voldoen.  Ook kunnen bepaalde voorwaarden worden opgenomen op basis van de vereisten in het Algoritmekader.</p>"},{"location":"instrumenten/modelcontractbepalingen/#europese-commissie","title":"Europese Commissie","text":"<p>De Europese contractvoorwaarden voor AI bieden aanbestedende organisaties de mogelijkheid om specifieke clausules op te nemen in de overeenkomst. Op deze manier worden afspraken gemaakt over onderwerpen die in lijn zijn met de aankomende AI-Act. Er zijn 2 versies van de AI-inkoopvoorwaarden opgesteld: een set voorwaarden voor AI-toepassingen met een hoog-risicoprofiel en een set voorwaarden voor AI-toepassingen met een laag-risicoprofiel.</p>"},{"location":"instrumenten/modelcontractbepalingen/#gemeente-amsterdam","title":"Gemeente Amsterdam","text":"<p>De Europese contractvoorwaarden voor AI zijn gebaseerd op onder andere de modelbepalingen die de Gemeente Amsterdam al eerder opstelde. Deze dienen als voorbeeld voor andere gemeenten die algoritmische toepassingen willen inkopen.</p>"},{"location":"instrumenten/modelcontractbepalingen/#ai-module-bij-arbit-2022","title":"AI-module bij ARBIT-2022","text":"<p>De AI-module bij de ARBIT is gebaseerd op het gepubliceerd model van de Europese Commissie dat hierboven beschreven wordt. Via een verwijzing in de gebruikte modelovereenkomst kan de AI-module onderdeel gaan uitmaken van een onder de ARBIT te sluiten overeenkomst.</p> <p>De ARBIT zijn de Algemene Rijksinkoopvoorwaarden bij IT\u2011overeenkomsten (ARBIT) en zijn bedoeld voor kleine en middelgrote IT-inkopen door de overheid. Lees meer hierover op de website van PIANOo.</p>"},{"location":"instrumenten/modelcontractbepalingen/#relevantie","title":"Relevantie","text":"<p>Steeds meer organisaties kopen algoritmische toepassingen in die veel impact hebben op gebruikers of beslissingen. Het is daarom van belang dat aanbestedende overheidsorganisaties afspraken maken met leveranciers, zodat de werking van de algoritmische toepassing transparant is en op een veilige en verantwoorde manier gebruikt wordt. Verschillende organisaties hebben daarom (voorbeeld-)contractvoorwaarden voor het inkopen van AI-systemen beschikbaar gesteld. Denk aan de Europese Commissie en de Gemeente Amsterdam.</p>"},{"location":"instrumenten/modelcontractbepalingen/#bijbehorende-vereisten","title":"Bijbehorende vereisten","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieidVereistenRollenLevenscyclusOnderwerpenaia-01Bevorder AI-geletterdheid van personeel en gebruikers                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              aia-02Documentatie beoordeling niet-hoog-risico AI                  projectleider                               ontwerp                               governance                               transparantie              aia-03Verplicht risicobeheersysteem voor hoog-risico AI                  projectleider                               organisatieverantwoordelijkheden                               governance              aia-04Risicobeoordeling voor jongeren en kwetsbaren                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              aia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteria                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              aia-06Technische documentatie voor hoog-risico AI                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie                               technische-robuustheid-en-veiligheid              aia-07Automatische logregistratie voor hoog-risico AI                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               transparantie                               technische-robuustheid-en-veiligheid              aia-08Transparantie in ontwerp voor hoog-risico AI                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-09Toezichtmogelijkheden voor gebruikers                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              aia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-11Kwaliteitsbeheersysteem voor hoog-risico AI                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              aia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-13Bewaartermijn voor gegenereerde logs                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem                  projectleider                               implementatie                               transparantie              aia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico                  projectleider                               implementatie                               governance                               transparantie              aia-18Corrigerende maatregelen voor non-conforme AI                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-22Maatregelen van gebruiksverantwoordelijken voor gebruik                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               implementatie                               governance              aia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              aia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem                  projectleider                               monitoring-en-beheer                               menselijke-controle              aia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-26Informeren werknemers                  projectleider                               implementatie                               transparantie              aia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie                               governance              aia-28Recht op uitleg AI-besluiten                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              aia-29Beoordeling van grondrechten                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              aia-30Transparantieverplichtingen                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              aia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               transparantie              aia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij                  projectleider                               monitoring-en-beheer                               governance                               transparantie              aia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               governance                               technische-robuustheid-en-veiligheid              aia-35Verdere verwerking van persoonsgegevens in AI-testomgevingen                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              aia-36Monitoring na het in handel brengen                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-37Melden van ernstige incidenten                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              aia-38Veilig melden van inbreuk op AI verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              aia-39Klachtrecht aanbieders verder in AI-waardeketen                  projectleider                               organisatieverantwoordelijkheden                               governance                               fundamentele-rechten              arc-01De archiefwet is ook van toepassing op algoritmes en AI-systemen                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               governance                               data              aut-01Auteursrechten mogen niet worden geschonden                  jurist                               dataverkenning-en-datapreparatie                               ontwerp                               data                               governance              avg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvinden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-02Beperkte bewaartermijn van persoonsgegevens                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               uitfaseren                               privacy-en-gegevensbescherming              avg-03Persoonsgegevens verzamelen voor specifieke doeleinden                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              avg-04Proportionaliteit en subsidiariteit                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              avg-05Juistheid en actualiteit van gegevens                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              avg-07Transparantie bij verwerking persoonsgegevens                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              avg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              avg-09Privacyrechten                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              avg-10Recht op niet geautomatiseerde besluitvorming                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming              avg-11Privacy door ontwerp                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-12Beveiliging van de verwerking                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              avg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              awb-01Relevante feiten en belangen zijn bekend                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten              awb-02Een besluit berust op een deugdelijke motivering                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              bio-01Beveiliging informatie en informatiesystemen                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              bzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              dat-01Verbod op schenden databankenrechten                  jurist                               dataverkenning-en-datapreparatie                               data              grw-01Beschermen van fundamentele rechten en vrijheden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              grw-02AI-systemen en algoritmes mogen niet discrimineren                  projectleider                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              woo-01Eenieder heeft recht op toegang tot publieke informatie                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"instrumenten/modelcontractbepalingen/#bronnen","title":"Bronnen","text":"Bron Modelbepalingen voor gemeenten voor verantwoord gebruik van Algoritmische toepassingen Contractvoorwaarden voor het inkopen van artifici\u00eble intelligentie (AI) AI-module bij de modelovereenkomst ARBIT-2022"},{"location":"instrumenten/modelcontractbepalingen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van modelbepalingen of contractvoorwaarden op het gebied van algoritmen? Laat het ons weten!</p>"},{"location":"levenscyclus/","title":"Levenscyclus algoritmes en AI","text":"<p>Om algoritmes op een verantwoorde manier te gebruiken, zul je op de juiste momenten aandacht moeten hebben voor de juiste onderwerpen en risico's.  Van het ontwikkelen van een oplossing, tot het in gebruik nemen van die oplossing en er uiteindelijk weer mee stoppen. Door al in een vroeg stadium aandacht besteden aan bijvoorbeeld een eventuele inbreuk op mensenrechten kan je hier gedurende het hele proces al rekening mee houden. </p> <p>De levenscyclus helpt je om te bepalen wat je wanneer moet doen.</p> <pre><code>\n  flowchart TD\n      subgraph organisatieniveau [organisatieniveau &amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp]\n        0(0. Organisatieverantwoordelijkheden) --&gt; 1(1. Probleemanalyse);\n        subgraph systeemniveau [systeemniveau &amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp]\n          7(7. Monitoring en beheer) --&gt; 1(1. Probleemanalyse);\n          1(1. Probleemanalyse) --&gt; 2(2. Ontwerp);\n          2(2. Ontwerp) --&gt; 3(3. Dataverkenning en datapreparatie);\n          3(3. Dataverkenning en datapreparatie) --&gt; 4(4. Ontwikkelen);\n          4(4. Ontwikkelen) --&gt; 5(5. Verficatie en validatie);\n          5(5. Verficatie en validatie) --&gt; 6(6. Implementatie);\n          6(6. Implementatie) --&gt; 7(7. Monitoring en beheer);\n          7(7. Monitoring en beheer) -.-&gt; 8(8. Uitfaseren);\n        end\n      end\n\n      click 0 href \"organisatieverantwoordelijkheden\"\n      click 1 href \"probleemanalyse\"\n      click 2 href \"ontwerp\"\n      click 3 href \"dataverkenning-en-datapreparatie\"\n      click 4 href \"ontwikkelen\"\n      click 5 href \"verificatie-en-validatie\"\n      click 6 href \"implementatie\"\n      click 7 href \"monitoring-en-beheer\"\n      click 8 href \"uitfaseren\"\n\n      style 0 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 1 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 2 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 3 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 4 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 5 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 6 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 7 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 8 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n\n      style organisatieniveau fill:transparant\n</code></pre> <p>Tip</p> <p>In de praktijk herhaal je soms fases of ga je terug naar een eerdere fase. Mislukt bijvoorbeeld het valideren (fase 5), dan moet je terug naar de ontwerpfase (fase 2) omdat het product nog niet voldoet aan de wensen of vereisten.</p>"},{"location":"levenscyclus/#fases-van-de-levenscyclus","title":"Fases van de levenscyclus","text":"<ol> <li> Organisatieverantwoordelijkheden</li> <li> Probleemanalyse</li> <li> Ontwerp</li> <li> Dataverkenning en datapreparatie</li> <li> Ontwikkelen</li> <li> Verficatie en validatie</li> <li> Implementeren</li> <li> Monitoring en beheer</li> <li> Uitfaseren</li> </ol>"},{"location":"levenscyclus/#systeemniveau-en-organisatieniveau","title":"Systeemniveau en organisatieniveau","text":"<p>De levenscyclus kent twee verschillende niveau's: </p> <ul> <li>organisatieniveau: Sommige vereisten zijn algemeen en vragen om een organisatiebrede aanpak. Dit gaat bijvoorbeeld om passende processen en risicomanagment in je organisatie. Of het cre\u00eberen van bewustzijn en kennis binnen je organisatie. In het ideale geval besteed je hier al aandacht aan voordat je begint met de ontwikkeling of het gebruik van algoritmes. Bij deze fase horen maatregelen die je niet voor ieder systeem opnieuw zal hoeven te bekijken.</li> <li>systeemniveau: Sommige vereisten voor verantwoorde inzet van algoritmes zul je bij ieder algoritme weer opnieuw aandacht moeten geven. Dat geldt bijvoorbeeld voor het beschermen van grondrechten. </li> </ul>"},{"location":"levenscyclus/#andere-levenscyclusmodellen","title":"Andere levenscyclusmodellen","text":"<p>De 9 fasen van de levenscyclus zijn gebaseerd op 10 belangrijke levenscyclusmodellen voor het ontwikkelen van AI, zoals:</p> <ul> <li>CRISP-DM (cross-industry standard process for data mining)</li> <li>ASUM-DM (analytics solutions unified method)</li> <li>SEMMA (Sample, Explore, Modify, Model, and Assess)</li> <li>Microsoft TDSP (Team Data Science Process)</li> <li>MDLM (mobile device lifecycle management)</li> <li>NIST (National Institute of Standards and Technology)</li> <li>ISO/IEC 22989</li> </ul> <p>Deze 9 fasen passen zo goed mogelijk bij de manier van werken van overheden. Het is geen verplicht model. Mogelijk past een ander levenscyclusmodel beter bij jouw organisatie.</p>"},{"location":"levenscyclus/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/","title":"Dataverkenning en datapreparatie","text":"<p>In deze fase worden relevante datasets ge\u00efdentificeerd en wanneer nodig wordt nieuwe data verzameld.  In deze fase zal ook de ontwikkelomgeving (verder) worden ingericht indien nodig.  Het is van belang dat voorafgaand aan verzameling is vastgesteld dat de benodigde data mag worden verwerkt en dat de juiste maatregelen worden getroffen, zodra de data kan worden verwerkt.  Denk hierbij aan het anonimiseren, pseudonimiseren of aggregeren van persoonsgegevens.  De data zullen vervolgens worden opgeschoond, geanalyseerd en voorbereid voor verdere verwerking. </p> <p>Het is van belang dat dataverzameling op de juiste manier gebeurt, en dat datasets die gebruikt gaan worden van goede kwaliteit zijn.  In deze fase is het van belang om de datakwaliteit en eventuele bias in de dataset te onderzoeken.  Indien er risico's optreden door bijvoorbeeld missende data of niet representatieve data, is het belangrijk om te kijken wat voor effecten dit heeft op het oorspronkelijke ontwerp van het algoritme of AI-systeem.  Dit kan betekenen dat nieuwe keuzes moeten worden gemaakt in het ontwerp en eventueel eerste deze fase van ontwerp (deels) opnieuw moet worden doorlopen. </p> <p>Met voorgaande handelingen wordt het fundament gelegd om het algoritme of AI-systeem te kunnen ontwikkelen.  In de praktijk zal bijvoorbeeld het analyseren van de data niet stoppen na deze fase, maar terugkerend zijn in alle fasen die volgen.  Als de verzamelde data van voldoende kwaliteit is en de vereiste maatregelen zijn getroffen, dan kan worden gestart met het ontwikkelen van het algoritme of AI-systeem. </p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#vereisten","title":"Vereisten","text":"idVereistenaia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06Technische documentatie voor hoog-risico AIaia-35Verdere verwerking van persoonsgegevens in AI-testomgevingenaut-01Auteursrechten mogen niet worden geschondenavg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02Beperkte bewaartermijn van persoonsgegevensavg-03Persoonsgegevens verzamelen voor specifieke doeleindenavg-04Proportionaliteit en subsidiariteitavg-05Juistheid en actualiteit van gegevensavg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-11Privacy door ontwerpavg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personendat-01Verbod op schenden databankenrechtengrw-02AI-systemen en algoritmes mogen niet discrimineren"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-02Beschrijf welke data gebruikt wordt voor de beoogde toepassingowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magdat-01Controleer de datakwaliteitdat-02Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.dat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waaromdat-05Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregerendat-06Controleer de auteursrechten van eigen datadat-07Gebruik duurzame datacentersTrain-, validatie- en testdataControle of eigenaarschap over de datadat-09Beperk de omvang van datasets voor energie-effici\u00ebntieimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenmon-02Beveilig de software <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/implementatie/","title":"Implementatie","text":"<p>In deze fase wordt het algoritme of AI-systeem in de praktijk gebracht en duurzaam ge\u00efntegreerd in het bedrijfsproces.  In de praktijk worden veelal eerst een pilot uitgevoerd voor een afgebakende periode of over een beperkt aan zaken.  In deze situatie, een pilot, wordt tijdelijk productiedata verwerkt.  Dit vraagt om een goede samenwerking tussen het ontwikkelteam en de gebruikers van het algoritme of AI-systeem.  Niet alleen de prestaties van het algoritme of AI-systeem worden nogmaals gevalideerd, maar bijvoorbeeld ook of de output zodanig wordt gepresenteerd dat gebruikers hiermee kunnen werken.  Na deze pilot wordt onderzocht in hoeverre het algoritme of AI-systeem presteert conform wens en verwachting.  Er kan worden gekozen om het algoritme eerst nog door te ontwikkelen op basis van de bevindingen, uit te faseren of om de oplossing structureel onderdeel te maken van de bedrijfsvoering door het te implementeren. </p> <p>Als een besluit wordt genomen om de oplossing te implementeren, dan is het van belang dat gebruikers goed begrijpen hoe de resultaten van het algoritme of AI-systeem moeten worden ge\u00efnterpreteerd, dat de rest-risico's bekend zijn, de verantwoordelijkheden belegd zijn en dat er duidelijke werkinstructies zijn over het gebruik van het algoritme of AI-systeem. Service- en incidentmanagement moet volledig worden geoperationaliseerd, zodat gebruikers kunnen worden geholpen bij vragen of incidenten.  Een kenmerkend element van deze fase is dat vanaf nu betrokkenen onderhevig zijn aan de werking van het algoritme of AI-systeem.  Beslissingen en besluiten komen nu bijvoorbeeld mede of geheel door de werking van het algoritme of AI-systeem tot stand.  Waar passend, bijvoorbeeld bij impactvolle of hoog risico AI-systemen wordt dit duidelijk gecommuniceerd naar betrokken, voordat de oplossing volledig is ge\u00efmplementeerd.  </p>"},{"location":"levenscyclus/implementatie/#vereisten","title":"Vereisten","text":"idVereistenaia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-22Maatregelen van gebruiksverantwoordelijken voor gebruikaia-26Informeren werknemersaia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemaia-30Transparantieverplichtingenavg-07Transparantie bij verwerking persoonsgegevensavg-10Recht op niet geautomatiseerde besluitvormingawb-02Een besluit berust op een deugdelijke motiveringbzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister"},{"location":"levenscyclus/implementatie/#maatregelen","title":"Maatregelen","text":"idMaatregelenpba-04Overleg regelmatig met belanghebbendenowp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrixowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesdat-07Gebruik duurzame datacentersowk-02Maak een noodplan voor het stoppen van het algoritmeimp-01Maak een openbaar besluit over de inzet van het algoritmeimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenimp-03Organiseer menselijke controle van het algoritmeimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregisterimp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeemimp-07Vermeld het gebruik van persoonsgegevens in een privacyverklaringimp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregisterimp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.Aansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingVerken maatregelen van aanbieder om schending auteursrechten te voorkomenVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstraject <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/monitoring-en-beheer/","title":"Monitoring en beheer","text":"<p>Het algoritme of AI-systeem wordt in deze fase voortdurend gemonitord om ervoor te zorgen dat het blijft presteren zoals verwacht en kan worden gebruikt door gebruikers.  Eventuele afwijkingen of degradatie van prestaties worden gesignaleerd en er worden maatregelen getroffen om dit te herstellen.  Dit is van belang vanuit een technisch perspectief (presteert het model nog wel waar het voor ontworpen is), maar ook vanuit een juridische en ethische blik (functioneert het model nog wel rechtmatig en zijn er geen onvoorziene nadelige effecten op mens en maatschappij).  Hierbij dient ook voortdurend gemonitord te worden of de omstandigheden waarin het algoritme of AI-systeem wordt gebruikt veranderlijk zijn, en of daar op geanticipeerd moet worden.  Dit kan bijvoorbeeld spelen bij veranderende data of bij het uitvoeren van nieuw beleid of wet- en regelgeving in het werkproces dat wordt ondersteund met het algoritme of AI-systeem. </p> <p>Het is van belang dat beheer wordt uitgevoerd over het algoritme of AI-systeem, zodat de (gehele) oplossing operationeel blijft.  Een wijziging in onderliggende systemen kan er bijvoorbeeld voor zorgen dat het algoritme of AI-systeem niet meer wordt voorzien van de noodzakelijk data om de benodigde output te genereren.  Het beheerteam zorgt ervoor dat dergelijke situaties worden voorkomen of opgelost. Er kunnen ook incidenten worden gemeld door gebruikers die worden opgelost door het beheerteam.  </p>"},{"location":"levenscyclus/monitoring-en-beheer/#vereisten","title":"Vereisten","text":"idVereistenaia-04Risicobeoordeling voor jongeren en kwetsbarenaia-07Automatische logregistratie voor hoog-risico AIaia-08Transparantie in ontwerp voor hoog-risico AIaia-09Toezichtmogelijkheden voor gebruikersaia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13Bewaartermijn voor gegenereerde logsaia-18Corrigerende maatregelen voor non-conforme AIaia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeemaia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdaia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemaia-28Recht op uitleg AI-besluitenaia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-36Monitoring na het in handel brengenaia-37Melden van ernstige incidentenaia-38Veilig melden van inbreuk op AI verordeningarc-01De archiefwet is ook van toepassing op algoritmes en AI-systemenavg-07Transparantie bij verwerking persoonsgegevensawb-02Een besluit berust op een deugdelijke motiveringbzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregistergrw-01Beschermen van fundamentele rechten en vrijhedengrw-02AI-systemen en algoritmes mogen niet discrimineren"},{"location":"levenscyclus/monitoring-en-beheer/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-07Controleer en verbeter regelmatig de kwaliteit van het algoritmeowp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrixowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktdat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsproceduredat-07Gebruik duurzame datacentersowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenowk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de codever-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isver-01Toets het algoritme op biasimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenimp-03Organiseer menselijke controle van het algoritmeimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregisterimp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.mon-01Maak back-ups van algoritmesmon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenVeranderingen in de datamon-05Meten, monitoren en rapporteren van milieu-impact van algoritmesBepaal of de output bepalende invloed heeft in een besluit richting personenContractuele afspraken over data en artefactenBewijs laten leveren dat auteursrechten niet worden geschonden met de outputBewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputGarantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeDe mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingVaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwerp/","title":"Ontwerp","text":"<p>In de ontwerpfase wordt het conceptuele ontwerp van het AI-systeem uitgedacht.  Het is van belang om belangrijke uitgangspunten en beleid, zoals doelarchitectuur en de datastrategie, van de betreffende organisatie meteen te verwerken in het ontwerp en dat het applicatielandschap en de databronnen in beeld wordt gebracht.  In deze fase worden doorgaans veel werkzaamheden verzet, zoals business- en informatieanalyse, om een goed beeld te krijgen hoe aan de beoogde doelstellingen kan worden voldaan met een passende oplossing.  </p> <p>Het is goed denkbaar dat meerdere ontwerpen in deze fase tot stand komen voor het te ontwikkelen algoritme of AI-systeem.  Het is van belang om deze ontwerpen te toetsen bij bijvoorbeeld de proceseigenaar, opdrachtgever en gebruiker, maar ook bij informatiebeveiligingsadviseurs, privacy officers, informatiebeheerders, architecten of een ethicus.  Deze experts kunnen vanuit hun vakgebied een eerste toets doen in hoeverre het ontwerp haalbaar of gewenst is, aansluit bij de gebruikersbehoefte, aan welke vereisten moet worden voldaan of dat er risicoanalyses moeten worden uitgevoerd en een onafhankelijke commissies moet worden betrokken.</p> <p>Met deze input kan het ontwerp worden verbeterd en vraagstukken over bijvoorbeeld governance en risicomanagement verder worden uitgewerkt.  In deze fase kan ook een eerste stap worden gezet om de vereisten te vertalen naar concrete maatregelen, te structureren en te beleggen bij de betrokken experts.  Als bijvoorbeeld is vastgesteld dat persoonsgegevens noodzakelijkerwijs moeten worden verwerkt en hier een grondslag voor is, dan is het van belang dat voorafgaand aan de dataverkenning en datapreparatie fase voldoende (technische) maatregelen zijn getroffen om de data veilig te verwerken in de beoogde (ontwikkel)omgeving. </p> <p>Daarnaast dient er in de ontwerpfase ook aandacht besteed te worden aan de succesfactoren van een algoritme of AI-systeem.  Het is belangrijk om in een multidisciplinaire setting te bepalen hoe het algoritme in de praktijk ge\u00ebvalueerd kan worden en wanneer we kunnen spreken van een rechtvaardig succes. Hierbij dient er ook te worden nagedacht over evaluatiemethoden om na te gaan of het algoritme of AI-systeem voldoet aan bijvoorbeeld het vereiste van non-discriminatie. </p> <p>Nadat een besluit is genomen over het definitieve ontwerp van het algoritme of AI-systeem, kan worden gestart met het inrichten van de ontwikkelomgeving (indien nodig), de dataverkenning, datapreparatie.  Dit besluit betekent dat een akkoord wordt gegeven voor het type algoritme en de beoogde werking.  </p>"},{"location":"levenscyclus/ontwerp/#vereisten","title":"Vereisten","text":"idVereistenaia-02Documentatie beoordeling niet-hoog-risico AIaia-04Risicobeoordeling voor jongeren en kwetsbarenaia-08Transparantie in ontwerp voor hoog-risico AIaia-09Toezichtmogelijkheden voor gebruikersaia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13Bewaartermijn voor gegenereerde logsaia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-28Recht op uitleg AI-besluitenaia-29Beoordeling van grondrechtenaia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaut-01Auteursrechten mogen niet worden geschondenavg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02Beperkte bewaartermijn van persoonsgegevensavg-03Persoonsgegevens verzamelen voor specifieke doeleindenavg-04Proportionaliteit en subsidiariteitavg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-10Recht op niet geautomatiseerde besluitvormingavg-11Privacy door ontwerpavg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01Relevante feiten en belangen zijn bekendawb-02Een besluit berust op een deugdelijke motiveringgrw-01Beschermen van fundamentele rechten en vrijheden"},{"location":"levenscyclus/ontwerp/#maatregelen","title":"Maatregelen","text":"idMaatregelenpba-04Overleg regelmatig met belanghebbendenowp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrixowp-02Beschrijf welke data gebruikt wordt voor de beoogde toepassingowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-04Beschrijf welke techniek gebruikt wordt voor de beoogde toepassingowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-07Maak een lijst van de meest kwetsbare groepen en bescherm hen extraowp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten wordenowp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesowp-11Koop duurzaam algoritmes inowp-12Ontwerp eenvoudigere en minder complexe algoritmesdat-06Controleer de auteursrechten van eigen dataowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenver-01Toets het algoritme op biasimp-03Organiseer menselijke controle van het algoritmemon-05Meten, monitoren en rapporteren van milieu-impact van algoritmesBespreek de vereiste met aanbieder of opdrachtnemerContractuele afspraken over data en artefactenCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Bewijs laten leveren dat auteursrechten niet worden geschonden met de outputBewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Voer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectGarantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeDe mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingVaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/ontwikkelen/","title":"Ontwikkelen","text":"<p>Dit is de fase waarin het algoritme of AI-systeem wordt ontwikkeld door het ontwikkelteam.  Als het gaat om AI-systemen, omvat deze fase het trainen van modellen met behulp van de voorbereide gegevens. Als het gaat om algoritmes op basis van rekenregels, betreft dit het implementeren van deze rekenregels in de (ontwikkelomgeving van de) systemen.  </p> <p>Het algoritme of AI-systeem technisch correct ontwikkelen, inclusief het kunnen begrijpen van de beperkingen ervan, vraagt om een samenspel van expertise vanuit verschillende disciplines.  Denk hierbij aan de proceseigenaar, domeinexperts van het te ondersteunen werkproces, data scientists, data engineer, (privacy)juristen, beleidsmedewerkers en een ethicus.  Een voorbeeld hiervan is het beoordelen van de zogenaamde inputvariabelen of rekenregels (die voor een groot deel bepalen hoe een algoritme of AI-systeem functioneert) van een machine learning model of algoritme.  Deze rollen zijn bijzonder waardevol bij het beoordelen of deze variabelen of rekenregels juridisch zijn toegestaan, ethisch wenselijk zijn, technisch gezien- voldoende significant zijn en of deze van toegevoegde waarde zijn voor gebruikers.  Dit multidisciplinaire team kan tijdens de ontwikkeling continu bijsturen, zodat het algoritme of AI-systeem op een verantwoorde wijze functioneert en aansluit bij de beoogde doelstellingen.  </p> <p>In deze fase is niet alleen het ontwikkelen van een algoritme of AI-systeem, maar ook het documenteren van belangrijke afwegingen en het opstellen van technische documentatie van groot belang.  Daarnaast zullen tal van (technische) maatregelen moeten worden getroffen zoals de verdere beveiliging van het informatiesysteem of bij de ontsluiting van de output naar gebruikers, het automatische genereren van logs en het inrichten van service en incidentmanagementprocedures.  </p>"},{"location":"levenscyclus/ontwikkelen/#vereisten","title":"Vereisten","text":"idVereistenaia-06Technische documentatie voor hoog-risico AIaia-07Automatische logregistratie voor hoog-risico AIaia-08Transparantie in ontwerp voor hoog-risico AIaia-09Toezichtmogelijkheden voor gebruikersaia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdaia-30Transparantieverplichtingenaia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-35Verdere verwerking van persoonsgegevens in AI-testomgevingenarc-01De archiefwet is ook van toepassing op algoritmes en AI-systemenavg-02Beperkte bewaartermijn van persoonsgegevensavg-03Persoonsgegevens verzamelen voor specifieke doeleindenavg-09Privacyrechtenawb-01Relevante feiten en belangen zijn bekend"},{"location":"levenscyclus/ontwikkelen/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenowp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten wordenowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesowp-12Ontwerp eenvoudigere en minder complexe algoritmesdat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waaromdat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsproceduredat-05Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregerendat-07Gebruik duurzame datacentersTrain-, validatie- en testdataowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019owk-02Maak een noodplan voor het stoppen van het algoritmeowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenowk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de codeowk-05Kies energiezuinige programmeermethodenowk-06Optimaliseer AI-trainingsprocessen voor energie-effici\u00ebntiever-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenmon-01Maak back-ups van algoritmesmon-02Beveilig de softwareBepaal of de output bepalende invloed heeft in een besluit richting personenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/organisatieverantwoordelijkheden/","title":"Organisatieverantwoordelijkheden","text":"<p>Voordat je start met de ontwikkeling of het gebruik van een algoritme, zul je moeten zorgen dat je organisatie voldoende ingericht is om algoritmes te gebruiken of te ontwikkelen.  In deze fase beschrijven we de randvoorwaarden die je als organisatie moet hebben om aan de slag te gaan. Dit zijn aspecten die je in het ideale geval al regelt voordat je begint aan het gebruik van algoritmes. Het zijn ook taken die je voortdurend aandacht zal moeten geven, maar die je niet voor ieder algorite opnieuw hoeft te organiseren. </p>"},{"location":"levenscyclus/organisatieverantwoordelijkheden/#vereisten","title":"Vereisten","text":"idVereistenaia-01Bevorder AI-geletterdheid van personeel en gebruikersaia-03Verplicht risicobeheersysteem voor hoog-risico AIaia-11Kwaliteitsbeheersysteem voor hoog-risico AIaia-18Corrigerende maatregelen voor non-conforme AIaia-22Maatregelen van gebruiksverantwoordelijken voor gebruikaia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningaia-28Recht op uitleg AI-besluitenaia-35Verdere verwerking van persoonsgegevens in AI-testomgevingenaia-37Melden van ernstige incidentenaia-38Veilig melden van inbreuk op AI verordeningaia-39Klachtrecht aanbieders verder in AI-waardeketenavg-09Privacyrechtenavg-12Beveiliging van de verwerkingbio-01Beveiliging informatie en informatiesystemenwoo-01Eenieder heeft recht op toegang tot publieke informatie"},{"location":"levenscyclus/organisatieverantwoordelijkheden/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-01Bepaal of er genoeg experts beschikbaar zijnorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesorg-03Maak een plan voor het omgaan met risico\u2019sorg-04Maak afspraken over het wijzigen van de codeorg-05Maak afspraken over het beheer van gebruikersorg-06Maak afspraken over het beheer van wachtwoordenorg-07Controleer en verbeter regelmatig de kwaliteit van het algoritmeimp-01Maak een openbaar besluit over de inzet van het algoritmeimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenmon-03Maak een noodplan voor beveiligingsincidenten <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/probleemanalyse/","title":"Probleemanalyse","text":"<p>In deze fase wordt het probleem en de doelstellingen van een opdrachtgever geanalyseerd en beschreven.  Er wordt bijvoorbeeld onderzocht welke publieke taak moet worden ondersteund en welke publieke waarden daarbij moeten worden beschermd of juist gerealiseerd.  In deze fase wordt onderzocht of het ontwikkelen van een algoritme of AI-systeem een geschikt middel is om het doel te realiseren en het probleem op te lossen. Dat hangt van verschillende zaken af.  Hierbij kan worden gedacht aan de middelen (capaciteit en financi\u00eble middelen) die nodig zijn om algoritmen en AI op een verantwoorde wijze te ontwikkelen, de complexiteit van de oplossing, het in beeld brengen van de verwachte risico's (hoog over), een eerste beeld krijgen bij wat voor data nodig zijn en het in kaart brengen en beleggen van de verschillende verantwoordelijkheden.  Daarnaast is het van belang om het beleid met betrekking tot de inzet van algoritme en AI van een organisatie te raadplegen.  </p> <p>Er zal een conclusie moeten volgen of de ontwikkeling van een algoritme of AI-systeem passend is.  Deze fase wordt doorgaans afgerond met een akkoord van de (gemandateerd) verantwoordelijk(en)/opdrachtgever om een algoritme of een AI-systeem te ontwikkelen.  Een vastgestelde business case of plan van aanpak vormen veelal de basis om de ontwerpfase te starten met de benodigde experts. </p>"},{"location":"levenscyclus/probleemanalyse/#vereisten","title":"Vereisten","text":"idVereistenavg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvindengrw-01Beschermen van fundamentele rechten en vrijheden"},{"location":"levenscyclus/probleemanalyse/#maatregelen","title":"Maatregelen","text":"idMaatregelenpba-01Beschrijf het probleem dat het algoritme moet oplossenpba-02Beschrijf het doel van het algoritmepba-03Beschrijf waarom een algoritme het probleem moet oplossenpba-04Overleg regelmatig met belanghebbendenpba-05Beschrijf de wettelijke grondslag voor de inzet van het algoritmeowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingVerken maatregelen van aanbieder om schending auteursrechten te voorkomenMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocument <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/uitfaseren/","title":"Uitfaseren","text":"<p>Als wordt besloten dat het algoritme of AI-systeem niet langer nodig is of wordt vervangen door een wezenlijk andere versie, wordt het gearchiveerd en uitgefaseerd.  Hiermee wordt ervoor gezocht dat later kan worden gereconstrueerd hoe het algoritme of AI-systeem heeft gefunctioneerd en dat gebruikers er geen gebruik meer van kunnen maken.  </p> <p>Archiveren betekent dat documentatie en eventuele relevante artefacten (zoals logbestanden en de parameters van het model) worden bewaard voor een bepaalde periode.  Het gaat daarbij ook om informatie over het algoritme of AI-systeem, bijvoorbeeld het besluit en onderbouwing waarom het niet meer wordt gebruikt en waarom het in het verleden wel gebruikt werd.  Archiveren is niet enkel relevant aan het einde van de levenscyclus, maar is ook gedurende het gebruik van het algoritme of AI-systeem van belang.  Er moet tijdig worden vastgesteld welke versies van een model moeten worden gearchiveerd, bijvoorbeeld al tijdens de ontwerpfase. </p> <p>Bij AI-systemen is er in praktijk vaak sprake van hertrainen op nieuwe data, wat het model anders maakt en andere voorspellingen kan doen geven.  Ook meer eenvoudige algoritmes kunnen gedurende de tijd veranderen en andere voorspellingen geven, bijvoorbeeld door veranderende data of veranderende rekenregels.  Er moet worden vastgesteld welke versies van een model moet gearchiveerd. </p> <p>Bij uitfaseren wordt het algoritme of AI-systeem verwijderd uit de productieomgeving en, na archivering, wordt de trainingsdata uit de ontwikkelomgeving verwijderd.  Het algoritme is hiermee niet meer te gebruiken door gebruikers.  Gebruikers moeten hier vooraf over worden ge\u00efnformeerd en waar passend, bijvoorbeeld bij impactvolle of hoog risico AI-systemen, worden betrokkenen ge\u00efnformeerd over het be\u00ebindigen van het gebruik. </p>"},{"location":"levenscyclus/uitfaseren/#vereisten","title":"Vereisten","text":"idVereistenaia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13Bewaartermijn voor gegenereerde logsarc-01De archiefwet is ook van toepassing op algoritmes en AI-systemenavg-02Beperkte bewaartermijn van persoonsgegevens"},{"location":"levenscyclus/uitfaseren/#maatregelen","title":"Maatregelen","text":"idMaatregelen <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"levenscyclus/verificatie-en-validatie/","title":"Verificatie en validatie","text":"<p>Bij de verificatie en validatie van het algoritme of AI-systeem dient bepaald te worden of het algoritme of AI-systeem gebouwd is volgens de (technische) specificaties en voldoet aan de beoogde doelstellingen.  Hiervoor moeten technische, maar ook organisatorische maatregelen worden getroffen.  </p> <p>Bij verificatie kan worden gedacht aan het (laten) controleren of het algoritme of AI-systeem voldoet aan de (technische) specificaties, bijvoorbeeld door een interne of externe audit of in de toekomst een conformiteitsbeoordeling voor hoog risico AI-systemen.  Hiermee kan (onafhankelijk) worden vastgesteld of het systeem voldoet aan de vereisten die organisaties daaraan stellen.  Op basis van bevindingen uit een audit of conformiteitsbeoordeling, is het denkbaar dat het ontwikkelteam nog bepaalde maatregelen moet treffen om te voldoen aan de specificaties. </p> <p>Bij het valideren van een algoritme of AI-systeem moet worden bepaald of het goed genoeg presteert en of het geschikt is voor het beoogde doel van het systeem.  Wanneer het een AI-systeem betreft, is het belangrijk dat dit gevalideerd wordt op nieuwe, niet eerder geziene data.  Het valideren betreft het iteratief evalueren van de nauwkeurigheid en prestaties van het systeem.  Daarnaast is het ook belangrijk om te valideren of het algoritme gelijke prestaties toont voor verschillende groepen en om te testen hoe het algoritme presteert in uitzonderlijke gevallen.  Het is net als in de ontwerpfase belangrijk dat een multidisciplinair team beoordeelt of de werking passend en bijvoorbeeld non-discriminatoir is.  In het geval van impactvolle algoritmen of hoog risico AI-systemen, is het raadzaam om een onafhankelijke commissie of partij te betrekken die een advies geeft over de werking van het algoritme of AI-systeem.  </p> <p>In praktijk zal vaak na validatie weer worden teruggegaan naar de ontwikkelfase om prestaties van het model te verbeteren voorafgaand aan implementatie van de oplossing.  Het is ook denkbaar dat het algoritme of AI-systeem onvoldoende aansluit bij de doelstellingen en het gebruik ervan moet wordt be\u00ebindigd.  Een andere conclusie kan zijn dat het presteert conform verwachting en naar de implementatiefase kan worden gegaan.  </p>"},{"location":"levenscyclus/verificatie-en-validatie/#vereisten","title":"Vereisten","text":"idVereistenaia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06Technische documentatie voor hoog-risico AIaia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-29Beoordeling van grondrechtenaia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoavg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01Relevante feiten en belangen zijn bekendgrw-01Beschermen van fundamentele rechten en vrijhedengrw-02AI-systemen en algoritmes mogen niet discrimineren"},{"location":"levenscyclus/verificatie-en-validatie/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesdat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waaromver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isver-01Toets het algoritme op biasver-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidRestrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstraject <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"maatregelen/","title":"Maatregelen","text":"<p>Overzicht van aanbevolen maatregelen voor verantwoord gebruik van algoritmes en AI-systemen. Het zijn adviezen om te voldoen aan de vereisten voor overheden. Andere maatregelen zijn ook mogelijk.</p>"},{"location":"maatregelen/#alle-maatregelen-zijn-adviezen","title":"Alle maatregelen zijn adviezen","text":"<p>De maatregelen zijn niet verplicht. Het zijn adviezen uit:</p> <ul> <li>Toetsingskader Algoritmes, Algemene Rekenkamer</li> <li>Onderzoekskader algoritmes, Auditdienst Rijk</li> <li>nationale en internationale standaarden (NEN, JTC21 en ISO)</li> <li>onze werkgroepen</li> </ul>"},{"location":"maatregelen/#voorbeeld","title":"Voorbeeld","text":"<p>Onderzoek het ontwikkelde algoritme op onbewuste vooringenomenheid (discriminatie) door middel van een bias-analyse.</p> <p>Deze maatregel helpt om te voldoen aan de vereiste om niet te discrimineren. Maar deze maatregel is niet verplicht. Je organisatie mag ook eigen maatregelen nemen. Zolang je uiteindelijk maar voldoet aan de vereiste.</p> <p>Tip</p> <p>Aantal maatregelen verschilt per situatie</p> <p>Welke maatregelen handig zijn in jouw situatie, hangt af van:</p> <ul> <li>de fase in de levenscyclus van je project</li> <li>de vereisten waar jouw organisatie aan moet voldoen</li> <li>jouw rol in de organisatie</li> </ul> <p>Tip</p> <p>Met \u00e9\u00e9n maatregel voldoe je soms aan meerdere vereisten.</p>"},{"location":"maatregelen/#overzicht-maatregelen","title":"Overzicht maatregelen","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedataduurzaamheidfundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingpublieke-inkooptechnische-robuustheid-en-veiligheidtransparantieidMaatregelenRollenLevenscyclusOnderwerpenorg-01Bepaal of er genoeg experts beschikbaar zijn                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              org-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmes                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              org-03Maak een plan voor het omgaan met risico\u2019s                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              org-04Maak afspraken over het wijzigen van de code                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid                               governance              org-05Maak afspraken over het beheer van gebruikers                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid                               governance              org-06Maak afspraken over het beheer van wachtwoorden                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid                               governance              org-07Controleer en verbeter regelmatig de kwaliteit van het algoritme                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              pba-01Beschrijf het probleem dat het algoritme moet oplossen                  projectleider                               probleemanalyse                               governance                               menselijke-controle              pba-02Beschrijf het doel van het algoritme                  projectleider                               probleemanalyse                               governance                               menselijke-controle              pba-03Beschrijf waarom een algoritme het probleem moet oplossen                  projectleider                               probleemanalyse                               governance                               menselijke-controle              pba-04Overleg regelmatig met belanghebbenden                  projectleider                               probleemanalyse                               ontwerp                               implementatie                               governance                               fundamentele-rechten              pba-05Beschrijf de wettelijke grondslag voor de inzet van het algoritme                  jurist                               probleemanalyse                               governance              owp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrix                  projectleider                               ontwerp                               implementatie                               monitoring-en-beheer                               governance              owp-02Beschrijf welke data gebruikt wordt voor de beoogde toepassing                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               data              owp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit mag                  projectleider                               jurist                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               implementatie                               privacy-en-gegevensbescherming              owp-04Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing                  ontwikkelaar                               ontwerp                               technische-robuustheid-en-veiligheid              owp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horen                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop                               governance              owp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafweging                  projectleider                               beleid-en-advies                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              owp-07Maak een lijst van de meest kwetsbare groepen en bescherm hen extra                  beleid-en-advies                               ontwerp                               fundamentele-rechten              owp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten worden                  ontwikkelaar                               projectleider                               jurist                               ontwerp                               ontwikkelen                               transparantie              owp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerkt                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               publieke-inkoop                               privacy-en-gegevensbescherming              owp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmes                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               implementatie                               publieke-inkoop                               technische-robuustheid-en-veiligheid              owp-11Koop duurzaam algoritmes in                  projectleider                               ontwerp                               publieke-inkoop                               duurzaamheid              owp-12Ontwerp eenvoudigere en minder complexe algoritmes                  ontwikkelaar                               ontwerp                               ontwikkelen                               duurzaamheid              dat-01Controleer de datakwaliteit                  ontwikkelaar                               dataverkenning-en-datapreparatie                               data              dat-02Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.                  ontwikkelaar                               dataverkenning-en-datapreparatie                               data              dat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waarom                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               privacy-en-gegevensbescherming              dat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedure                  jurist                               projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               privacy-en-gegevensbescherming              dat-05Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregeren                  ontwikkelaar                               jurist                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              dat-06Controleer de auteursrechten van eigen data                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               data              dat-07Gebruik duurzame datacenters                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               ontwikkelen                               implementatie                               monitoring-en-beheer                               duurzaamheid              Train-, validatie- en testdata                  dataverkenning-en-datapreparatie                               ontwikkelen                               data                               technische-robuustheid-en-veiligheid                               bias-en-non-discriminatie              Controle of eigenaarschap over de data                  dataverkenning-en-datapreparatie                               data                               publieke-inkoop              dat-09Beperk de omvang van datasets voor energie-effici\u00ebntie                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               data                               duurzaamheid              owk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019                  projectleider                               ontwikkelaar                               ontwikkelen                               technische-robuustheid-en-veiligheid              owk-02Maak een noodplan voor het stoppen van het algoritme                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               governance                               menselijke-controle              owk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houden                  projectleider                               jurist                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               privacy-en-gegevensbescherming              owk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de code                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              owk-05Kies energiezuinige programmeermethoden                  ontwikkelaar                               ontwikkelen                               duurzaamheid              owk-06Optimaliseer AI-trainingsprocessen voor energie-effici\u00ebntie                  ontwikkelaar                               ontwikkelen                               duurzaamheid              ver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld is                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               bias-en-non-discriminatie              ver-01Toets het algoritme op bias                  projectleider                               beleid-en-advies                               ontwikkelaar                               jurist                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              ver-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid                  jurist                               verificatie-en-validatie                               governance                               transparantie              imp-01Maak een openbaar besluit over de inzet van het algoritme                  projectleider                               organisatieverantwoordelijkheden                               implementatie                               governance                               transparantie              imp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controleren                  ontwikkelaar                               dataverkenning-en-datapreparatie                               implementatie                               monitoring-en-beheer                               bias-en-non-discriminatie                               technische-robuustheid-en-veiligheid              imp-03Organiseer menselijke controle van het algoritme                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               menselijke-controle                               governance              imp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregister                  projectleider                               beleid-en-advies                               implementatie                               monitoring-en-beheer                               transparantie              imp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeem                  projectleider                               beleid-en-advies                               implementatie                               governance                               menselijke-controle              imp-06Spreek af hoe de organisatie omgaat met privacy-verzoeken                  projectleider                               beleid-en-advies                               jurist                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               governance                               data              imp-07Vermeld het gebruik van persoonsgegevens in een privacyverklaring                  projectleider                               jurist                               implementatie                               privacy-en-gegevensbescherming              imp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregister                  projectleider                               jurist                               implementatie                               transparantie                               privacy-en-gegevensbescherming              imp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.                  projectleider                               ontwikkelaar                               implementatie                               monitoring-en-beheer                               governance              mon-01Maak back-ups van algoritmes                  ontwikkelaar                               beleid-en-advies                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              mon-02Beveilig de software                  projectleider                               beleid-en-advies                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              mon-03Maak een noodplan voor beveiligingsincidenten                  projectleider                               beleid-en-advies                               jurist                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               governance              Veranderingen in de data                  monitoring-en-beheer                               data                               technische-robuustheid-en-veiligheid              mon-05Meten, monitoren en rapporteren van milieu-impact van algoritmes                  ontwikkelaar                               beleid-en-advies                               projectleider                               ontwerp                               monitoring-en-beheer                               duurzaamheid              Aansprakelijkheidsvoorwaarden worden beoordeeld in de aanbesteding                  jurist                               probleemanalyse                               implementatie                               publieke-inkoop              Bepaal of de output bepalende invloed heeft in een besluit richting personen                  projectleider                               beleid-en-advies                               ontwikkelen                               monitoring-en-beheer                               publieke-inkoop              Bespreek de vereiste met aanbieder of opdrachtnemer                  projectleider                               ontwerp                               ontwikkelen                               publieke-inkoop              Contractuele afspraken over data en artefacten                  jurist                               ontwerp                               monitoring-en-beheer                               publieke-inkoop              Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.                  projectleider                               ontwerp                               ontwikkelen                               publieke-inkoop              Verken maatregelen van aanbieder om schending auteursrechten te voorkomen                  projectleider                               beleid-en-advies                               probleemanalyse                               implementatie                               publieke-inkoop              Bewijs laten leveren dat auteursrechten niet worden geschonden met de output                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               publieke-inkoop              Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdata                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               publieke-inkoop              Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak de vereiste onderdeel van het programma van eisen                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak de vereiste onderdeel van de contractovereenkomst                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak de vereiste onderdeel van Service Level Agreement                  ontwerp                               ontwikkelen                               publieke-inkoop              Maak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaarden                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocument                  projectleider                               beleid-en-advies                               probleemanalyse                               ontwikkelen                               monitoring-en-beheer                               governance                               publieke-inkoop              Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.                  ontwikkelaar                               ontwerp                               ontwikkelen                               publieke-inkoop              Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaakt                  projectleider                               ontwikkelen                               verificatie-en-validatie                               publieke-inkoop              Voer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstraject                  projectleider                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               implementatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               publieke-inkoop              Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de output                  projectleider                               jurist                               ontwikkelen                               monitoring-en-beheer                               publieke-inkoop              Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdata                  projectleider                               jurist                               ontwerp                               monitoring-en-beheer                               publieke-inkoop              Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst                  projectleider                               jurist                               ontwerp                               ontwikkelen                               publieke-inkoop              Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijke                  projectleider                               ontwikkelaar                               ontwerp                               monitoring-en-beheer                               publieke-inkoop              De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbesteding                  projectleider                               ontwerp                               monitoring-en-beheer                               publieke-inkoop              Vaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen                  projectleider                               ontwerp                               monitoring-en-beheer                               publieke-inkoop"},{"location":"maatregelen/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"maatregelen/0-org-01-benodigde-expertise-en-capaciteit/","title":"Bepaal of er genoeg experts beschikbaar zijn","text":"<p>org-01OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#maatregel","title":"Maatregel","text":"<p>Bepaal welke expertise en capaciteit noodzakelijk is voor het ontwikkelen, inkopen en gebruiken van algoritmes en AI-systemen en stel vast of er voldoende expertise en capaciteit beschikbaar is.</p>"},{"location":"maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#toelichting","title":"Toelichting","text":"<ul> <li>Bepaal welke expertise en capaciteit binnen de organisatie noodzakelijk is voor het ontwikkelen, inkopen en gebruiken van algoritmes en AI-systemen.</li> <li>Dit is sterk afhankelijk van de specifieke toepassing en de inzichten die voortkomen uit risicoanalyses. Hoe complexer en risicovoller de toepassing, des te meer expertise en capaciteit noodzakelijk is. </li> <li>Interne en externe actoren die betrokken zijn bij het ontwikkelen, inkopen en gebruik moeten over voldoende expertise en capaciteit beschikken om hun taken naar behoren uit te voeren.</li> <li>Stel vast of er afhankelijkheden van externe aanbieders ontstaan.  </li> <li>Bepaal voorafgaand aan het (laten) ontwikkelen of inkopen van algoritmes en AI-systemen of voldoende expertise en capaciteit beschikbaar is om tot een verantwoorde inzet ervan te komen.</li> <li>Leg vast of er voldoende expertise en capaciteit beschikbaar is en onderbouw dit in projectdocumentatie.      </li> </ul>"},{"location":"maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.12 </li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.04</li> <li>Algoritmekader</li> </ul>"},{"location":"maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/0-org-02-vastgestelde-beleidskaders/","title":"Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmes","text":"<p>org-02OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"maatregelen/0-org-02-vastgestelde-beleidskaders/#maatregel","title":"Maatregel","text":"<p>Pas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmes en AI-systemen.</p>"},{"location":"maatregelen/0-org-02-vastgestelde-beleidskaders/#toelichting","title":"Toelichting","text":"<ul> <li>Interne vastgestelde beleidskaders moeten worden toegepast bij het ontwikkelen, inkopen of gebruiken van algoritmes en AI-systemen.</li> <li>Het is van belang dat tijdig, bijvoorbeeld in de probleemanalyse fase, inzichtelijk wordt gemaakt welke interne beleidskaders moeten worden toegepast.</li> <li>Hierbij kan worden gedacht aan definities die moet worden gehanteerd, het naleven van inkoopbeleid, strategisch beleid volgen met betrekking tot het mogen inzetten van algoritmes en AI-systemen binnen de organisaties of het doorlopen van processen en protocollen die moeten worden toegepast.</li> <li>Vraag de betrokken experts welke beleidskaders van toepassing zijn vanuit diens specifieke expertise. </li> <li>Ten behoeve van controles en audits is het van belang dat aantoonbaar wordt gemaakt dat de vastgestelde beleidskaders zijn nageleefd. </li> </ul> <p>## Bijbehorende vereiste(n)</p> Vereisteawb-01 - Relevante feiten en belangen zijn bekendaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIbio-01 - Beveiliging informatie en informatiesystemenaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-09 - Toezichtmogelijkheden voor gebruikers"},{"location":"maatregelen/0-org-02-vastgestelde-beleidskaders/#risico","title":"Risico","text":"<p>De in te zetten algoritmes of AI-systemen voldoen niet aan vastgestelde beleidskaders. </p>"},{"location":"maatregelen/0-org-02-vastgestelde-beleidskaders/#bronnen","title":"Bronnen","text":"<p>Onderzoekskader Algoritmes Auditdienst Rijk, SV.8</p>"},{"location":"maatregelen/0-org-02-vastgestelde-beleidskaders/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/0-org-03-toepassen_risicobeheer/","title":"Maak een plan voor het omgaan met risico\u2019s","text":"<p>org-03OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"maatregelen/0-org-03-toepassen_risicobeheer/#maatregel","title":"Maatregel","text":"<p>Pas risicobeheer gestructureerd toe voorafgaand en gedurende de ontwikkeling en gebruik van algoritmes en AI-systemen.</p>"},{"location":"maatregelen/0-org-03-toepassen_risicobeheer/#toelichting","title":"Toelichting","text":"<ul> <li>Bepaal tijdig, bijvoorbeeld in de probleemanalyse- of ontwikkelfase, om wat voor toepassing het gaat (algoritme of AI-systeem) en bepaal welke risicoclassificatie hierbij hoort.</li> <li>Bepaal op basis van de toepassing en de risicoclassificatie, welke aspecten van risicobeheer moeten worden toegepast.</li> <li>Inventariseer tijdig, bijvoorbeeld in de probleemanalayse- of ontwikkelfase, bij betrokken experts welke beleidskaders en instrumenten binnen de organisatie moeten worden ingezet om risicobeheer toe te passen.</li> <li>Bepaal op basis van de levenscyclus van een algoritme of AI-systeem wanneer welke aspecten van risicobeheer moeten worden toegepast. </li> <li>Maak inzichtelijk op welke niveaus risicobeheer kan en moet worden belegd bij het ontwikkelen en gebruiken van algoritmes en AI-systemen.</li> <li>Daarbij gaat het om het identificeren, analyseren, evalueren (afhankelijk van de risicobereidheid), behandelen (risicoreactie, o.a. maatregelen), monitoren &amp; beoordelen en communiceren &amp; rapporteren van risico's.</li> <li>Gedurende de levenscyclus van een algoritme of AI-systemen kunnen nieuwe risico's ontstaan waar mogelijk nieuwe maatregelen voor moeten worden getroffen. Het is van belang dat iteratief wordt gewerkt aan mitigerende maatregelen en dat risicobeheer periodiek wordt toegepast.</li> </ul> <p>Let op! Sommige maatregelen in het Algoritmekader gaan dieper in op het uitvoeren van risicoanalyses. </p>"},{"location":"maatregelen/0-org-03-toepassen_risicobeheer/#risico","title":"Risico","text":"<p>Risico's worden niet (tijdig) vastgesteld en adequaat geadresseerd en behandeld.  </p>"},{"location":"maatregelen/0-org-03-toepassen_risicobeheer/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/0-org-03-toepassen_risicobeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.13 </li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.03</li> <li>Algoritmekader</li> </ul>"},{"location":"maatregelen/0-org-03-toepassen_risicobeheer/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/0-org-04-wijzigingenproces/","title":"Maak afspraken over het wijzigen van de code","text":"<p>org-04OrganisatieverantwoordelijkhedenProjectleiderOntwikkelaarTechnische robuustheid en veiligheidGovernance</p>"},{"location":"maatregelen/0-org-04-wijzigingenproces/#maatregel","title":"Maatregel","text":"<p>Richt een wijzigingenproces in, waarmee bepaald wordt hoe codewijzigingen plaatsvinden.</p>"},{"location":"maatregelen/0-org-04-wijzigingenproces/#toelichting","title":"Toelichting","text":"<p>Bij het inrichten van een proces om wijzigingen aan de code te mogen aanbrengen, kunnen aan de volgende elementen worden gedacht:</p> <ul> <li>Wijzigingen dienen van te voren te worden geautoriseerd door de systeemeigenaar of product owner. (BIO 12.1.2)</li> <li>Wijzigingen worden getest in een andere omgeving dan de productieomgeving. (BIO 12.1.4, 14.2.3, 14.2.9, 14.3.1)</li> <li>Wijzigingen worden door de systeemeigenaar of product owner goedgekeurd op basis van gedocumenteerde testresultaten en pas daarna doorgevoerd in de productieomgeving. (BIO 12.1.2, 14.2.2, 14.2.9)</li> <li>Er dient functiescheiding te zijn ingericht tussen het aanvragen, goedkeuren en doorvoeren van wijzigingen om onbevoegde en onbedoelde wijzigingen te beperken. (BIO 6.1.2, 14.2.2)</li> <li>Er dient periodiek controle plaats te vinden op wijzigingen aan het systeem, zodanig dat oneigenlijke wijzigingen worden gesignaleerd. (BIO 9.4.4, 12.4.1)</li> </ul>"},{"location":"maatregelen/0-org-04-wijzigingenproces/#risico","title":"Risico","text":"<p>Als een formeel wijzigingenproces ontbreekt bestaat het risico van ongeautoriseerde toegang, wijziging of beschadiging van de code van het algoritme, of de uitkomsten van het algoritme.</p>"},{"location":"maatregelen/0-org-04-wijzigingenproces/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemen"},{"location":"maatregelen/0-org-04-wijzigingenproces/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.1 t/m IB.5</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.07 </li> </ul>"},{"location":"maatregelen/0-org-04-wijzigingenproces/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/0-org-05-gebruikersbeheer/","title":"Maak afspraken over het beheer van gebruikers","text":"<p>org-05OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesTechnische robuustheid en veiligheidGovernance</p>"},{"location":"maatregelen/0-org-05-gebruikersbeheer/#maatregel","title":"Maatregel","text":"<p>Richt gebruikersbeheer in, waarmee bepaald wordt wie toegang heeft tot wat, en wat er bijvoorbeeld gebeurt bij indiensttreding, functiewijziging en uitdiensttreding.</p>"},{"location":"maatregelen/0-org-05-gebruikersbeheer/#toelichting","title":"Toelichting","text":"<p>Gebruikersbeheer zorgt ervoor dat accounts en autorisaties beheerst worden aangevraagd, geautoriseerd, gewijzigd en ingetrokken bij indiensttreding, functiewijziging en uitdiensttreding. Ook wordt functievermenging voorkomen bij toegang en gebruik van het algoritme, de data of de uitkomsten van een algoritme.</p> <p>Bij het inrichten van gebruikersbeheer moeten aan de volgende elementen worden gedacht:</p> <ul> <li>Gebruikers en beheerders krijgen slechts toegang tot functionaliteit die zij uit hoofde van hun functie nodig hebben (need to know, need to use). Daartoe is een beschrijving beschikbaar welke rollen en rechten per applicatie bij een functie horen (BIO 6.1.2, 9.2.2 en 9.4).</li> <li>Het verlenen en muteren van accounts en toegangsrechten vindt plaats na goedkeuring door een bevoegde functionaris. Dit aan de hand van een actueel mandaatregister waaruit blijkt welke personen beslissende bevoegdheden hebben voor het verlenen van een bepaald type (niveau) toegangsrechten danwel functieprofielen (BIO 9.2.1.2, 9.2.2.1, 9.4).</li> <li>Er bestaat functiescheiding tussen het aanvragen, autoriseren en doorvoeren van wijzigingen in gebruikersaccounts en toegangsrechten (BIO 9.2.1.2, 9.2.2.1, 9.2.3).</li> <li>Functiewijzigingen en uitdiensttredingen worden bewaakt voor aanpassen van de toegangsrechten en voor intrekken van de identiteits- en authenticatiemiddelen (BIO 9.2.2, 9.2.6).</li> <li>Het aantal accounts met verhoogde rechten is beperkt en verklaard, en staat in logische verhouding tot de beheerders en of ICT-afdeling (BIO 9.1.2.(1), 9.2.3, 9.2.4).</li> <li>Gebruikersaccounts en beheeraccounts dienen altijd persoonsgebonden en verklaard te zijn, zodat handelingen altijd te herleiden zijn naar \u00e9\u00e9n verantwoordelijke (BIO 9.1, 9.4.2).</li> <li>Eindgebruikers hebben geen directe toegang tot de onderliggende componenten (zoals de database) (BIO 9.2.3, 13.1.3).</li> <li>Toegangsrechten op onderliggende componenten dienen periodiek, minimaal jaarlijks, ge\u00ebvalueerd te worden. Dit interval dient te zijn beschreven in het toegangsbeleid en zijn bepaald op basis van het risiconiveau. De uitkomsten van de evaluatie en de opvolging daarvan worden vastgelegd (BIO 9.2.5).</li> </ul> <p>Voor deze maatregelen is het van belang om aandacht te hebben voor de volgende zaken:</p> <ul> <li>Autorisatiematrix en beschrijving rollen/rechten per systeem(laag)</li> <li>Lijst met wijzigingen rollen en bijbehorende goedkeuringen</li> <li>Overzicht aantallen en rechten per (systeem)laag</li> </ul>"},{"location":"maatregelen/0-org-05-gebruikersbeheer/#risico","title":"Risico","text":"<p>Er bestaan meerdere risico's wanneer er geen gebruikersbeheer is: - Toegangsrechten kunnen niet meer up-to-date zijn, bijvoorbeeld wanneer er geen rekening wordt gehouden met het IDU-proces (). Er bestaat dan het risico dat gebruikers toegang tot de omgeving van het algoritme, de data of de uitkomsten van het algoritme hebben die zij niet zouden mogen hebben. - Wanneer functievermenging niet wordt voorkomen bij toegang en gebruik van het algoritme, bestaat het risico dat er ongeautoriseerde wijzigingen worden doorgevoerd aan het algoritme, de data of de uitkomsten van het algoritme. - Wanneer gebruik wordt gemaakt van generieke-, groeps- of onpersoonlijke accounts, bestaat het risico dat handelingen niet te herleiden zijn naar een verantwoordelijke persoon.</p>"},{"location":"maatregelen/0-org-05-gebruikersbeheer/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemen"},{"location":"maatregelen/0-org-05-gebruikersbeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.10 t/m IB.17</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.01, 4.02, 4.04, 4.05</li> </ul>"},{"location":"maatregelen/0-org-05-gebruikersbeheer/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/0-org-06-wachtwoordbeheer/","title":"Maak afspraken over het beheer van wachtwoorden","text":"<p>org-06OrganisatieverantwoordelijkhedenProjectleiderOntwikkelaarTechnische robuustheid en veiligheidGovernance</p>"},{"location":"maatregelen/0-org-06-wachtwoordbeheer/#maatregel","title":"Maatregel","text":"<p>Richt wachtwoordbeheer in, waarmee bepaald wordt hoe wachtwoorden worden opgeslagen, wanneer wijzigingen moeten plaatsvinden en waaraan wachtwoorden moeten voldoen. Hiermee wordt de toegang tot bijvoorbeeld ontwikkelomgevingen geregeld op een veilige manier.</p>"},{"location":"maatregelen/0-org-06-wachtwoordbeheer/#toelichting","title":"Toelichting","text":"<p>Bij het inrichten van wachtwoordbeheer moeten de volgende zaken worden toegepast:</p> <ul> <li>Alle wachtwoorden van gebruikers en beheerders dienen periodiek te worden gewijzigd, met een maximum van 1 jaar (BIO 9.4.3). Initi\u00eble wachtwoorden en wachtwoorden die gereset zijn, hebben een maximale geldigheidsduur van 24 uur en moeten bij het eerste gebruik worden gewijzigd.</li> <li>Voor toegang vanuit een onvertrouwde omgeving dient twee-factor authenticatie te worden gebruikt (BIO 9.4.2.1). Als er geen gebruik wordt gemaakt van two-factor authenticatie, is de wachtwoordlengte minimaal 8 posities en complex van samenstelling. In situaties waar geen two-factor authenticatie mogelijk is, wordt minimaal halfjaarlijks het wachtwoord vernieuwd.</li> <li>Na een periode van maximaal 15 minuten inactiviteit dient de toegang tot de applicatie te worden vergrendeld en na 10 foutieve inlogpogingen dient het account geblokkeerd te worden (BIO 11.2.9, BIO 9.4.3). De tijdsduur dat een account wordt geblokkeerd na overschrijding van het aantal keer foutief inloggen is vastgelegd.</li> <li>Wachtwoorden mogen niet in originele vorm (plaintext) worden opgeslagen, maar dienen versleuteld te worden. (NIST 5.1.1.2)</li> <li>De eisen aan wachtwoorden moeten geautomatiseerd worden afgedwongen.</li> </ul>"},{"location":"maatregelen/0-org-06-wachtwoordbeheer/#risico","title":"Risico","text":"<p>Als het wachtwoordbeheer van onvoldoende kwaliteit is, kan oneigenlijke toegang plaatsvinden tot het algoritme of uitkomsten van het algoritme, bijvoorbeeld doordat het wachtwoord te eenvoudig is.</p>"},{"location":"maatregelen/0-org-06-wachtwoordbeheer/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemen"},{"location":"maatregelen/0-org-06-wachtwoordbeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.6 t/m IB.9</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.03</li> <li>NIST 5.1.1.2</li> </ul>"},{"location":"maatregelen/0-org-06-wachtwoordbeheer/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/0-org-07-periodieke-evaluatie-kwaliteit/","title":"Controleer en verbeter regelmatig de kwaliteit van het algoritme","text":"<p>org-07OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderBeleid en adviesGovernance</p>"},{"location":"maatregelen/0-org-07-periodieke-evaluatie-kwaliteit/#maatregel","title":"Maatregel","text":"<p>Richt een proces in voor een periodieke evaluatie van de kwaliteit van het algoritme of AI-systeem.</p>"},{"location":"maatregelen/0-org-07-periodieke-evaluatie-kwaliteit/#toelichting","title":"Toelichting","text":"<ul> <li>Het is van belang dat een proces wordt ingericht waarmee periodiek de kwaliteit van algoritmes of AI-systemen wordt ge\u00ebvalueerd.</li> <li>Bij kwaliteit van een algoritme of AI-systeem kan worden gedacht aan doeltreffenheid, doelmatigheid, betrouwbaarheid en accuraatheid (geschiktheid) en non-discriminatie.</li> <li>Hieronder vallen het analyseren en evalueren van ingediende klachten en incidenten.</li> <li>Na verloop van tijd kan de accuraatheid van machine learning modellen bijvoorbeeld wijzigen of kan het gebeuren dat bepaalde groepen (indien van toepassing) anders worden behandeld.</li> <li>Het is van belang dat monitoringsactiviteiten worden ingericht om deze kwaliteitsaspecten tijdig te beoordelen.</li> <li>Als er ongewenste wijzigingen plaatsvinden met betrekking tot de kwaliteit, moeten die worden ge\u00ebvalueerd en zullen maatregelen moeten worden getroffen om deze te herstellen.</li> <li>Het proces moet er voor zorgen dat de juiste experts of stakeholders worden betrokken bij het proces van evaluatie en het treffen van passende maatregelen.</li> </ul> <p>Let op! Sommige maatregelen in het Algoritmekader gaan dieper in op het uitvoeren van risicoanalyses. </p>"},{"location":"maatregelen/0-org-07-periodieke-evaluatie-kwaliteit/#risico","title":"Risico","text":"<p>Zonder evaluatie van de kwaliteit van het algoritme is er geen goede sturing, beheersing en verantwoording mogelijk als er ongewenste wijzigingen plaatsvinden in het algoritme of AI-systeem. </p>"},{"location":"maatregelen/0-org-07-periodieke-evaluatie-kwaliteit/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-29 - Beoordeling van grondrechten"},{"location":"maatregelen/0-org-07-periodieke-evaluatie-kwaliteit/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.16, SV.17 </li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.08</li> </ul>"},{"location":"maatregelen/0-org-07-periodieke-evaluatie-kwaliteit/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/1-pba-01-formuleren-probleemdefinitie/","title":"Beschrijf het probleem dat het algoritme moet oplossen","text":"<p>pba-01ProbleemanalyseProjectleiderGovernanceMenselijke controle</p>"},{"location":"maatregelen/1-pba-01-formuleren-probleemdefinitie/#maatregel","title":"Maatregel","text":"<p>Formuleer en documenteer wat de aanleiding is om een algoritme of AI-systeem in te willen zetten.  Formuleer duidelijk de probleemdefinitie en probleemafbakening waarvoor het algoritme een oplossing zou moeten vormen. </p>"},{"location":"maatregelen/1-pba-01-formuleren-probleemdefinitie/#toelichting","title":"Toelichting","text":"<p>Formuleer de probleemdefinitie en probleemafbakening zo concreet en precies mogelijk. Maak dit waar mogelijk kwantificeerbaar. </p>"},{"location":"maatregelen/1-pba-01-formuleren-probleemdefinitie/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/1-pba-01-formuleren-probleemdefinitie/#risico","title":"Risico","text":"<p>Het algoritme dient niet het onderliggende probleem.  Zonder eenduidigheid over het op te lossen probleem is geen sturing op en verantwoording over het algoritme mogelijk. </p>"},{"location":"maatregelen/1-pba-01-formuleren-probleemdefinitie/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, 1.01</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.1</li> </ul>"},{"location":"maatregelen/1-pba-01-formuleren-probleemdefinitie/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/1-pba-02-formuleren-doelstelling/","title":"Beschrijf het doel van het algoritme","text":"<p>pba-02ProbleemanalyseProjectleiderGovernanceMenselijke controle</p>"},{"location":"maatregelen/1-pba-02-formuleren-doelstelling/#maatregel","title":"Maatregel","text":"<p>Het doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd.  Maak de consequenties van het algoritme specifiek en zorg dat het doel van het algoritme formeel is vastgesteld en vastgelegd. </p>"},{"location":"maatregelen/1-pba-02-formuleren-doelstelling/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Het doel van de inzet van een algoritme dient zo concreet en specifiek mogelijk gedefinieerd te worden.  Indien er meerdere doelen zijn, is het belangrijk om een zekere rangorde te maken: wat zijn de belangrijkste doelen? En waarom? Welke doelen zijn subdoelen, waarvoor het minder belangrijk is om deze te realiseren?</p> </li> <li> <p>Indien mogelijk, dienen de doelstellingen gekwantificeerd te worden (SMART). </p> </li> <li> <p>Om te zorgen voor voldoende draagvlak voor de beoogde doelen, is het noodzaak om voldoende belanghebbenden te betrekken.  Hierbij kan het ook helpen om burgers te betrekken bij de totstandkoming van de doelstellingen, bijvoorbeeld door middel van een burgerpanel of het betrekken van belangengroepen. </p> </li> </ul>"},{"location":"maatregelen/1-pba-02-formuleren-doelstelling/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/1-pba-02-formuleren-doelstelling/#risico","title":"Risico","text":"<p>Het algoritme dient niet het beoogde doel en onderliggend probleem.  Zonder eenduidigheid over het doel is geen sturing op en verantwoording over het algoritme mogelijk.  Er is dan een groter risico op fouten en/of verschillen in interpretatie. </p> <p>Wanneer doelstellingen niet meetbaar zijn gemaakt, is het onmogelijk om achteraf te kwantificeren of de doelstellingen zijn behaald.  Doelstellingen zijn in dat geval moeilijk bespreekbaar.  </p>"},{"location":"maatregelen/1-pba-02-formuleren-doelstelling/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.01, 1.02</li> <li>Impact Assessment Mensenrechten en Algoritmes, 1.2</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.3</li> </ul>"},{"location":"maatregelen/1-pba-02-formuleren-doelstelling/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/","title":"Beschrijf waarom een algoritme het probleem moet oplossen","text":"<p>pba-03ProbleemanalyseProjectleiderGovernanceMenselijke controle</p>"},{"location":"maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#maatregel","title":"Maatregel","text":"<p>Bepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken. </p>"},{"location":"maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Bepaal waarom het gewenst of nodig is om een algoritme in te zetten, en of er ook alternatieven zijn om het probleem op te lossen.  Documenteer de onderbouwing waarom een algoritme een betere oplossing zou bieden dan een niet-geautomatiseerd of niet-digitaal proces. </p> </li> <li> <p>Maak een bewuste afweging of een algoritme het juiste middel is om het probleem op doelmatige en doeltreffende wijze op te lossen, en documenteer deze afweging. </p> </li> </ul>"},{"location":"maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#risico","title":"Risico","text":"<p>Het algoritme is niet het juiste middel om het probleem op te lossen. Het risico daarbij bestaat dat het probleem niet wordt opgelost. </p>"},{"location":"maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, 1.01</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.2</li> </ul>"},{"location":"maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/1-pba-04-betrek-belanghebbenden/","title":"Overleg regelmatig met belanghebbenden","text":"<p>pba-04ProbleemanalyseOntwerpImplementatieProjectleiderGovernanceFundamentele rechten</p>"},{"location":"maatregelen/1-pba-04-betrek-belanghebbenden/#maatregel","title":"Maatregel","text":"<p>Breng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus. Belanghebbenden zijn onder meer eindgebruikers, mensen en rechtspersonen die door het algoritme geraakt kunnen worden en vertegenwoordigende organisaties.</p>"},{"location":"maatregelen/1-pba-04-betrek-belanghebbenden/#toelichting","title":"Toelichting","text":"<p>Algoritmes worden vaak gebruikt binnen een (specifieke) context waar deze invloed op uitoefenen. Medewerkers moeten bijvoorbeeld werken met de uitkomsten of anderen zijn onderwerp van het algoritme. Om te voorkomen dat er een mismatch ontstaat met de realiteit, is het van belang om specifieke domeinkennis te betrekken.</p> <p>Het betrekken van belanghebbenden is van belang in bijna alle fasen van de levenscyclus.</p> <p>In de fase van de probleemanalyse is het allereerst van belang in kaart te brengen welke stakeholders er zijn. Wie gaan bijvoorbeeld werken met het algoritme (eindgebruikers)? En welke demografie\u00ebn worden geraakt door een algoritme? Bij wie liggen de voordelen en bij wie liggen de nadelen? Ga vervolgens in gesprek met belanghebbenden - al dan niet vertegenwoordigd door belangenorganisaties zoals burgerrechtenorganisaties - over het te ontwerpen algoritme en de context waarin het gebruikt wordt. Bespreek daarbij welke definitie en metriek van fairness past bij de context.</p> <p>In de fase van dataverkenning en datapreparatie is het van belang om domeinexpertise te betrekken, om zo in kaart te brengen wat de data features betekenen en waar zij vandaan komen. Op basis daarvan kan in kaart gebracht worden of er sprake is van bias en/of links met beschermde persoonskenmerken.</p> <p>In de fase van implementatie is het van belang de eindgebruikers te betrekken. Het is dan vooral van belang om maatregelen te nemen om automation bias, deployment bias en reinforcing feedback loop te voorkomen of te beperken.</p> <p>In de fase van monitoren is het van belang belanghebbenden te betrekken bij de evaluatie. Dit kan bijvoorbeeld in de vorm van een survey of focusgroep. Zij kunnen problemen in de praktijk naar voren brengen, die niet altijd terug te vinden zijn in de data.</p> <p>Terugkoppelen aan buitenwereld.</p>"},{"location":"maatregelen/1-pba-04-betrek-belanghebbenden/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/1-pba-04-betrek-belanghebbenden/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algemene Rekenkamer 2.12</li> <li>The Fairness Handbook </li> <li>Handreiking non-discriminatie by design</li> <li>Ethics Guidelines for Trustworthy AI</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.10 </li> </ul>"},{"location":"maatregelen/1-pba-04-betrek-belanghebbenden/#risico","title":"Risico","text":"<p>De mismatch kan nadelige gevolgen hebben voor de effectiviteit van het algoritme binnen een context. Het kan daarnaast ook ongerechtvaardigde discriminatie in de hand werken. Ontwikkelaars kunnen bijvoorbeeld missen dat in de context van het algoritme een variabele een proxy is voor een discriminatiegrond.</p>"},{"location":"maatregelen/1-pba-04-betrek-belanghebbenden/#voorbeeld","title":"Voorbeeld","text":"<p>Richt een burgerpanel in.</p> <p>Methodologie van Waag, Civic AI lab, Stakeholder escalation ladder. Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/1-pba-05-wettelijke-grondslag/","title":"Beschrijf de wettelijke grondslag voor de inzet van het algoritme","text":"<p>pba-05ProbleemanalyseJuristGovernance</p>"},{"location":"maatregelen/1-pba-05-wettelijke-grondslag/#maatregel","title":"Maatregel","text":"<p>Beschrijf de wettelijke grondslag voor de inzet van het algoritme en de beoogde besluiten die genomen zullen worden op basis van het algoritme.</p>"},{"location":"maatregelen/1-pba-05-wettelijke-grondslag/#toelichting","title":"Toelichting","text":"<ul> <li>Analyseer of er een concrete wettelijke grondslag is die de inzet van het algoritme mogelijk maakt en deze inzet voldoende voorzienbaar maakt. </li> <li>Als de verwachting is dat een algoritme tot gevolg heeft dat wordt ingegrepen in het leven of de vrijheid van mensen, en zeker als de verwachting is dat er grondrechten worden geraakt, moet er een wettelijke grondslag bestaan voor de inzet van het algoritme.</li> <li>Voor het verwerken van persoonsgegevens is een wettelijke grondslag noodzakelijk. </li> </ul>"},{"location":"maatregelen/1-pba-05-wettelijke-grondslag/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekendavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvinden"},{"location":"maatregelen/1-pba-05-wettelijke-grondslag/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, SV.7, PRI.6</li> <li>Impact Assessment Mensenrechten en Algoritmes, 1.4</li> </ul>"},{"location":"maatregelen/1-pba-05-wettelijke-grondslag/#risico","title":"Risico","text":"<p>Het algoritme en beoogde besluiten voldoen niet aan wet- en regelgeving en intern beleid en kaders.</p>"},{"location":"maatregelen/1-pba-05-wettelijke-grondslag/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/","title":"Beschrijf de rollen en verantwoordelijkheden in een RACI-matrix","text":"<p>owp-01OntwerpImplementatieMonitoring en beheerProjectleiderGovernance</p>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#maatregel","title":"Maatregel","text":"<p>Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmes en AI-systemen en pas een RACI-matrix toe. De rollen en verantwoordelijkheden worden vastgesteld door de verantwoordelijke(n).</p>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#toelichting","title":"Toelichting","text":"<ul> <li>Duidelijkheid en borging van rollen en verantwoordelijkheden zorgen voor een effectief en verantwoord verloop van het proces rondom de ontwikkeling, inkoop en gebruik van een algoritme.  Zeker wanneer ongewenste effecten optreden en maatregelen nodig zijn, is duidelijkheid over rollen, verantwoordelijkheden en bijbehorende besluitvormingsstructuren van belang.</li> <li>Een RACI-matrix/VERI-matrix is een passend middel om de verantwoordelijkheden (Responsible/Verantwoordelijk, Accountable/Eindverantwoordelijk, Consulted/Geraadpleegd, Informed/Ge\u00efnfomeerd) te bepalen.</li> <li>Werk specifieke, gevoelige activiteiten nader uit te in concrete taken en verantwoordelijkheden, bijvoorbeeld welke stappen moeten worden gezet om data veilig te leveren ten behoeve van een onderzoek naar onbwuste vooringenomenheid.  </li> </ul>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#vaststellen-van-rollen-en-verantwoordelijkheden","title":"Vaststellen van rollen en verantwoordelijkheden","text":"<ul> <li>Laat de rollen en verantwoordelijkheden vaststellen door de verantwoordelijke(n). Het doel van vaststelling is dat de verantwoordelijke(n) de verantwoordelijkheid neemt en actief een keuze maakt om het algoritme of AI-systemen te (laten) ontwikkelen of gebruiken op de beoogde wijze en met de bijbehorende verantwoordelijkheden. Met het vaststellen worden afspraken geformaliseerd. </li> <li>Vaststelling van de verantwoordelijkheden kan plaatsvinden door beleidsdocumenten, werkinstructies, verwerkersovereenkomst of een PIA/DPIA, mits de verantwoordelijkheden voldoende duidelijk zijn beschreven.</li> <li>Gedurende de levenscyclus kan het voorkomen dat rollen en verantwoordelijkheden opnieuw moet worden beschreven en vastgesteld.</li> </ul>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#verwerking-van-persoonsgegevens","title":"Verwerking van persoonsgegevens","text":"<ul> <li>Bij het verwerken van persoonsgegevens moet worden vastgelegd wie de (gezamelijke) verwerkingsverantwoordelijken zijn en wie de verwerkers. Uit deze vaststelling van de rolverdeling volgen onder de AVG verschillende rechten en plichten.</li> <li>Bij de ontwikkeling en gebruiken van algoritmes en AI-systemen is het denkbaar dat de noodzaak voor het verwerken van persoonsgegevens wijzigt en dat meer of andere verwerkingen moeten plaatsvinden. Het is van belang dat wederom wordt beoordeeld wat dit betekent voor de bijbehorende verantwoordelijkheden. Als er sprake is van een wezenlijke wijziging ten opzichte van de al vastgestelde situatie, bijvoorbeeld doordat er meer persoonsgegevens worden verwerkt door een andere partij, dan zal de verwerkingsverantwoordelijke opnieuw tot vaststelling moeten overgaan om de afspraken te formaliseren.</li> </ul>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#voorbeeld","title":"Voorbeeld","text":"<p>Rapport Kleur Bekennen, Algemene Rekenkamer, p. 114, figuur 5-4</p>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#risico","title":"Risico","text":"<p>De sturing en verantwoording is ontoereikend of niet geborgd, waardoor er onvoldoende betrokkenheid of capaciteit is van verantwoordelijken. Ook kan er dan onvoldoende deskundigheid in de organisatie zijn, wat de kans vergroot op fouten en ongewenste effecten. Zonder het vaststellen van rollen en verantwoordelijkheden, kan er geen effectieve sturing plaatsvinden op partijen die betrokken zijn bij het ontwikkelen of gebruiken van algoritmes of AI-systemen.</p>"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-06 - Verantwoordingsplicht voor de rechtmatigheid van de verwerkingawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.06, 3.02</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.9, SV.19, PRI.1</li> </ul>"},{"location":"maatregelen/2-owp-02-gebruikte-data/","title":"Beschrijf welke data gebruikt wordt voor de beoogde toepassing","text":"<p>owp-02OntwerpDataverkenning en datapreparatieOntwikkelaarBeleid en adviesData</p>"},{"location":"maatregelen/2-owp-02-gebruikte-data/#maatregel","title":"Maatregel","text":"<p>Beschrijf welke data gebruikt wordt voor de beoogde toepassing. </p>"},{"location":"maatregelen/2-owp-02-gebruikte-data/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Maak in een vroege fase van de ontwikkeling een inschatting van welke data er gebruikt gaat worden voor het algoritme. Welke data is er beschikbaar? Wat voor type data gaat gebruikt worden  en uit welke bronnen is de data afkomstig?</p> </li> <li> <p>Maak al een eerste inschatting van de kwaliteit van de data, en of dit voldoende is voor de beoogde toepassing. Later in de levenscyclus moet je nog nader onderzoek doen naar de kwaliteit van de data. </p> </li> </ul>"},{"location":"maatregelen/2-owp-02-gebruikte-data/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/2-owp-02-gebruikte-data/#risico","title":"Risico","text":""},{"location":"maatregelen/2-owp-02-gebruikte-data/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteria"},{"location":"maatregelen/2-owp-02-gebruikte-data/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, 2A.2.1</li> </ul>"},{"location":"maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/","title":"Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit mag","text":"<p>owp-03OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieProjectleiderJuristPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#maatregel","title":"Maatregel","text":"<p>Het doel voor het verwerken van persoonsgegevens met een algoritme of AI-systeem is welbepaald en omschreven.</p>"},{"location":"maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#toelichting","title":"Toelichting","text":"<ul> <li>Persoonsgegevens mogen alleen worden verwerkt voor een \u2018welbepaald, uitdrukkelijk omschreven en gerechtvaardigd\u2019 doel;</li> <li>De  wettelijke grondslag / wettelijke taak voor de verwerking van de persoonsgegevens moet zijn beschreven, bijvoorbeeld in een DPIA;</li> <li>De verwerking van persoonsgevens voor het ontwikkelen en gebruiken van het algoritme of AI-systeem moet verenigbaar met het oorspronkelijke verwerkingsdoel (doelbinding);</li> <li>Eventuele verdere (subsidiaire) verwerkingen, zoals het verwerken van persoonsgegevens voor een onderzoek naar onbewuste vooringenomenheid, moeten uitdrukkelijk worden omschreven.</li> </ul>"},{"location":"maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#risico","title":"Risico","text":"<p>Als het doel voor het verwerken van persoonsgegevens onvoldoende is omschreven en onderbouwd, ontstaat het risico dat onrechtmatig persoonsgegevens worden verwerken en een inbreuk wordt gemaakt op privacyrechten van betrokkenen.</p>"},{"location":"maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.01, 3.05</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.4 </li> </ul>"},{"location":"maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/2-owp-04-gebruikte-techniek/","title":"Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing","text":"<p>owp-04OntwerpOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/2-owp-04-gebruikte-techniek/#maatregel","title":"Maatregel","text":"<p>Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing. </p>"},{"location":"maatregelen/2-owp-04-gebruikte-techniek/#toelichting","title":"Toelichting","text":"<ul> <li>Beschrijf wat voor soort algoritme er gebruikt gaat worden voor de beoogde toepassing. </li> <li> <p>Bepaal of je gebruik wilt maken van een:</p> <ul> <li>zelflerend algoritme</li> <li>niet-zelflerend algoritme zoals een algoritme gebaseerd op rekenregels</li> </ul> </li> <li> <p>Beschrijf vervolgens ook:</p> <ul> <li>waarom er voor dit type algoritme wordt gekozen</li> <li>wat de alternatieven zijn en waarom die minder passend zijn?</li> <li>waarom dit algoritme het meest geschikt is om het beoogde doel van het algoritme te bereiken. </li> </ul> </li> <li> <p>De precieze details kunnen in dit stadium van de levenscyclus waarschijnlijk nog niet ingevuld worden. Maak een goede eerste inschatting van de gebruikte techniek. Eventueel kan je er ook voor kiezen om verschillende technieken verder te onderzoeken. Dat betekent dat er meerdere algoritmes ontwikkeld worden (op basis van verschillende technieken), en je later een definitieve keuze maakt. </p> </li> </ul>"},{"location":"maatregelen/2-owp-04-gebruikte-techniek/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/2-owp-04-gebruikte-techniek/#risico","title":"Risico","text":""},{"location":"maatregelen/2-owp-04-gebruikte-techniek/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekendaia-06 - Technische documentatie voor hoog-risico AIaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging"},{"location":"maatregelen/2-owp-04-gebruikte-techniek/#bronnen","title":"Bronnen","text":"<p>Impact Assessment Mensenrechten en Algoritmes, 2A.1, 2B.1</p>"},{"location":"maatregelen/2-owp-05-soort-algoritme/","title":"Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horen","text":"<p>owp-05OntwerpOntwikkelenProjectleiderBeleid en adviesPublieke inkoopGovernance</p>"},{"location":"maatregelen/2-owp-05-soort-algoritme/#maatregel","title":"Maatregel","text":"<p>Stel vast of het gaat om een algoritme en/of AI-systeem en wat de bijbehorende risicoclassificatie is om te bepalen welke vereisten hierop van toepassing zijn.</p>"},{"location":"maatregelen/2-owp-05-soort-algoritme/#toelichting","title":"Toelichting","text":"<p>Het verschilt per typen algoritmen of AI-systemen welke vereisten hierop van toepassing is en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen.  Dit is mede afhankelijk van de bijbehorende risicoclassificatie.  Hiervoor kan in de nabije toekomst de 'beslisboom' in het Algoritmekader voor worden gebruikt'.  Deze stap is van groot belang, omdat dit ook bepalend is welke contractuele verplichtingen moeten worden gecre\u00eberd tussen opdrachtgever en opdrachtnemer/aanbieder. </p>"},{"location":"maatregelen/2-owp-05-soort-algoritme/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-08 - Transparantie in ontwerp voor hoog-risico AIavg-04 - Proportionaliteit en subsidiariteitaia-06.4-documentatie-beoordeling-niet-hoog-risico-ai"},{"location":"maatregelen/2-owp-05-soort-algoritme/#bronnen","title":"Bronnen","text":"<p>Algoritmekader</p>"},{"location":"maatregelen/2-owp-05-soort-algoritme/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/2-owp-06-afwegen-grondrechten/","title":"Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafweging","text":"<p>owp-06ProbleemanalyseOntwerpVerificatie en validatieMonitoring en beheerProjectleiderBeleid en adviesFundamentele rechten</p>"},{"location":"maatregelen/2-owp-06-afwegen-grondrechten/#maatregel","title":"Maatregel","text":"<p>Identificeer welke grondrechten geraakt worden door het in te zetten algoritme en maak een afweging of dit aanvaardbaar is</p>"},{"location":"maatregelen/2-owp-06-afwegen-grondrechten/#toelichting","title":"Toelichting","text":"<p>Een algoritme kan invloed hebben op grondrechten. Op een aantal grondrechten kan een algoritme sneller invloed hebben, zoals recht op persoonsgegevensbescherming, recht op behoorlijk bestuur en recht op gelijke behandeling. Deze veelvoorkomende grondrechten krijgen op andere plekken in het Algoritmekader specifieke aandacht.  Er zijn echter ook grondrechten die bij minder algoritmen relevant zijn, maar desalniettemin in die gevallen zeer invloedrijk kunnen zijn.  Het is van belang uiteindelijk een totale afweging te maken van alle grondrechten die (mogelijk) geraakt worden ten opzichte van de voordelen van het in te zetten algoritme.  Een voorbeeld van een grondrecht dat minder snel geraakt wordt is bijvoorbeeld een algoritme om hate speech te kunnen detecteren. Zo'n algoritme zal van invloed kunnen zijn op de vrijheid van meningsuiting en het recht op informatie.</p> <p>Doorloop in lijn met Deel 4 van het Impact Assessment Mensenrechten en Algoritmes de volgende stappen:</p> <ol> <li>Breng in kaart welke grondrechten geraakt kunnen worden door de inzet van het algoritme. Hiervoor kan bijlage 1 uit het Impact Assessment Mensenrechten en Algoritmes gebruikt worden.</li> <li>Als dat het geval is, is het allereerst van belang om te controleren of hiervoor specifieke wetgeving is waar de inzet van het algoritme aan moet voldoen.</li> <li>Bepaal hoe zwaar de geindentificeerde grondrechten worden geraakt door het beoogde algoritme.</li> <li>Bepaal hoe doeltreffend/effectief het algoritme in de praktijk is.</li> <li>Bepaal of de inzet van het algoritme noodzakelijk is om het beoogde doel te bereiken. Zijn er alternatieven? Of zijn er mitigerende maatregelen die genomen kunnen worden waardoor grondrechten niet of minder worden geraakt en eventuele nadelige gevolgen verzacht kunnen worden?</li> <li>Gegeven alle voorgaande stappen, bepaal of de inzet van het algoritme en proportioneel is om het beoogde doel te bereiken. Wegen de voordelen op tegen de nadelen?</li> </ol> <p>Het is van belang voldoende belanghebbenden te betrekken bij het doorlopen van deze stappen om te zorgen dat alle eventueel nadelige aspecten van het in te zetten algoritme worden meegenomen.  Documenteer de doorlopen stappen en leg de keuzes en afwegingen goed vast. </p> <p>Opmerking</p> <p>Zoals vermeld in de vereiste voor beoordeling van gevolgen voor grondrechten uit de AI-verordening moeten sommige hoog-risico AI-systemen een beoordeling doen van de gevolgen voor grondrechten. Het is nog niet bekend welke vorm dit precies moet hebben.</p>"},{"location":"maatregelen/2-owp-06-afwegen-grondrechten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistegrw-01 - Beschermen van fundamentele rechten en vrijhedenaia-29 - Beoordeling van grondrechten"},{"location":"maatregelen/2-owp-06-afwegen-grondrechten/#bronnen","title":"Bronnen","text":"<p>Impact Assessment Mensenrechten en Algoritmes, deel 4</p>"},{"location":"maatregelen/2-owp-06-afwegen-grondrechten/#risico","title":"Risico","text":"<p>Het risico is dat er grondrechten, anders dan die expliciet beschermd zijn in andere maatregelen en vereisten, aangetast worden.</p>"},{"location":"maatregelen/2-owp-06-afwegen-grondrechten/#voorbeeld","title":"Voorbeeld","text":"<p>Hoofdstuk 4 van het Impact Assesment Mensenrechten en Algoritmen (IAMA) richt zich specifiek op de grondrechten. In bijlage 1 is tevens een overzicht te vinden van mogelijk relevante grondrechten.</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/2-owp-07-kwetsbare-groepen/","title":"Maak een lijst van de meest kwetsbare groepen en bescherm hen extra","text":"<p>owp-07OntwerpBeleid en adviesFundamentele rechten</p>"},{"location":"maatregelen/2-owp-07-kwetsbare-groepen/#maatregel","title":"Maatregel","text":"<p>Bepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.</p>"},{"location":"maatregelen/2-owp-07-kwetsbare-groepen/#toelichting","title":"Toelichting","text":"<ul> <li>Verschillende groepen kunnen op een andere manier geraakt worden door het inzetten van een algoritme. Dit is afhankelijk van de context waarin het algoritme wordt ingezet, en dient daardoor bij iedere toepassing opnieuw bekeken te worden. </li> <li>Bedenk wat er met de uitkomsten van het algoritme gedaan wordt, en wat de consequenties daarvan zijn voor burgers. Hierbij kan gedacht worden aan de volgende aspecten:<ul> <li>Worden bepaalde groepen sneller gemonitord?</li> <li>Wat als het model het fout heeft? </li> <li>Wordt het systeem gebruikt om informatie te verkrijgen, om besluiten voor te bereiden of om zelfstandige besluiten te nemen en welke gevolgen heeft dat voor de mate waarin het algoritme bepalend zal zijn in de praktijk? </li> <li>Worden de gegevens veilig en vertrouwelijk behandeld; welke gevolgen zou een datalek hebben voor groepen of categorie\u00ebn personen?</li> <li>Worden data gedeeld met andere partijen en wat is het gevaar dat die misbruik maken van de data met negatieve gevolgen voor groepen of categorie\u00ebn personen?</li> </ul> </li> <li>Houd hierbij ook rekening met de impact van het in te zetten algoritme op de samenleving (vanuit sociaal, democratisch en milieu/ecologisch perspectief).</li> <li>Om de impact op groepen te bepalen, kan het handig zijn een mensenrechtentoets zoals het Impact Assessment Mensenrechten en Algoritmes toe te passen. </li> <li>Bepaal of er maatregelen genomen kunnen worden om de ge\u00efdentificeerde groepen extra bescherming te bieden. Hierbij kan men denken aan de volgende aspecten: Kan de (extra) administratieve druk voor bepaalde groepen worden weggenomen? Worden resultaten van het algoritme naast de resultaten van een expert gelegd? Is het wenselijk om een proces in te richten waarbij zowel algoritme als een expert een uitkomst geven? Kunnen we de betreffende groep extra hulp aanbieden? Is het wenselijk bij negatieve uitkomsten een vier-ogen-principe toe te passen? </li> <li>De impact van het algoritme op de groepen die ge\u00efdentificeerd worden in deze stap, kunnen mogelijk onderzocht worden in een biasanalyse. Daarbij kan geidentificeerd worden of bepaalde groepen oververtegenwoordigd of ondervertegenwoordigd zijn in selecties, of dat het algoritme andere of meer fouten maakt voor bepaalde groepen. </li> <li>Merk op dat het onmogelijk is om de risico's voor alle specifieke groepen af te vangen. Hierbij kan het helpen om te focussen op de meest kwetsbare groepen. </li> </ul>"},{"location":"maatregelen/2-owp-07-kwetsbare-groepen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistegrw-01 - Beschermen van fundamentele rechten en vrijhedenaia-04 - Risicobeoordeling voor jongeren en kwetsbaren"},{"location":"maatregelen/2-owp-07-kwetsbare-groepen/#risico","title":"Risico","text":"<p>De impact van het algoritme op de besluitvorming en op personen, doelgroepen en/of de samenleving is niet inzichtelijk, waardoor onvoldoende maatregelen zijn getroffen om ongewenste effecten (zoals bias en discriminatie) te voorkomen. </p>"},{"location":"maatregelen/2-owp-07-kwetsbare-groepen/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.4, DM.16</li> <li>Kamerstukken II 2023/24, 31066-1374</li> <li>Impact Assessment Mensenrechten en Algoritmes, 4.1</li> <li>Handreiking non-discriminatie by design, 1.7 en 1.8 en 1.15</li> </ul>"},{"location":"maatregelen/2-owp-07-kwetsbare-groepen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/2-owp-08-archiveren-documenten/","title":"Bepaal welke documenten voor hoe lang gearchiveerd moeten worden","text":"<p>owp-08OntwerpOntwikkelenOntwikkelaarProjectleiderJuristTransparantie</p>"},{"location":"maatregelen/2-owp-08-archiveren-documenten/#maatregel","title":"Maatregel","text":"<p>Stel vast welke documenten, (samengesteld geheel van) data/informatie van/in het algoritme of het AI-systeem gelden als \"archiefbescheiden\" in de zin van artikel 1 c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde. Bepaal de bijbehorende bewaartermijnen vast voor de archiefbescheiden.</p>"},{"location":"maatregelen/2-owp-08-archiveren-documenten/#toelichting","title":"Toelichting","text":"<ul> <li>Bij archiefbescheiden kan worden gedacht aan de broncode, trainings- en testdata, (technische) documentatie en de output. </li> <li>Deze archiefbescheiden moeten voor een bepaalde tijd worden bewaard (de bewaartermijn).</li> <li>Overleg hierover met de verantwoordelijke binnen de organisatie voor het toepassen van de Archiefwet.</li> <li>Het is mogelijk dat de selectielijsten nog niet duiden welke informatie of data, specifiek bij de toepassing van algoritmen en AI, moet worden toegepast en hier dus ook nog geen termijnen bij zijn gekoppeld. </li> <li>Stel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld. Er zijn gevallen waarbij het openbaren van archiefbescheiden is uitgesloten. Stem in het begin van het proces (pro-actief) met de opdrachtgever af wat de wenselijkheid is t.a.v. transparantie/openheid (uitgangspunt zou 'open, tenzij' moeten zijn).</li> <li>Stel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt. Het moet mogelijk zijn dat de archiefbescheiden daadwerkelijk overhandigd kunnen worden aan betrokken partijen. Denk hierbij aan burgers, onderneming, toezichthouder of rechters. Duurzaam betekent hier met behoud van functie en kwaliteit voor langere tijd. Onderzoek welke voorziening hiervoor beschikbaar is binnen de organisatie.</li> </ul> <p>Tip</p> <p>Formeer hierbij een multi-discipinaire groep (bestaande uit bijvoorbeeld een inkoper, ontwikkelaar, data scientist, proceseigenaar en archiefdeskundige) om deze maatregel toe te passen.</p>"},{"location":"maatregelen/2-owp-08-archiveren-documenten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistearc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaia-12--bewaartermijn-voor-documentatie"},{"location":"maatregelen/2-owp-08-archiveren-documenten/#bronnen","title":"Bronnen","text":"<ul> <li>Rekenen en rekenschap. Essay over Algoritmes en de Archiefwet</li> <li>Toetsingskader Algemene Rekenkamer 4.06 </li> <li>Onderzoekskader Auditdienst Rijk, DM.13 </li> </ul>"},{"location":"maatregelen/2-owp-08-archiveren-documenten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/2-owp-09-model-verwerkersovereenkomst-onderdeel-aanbesteding/","title":"Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerkt","text":"<p>owp-09OntwerpMonitoring en beheerProjectleiderBeleid en adviesPublieke inkoopPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/2-owp-09-model-verwerkersovereenkomst-onderdeel-aanbesteding/#maatregel","title":"Maatregel","text":"<p>Inventariseer of er mogelijk sprake is van een algoritme of AI-systeem dat een hoog risico kan inhouden voor de rechten en vrijheden van natuurlijke personen of impactvol kan zijn voor hen en maak in voorkomend geval in de model-verwerkersovereenkomst een uitdrukkelijke verwijzing naar een concreet DPIA-document (met datum/kenmerk) of (indien op dat moment nog in bezit of bekend bij de steller) een expliciet invulveld voor het duiden van de betreffende DPIA, zodat die wordt genoemd ter completeren van de verwerkersovereenkomst vooraf het overeenkomen/ondertekenen van die verwerkersovereenkomst.</p>"},{"location":"maatregelen/2-owp-09-model-verwerkersovereenkomst-onderdeel-aanbesteding/#toelichting","title":"Toelichting","text":"<p>Een model-verwerkersoverenkomst is veelal een verplicht onderdeel bij het publiek inkopen van software waarbij persoonsgegevens worden verwerkt en bij de totstandkoming van de overeenkomst.</p>"},{"location":"maatregelen/2-owp-09-model-verwerkersovereenkomst-onderdeel-aanbesteding/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen"},{"location":"maatregelen/2-owp-09-model-verwerkersovereenkomst-onderdeel-aanbesteding/#bronnen","title":"Bronnen","text":"<p>Algoritmekader</p>"},{"location":"maatregelen/2-owp-09-model-verwerkersovereenkomst-onderdeel-aanbesteding/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/2-owp-10-projectstartarchitectuur/","title":"Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmes","text":"<p>owp-10OntwerpOntwikkelenVerificatie en validatieImplementatieProjectleiderBeleid en adviesPublieke inkoopTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/2-owp-10-projectstartarchitectuur/#maatregel","title":"Maatregel","text":"<p>Voer een Project Startarchitectuur (PSA) uit als algoritmes of AI-systemen worden ontwikkeld of ingekocht.</p>"},{"location":"maatregelen/2-owp-10-projectstartarchitectuur/#toelichting","title":"Toelichting","text":"<ul> <li>Een Project Startarchitectuur (PSA) is een hulpmiddel dat bij een project wordt ingezet om veranderingen van A naar Beter te faciliteren.</li> <li>De PSA richt zich daarbij op de kaders die op een project van toepassing zijn en wat de oplossing bijdraagt aan het realiseren van de gewenste, toekomstige architectuur, wat de implicaties zullen zijn voor bestaande voorzieningen en waar het project zal afwijken van bestaande beelden.</li> <li>Met de PSA wordt een concreet en doelgericht ICT-architectuurkader opgesteld, waarbinnen het project moet worden uitgevoerd. </li> <li>De PSA maakt concreet wat architectuur voor een project betekent.</li> <li>Door een PSA uit te voeren ontstaan inzichten hoe het betreffende algoritme of AI-systeem zo optimaal mogelijk onderdeel kan worden gemaakt van het bestaande applicatielandschap, waarmee bijvoorbeeld kan worden voorkomen dat het algoritme of AI-systeem na verloop van tijd geen input meer kan ontvangen door onverwachte wijzigingen in systemen.</li> <li>Onderwerpen als privacy, informatiebeheer en beheer worden hierin ook globaal meegenomen. </li> </ul>"},{"location":"maatregelen/2-owp-10-projectstartarchitectuur/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingawb-01 - Relevante feiten en belangen zijn bekendavg-11 - Privacy door ontwerp"},{"location":"maatregelen/2-owp-10-projectstartarchitectuur/#risico","title":"Risico","text":"<p>Het algoritme of AI-systeem kan niet of na verloop van tijd niet meer functioneren, doordat onverwachte of ongewenst wijzigingen in het applicatielandschap plaatsvinden. </p>"},{"location":"maatregelen/2-owp-10-projectstartarchitectuur/#bronnen","title":"Bronnen","text":"<ul> <li>Project Startarchitectuur,NORA</li> <li>PSA Format</li> <li>PSA Handleiding</li> <li>Algoritmekader</li> </ul>"},{"location":"maatregelen/2-owp-10-projectstartarchitectuur/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/","title":"Koop duurzaam algoritmes in","text":"<p>owp-11OntwerpProjectleiderPublieke inkoopDuurzaamheid</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#maatregel","title":"Maatregel","text":"<p>Kies softwareoplossingen van leveranciers die duurzaamheid bevorderen, en stel heldere eisen aan energieverbruik, hernieuwbare energiebronnen en transparantie over de milieuprestaties van software.</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#toelichting","title":"Toelichting","text":"<p>Door software duurzaam in te kopen, kun je als organisatie al vroeg in het ontwikkelproces bijdragen aan de verduurzaming van je algoritmes. Kies daarom softwareoplossingen van leveranciers die maatschappelijk verantwoord ondernemen (MVI) en energie-effici\u00ebntie vooropstellen.</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#duurzaamheidscriteria-en-leveranciersselectie","title":"Duurzaamheidscriteria en leveranciersselectie","text":"<p>Om software duurzaam in te kopen, kun je leveranciers beoordelen op specifieke duurzaamheidscriteria. Enkele belangrijke criteria zijn:</p> <ul> <li>het energieverbruik van de software</li> <li>het gebruik van hernieuwbare energiebronnen in de benodigde datacenters</li> <li>het beperken van CO\u2082-uitstoot tijdens de levenscyclus van de software</li> </ul> <p>Vraag om inzicht in milieuprestaties en certificeringen, zoals ISO-14001, om de toewijding van leveranciers aan duurzaamheid te toetsen. De ISO-14001 is een internationaal geaccepteerde standaard met eisen voor een milieumanagementsysteem.</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#aanbestedingsvoorwaarden-en-contractuele-eisen","title":"Aanbestedingsvoorwaarden en contractuele eisen","text":"<p>Stel in aanbestedingen duidelijke eisen aan duurzaamheidscriteria, zoals het gebruik van \"groene technologie\u00ebn, het aanbieden van Software-as-a-Service (SaaS) en open standaarden. Zo maak je duurzame keuzes die bijdragen aan een langere levensduur en energie-effici\u00ebntie van je algoritmes. Door KPI\u2019s op te nemen voor energie-effici\u00ebntie en CO\u2082-reductiedoelen kun je de voortgang van deze doelen concreet monitoren.</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#bonus-malusregeling-en-monitoring","title":"Bonus-malusregeling en monitoring","text":"<p>Om naleving van duurzame doelstellingen te stimuleren, kun je een bonus-malusregeling inzetten. Leveranciers ontvangen een bonus wanneer zij duurzame doelstellingen halen, en kunnen worden aangesproken als beloofde duurzaamheidsnormen niet worden behaald. Monitoring via jaarlijkse rapportages helpt om de voortgang van de duurzaamheidsdoelen te evalueren en, indien nodig, bij te sturen.</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#extra-overwegingen","title":"Extra overwegingen","text":"<p>Extra overwegingen die je kunt maken bij het aankopen van algoritmes, zoals genoemd in de handreiking 'Hoe maak ik mijn inkoop van software duurzamer?' van PIANOo:</p> <ul> <li>Ga na of je de software wel echt moet inkopen.</li> <li>Probeer zoveel mogelijk uit te vragen in een SaaS-oplossing.</li> <li>Vraag een oplossing in een Cloud-omgeving.</li> <li>Ga na of \u2018serverless\u2019 ook een oplossing is.</li> <li>Vraag om de broncode van de software.</li> <li>Denk goed na over de technische levensduur van verschillende componenten.</li> <li>Open standaarden zijn een vorm van duurzaamheid.</li> <li>Pas containerisatie en virtualisatie toe.</li> <li>Neem eisen op over opschalingsmogelijkheden.</li> </ul>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#risico","title":"Risico","text":"<p>Zonder duurzaamheidscriteria in de inkoop van software loop je het risico op hogere energie- en kostenlasten, en beperk je de mogelijkheden om duurzaamheidsdoelstellingen te halen bij je algoritmes.</p>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking: Hoe maak ik mijn inkoop van software duurzamer? (PIANOo)</li> </ul>"},{"location":"maatregelen/2-owp-11-duurzaam-inkopen/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/","title":"Ontwerp eenvoudigere en minder complexe algoritmes","text":"<p>owp-12OntwerpOntwikkelenOntwikkelaarDuurzaamheid</p>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#maatregel","title":"Maatregel","text":"<p>Ontwerp algoritmes gericht op eenvoud en effici\u00ebntie, zodat het energieverbruik en de benodigde rekenkracht tijdens gebruik minimaal blijven.</p>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#toelichting","title":"Toelichting","text":"<p>Door algoritmes minder complex en rekenintensief te ontwerpen, verlaag je de benodigde middelen en energie bij het trainen en uiteindelijk runnen van deze algoritmes. Een effici\u00ebnter ontwerp maakt de algoritmes energiezuiniger in de trainings- en gebruiksfase en draagt zo bij aan duurzaamheid in de gehele levenscyclus. Complexe algoritmes vereisen vaak aanzienlijke rekenkracht, wat energie-intensief kan zijn. Door algoritmes eenvoudiger te ontwerpen en optimalisaties toe te passen, kun je de benodigde rekencapaciteit en het energieverbruik drastisch verminderen zonder afbreuk te doen aan de prestaties.</p>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#modellen-vereenvoudigen-en-focussen-op-kernfunctionaliteit","title":"Modellen vereenvoudigen en focussen op kernfunctionaliteit","text":"<p>Wanneer je een nieuw algoritme ontwikkelt, kun je de omvang en rekenbelasting beperken door alleen noodzakelijke functionaliteit op te nemen. Focus op de kernfunctionaliteit, zodat je gebruik maakt van een kleiner model dat beter te begrijpen en gemakkelijker te beheren is. Het vermijden van overbodige functionaliteiten maakt het algoritme minder zwaar en verlaagt de milieu-impact aanzienlijk.</p>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#minder-complexiteit-door-divide-and-conquer-en-dynamisch-programmeren","title":"Minder complexiteit door divide-and-conquer en dynamisch programmeren","text":"<p>Een populaire methode om complexiteit te verlagen is het divide-and-conquer principe, waarbij je een probleem in kleinere subproblemen opsplitst en deze vervolgens oplost. Dit vermindert de rekenlast aanzienlijk en verhoogt de effici\u00ebntie. Ook kun je met dynamisch programmeren optimalisaties toevoegen door eerder berekende resultaten op te slaan en te hergebruiken, wat herhaling van berekeningen voorkomt en de rekenkracht vermindert.</p>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#minder-complexiteit-door-modeloptimalisatie","title":"Minder complexiteit door modeloptimalisatie","text":"<ul> <li>Door gebruik te maken van pruning kunnen minder relevante verbindingen en nodes in een neuraal netwerk worden verwijderd, waardoor de rekenbelasting vermindert.</li> <li>Quantization verlaagt de precisie van numerieke waarden in een model, wat opslag en rekenkracht verlaagt zonder de prestaties significant te be\u00efnvloeden.</li> <li>Knowledge distillation kan verder helpen door de kennis van een groot model over te dragen naar een kleiner, minder complex model, dat vervolgens effici\u00ebnter werkt.</li> </ul>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#risico","title":"Risico","text":"<p>Ontwerpen zonder oog voor effici\u00ebntie kan leiden tot energie-intensieve algoritmes die hoge kosten en milieubelasting met zich meebrengen.</p>"},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#bronnen","title":"Bronnen","text":""},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#-what-is-knowledge-distillation-ibm","title":"- What is knowledge distillation? (IBM)","text":""},{"location":"maatregelen/2-owp-12-eenvoudigere-algoritmes/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/3-dat-01-datakwaliteit/","title":"Controleer de datakwaliteit","text":"<p>dat-01Dataverkenning en datapreparatieOntwikkelaarData</p>"},{"location":"maatregelen/3-dat-01-datakwaliteit/#maatregel","title":"Maatregel","text":"<p>Stel vast of de gebruikte data van voldoende kwaliteit is voor de beoogde toepassing.</p>"},{"location":"maatregelen/3-dat-01-datakwaliteit/#toelichting","title":"Toelichting","text":"<ul> <li>Stel functionele eisen voor de data kwaliteit vast en analyseer structureel of er aan deze eisen wordt voldaan. </li> <li>De kwaliteit van de data die als input voor het algoritme wordt gebruikt is bepalend voor de uitkomsten van het algoritme. Hier wordt soms ook naar gerefereerd als garbage in = garbage out. </li> <li>Een vraag die gesteld dient te worden: beschrijft de data het fenomeen dat onderzocht dient te worden? </li> <li> <p>Het Raamwerk gegevenskwaliteit bevat een breed toepasbare set van kwaliteitsdimensies:</p> <ul> <li>juistheid</li> <li>compleetheid</li> <li>validiteit</li> <li>consistentie</li> <li>actualiteit</li> <li>precisie</li> <li>plausibiliteit</li> <li>traceerbaarheid</li> <li>begrijpelijkheid</li> </ul> <p>Deze dimensies zijn aangevuld met kwaliteitsattributen welke gebruikt kunnen worden om de verschillende dimensies meetbaar te maken. </p> </li> <li> <p>De vraag of de data kwaliteit voldoende is hangt sterk samen met de vraag of er bias in de onderliggende data zit. Analyseer daarom ook welke bias en aannames er besloten zijn in de onderliggende data. Denk hierbij onder andere aan de volgende vormen van bias:</p> <ul> <li>historische bias</li> <li>meetbias</li> <li>representatie bias</li> </ul> </li> </ul> <p>Let op!</p> <p>Wanneer je een algoritme inkoopt en de ontwikkeling van het algoritme uitbesteedt aan een derde partij, houdt er dan dan rekening mee dat data traceerbaar en reproduceerbaar moet zijn. Maak hier heldere afspraken over met de aanbieder. </p>"},{"location":"maatregelen/3-dat-01-datakwaliteit/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-05 - Juistheid en actualiteit van gegevensaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteria"},{"location":"maatregelen/3-dat-01-datakwaliteit/#risico","title":"Risico","text":"<ul> <li>Door onjuiste beslissingen van gegevens kunnen verkeerde beslissingen genomen worden. </li> <li>Het model cre\u00ebert onwenselijke systematische afwijking voor specifieke personen, groepen of andere eenheden. Dit kan leiden tot ongelijke behandeling en discriminerende effecten met eventuele schade voor betrokkenen. </li> </ul>"},{"location":"maatregelen/3-dat-01-datakwaliteit/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, DM.9, DM.19</li> <li>Toetsingskader Algoritmes, Algemene Rekenkamder, 2.18</li> <li>NORA, Raamwerk gegevenskwaliteit</li> <li>Impact Assessment Mensenrechten en Algoritmes, 2A.2.2</li> <li>Handreiking non-discriminatie by design</li> </ul>"},{"location":"maatregelen/3-dat-01-datakwaliteit/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/3-dat-02-fair-data/","title":"Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.","text":"<p>dat-02Dataverkenning en datapreparatieOntwikkelaarData</p>"},{"location":"maatregelen/3-dat-02-fair-data/#maatregel","title":"Maatregel","text":"<p>Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.</p>"},{"location":"maatregelen/3-dat-02-fair-data/#toelichting","title":"Toelichting","text":"<p>De internationale FAIR-principes zijn richtlijnen voor de manier van beschrijven, opslag en publicatie van data. </p> <ul> <li>Findable (vindbaar): Metadata moet gemakkelijk te vinden zijn voor zowel mensen als computers.</li> <li>Accessible (toegankelijk): Gebruikers moeten weten hoe toegang tot de data verkregen kan worden (autorisatie en authenticatie)</li> <li>Interoperable (uitwisselbaar): Data moet meestal ge\u00efntegreerd worden met andere data en bijbehorden applicaties, opslag en processen.</li> <li>Reusable (herbruikbaar): Het uiteindelijke doel van FAIR is om hergebruik van data te optimaliseren.</li> </ul> <p>Wanneer je voldoet aan de 15 principes is je data 'machine actionable'. Dit maakt het mogelijk dat de data effectief gebruikt kan worden voor verschillende algoritmes en AI-systemen.</p> <p>FAIR data betekent niet per definitie dat data open data is. Juist ook voor (privacy) gevoelige data (gesloten data) kan het heel zinvol zijn om te voldoen aan de principes voor FAIR data, om juist daarmee specifieke geautoriseerde toegang tot gevoelige data mogelijk te kunnen maken.</p>"},{"location":"maatregelen/3-dat-02-fair-data/#15-principes-voor-fair-data","title":"15 principes voor FAIR data","text":"<p>Er zijn 15 principes voor FAIR data geformuleerd:</p>"},{"location":"maatregelen/3-dat-02-fair-data/#findable-vindbaar","title":"Findable (vindbaar)","text":"<ul> <li> <p>F1: Aan (meta)data wordt een wereldwijd unieke en permanente identifier toegevoegd</p> <p>Voorbeeld</p> <p>Met behulp van Persistent Identifiers (PID) zorg je ervoor dat jouw data (bijvoorbeeld onderzoeksdata) altijd vindbaar blijft.  PID's kun je vergelijken met het ISBN-nummer bij boeken. Het idee is dat ook als de locatie of de onderliggende infrastructuur verandert, de verwijzing intact blijft. </p> </li> <li> <p>F2: Data wordt beschreven met rijke metadata</p> <p>Voorbeeld</p> <p>Het team van data.overheid.nl heeft de metadata standaard DCAT-AP-DONL ontwikkeld die speciaal voor de uitwisseling van dataset informatie voor de Nederlandse situatie is ingericht. Dit is gebaseerd op de Data Catalog Vocabulary (DCAT) versie die de Europese Unie heeft opgesteld. Je kan hierover meer lezen op de site van data.overheid.nl.</p> </li> <li> <p>F3: Metadata bevat duidelijk en expliciet de identificatie van de data die ze beschrijven</p> </li> <li>F4: (Meta)data worden geregistreerd of ge\u00efndexeerd in een doorzoekbare bron </li> </ul>"},{"location":"maatregelen/3-dat-02-fair-data/#accessible-toegankelijk","title":"Accessible (toegankelijk)","text":"<ul> <li>A1: (Meta)data zijn opvraagbaar op basis van hun identificatiecode met behulp van een gestandaardiseerd communicatieprotocol </li> <li>A1.1: Het protocol is open, vrij en universeel implementeerbaar </li> <li>A1.2: Het protocol maakt waar nodig een authenticatie- en autorisatieprocedure mogelijk </li> <li>A2: Metadata zijn toegankelijk, ook als de data niet meer beschikbaar zijn </li> </ul>"},{"location":"maatregelen/3-dat-02-fair-data/#interoperable-uitwisselbaar","title":"Interoperable (uitwisselbaar)","text":"<ul> <li>I1: (Meta)data gebruikt een formele, toegankelijke, gedeelde en breed toepasbare taal voor kennisrepresentatie </li> <li> <p>I2: (Meta)data gebruikt gegevenswoordenboeken of vocabulaires die FAIR-principes volgen </p> <p>Voorbeeld woordenboek</p> <p>In het woordenboek Hitte staan ongeveer 230 definities van termen rond het thema hitte die gebruikt worden in het klimaatadaptatieveld. Dit woordenboek is ontwikkeld in opdracht van het ministerie van Infrastructuur en Waterstaat door overheidsstichting Geonovum.</p> </li> <li> <p>I3: (Meta)data bevat gekwalificeerde verwijzingen naar andere (meta)data </p> </li> </ul>"},{"location":"maatregelen/3-dat-02-fair-data/#reusable-herbruikbaar","title":"Reusable (herbruikbaar)","text":"<ul> <li>R1: (Meta)data wordt rijkelijk beschreven met een veelheid aan nauwkeurige en relevante attributen </li> <li>R1.1: (Meta)data wordt vrijgegeven met een duidelijke en toegankelijke licentie voor datagebruik </li> <li> <p>R1.2: (Meta)data wordt geassocieerd met gedetailleerde herkomst </p> <p>Voorbeeld</p> <p>PROV-DM is een conceptueel datamodel dat gebruikt kan worden voor de herkomstinformatie (provenance) van data. </p> </li> <li> <p>R1.3: (Meta)data voldoet aan domein-relevante normen </p> </li> </ul>"},{"location":"maatregelen/3-dat-02-fair-data/#vereisten","title":"Vereisten","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p> <p>Opmerking</p> <p>Artikel 5b van de Wet hergebruik van overheidsinformatie stelt dat dnderzoeksgegevens in overeenstemming met de FAIR-beginselen actief beschikbaar moeten worden gesteld voor hergebruik door een publiek gefinancierde onderzoeksorganisatie. Dit geldt voor zover:</p> <ol> <li>die documenten zijn geproduceerd in het kader van geheel of gedeeltelijk met overheidsmiddelen gefinancierde wetenschappelijke onderzoeksactiviteiten;</li> <li>die documenten openbaar zijn gemaakt via een institutionele of thematische databank als bedoeld in artikel 10, tweede lid, van de richtlijn; en</li> <li>rechtmatige handelsbelangen, activiteiten inzake kennisoverdracht en reeds bestaande intellectuele eigendomsrechten zich hiertegen niet verzetten.</li> </ol>"},{"location":"maatregelen/3-dat-02-fair-data/#bronnen","title":"Bronnen","text":"<ul> <li>GO FAIR Foundation</li> <li>3-point FAIRification framework 3PFF</li> <li>Toolbox verantwoord datagebruik, 2b</li> <li>NORA online</li> </ul>"},{"location":"maatregelen/3-dat-03-persoonsgegevens-beschrijven/","title":"Beschrijf welke persoonsgegevens het algoritme gebruikt en waarom","text":"<p>dat-03Dataverkenning en datapreparatieOntwikkelenVerificatie en validatieProjectleiderOntwikkelaarPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/3-dat-03-persoonsgegevens-beschrijven/#maatregel","title":"Maatregel","text":"<p>Er is een overzicht opgesteld welke persoonsgegevens mogen worden verwerkt en om welke categorie persoonsgegevens het gaat. Het principe van dataminimalisatie is toegepast, zodat het minimum aantal persoonsgegevens wordt verwerkt om het beoogde doel te bereiken. </p>"},{"location":"maatregelen/3-dat-03-persoonsgegevens-beschrijven/#toelichting","title":"Toelichting","text":"<ul> <li>Er is een overzicht opgesteld welke persoonsgegevens mogen worden verwerkt mogen worden verwerkt.</li> <li>Bij de persoonsgegevens is aangegeven om wat voor categorie persoonsgegevens het gaat.</li> <li>Per kenmerk is toegelicht waarom deze noodzakelijk is om te verwerken voor het ontwikkelen en gebruiken van het algoritme of AI-systeem.</li> <li>Het principe van dataminimalisatie is toegepast, wat betekent dat een keuze is gemaakt of een persoonsgegevens al dan niet strikt noodzakelijk is om het doel te bereiken of dat verwerking ervan achterwege kan blijven.</li> <li>Voor het beschermen van deze persoonsgegevens wordt per kenmerk aangegeven op welke manier deze kan worden beschermd (anonimiseren, pseudonomiseren, aggregeren). </li> <li>Een DPIA kan worden gebruikt om bovenstaande activiteiten uit te voeren.</li> </ul>"},{"location":"maatregelen/3-dat-03-persoonsgegevens-beschrijven/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-04-proportionaliteit-en-subsidiariteit.md"},{"location":"maatregelen/3-dat-03-persoonsgegevens-beschrijven/#risico","title":"Risico","text":"<p>Het algoritme of AI-systeem verwerkt persoonsgegevens die het niet mag verwerken. </p>"},{"location":"maatregelen/3-dat-03-persoonsgegevens-beschrijven/#bronnen","title":"Bronnen","text":"<p>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.7 </p>"},{"location":"maatregelen/3-dat-03-persoonsgegevens-beschrijven/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/3-dat-04-bewaartermijnen-persoonsgegevens/","title":"Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedure","text":"<p>dat-04OntwikkelenMonitoring en beheerJuristProjectleiderTechnische robuustheid en veiligheidPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/3-dat-04-bewaartermijnen-persoonsgegevens/#maatregel","title":"Maatregel","text":"<p>Bepaal de bewaartermijnen en richt een vernietigingsprocesdure in voor de verwerkte (persoons)gegevens.</p>"},{"location":"maatregelen/3-dat-04-bewaartermijnen-persoonsgegevens/#toelichting","title":"Toelichting","text":"<ul> <li>(Persoons)gegevens die het algoritme of AI-systeemn verwerkt worden niet langer bewaard dan voor de verwezenlijking van de  verwerkingsdoeleinden noodzakelijk is.</li> <li>Beschrijf de bewaartermijnen voor de gegevens, bijvoorbeeld in een DPIA.</li> <li>Beschrijf hoe de (persoons)gegeven moeten worden vernietigd.</li> <li>Zorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme of AI-systeem en de onderliggende (zaak)systemen.</li> <li>Controleer of deze maatregelen voor de bewaartermijnen en vernietiging van de (persoons)gegevens (in de onderliggende systemen) zijn getroffen en zorg dat dit aantoonbaar is, bijvoorbeeld met logbestanden.</li> <li>Maak aantoonbaar dat persoonsgegevens zijn vernietigd, bijvoorbeeld met logbestanden.  </li> </ul>"},{"location":"maatregelen/3-dat-04-bewaartermijnen-persoonsgegevens/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistearc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaia-12 - Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieavg-02 - Beperkte bewaartermijn van persoonsgegevens"},{"location":"maatregelen/3-dat-04-bewaartermijnen-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.11</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.17</li> </ul>"},{"location":"maatregelen/3-dat-04-bewaartermijnen-persoonsgegevens/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/3-dat-05-pseudonimiseren-anonimiseren/","title":"Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregeren","text":"<p>dat-05Dataverkenning en datapreparatieOntwikkelenOntwikkelaarJuristPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/3-dat-05-pseudonimiseren-anonimiseren/#maatregel","title":"Maatregel","text":"<p>Pas maatregelen toe als pseudonimiseren, anonimisering of aggregeren van persoonsgegevens toe bij het verwerken van de data. </p>"},{"location":"maatregelen/3-dat-05-pseudonimiseren-anonimiseren/#toelichting","title":"Toelichting","text":"<ul> <li>Als is vastgesteld welke persoonsgegevens mogen worden verwerkt voor het ontwikkelen en gebruiken van algoritmes en AI-systemen, moet worden nagegaan of er maatregelen kunnen worden getroffen om deze te beschermen.</li> <li>Het algoritme verwerkt niet meer persoonsgegevens dan noodzakelijk; de verwerkte gegevens zijn proportioneel en substantieel.</li> <li>Hierbij kan worden gedacht aan het pseudonomiseren, anonimiseren of aggregeren van persoonsgegevens.</li> <li>Het bepalen of persoonsgegevens mogen worden verwerkt voor algoritmes en AI-systemen moet worden bekeken in samenhang met maatregelen die kunnen worden getroffen om deze gegevens te beschermen. </li> </ul>"},{"location":"maatregelen/3-dat-05-pseudonimiseren-anonimiseren/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-12 - Beveiliging van de verwerking"},{"location":"maatregelen/3-dat-05-pseudonimiseren-anonimiseren/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, PRI.5</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.20</li> </ul>"},{"location":"maatregelen/3-dat-05-pseudonimiseren-anonimiseren/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/3-dat-06-schending-auteursrechten/","title":"Controleer de auteursrechten van eigen data","text":"<p>dat-06OntwerpDataverkenning en datapreparatieJuristData</p>"},{"location":"maatregelen/3-dat-06-schending-auteursrechten/#maatregel","title":"Maatregel","text":"<p>Controleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.</p>"},{"location":"maatregelen/3-dat-06-schending-auteursrechten/#toelichting","title":"Toelichting","text":"<p>Het is van belang om te controleren of de te verwerken data waar overheidsorganisaties zelf over beschikken rechtmatig zijn verkregen en geen inbreuken maken op auteursrechten. Hier kan worden gedacht aan data die is gescraped van het internet en zou kunnen worden gebruikt voor de ontwikkeling van een algoritme of AI-systeem.</p>"},{"location":"maatregelen/3-dat-06-schending-auteursrechten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/3-dat-06-schending-auteursrechten/#bronnen","title":"Bronnen","text":"<p>Algoritmekader</p>"},{"location":"maatregelen/3-dat-06-schending-auteursrechten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/3-dat-07-duurzame-datacenters/","title":"Gebruik duurzame datacenters","text":"<p>dat-07Dataverkenning en datapreparatieOntwikkelenImplementatieMonitoring en beheerOntwikkelaarProjectleiderDuurzaamheid</p>"},{"location":"maatregelen/3-dat-07-duurzame-datacenters/#maatregel","title":"Maatregel","text":"<p>Maak gebruik van datacenters die gebruikmaken van duurzame energiebronnen en energie-effici\u00ebnte technologie\u00ebn voor de opslag en verwerking van data.</p>"},{"location":"maatregelen/3-dat-07-duurzame-datacenters/#toelichting","title":"Toelichting","text":"<p>Door data op te slaan en algoritmes te laten draaien in datacenters die hernieuwbare energiebronnen inzetten en restwarmte recyclen, kun je de ecologische voetafdruk van je applicaties aanzienlijk verkleinen. Datacenters die zich op duurzaamheid richten, verlagen de CO\u2082-uitstoot van hun infrastructuur en bieden mogelijk duurzaamheidsrapportages. Let bij het kiezen van een provider op mogelijke greenwashing; dit gebeurt wanneer bedrijven beweren groen te zijn zonder dit met concrete maatregelen te onderbouwen.</p>"},{"location":"maatregelen/3-dat-07-duurzame-datacenters/#technologieen-voor-energie-efficiente-datacenters","title":"Technologie\u00ebn voor energie-effici\u00ebnte datacenters","text":"<p>Om datacenters energie-effici\u00ebnt te maken, zijn er verschillende benaderingen: - Gebruik van groene energiebronnen: Kies voor datacenters/providers die hernieuwbare energie gebruiken. Maak bijvoorbeeld afspraken over een doel, zoals een DCie-score van minimaal 50%, gewogen over een heel jaar. De DCie score van elk Overheids Datacenter (ODC) kun je hier bekijken. Je kunt ook kijken of ze naast duurzame stroom ook restwarmte van servers benutten om bijvoorbeeld nabijgelegen gebouwen te verwarmen. - Koeling en energiebeheer optimaliseren: Adiabatische koeling, waarbij water en lucht worden gebruikt in plaats van elektriciteit, verlaagt het energieverbruik. Effici\u00ebnte stroomverdeling en warmteterugwinning dragen verder bij aan een lagere ecologische voetafdruk. - Monitoren: Blijf controleren op duurzame prestaties door te letten op certificeringen, zoals ISO 14001, ISO 50001 en BREEAM, en vraag naar energierapportages en details over het energieverbruik en de herkomst van stroom. Dit helpt om claims van duurzaamheid te toetsen en te voorkomen dat je in greenwashing trapt.</p>"},{"location":"maatregelen/3-dat-07-duurzame-datacenters/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"maatregelen/3-dat-07-duurzame-datacenters/#risico","title":"Risico","text":"<p>Door geen gebruik te maken van duurzame datacenters, loop je het risico op een hogere CO\u2082-uitstoot en hogere energiekosten.</p>"},{"location":"maatregelen/3-dat-07-duurzame-datacenters/#bronnen","title":"Bronnen","text":"<ul> <li>Rijks ICT Dashboard - Duurzaamheid</li> <li>Denk Doe Duurzaam - Doelen voor ICT</li> </ul>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/","title":"Train-, validatie- en testdata","text":"<p>Dataverkenning en datapreparatieOntwikkelenDataTechnische robuustheid en veiligheidBias en non discriminatie</p>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#maatregel","title":"Maatregel","text":"<p>Indien je gebruik maakt van machine learning technieken, maak een passende keuze voor gescheiden train-, test- en validatiedata en houdt hierbij rekening met underfittng en overfitting. </p>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#toelichting","title":"Toelichting","text":"<p>Verdeel je dataset in drie delen:</p> <ol> <li> <p>de trainingsset</p> <p>Deze dataset wordt gebruikt om het model te trainen. Uit deze dataset worden de onderliggende patronen of relaties geleerd die later gebruikt kunnen worden om voorspellingen mee te doen.</p> <p>De kwaliteit van deze dataset moet goed zijn en zo representatief mogelijk voor de doelpopulatie. Eventuele bias of vooroordelen in deze dataset kan door het trainen in het model sluipen.</p> </li> </ol> <p>Let bij het samenstellen van de traningsset op dat de data waarop het model gebaseerd is, niet beschikbaar zijn voordat de uitkomsten zijn geobserveerd. Met andere woorden, zorg ervoor de de voorspellingen geen onderdeel kunnen zijn van de inputvariabelen. </p> <ol> <li> <p>de validatieset</p> <p>De validatieset fungeert als een onafhankelijke, onbevooroordeelde dataset voor het vergelijken van de prestaties van verschillende algoritmen die zijn getraind op onze trainingsset.</p> <p>Verschillende modellen kunnen getraind worden op de trainingsdataset. Zo kan je bijvoorbeeld vari\u00ebren in de (hyper)parameters of de inputvariabelen. Dit leidt tot verschillende varianten van het model. Om de prestaties van de verschillende modellen te vergelijken, moeten we een nieuwe dataset gebruiken: de validatieset. Zou je hiervoor de trainingsdataset gebruiken, kan dat leiden tot overfitting, wanneer het model dan te specifiek afgestemd is op 1 dataset. Het model kan dan niet voldoende generaliseren voor nieuwe situaties.</p> </li> <li> <p>de testset</p> <p>Nadat er met behulp van de validatieset een keuze is gemaakt voor een passend model en bijbehorende (hyper)parameters, moet je het model nog testen op nieuwe data. Dit geeft een beeld van de werkelijke prestaties van het model in nieuwe omstandigheden. </p> <p>Let op dat je pas naar deze resultaten kijkt als laatste stap. Inzichten uit deze testdataset mogen niet worden meegenomen in de ontwikkeling, omdat dit kan leiden tot overfitting. Het model zal dan in productie mogelijk minder goed presteren. </p> </li> </ol>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#hoe-split-ik-mijn-dataset","title":"Hoe split ik mijn dataset?","text":""},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#grootte-van-de-drie-datasets","title":"Grootte van de drie datasets","text":"<p>Er is geen optimale verdeling van de drie datsets. Veelvoorkomende verhoudingen om je data in te splitten zijn:</p> <ul> <li>80% trainingsset, 10% validatieset, 10% testset</li> <li>70% trainingsset, 15% validatieset, 15% testset</li> <li>60% trainingsset, 20% validatieset, 20% testset</li> </ul> <p>Afhankelijk van de hoeveelheid beschikbare data en de context maak je hierin een keuze. Houdt hierbij rekening met:</p> <ul> <li>Hoe minder trainingdata, hoe groter de variantie van het model tijdens het trainen. De patronen en relaties die ontdekt zijn, bevatten dan een grotere onzekerheid. </li> <li>Hoe minder validatie- en testdata je gebruikt, hoe grote de variantie en de onzekerheid in de verwachte prestaties van het algoritme. </li> <li>Hoe complexer het model, en hoe meer (hyper)parameters er zijn om te optimaliserne, hoe groter de validatieset moet zijn om het model met optimale presetaties te vinden. Wanneer er weinig hyperparameters zijn, is een relatief kleine validatieset vaak voldoende.</li> </ul>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#k-fold-cross-validation","title":"k-fold cross validation","text":"<p>Naast dat je de datasets willekeurig kan verdelen in drie delen (aselect), kan je ook meer geavanceerde technieken gebruiken. Een robuuste en veelgebruikte techniek is k-fold cross validation, waarbij het model k keer wordt getraind op verschillende delen van de data. </p>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#risico","title":"Risico","text":"<p>Door onjuiste training van het model presteert het model in de praktijk minder goed dan bij de tests. Als trainings-, validatie- en testdata door elkaar lopen (\"data leakage\"), kan dit leiden tot overfitting, waardoor het model beter lijkt te presteren dan in werkelijkheid het geval is.</p>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, DM.5, DM.6</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.15, 2.21 </li> </ul>"},{"location":"maatregelen/3-dat-07-training-validatie-en-testdata/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/3-dat-08-eigenaarschap-data/","title":"Controle of eigenaarschap over de data","text":"<p>Dataverkenning en datapreparatieDataPublieke inkoop</p>"},{"location":"maatregelen/3-dat-08-eigenaarschap-data/#maatregel","title":"Maatregel","text":"<p>De organisatie heeft volledige controle of eigenaarschap over de data. Wanneer dit niet mogelijk is, zijn afspraken gemaakt om de functionele eisen te waarborgen.</p>"},{"location":"maatregelen/3-dat-08-eigenaarschap-data/#toelichting","title":"Toelichting","text":""},{"location":"maatregelen/3-dat-08-eigenaarschap-data/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteria"},{"location":"maatregelen/3-dat-08-eigenaarschap-data/#risico","title":"Risico","text":"<p>De organisatie is afhankelijk voor de data of het model afhankelijk van derden en kan daardoor reproduceerbaarheid en prestatie niet garanderen.</p>"},{"location":"maatregelen/3-dat-08-eigenaarschap-data/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, DM.23</li> </ul>"},{"location":"maatregelen/3-dat-08-eigenaarschap-data/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/3-dat-09-dataminimalisatie/","title":"Beperk de omvang van datasets voor energie-effici\u00ebntie","text":"<p>dat-09Dataverkenning en datapreparatieOntwikkelaarProjectleiderDataDuurzaamheid</p>"},{"location":"maatregelen/3-dat-09-dataminimalisatie/#maatregel","title":"Maatregel","text":"<p>Houd datasets klein en gericht om onnodige energieconsumptie te voorkomen tijdens de verwerking en opslag van data voor algoritmes. We noemen dit ook wel dataminimalisatie.</p>"},{"location":"maatregelen/3-dat-09-dataminimalisatie/#toelichting","title":"Toelichting","text":"<p>Hoe meer je bewaart, hoe meer ruimte dat kost om op te slaan. Bovendien verbruikt elk apparaat dat nodig is om data op te slaan stroom. Dat heeft grote invloed op de CO\u2082-uitstoot van een datacentrum. Grote datasets brengen daarom hoge energie- en opslagkosten met zich mee. Door de dataset bewust te beperken tot relevante gegevens, kun je ook de energie-effici\u00ebntie van algoritmes aanzienlijk verbeteren. Vooral bij de ontwikkeling van AI-systemen kan het verminderen van data bijdragen aan lagere energiebehoeften en CO\u2082-uitstoot.</p>"},{"location":"maatregelen/3-dat-09-dataminimalisatie/#technieken-voor-dataminimalisatie","title":"Technieken voor dataminimalisatie","text":"<ul> <li>Slimme selectie van trainingsdata: Gebruik methoden die irrelevante data uit de dataset filteren, zoals dataselectie-algoritmes en sampling-technieken. Door te focussen op relevante data, beperk je de omvang zonder de prestaties van het model te be\u00efnvloeden.</li> <li>Verwijderen van redundante en dubbele data: Deduplicatie van data minimaliseert onnodige verwerkingskracht. Door alleen unieke en relevante gegevens op te slaan, wordt de opslagbehoefte verder beperkt.</li> <li>Opschonen en archiveren van verouderde data: Regelmatige archivering of verwijdering van verouderde data in je dataset zorgt voor een verminderde voetafdruk en verhoogt ook de effici\u00ebntie.</li> </ul>"},{"location":"maatregelen/3-dat-09-dataminimalisatie/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"maatregelen/3-dat-09-dataminimalisatie/#risico","title":"Risico","text":"<p>Zonder dataminimalisatie loopt je organisatie het risico op onnodig hoge energie- en opslagkosten, en een grotere ecologische impact.</p>"},{"location":"maatregelen/3-dat-09-dataminimalisatie/#bronnen","title":"Bronnen","text":"<ul> <li>Rijks ICT-dashboard</li> <li>Sustainable artificial intelligence \u2013 TU Delft</li> </ul>"},{"location":"maatregelen/4-owk-01-security-by-design/","title":"Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019","text":"<p>owk-01OntwikkelenProjectleiderOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/4-owk-01-security-by-design/#maatregel","title":"Maatregel","text":"<p>Hanteer principes van \u2018security by design\u2019 (informatiebeveiligingsmaatregelen) als uitgangspunten bij de ontwikkeling van het algoritme. Stel vast welke principes horen bij security by design en welke relevant zijn voor het ontwerp of de ontwikkeling van het algoritme. Mogelijke documenten waarin deze principes kunnen worden opgenomen, zijn het security beleid, of ontwikkelbeleid. Bij het bepalen en vaststellen van de juiste principes kunnen interviews met de ontwikkelaar en software-architecten helpen.</p>"},{"location":"maatregelen/4-owk-01-security-by-design/#toelichting","title":"Toelichting","text":"<p>Security by design is gehanteerd en terug te zien als uitgangspunt. (BIO 14.2.1.1) </p> <p>Security by design benadrukt het belang van het in een vroeg stadium integreren van securitymaatregelen. Op die manier kan worden voldaan aan regelgeving, maar wordt de weerbaarheid tegen bijvoorbeeld cyberaanvallen verhoogd. In een vroeg stadium nadenken over security betekent dat vroeg al de benodigde expertise wordt betrokken, zoals een security-officer.</p>"},{"location":"maatregelen/4-owk-01-security-by-design/#risico","title":"Risico","text":"<p>Wanneer tijdens het ontwerp en de inrichting van het algoritmisch systeem niet voldoende rekening wordt gehouden met vastgestelde security-by-design principes kan dit leiden tot een onvoldoende veilige (software-)omgeving. Dit kan tot gevolg hebben: oneigenlijke toegang, wijzigingen of vernietigingen van het algoritme, de data of uitkomsten van het algoritme.</p>"},{"location":"maatregelen/4-owk-01-security-by-design/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemenavg-12 - Beveiliging van de verwerkingaia-07 - Automatische logregistratie voor hoog-risico AI"},{"location":"maatregelen/4-owk-01-security-by-design/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, (BIO 14.2.1.1)</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.28</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.09</li> </ul>"},{"location":"maatregelen/4-owk-01-security-by-design/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/4-owk-02-stopzetten-gebruik/","title":"Maak een noodplan voor het stoppen van het algoritme","text":"<p>owk-02OntwikkelenImplementatieProjectleiderOntwikkelaarGovernanceMenselijke controle</p>"},{"location":"maatregelen/4-owk-02-stopzetten-gebruik/#maatregel","title":"Maatregel","text":"<p>Tref (technische) maatregelen waarmee het gebruik van het algoritme of AI-systeem kan worden stopgezet.</p>"},{"location":"maatregelen/4-owk-02-stopzetten-gebruik/#toelichting","title":"Toelichting","text":"<ul> <li>Er moet in een proces zijn beschreven wanneer het gebruik van algoritmes en AI-systemen moet worden stopgezet.</li> <li>Het is van belang dat bij het ontwerp van algoritmes en AI-systemen er rekening wordt gehouden met dat het werkproces ook zonder het algoritme of AI-systeem kan worden uitgevoerd.</li> <li>Als blijkt dat het algoritme of AI-systeem ongewenst functioneert, dan moeten (technische) maatregelen zijn getroffen waarmee het gebruik daadwerkelijk kan worden stopgezet. Denk hierbij aan een stopknop en werkinstructies hoe het gebruik kan worden be\u00ebindigd.</li> <li>Maak aantoonbaar dat deze maatregelen zijn getroffen.</li> <li>De proceseigenaar of een menselijk toezichthouder moet in staat zijn om het algoritme of AI-systeem op elk moment te kunnen be\u00ebindigen.</li> <li>Het stopzetten van het gebruik van een algoritme mag niet tot gevolg hebben dat betrokkenen niet meer kunnen achterhalen hoe besluiten tot stand zijn gekomen of dat gevolgen niet meer kunnen worden gecorrigeerd als dat noodzakelijk is. </li> </ul>"},{"location":"maatregelen/4-owk-02-stopzetten-gebruik/#risico","title":"Risico","text":"<p>Betrokkenen of belanghebbenden kunnen nadelige gevolgen ondervinden van een algoritme of AI-systeem dat onjuist functioneert en niet tijdig kan worden stopgezet.  </p>"},{"location":"maatregelen/4-owk-02-stopzetten-gebruik/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-18 - Corrigerende maatregelen voor non-conforme AIawb-01 - Relevante feiten en belangen zijn bekendaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIgrw-01 - Beschermen van fundamentele rechten en vrijhedenaia-29 - Beoordeling van grondrechtengrw-02 - AI-systemen en algoritmes mogen niet discriminerenaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-09 - Toezichtmogelijkheden voor gebruikersavg-04 - Proportionaliteit en subsidiariteitaia-24 - Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem"},{"location":"maatregelen/4-owk-02-stopzetten-gebruik/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.18, SV.17 </li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.03</li> <li>Impact Assessment Mensenrechten en Algoritmes, 1.5</li> </ul>"},{"location":"maatregelen/4-owk-02-stopzetten-gebruik/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/4-owk-03-privacyrisico/","title":"Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houden","text":"<p>owk-03OntwerpOntwikkelenMonitoring en beheerProjectleiderJuristPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/4-owk-03-privacyrisico/#maatregel","title":"Maatregel","text":"<p>Uitvoeren risicoanalyse en formuleren mitigerende maatregelen voor privacyrisico.</p>"},{"location":"maatregelen/4-owk-03-privacyrisico/#toelichting","title":"Toelichting","text":"<ul> <li>Verifieer of een DPIA is uitgevoerd over het werkproces dat wordt of zal worden ondersteund met een algoritme of AI-systeem. Zo nee, voer een risico analyse (DPIA) uit om de risico's voor de rechten en vrijheden van betrokkenen met de inzet van algoritmes en AI-systemen in beeld te brengen.</li> <li>Organisatorische en technische maatregelen moeten worden getroffen om persoonsgegevens bij de ontwikkeling en het gebruik van het algoritme of AI-systeem te beschermen.</li> <li>Beleg de mitigerende maatregelen bij betrokken actoren. Denk bijvoorbeeld aan het toekennen van de maatregelen als anonimiseren en pseudonimiseren van persoonsgegevens aan een data engineer, voordat deze kunnen worden gebruikt ten behoeve van het ontwikkelen of controleren van het algoritme of AI-systeem.</li> <li>Bepaal welke maatregelen moeten zijn gerealiseerd voordat mag worden gestart met de verwerking van de persoonsgegevens en welke moeten worden gemonitord.  </li> <li>Monitor de voortgang op het realiseren van de maatregelen en zorg voor bewijsstuken als deze zijn gerealiseerd. Deze bewijsstukken kunnen onderdeel worden van een audit.</li> <li>Als er een noodzaak is om na verloop van tijd meer persoonsgegevens te verwerken of om andere verwerkingen uit te voeren, zal opnieuw een beoordeling moeten plaatsvinden of er privacyrisico's ontstaan en hoe deze kunnen worden gemitigeerd. Gedurende de levenscyclus van het algoritme of AI-systeem moet aandacht blijven voor het uitvoeren van de risicoanalyse voor privacyrisico's.</li> <li>Bij hoge risico's voor het verwerken van persoonsgegevens is een voorafgaande raadpleging bij de Autoriteit Persoonsgegevens onder artikel 36 AVG verplicht. Bepaal of raadpleging noodzakelijk is. </li> </ul>"},{"location":"maatregelen/4-owk-03-privacyrisico/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen"},{"location":"maatregelen/4-owk-03-privacyrisico/#risico","title":"Risico","text":"<p>Privacyrisico's met de inzet van algoritmes en AI-systemen worden niet gemitigeerd, waardoor privacyrechten van betrokkenen worden geschonden. </p>"},{"location":"maatregelen/4-owk-03-privacyrisico/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.2, PRI.3</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.03</li> <li>Besluit inzake lijst van verwerkingen van persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens</li> <li>Model DPIA Rijksdienst</li> </ul>"},{"location":"maatregelen/4-owk-03-privacyrisico/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/4-owk-04-logging/","title":"Maak logbestanden waarin staat wie wanneer toegang had tot de data en de code","text":"<p>owk-04OntwikkelenMonitoring en beheerOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/4-owk-04-logging/#maatregel","title":"Maatregel","text":"<p>Zorg ervoor dat logbestanden worden gecre\u00eberd waarin informatie wordt geregistreerd over gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen. Door goede logging is te achterhalen wanneer en door wie er toegang is geweest tot code en data (audit trail). Er kan loginformatie gegenereerd, bewaard, toegankelijk gemaakt en gemonitord worden. Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren. Bedenk wat deze informatie betekent in de context van de werking van het algoritme of algoritmisch systeem.</p>"},{"location":"maatregelen/4-owk-04-logging/#toelichting","title":"Toelichting","text":"<ul> <li>Met logbestanden is te achterhalen wanneer en door wie er (ongewenste) aanpassingen zijn gedaan (audit trail).</li> <li>Loginformatie moet worden gegenereerd, bewaard, gemonitord en toegankelijk worden gemaakt.</li> <li>Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren.</li> <li>Bedenk wat deze informatie betekent in de context van de werking van het algoritme of algoritmisch systeem. loginformatie gegenereerd, bewaard, toegankelijk gemaakt en gemonitord worden. Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren.</li> <li>Stel vast welke informatie bij het ontwikkelen en gebruiken van algoritmes en AI-systemen relevant is om te loggen. </li> <li>Log behalve het aanpassen van gegevens ook het uitlezen van gegevens waar dat relevant is. Bijvoorbeeld als persoonsgegevens worden opgevraagd.</li> <li>Logs dienen periodiek (of doorlopend) gecontroleerd to worden op relevante incidenten. Dat betekent dat wat er gelogd wordt geschikt moet zijn om relevante beveiligingsincidenten op te merken. </li> </ul>"},{"location":"maatregelen/4-owk-04-logging/#risico","title":"Risico","text":"<p>Wanneer loginformatie ontbreekt, is niet te achterhalen wanneer er (eventueel ongewenste) aanpassingen zijn gedaan (audit trail) op (de code van) het algoritme, of door wie.</p>"},{"location":"maatregelen/4-owk-04-logging/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemenaia-07 - Automatische logregistratie voor hoog-risico AIaia-13 - Bewaartermijn voor gegenereerde logs"},{"location":"maatregelen/4-owk-04-logging/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, BIO 12.3.1.1, 12.3.1.4, 12.3.1.5, 12.4.1.1, 12.4.2.2</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.27</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.06</li> </ul>"},{"location":"maatregelen/4-owk-04-logging/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/","title":"Kies energiezuinige programmeermethoden","text":"<p>owk-05OntwikkelenOntwikkelaarDuurzaamheid</p>"},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/#maatregel","title":"Maatregel","text":"<p>Gebruik energie-effici\u00ebnte programmeertechnieken en methoden die de benodigde rekenkracht minimaliseren.</p>"},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/#toelichting","title":"Toelichting","text":"<p>Energiezuinig programmeren maakt het mogelijk om de voetafdruk van algoritmes te verkleinen door minder energie en middelen te verbruiken. Door specifieke technieken toe te passen, zoals optimalisatie van processen en effici\u00ebnte geheugenbeheerstrategie\u00ebn, kun je als ontwikkelaar bijdragen aan het verduurzamen van algoritmes.</p>"},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/#technieken-voor-energiezuinige-softwareontwikkeling","title":"Technieken voor energiezuinige softwareontwikkeling","text":"<ol> <li> <p>Lean coding en minimalisatie van code bloat    Lean coding richt zich op het gebruik van alleen de benodigde code zonder overbodige complexiteit of libraries, wat resulteert in lagere energieconsumptie. Door \u201ccode bloat\u201d te vermijden, zorg je ervoor dat het algoritme minder verwerkingskracht en geheugen verbruikt.</p> </li> <li> <p>Gebruik van energiezuinige programmeertalen en frameworks    Programmeren in talen zoals Rust, Go en Elixir draagt bij aan energie-effici\u00ebntie doordat deze ontworpen zijn voor lage resource-omvang en hoge effici\u00ebntie. Ook frameworks die lichtgewicht en modulair zijn, ondersteunen energiezuinige processen.</p> </li> <li> <p>Parallel processing en multi-core optimalisaties    Door parallelle verwerking en multi-core optimalisaties toe te passen, wordt rekenwerk verdeeld over meerdere cores. Dit reduceert de totale verwerkingstijd, bespaart energie en verhoogt de prestaties van je code op het vlak van duurzaamheid.</p> </li> <li> <p>Microservices en modulaire architecturen    Een modulaire architectuur, zoals microservices, zorgt ervoor dat je onderdelen van de applicatie alleen activeert wanneer dat nodig is. Dit voorkomt onnodige belasting en beperkt energieverbruik behoorlijk.</p> </li> <li> <p>Geoptimaliseerd geheugenbeheer    Door effici\u00ebnt geheugenbeheer, zoals caching en lazy loading, voorkom je onnodige data-opslag en bewerkingen. Dit verlaagt de energievraag en verbetert de snelheid van het algoritme aanzienlijk.</p> </li> </ol>"},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/#risico","title":"Risico","text":"<p>Zonder energie-effici\u00ebnte methoden kan het algoritme onnodig veel energie verbruiken, wat leidt tot hogere operationele kosten en een grotere milieu-impact.</p>"},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/#bronnen","title":"Bronnen","text":""},{"location":"maatregelen/4-owk-05-energiezuinige-programmeermethoden/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/","title":"Optimaliseer AI-trainingsprocessen voor energie-effici\u00ebntie","text":"<p>owk-06OntwikkelenOntwikkelaarDuurzaamheid</p>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#maatregel","title":"Maatregel","text":"<p>Streef naar energiezuinige methoden voor AI-training, zoals het beperken van trainingscycli en het gebruik van energie-effici\u00ebnte hardware.</p>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#toelichting","title":"Toelichting","text":"<p>Het trainen van AI, vooral generatieve AI-modellen, vergt aanzienlijke energie en heeft daardoor een grote ecologische voetafdruk. Een enkele trainingsronde kan al een enorme hoeveelheid CO\u2082 uitstoten. Door enkele concrete methoden toe te passen, kun je deze impact beperken.</p>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#energie-optimalisatie-door-hardwarekeuze-en-serverbeheer","title":"Energie-optimalisatie door hardwarekeuze en serverbeheer","text":"<ul> <li>Gebruik energie-effici\u00ebnte hardware zoals specifiek afgestemde GPU's, die geschikt zijn voor de trainingsbehoeften van het model. Door bijvoorbeeld te kiezen voor GPU\u2019s die optimaal bij je model passen in plaats van de krachtigste beschikbare hardware, kan het energieverbruik drastisch worden verminderd.</li> <li>Verder kan servergebruik geoptimaliseerd worden door onnodige trainingsomgevingen tijdig te stoppen, vooral testomgevingen, en servers dynamisch te schalen met tools zoals Kubernetes of autoscaling technologie.</li> </ul>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#slimme-data-en-trainingsoptimalisatie","title":"Slimme data- en trainingsoptimalisatie","text":"<p>Niet alle beschikbare data dragen bij aan de modelprestaties. Door een dataselectiestrategie toe te passen, gebruik je enkel relevante datasets, wat zorgt voor minder intensieve rekenbelasting tijdens het trainingsproces. Daarnaast kan slimme caching helpen om repetitieve data-opvragingen te beperken, wat bijdraagt aan een lagere energievraag. Bovendien kun je hertrainingscycli van AI beperken door enkel updates te doen wanneer nieuwe data dit echt vereist. Dit voorkomt overbodige trainingscycli en bespaart energie.</p>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#risico","title":"Risico","text":"<p>Zonder energie-effici\u00ebnte methoden kan AI-training leiden tot hoge operationele kosten en een aanzienlijke ecologische impact, met name door overmatig gebruik van rekenkracht en energie-intensieve hardware.</p>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#bronnen","title":"Bronnen","text":"<ul> <li>How to Make Generative AI Greener - Harvard Business Review</li> <li>GreenOps: 4 Tips om AI-training duurzamer te maken - AG Connect</li> <li>Duurzame kunstmatige intelligentie - TU Delft</li> </ul>"},{"location":"maatregelen/4-owk-06-optimaliseer-AI-training/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/","title":"Controleer regelmatig of het algoritme werkt zoals het bedoeld is","text":"<p>ver-01OntwikkelenVerificatie en validatieMonitoring en beheerProjectleiderOntwikkelaarTechnische robuustheid en veiligheidBias en non discriminatie</p>"},{"location":"maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#maatregel","title":"Maatregel","text":"<p>Stel vast dat het algoritme voortdurend functioneert in lijn met de vastgestelde doelstelling. </p>"},{"location":"maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#toelichting","title":"Toelichting","text":"<ul> <li>Vertaal de vastgestelde doelstelling naar functionele eisen voor het algoritme. Werk het vastgestelde doel uit in een beschrijving in logische taal/pseudo code of documentatie die handvatten biedt aan de ontwikkelaar. </li> <li>Monitor de mate waarin aan deze eisen wordt voldaan door het algoritme. </li> <li>Bepaal en leg vast hoe eventuele parameters, business rules en indicatoren bepaald worden. Zorg dat dit breed wordt afgestemd in de organisatie (ontwikkelteam, opdrachtgevers en beheer).</li> <li>Houd hier rekening met eventuele (statistische) bias: meten we daadwerkelijk wat we denken te meten? </li> <li>Wanneer het algoritme meerdere doelen dient, is het belangrijk ook te evalueren op meerdere functionele eisen. </li> <li>Wanneer er sprake is van een (handmatige) behandeling, bepaal dan wanneer deze behandeling als 'succesvol' gezien kan worden. </li> </ul>"},{"location":"maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekendaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging"},{"location":"maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#risico","title":"Risico","text":"<p>Het algoritme functioneert niet in lijn met geformuleerde doelstellingen. </p>"},{"location":"maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.01, 2.07 </li> <li>Impact Assessment Mensenrechten en Algoritmes, 1 </li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, DM.1, DM.4 </li> </ul>"},{"location":"maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/5-ver-02-biasanalyse/","title":"Toets het algoritme op bias","text":"<p>ver-01OntwerpVerificatie en validatieMonitoring en beheerProjectleiderBeleid en adviesOntwikkelaarJuristBias en non discriminatie</p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#maatregel","title":"Maatregel","text":"<p>Analyseer of het gebruik van het algoritme of het proces daaromheen leidt tot onwenselijke of onrechtmatige verschillen in de behandeling van individuen en/of groepen.  </p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#toelichting","title":"Toelichting","text":"<p>Het uitvoeren van een analyse over onwenselijke of onrechtmatige verschillen bestaat grofweg uit 3 stappen:</p> <ul> <li>Stap 1: Analyseer of er sprake is van bias: systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen.</li> <li>Stap 2: Voer een rechtvaardigingstoets uit om te bepalen of het geconstateerde verschil uit stap 1 te rechtvaardigen is. </li> <li>Stap 3: Voer een ethische wenselijkheidstoets uit om te bepalen of het geconstateerde verschil uit stap 1 ethisch wenselijk is. </li> </ul> <p>Voor alle stappen geldt dat het belangrijk is om de gemaakte keuzes en afwegingen zorgvuldig te onderbouwen en te documenteren. De 3 stappen worden hieronder verder toegelicht. </p> <p>Opmerking</p> <p>Deze maatregel is in ieder geval van toepassing op natuurlijke personen. Voor andere rechtspersonen zoals bedrijven kan dit ook van toepassing zijn. Denk bijvoorbeeld aan een gelijke behandeling tussen eenmanszaken en grotere bedrijven. </p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#stap-1-analyseer-of-er-sprake-is-van-bias","title":"Stap 1: Analyseer of er sprake is van bias","text":"<p>In deze stap is het doel om te bepalen in welke mate er sprake is van een systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen.  Dit verschil kan zowel op een directe als een indirecte manier ontstaan. </p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#toetsen-op-direct-onderscheid","title":"Toetsen op direct onderscheid","text":"<p>Toetsen op direct onderscheid is in vergelijking tot toetsen op indirect onderscheid relatief eenvoudig. </p> <p> Bepaal of de inputvariabelen die gebruikt worden leiden tot een direct onderscheid op basis van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid<sup>1</sup> of burgelijke staat. </p> <p>Het is niet mogelijk om een uitputtend overzicht te geven van alle selectiecriteria die mogelijk tot direct onderscheid op grond van ras of nationaliteit kunnen leiden.  Wel zijn in de jurisprudentie verschillende voorbeelden en aanknopingspunten te vinden.  Zo staat vast dat selectie op basis van fysieke etnische kenmerken, zoals huidskleur, direct onderscheid op grond van ras oplevert<sup>2</sup>. Een ander voorbeeld is dat onderscheid op grond van een niet-westers klinkende naam direct onderscheid op grond van afkomst (en dus ras) oplevert<sup>3</sup>.</p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#toetsen-op-indirect-onderscheid","title":"Toetsen op indirect onderscheid","text":"<p>Ook selectiecriteria die op het eerste gezicht geen enkele link lijken te hebben met een discriminatiegrond kunnen leiden tot indirect onderscheid op grond van een discriminatiegrond.  Enkele voorbeelden van zulke 'ogenschijnlijk neutrale' selectiecriteria die verband hebben met ras of nationaliteit zijn: postcode, hoogte van het inkomen, kenteken, familielid in het buitenland, laaggeletterdheid.  Indirect onderscheid is in vergelijking met direct onderscheid lastiger op te signaleren en te voorkomen.  Daarom is het belangrijk jouw algoritmische toepassing regelmatig te analyseren op eventueel indirect onderscheid.  Het toetsen op indirect onderscheid bestaat uit 5 stappen:</p> <ol> <li> <p>Bepaal wat de kwetsbare groepen zijn. Eventueel kan dit aangevuld worden op basis van de discriminatiegronden uit non-discriminatie wetgeving. Of andere groepen waarvoor verschillen in behandeling ethisch onwenselijk zijn.</p> </li> <li> <p>Bepaal wat \"verschillen in behandeling\" betekent in de context van het algoritme. In deze stap is het belangrijk om voorafgaand aan de daadwerkelijke analyse met een brede groep stakeholders te bepalen wat 'eerlijk' en 'rechtvaardig' wordt bevonden in de context van het betreffende algoritme.  Er zijn veel verschillende manieren waarop je kan kijken naar onderscheid bij het gebruik van algoritmes. Voorbeelden van manieren waarop je naar onderscheid kan kijken zijn:</p> <ul> <li>Onderscheid op basis van gelijke uitkomsten (representatie).  De belangrijkste vraag die hier mee beantwoord wordt is: hebben personen uit verschillende groepen gelijke kans om geselecteerd te worden door het algoritme? Of is er sprake van een over- of ondervertegenwoording van bepaalde groepen in de selectie ten opzichte van de betreffende populatie?</li> <li>Onderscheid op basis van gelijke prestaties (fouten).  De belangrijkste vraag die hier mee beantwoord wordt is: presteert het algoritme gelijk voor personen uit verschillende groepen? Met andere woorden: maakt het algoritme vaker fouten bij bepaalde groepen? Dat kan er eventueel toe leiden dat bepaalde groepen vaker onterecht wel of niet geselecteerd worden door het algoritme. </li> </ul> <p>Om te toetsen of er sprake is van onderscheid op basis van gelijke prestaties, is het noodzakelijk om de prestaties van het algoritme goed te analyseren.  In het geval van classificatie is het daarvoor nodig om een zogeheten confusion matrix op te stellen.  Een confusion matrix is een tabel waarin de voorspellingen van het algoritme worden vergeleken met de werkelijke waarden (de ground truth). </p> <p>De verschillende maten/metrieken waarop gekeken kan worden naar onderscheid, worden in de (wetenschappelijke) literatuur ook wel fairness metrieken genoemd.  Veel van deze metrieken kunnen op basis van de confusion matrix berekend worden.  Een hulpmiddel om de meest passende metrieken te kiezen in jouw situatie is de Fairness tree. </p> <p>Door te denken vanuit verschillende perspectieven, zullen er in de praktijk meerdere metrieken van belang zijn.  Het kan echter voorkomen dat deze metrieken elkaar tegenspreken.  Maak een duidelijke prioritering van de verschillende metrieken om afwegingen te maken tussen de verschillende opvattingen van eerlijkheid. </p> </li> <li> <p>Verzamel de benodigde data die nodig is om bovenstaande groepen te bepalen. Bepaal welke data benodigd is om te analyseren of er verschillen zijn tussen bepaalde groepen.  In veel gevallen zal data benodigd zijn die demografische en beschermde kenmerken van groepen omschrijft.  Het verzamelen en verwerken van deze data kan in strijd zijn met privacy vereisten uit bijvoorbeeld de Algemene Verordening Gegevensbescherming. Het is daarom van belang om duidelijk afwegingen te maken tussen privacy en het analyseren van bias die rekening houdt met de juridische en ethische vereisten.</p> <p>Uitzondering voor hoog risico AI-systemen</p> <p>De AI-verordening biedt een uitzondering voor het verwerken van bijzondere categorie\u00ebn persoonsgegevens voor het monitoren, opsporen en corrigeren van bias bij AI-systemen met een hoog risico. Zie artikel 10.5, AI-verordening. </p> <p>Om de data op een veilige en rechtmatige manier te gebruiken voor een biasanalyse dient de data van voldoende kwaliteit te zijn.  Denk hier goed na of de data eventuele bias bevat die kan duiden op een bepaalde vooringenomenheid in de biasanalyse zelf (historische bias of representatie bias).  De data dient bijvoorbeeld voldoende actueel en volledig te zijn.</p> <p>Voor sommige groepen zal het onmogelijk zijn om te beschikken over data van voldoende kwaliteit om zorgvuldig te toetsen op bias.  De laaggeletterdheid van burgers of personen is bijvoorbeeld lastig meetbaar en in veel gevallen niet beschikbaar.  Bepaal in zo'n situatie of er andere mogelijkheden zijn deze groepen te helpen, of dat er andere mogelijkheden zijn om eventuele ongelijke behandeling bij deze groepen te constateren.  Bijvoorbeeld door hierop te monitoren in de klacht- en bezwarenprocedure. </p> </li> <li> <p>Bereken de verschillen in behandeling en/of uitkomsten van het algoritme. Er zijn verschillende open source softwarepakketten die je hierbij kunnen ondersteunen, zoals fairlearn, Aequitas, fairml, fairness of AI Fairness 360.</p> </li> <li> <p>Probeer te verklaren hoe het geconstateerde onderscheid is ontstaan. Als er in de vorige stap een significant onderscheid is geconstateerd, is het belangrijk om na te gaan hoe dit onderscheid is ontstaan.  Dit kan bijvoorbeeld ontstaan door:</p> <ul> <li>een vorm van bias in de onderliggende inputdata. Je kan hierbij denken aan: <ul> <li>historische bias: in hoeverre beschrijft de data de huidige situatie?</li> <li>representatie bias: is de data waarop getraind wordt representatief voor de bijbehorende populatie? Zijn trends uit de gebruikte data generaliseerbaar naar de totale populatie?</li> <li>meetbias: beschrijven de inputvariabelen wel wat ze moeten beschrijven? In hoeverre zijn dit benaderingen waarbij eventuele factoren worden weggelaten?</li> </ul> </li> <li>een vorm van bias in het proces na afloop van het algoritme<ul> <li>is er sprake van automatiseringsbias of bevestigingsbias in de (handmatige) beoordeling?</li> </ul> </li> </ul> </li> </ol> <p> Wanneer duidelijker is hoe de geconstateerde bias is ontstaan, is het goed om te verkennen of er mogelijkheden zijn om dit (in de toekomst) te voorkomen. </p> <p>Het is belangrijk hier een brede groep aan belanghebbenden bij te betrekken.  De oorzaken van bias komen uit de 'echte wereld', waarbij patronen in datasets historische, demografische en sociale verschillen weerspiegielen.  Het verklaren en voorkomen van bias vraagt daarmee niet alleen om technische oplossingen, maar het is belangrijk de hele socio-technische omgeving waarin het algoritme wordt ingezet mee te nemen. </p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#stap-2-voer-een-rechtvaardigingstoets-uit","title":"Stap 2: Voer een rechtvaardigingstoets uit","text":"<p>Wanneer er in Stap 1 is geconstateerd dat er sprake is van een onderscheid, dient de volgende vraag beantwoord te worden:</p> <p>Valt dit onderscheid te rechtvaardigen?</p> <p>Een geconstateerd systematisch onderscheid is niet altijd fout en is niet altijd verboden, maar het vraagt wel altijd om aandacht en zorgvuldigheid.  Het geconstateerde onderscheid kan in bepaalde situaties en onder bepaalde strikte voorwaarden gerechtvaardigd zijn:</p> <ul> <li>Voor direct onderscheid kan er bijvoorbeeld sprake zijn van een wettelijke uitzondering die het gemaakte onderscheid toelaat. </li> <li>Voor indirect onderscheid geldt dat behalve een wettelijke uitzondering er ook een objectieve rechtvaardiging kan bestaan, waarmee het geconstateerde onderscheid in bepaalde gevallen toelaatbaar kan zijn. </li> </ul> <p>Twee subvragen die hierbij beantwoord moeten worden zijn:</p> <ul> <li>streeft het in te zetten algoritme een legitiem doel na?</li> <li>bestaat er een redelijke relatie van evenredigheid tussen het gebruikte algoritme en de nagestreefde doelstelling?</li> </ul> <p>Wanneer er geen rechtvaardiging is voor het gemaakte onderscheid, spreken we van een verboden direct of indirect onderscheid, ofwel discriminatie.  Het algoritme of AI-systeem mag in dat geval niet gebruikt worden.</p> <p>Voor meer toelichting over het uitvoeren van een rechtvaardigingstoets, verwijzen we naar het rapport Discriminatie door risicoprofielen - Een mensenrechtelijk toetsingskader van het College voor de Rechten van de Mens. </p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#stap-3-voer-een-ethische-wenselijkheidstoets-uit","title":"Stap 3: Voer een ethische wenselijkheidstoets uit","text":"<p>Bepaal of het geconstateerde onderscheid uit Stap 1 ethisch wenselijk is. Dit hangt samen met de algemene wenselijkheid van de inzet van het algoritme.  </p> <p>In sommige gevallen kan het zo zijn dat ondanks dat er een objectieve rechtvaardiging bestaat voor het gemaakte onderscheid, dit vanuit ethisch perspectief toch onwenselijk is.  Bepaal met een grote groep belanghebbenden wat eventuele (nadelige) effecten van het gemaakte onderscheid kunnen zijn, of jullie dit eerlijk vinden en of er eventuele alternatieven zijn. </p> <p>Opmerking</p> <p>De bepaling over wat eerlijk is en wat ethisch wenselijk is kan in sommige gevallen ook politiek bevonden worden. Houd hier rekening met de politiek-bestuurlijke verantwoordelijkheden en zorg indien nodig dat de politiek-bestuurlijke verantwoordelijkhden duidelijk zijn. </p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistegrw-02 - AI-systemen en algoritmes mogen niet discriminerenaia-29 - Beoordeling van grondrechtengrw-01 - Beschermen van fundamentele rechten en vrijheden"},{"location":"maatregelen/5-ver-02-biasanalyse/#risico","title":"Risico","text":"<p>Wanneer er geen zorgvuldige analyse naar (onwenselijke) bias is uitgevoerd, bestaat het risico dat het gebruik van het algoritme discriminerende effecten met zich meebrengt.  Dit kan leiden tot een ongelijke behandeling van burgers met eventuele schade voor betrokkenen.</p>"},{"location":"maatregelen/5-ver-02-biasanalyse/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.19, 3.08</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, DM.16, DM.17, DM.18, DM.20, DM.21, DM.22 </li> <li>Discriminatie door risicoprofielen - Een mensenrechtelijk toetsingskader, College voor de Rechten van de Mens</li> <li>Handreiking non-discriminatie by design</li> </ul>"},{"location":"maatregelen/5-ver-02-biasanalyse/#voorbeelden","title":"Voorbeelden","text":"<ul> <li>Addendum Vooringenomenheid voorkomen, Algorithm Audit met bijbehorende data en broncode op Github</li> <li>Onderzoek misbruik uitwonendenbeurs, PricewaterhouseCoopers</li> <li>Pilot Slimme Check, Gemeente Amsterdam</li> <li>Bias toetsing 'Kort Verblijf Visa' aanvragen, Rijks ICT Gilde</li> <li>Report on Algorithmic bias assesment, SigmaRed</li> </ul> <ol> <li> <p>Er is een wetsvoorstel om de term 'hetero- of homoseksuele gerichtheid' in de Algmemene wet gelijke behandeling (Awgb) te wijzigingen in 'seksuele gerichtheid'. Met deze wijziging sluit de Awgb aan bij een eerdere wijziging van artikel 1 van de Grondwet.\u00a0\u21a9</p> </li> <li> <p>Zie Discriminatie door risicoprofielen, een mensenrechtelijk toetsingskader, College voor de Rechten van de Mens \u21a9</p> </li> <li> <p>Zie Discriminatie door risicoprofielen, een mensenrechtelijk toetsingskader, College voor de Rechten van de Mens, College voor de Rechten van de Mens 7 juni 2021, oordeel 2021-70; College voor de Rechten van de Mens 23 april 2015, oordeel 2015-44; College voor de Rechten van de Mens 23 april 2015, oordeel 2014-0426.\u00a0\u21a9</p> </li> </ol>"},{"location":"maatregelen/5-ver-03-vertaling-wetgeving-naar-systeem/","title":"Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid","text":"<p>ver-03Verificatie en validatieJuristGovernanceTransparantie</p>"},{"location":"maatregelen/5-ver-03-vertaling-wetgeving-naar-systeem/#maatregel","title":"Maatregel","text":"<p>Stel regelmatig vast dat wetgeving en (lokaal) beleid correct is vertaald naar de uitvoering van het te ondersteunen werkproces en de onderliggende systemen. </p>"},{"location":"maatregelen/5-ver-03-vertaling-wetgeving-naar-systeem/#toelichting","title":"Toelichting","text":"<ul> <li>Systemen die overheidsorganisaties inzetten voor bijvoorbeeld het verlenen van subsidies, vergunningen of bijstandsuitkeringen moeten de regels en processtappen volgen die in wetgeving zijn voorgeschreven.</li> <li>Er is een vertaling nodig van deze regels en processtappen naar de uitvoering van het werkproces, het datagebruik en onderliggende systemen.</li> <li>Algoritmes en AI-systemen moeten ook voldoen aan deze regels en processtappen.</li> <li>Als algoritmes of AI-systemen worden ontwikkeld, moet worden onderzocht wat deze regels zijn en hoe deze moeten worden toegepast bij het ontwikkelen van algoritmes of AI-systemen.</li> <li>Het moeten voldoen aan wetgeving en beleid kan dus in zekere zin 'begrenzend' werken op wat mag worden gedaan met algoritmes en AI-systemen. Dit is mede afhankelijk van de risico classificatie van de specifieke toepassing. </li> <li>Voor algoritmes, bijvoorbeeld regelgebaseerde rekenregels, moet bijvoorbeeld nauwkeurig worden geprogrammeerd in welke gevallen welke bedragen moeten worden uitgekeerd voor een bijstandsuitkering.</li> <li> <p>Voor AI-modellen moet bijvoorbeeld worden vastgesteld of de trainingsdata wel tot stand is gekomen in lijn met wetgeving en vastgesteld beleid (datakwaliteit) en welke verbanden en patronen (inputvariabelen) al dan niet passend zijn bij het ondersteunen van wettelijke taken.</p> </li> <li> <p>Er is een multidisciplinaire samenwerking nodig tussen de proceseigenaar, gebruikers, juristen, informatieanalisten en ontwikkelaar om deze vertaling zorgvuldig en doorlopend te maken.</p> </li> <li>Voorafgaand aan het (laten) ontwikkelen van een algoritme of AI-systeem moet dit zijn uitgevoerd.</li> <li>De toegepaste 'business rules' en de verwerkte data voor de uitvoering van het te ondersteunen werkproces met algoritmes en AI-systemen moeten worden onderzocht en beoordeeld.</li> <li>Diepgaande procesanalyses (Bv. BPMN niveau Analytisch) en procesbeschrijvingen kunnen hierbij ondersteunen. </li> <li>Als blijkt dat een werkproces niet (meer) conform (gewijzigde) wetgeving of beleid wordt uitgevoerd, dan moet worden beoordeeld of de verworven data of welke deel van de data geschikt is voor het ontwikkelen een AI-model.</li> <li>Het is dan raadzaam om de uitvoering van het betreffende werkproces en de werking van onderliggende systemen eerst te 'herstellen' en om hiermee een nieuw datafundament te cre\u00eberen (eerst een groot aantal zaken behandelen) die later als trainingsdata kan worden gebruikt. </li> </ul>"},{"location":"maatregelen/5-ver-03-vertaling-wetgeving-naar-systeem/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekendaia-08 - Transparantie in ontwerp voor hoog-risico AIawb-02 - Een besluit berust op een deugdelijke motiveringaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteria"},{"location":"maatregelen/5-ver-03-vertaling-wetgeving-naar-systeem/#risico","title":"Risico","text":"<p>Een beslissing of besluit wordt niet conform wetgeving genomen en is daarmee onrechtmatig, als geen goede vertaling wordt gemaakt van wetgeving naar het algoritme. </p>"},{"location":"maatregelen/5-ver-03-vertaling-wetgeving-naar-systeem/#bron","title":"Bron","text":"<ul> <li>Wetsanalyse</li> <li>Onderzoekskader Auditdienst Rijk, DM.15</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.05</li> </ul>"},{"location":"maatregelen/5-ver-03-vertaling-wetgeving-naar-systeem/#voorbeeld","title":"Voorbeeld","text":"<p>Handleiding Wetanalyse </p>"},{"location":"maatregelen/6-imp-01-politiek-bestuurlijk-besluit/","title":"Maak een openbaar besluit over de inzet van het algoritme","text":"<p>imp-01OrganisatieverantwoordelijkhedenImplementatieProjectleiderGovernanceTransparantie</p>"},{"location":"maatregelen/6-imp-01-politiek-bestuurlijk-besluit/#maatregel","title":"Maatregel","text":"<p>Een politieke-bestuurlijk besluit wordt genomen over de inzet van een impactvol algoritme en hoog risico AI-systemen. </p>"},{"location":"maatregelen/6-imp-01-politiek-bestuurlijk-besluit/#toelichting","title":"Toelichting","text":"<ul> <li>Door een politiek-bestuurlijk besluit te nemen over de inzet of be\u00ebindiging van een impactvol algoritme of hoog risico AI-systeem, wordt een afweging en keuze gemaakt over de wenselijkheid, haalbaarheid, transparantie en eventueel de mate van onbewuste vooringenomenheid van het betreffende algoritme of AI-systeem.</li> <li>Impactvolle algoritmes en hoog risico AI-systemen bevatten aspecten die vragen om politieke afwegingen, en niet enkel door de ambtelijke organistie mogen worden beoordeeld.</li> <li>Een voorbeeld van een politiek afweging is wanneer er wel of geen sprake is van een gerechtvaardigd onderscheid wat wordt gemaakt door een algoritme of AI-systeem. </li> <li>Het is van belang dat overheidsorganisaties een politiek-bestuurlijk kader opstellen waarin wordt beschreven hoe wordt omgegaan met dergelijke gevallen. </li> <li>Een openbaar besluit draagt bij aan de legitimiteit van de inzet van het algoritme of AI-systeem en de controleerbaarheid van de overheidsorganisatie. </li> </ul>"},{"location":"maatregelen/6-imp-01-politiek-bestuurlijk-besluit/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteawb-01 - Relevante feiten en belangen zijn bekendaia-08 - Transparantie in ontwerp voor hoog-risico AIawb-02 - Een besluit berust op een deugdelijke motivering"},{"location":"maatregelen/6-imp-01-politiek-bestuurlijk-besluit/#risico","title":"Risico","text":"<p>De ambtelijke organisatie maakt politieke-bestuurlijke afwegingen en beslissingen bij de inzet of be\u00ebindiging van het gebruik van impactvolle algoritmes en AI-systemen, terwijl deze daar niet toe bevoegd is.</p>"},{"location":"maatregelen/6-imp-01-politiek-bestuurlijk-besluit/#bronnen","title":"Bronnen","text":"<p>Algemene Rekenkamer</p>"},{"location":"maatregelen/6-imp-01-politiek-bestuurlijk-besluit/#voorbeeld","title":"Voorbeeld","text":"<p>Besluit College van Burgemeester en Wethouders Gemeente Amsterdam </p>"},{"location":"maatregelen/6-imp-02-aselecte-steekproeven/","title":"Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controleren","text":"<p>imp-02Dataverkenning en datapreparatieImplementatieMonitoring en beheerOntwikkelaarBias en non discriminatieTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/6-imp-02-aselecte-steekproeven/#maatregel","title":"Maatregel","text":"<p>Uitvoeren van aselecte steekproeven als aanvulling wanneer gebruik gemaakt wordt van risicogestuurde selectie.</p>"},{"location":"maatregelen/6-imp-02-aselecte-steekproeven/#toelichting","title":"Toelichting","text":"<p>Aselecte steekproeven kunnen een waardevolle toevoeging zijn bij risicogestuurde selectie.</p> <p>Het toevoegen van aselecte steekproeven maakt het mogelijk om over tijd te beoordelen of het algoritme nog voldoende effectief is. Populaties veranderen immers over tijd. Een selectie die het meest effectief was bij ingebruikname, kan over tijd dat niet meer zijn. Door alleen risicogestuurd te selecteren, wordt dit niet inzichtelijk, omdat bepaalde groepen zelden tot nooit gecontroleerd worden. Door de aanvullende mogelijkheid van monitoring, kan over tijd beoordeeld worden of er nog steeds sprake is van de meest proportionele vorm. Als dat niet zo is, kan bijvoorbeeld gekozen worden voor aanpassing van de risicogestuurde selectie of overgaan op volledig aselect.</p> <p>De maatregel gaat daarmee niet direct discriminatie tegen, omdat er sprake kan zijn van discriminatie ongeacht de effectiviteit van de risicogestuurde selectie. Een lagere effectiviteit maakt het echter lastiger het gemaakte onderscheid te rechtvaardigen.</p> <p>Het gebruik van een aselecte steekproef is in veel gevallen essentieel om het systeem te kunnen toetsen op vooringenomenheid.  Een aselecte steekproef geeft ook inzicht in heel deel van de populatie dat doorgaans niet geselecteerd en behandeld wordt door het betreffende risicogestuurde algoritme.  Dit maakt het mogelijk om te toetsen of er sprake is van een over- of ondervertegenwoordiging van bepaalde groepen, of om te bepalen of bepaalde typen fouten vaker gemaakt worden in bepaalde groepen.</p> <p>Bij AI-systemen die verder leren op basis van verkregen data kan daarnaast sprake zijn van een reinforcing feedbackloop, omdat zij geen representatieve data krijgen. Het toevoegen van aselecte steekproeven kan deze feedbackloop doorbreken.</p> <p>Het is aan te bevelen om, waar mogelijk, behandelaars niet in te lichten of een casus toegewezen is op basis van een risicogestuurd of aselecte selectie. Daardoor wordt beperkt dat een behandelaar met tunnelvisie een zaak bekijkt. De behandelaar weet immers dat er tussen de selecties zaken zitten waar niet sprake is van verhoogd risico. Op die manier kan automation bias beperkt te worden. Niet in alle gevallen zal dit mogelijk zijn, omdat de behandelaar ook uit andere aangeleverde gegevens kan halen op basis waarvan een casus geselecteerd is. Het is dan belang om op andere wijze de tunnelvisie tegen te gaan.</p> <p>De precieze inzet van aselecte steekproeven zal afhangen van de context. Zo verschilt het per context hoeveel zaken aselect geselecteerd moeten worden. Bepaal welke groepen er precies vergeleken dienen te worden en bepaal aan de hand daarvan een passende steekproefgrootte zodanig dat er gesproken kan worden over statistische significantie. </p> <p>In sommige gevallen zal de impact van een selectie ook dusdanig zijn, dat het zich niet leent voor aselecte steekproef. Zo kan een aselecte steekproef wel de basis zijn voor bureauonderzoek, maar mogelijk niet als enige basis voor een huisbezoek. Deze belangenenafweging moet per context gemaakt worden.</p>"},{"location":"maatregelen/6-imp-02-aselecte-steekproeven/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-29 - Beoordeling van grondrechtengrw-02 - AI-systemen en algoritmes mogen niet discriminerenaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging"},{"location":"maatregelen/6-imp-02-aselecte-steekproeven/#bronnen","title":"Bronnen","text":"<p>Rapportage Algoritmerisico's Nederland voorjaar 2024 (pp. 36-41)</p>"},{"location":"maatregelen/6-imp-02-aselecte-steekproeven/#risico","title":"Risico","text":"<ul> <li>Historical bias</li> <li>Representation bias</li> <li>Automation bias en Reinforcing Feedback Loop</li> </ul>"},{"location":"maatregelen/6-imp-02-aselecte-steekproeven/#voorbeeld","title":"Voorbeeld","text":"<p>In het onderzoek van zowel Algorithm Audit als PricewaterhouseCoopers naar de Controle Uitwonendenbeurs is het belang van de aselecte steekproef duidelijk geworden. </p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/6-imp-03-menselijke-tussenkomst/","title":"Organiseer menselijke controle van het algoritme","text":"<p>imp-03OntwerpImplementatieMonitoring en beheerProjectleiderBeleid en adviesMenselijke controleGovernance</p>"},{"location":"maatregelen/6-imp-03-menselijke-tussenkomst/#maatregel","title":"Maatregel","text":"<p>Richt (technische) controlemechanismen in voor menselijk tussenkomst waarmee de output van een algoritme of AI-systeem kan worden gecontroleerd.</p>"},{"location":"maatregelen/6-imp-03-menselijke-tussenkomst/#toelichting","title":"Toelichting","text":"<ul> <li>Algoritmes en AI-systemen worden vaak ingezet om beslissingen of besluitvorming van overheidsorganisaties te ondersteunen.</li> <li>Als overheidsorganisaties beslissingen of besluiten nemen, kan dit rechtsgevolgen hebben voor een betrokkene of deze op een andere manier in aanmerkelijke mate treffen. </li> <li>Algoritmes en AI-systemen zijn in de meeste gevallen niet foutloos. </li> <li>Daarom is het van belang dat deze output wordt gecontroleerd door een mens, zodat dit kan worden gecorrigeerd. Dit wordt 'menselijke tussenkomst' genoemd. </li> <li>Er is sprake van menselijke tussenkomst wanneer het menselijke toezicht op beslissingen of besluitvorming betekenisvol of zinvol is, en niet slechts symbolisch is.</li> <li>Menselijke tussenkomst moet worden uitgevoerd door iemand die bevoegd en bekwaam is om een beslissing of besluit te veranderen.</li> <li>Als een automatisch gegenereerde aanbeveling van een algoritme of AI-systeem (output) praktisch gezien standaard wordt overgenomen (bijvoorbeeld door deze al klikkend te accepteren), is er geen sprake meer van betekenisvolle menselijke tussenkomst. Hier is meer voor nodig.</li> <li>Het is van belang dat in een vroeg stadia wordt vastgesteld, bijvoorbeeld in de ontwerpfase, welke vormen van menselijke tussenkomst moeten worden ingezet en passend zijn gezien de specifieke algoritmische toepassing of AI-systeem. Dit kan worden gedaan op basis van uit te voeren risico analyses. </li> <li>In het geval van het uitoefenen van 'gebonden bevoegdheden', waarbij er weinig of geen beoordelingsruimte is om de beslissing of het besluit te wijzigen, kan het zijn dat menselijke tussenkomst geen meerwaarde heeft en kan worden volstaan met de automatisch gegenereerde output.</li> <li>Hierbij kan worden gedacht aan het opleggen van een boete in het kader van de Wet administratiefrechtelijke handhaving verkeersvoorschriften (Wahv) of het bijstellen van de hoogte van het recht op studiefinanciering op basis van veranderingen in het inkomen van een van de ouders.</li> <li>Er zullen technische en organisatorische maatregelen moeten worden getroffen om menselijke tussenkomst in te richten.</li> <li>Dit is ook het geval als een (externe) aanbieder algorimtes of AI-systemen levert. De gebruiksverantwoordelijke zal dan samen met aanbieder moeten onderzoeken hoe menselijke tussenkomst betekenisvol moet worden ingericht. </li> </ul>"},{"location":"maatregelen/6-imp-03-menselijke-tussenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-10 - Recht op niet geautomatiseerde besluitvorminggrw-01 - Beschermen van fundamentele rechten en vrijhedenaia-24 - Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeemawb-01 - Relevante feiten en belangen zijn bekendaia-09 - Toezichtmogelijkheden voor gebruikers"},{"location":"maatregelen/6-imp-03-menselijke-tussenkomst/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.01</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.5 </li> <li>Advies over geautomatiseerde selectietechniek Pels Rijcken, p.9</li> <li>Kamerstukken IT 2017-2018, 34 851, nr. (MvT UAVG), p. 120-121 </li> </ul>"},{"location":"maatregelen/6-imp-03-menselijke-tussenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>HvJEU december 2023, ECLI:EU:C:2023:957 (SCHUFA Scoring)</p>"},{"location":"maatregelen/6-imp-04-publiceren-algoritmeregister/","title":"Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregister","text":"<p>imp-04ImplementatieMonitoring en beheerProjectleiderBeleid en adviesTransparantie</p>"},{"location":"maatregelen/6-imp-04-publiceren-algoritmeregister/#maatregel","title":"Maatregel","text":"<p>Publiceer het algoritme  in het Nederlandse Algoritmeregister.  </p>"},{"location":"maatregelen/6-imp-04-publiceren-algoritmeregister/#toelichting","title":"Toelichting","text":"<ul> <li>De regering wil dat de overheid algoritmes en AI-systemen verantwoord gebruikt. Mensen moeten erop kunnen vertrouwen dat algoritmes voldoen aan de waarden en normen van de samenleving.</li> <li>Wanneer de overheid open is over algoritmes en hun toepassing, kunnen burgers, organisaties en media haar kritisch volgen.</li> <li>Impactvolle algoritmes en hoog risico AI-systemen moeten daarom worden gepubliceerd in het Algoritmeregister.</li> <li>In het Algoritmeregister moet uitleg zijn over hoe algoritmes en AI-systemen, of het proces wat hiermee wordt ondersteund werkt.</li> <li>Er is een Handreiking Algoritmeregister opgesteld met informatie over het publiceren van algoritmes en AI-systemen in het Algoritmeregister.</li> <li>De Algoritmeregister Publicatiestandaard kan overheidsorganisaties ondersteunen bij het helpen invullen van het Algoritmeregister.</li> <li>Sommige overheidsorganisaties publiceren hun algoritmes ook in een eigen Algoritmeregister, zodat burgers dit makkelijker kunnen vinden. Bijvoorbeeld het Algoritmeregister van de Gemeente Rotterdam, het Algoritmeregister van de Gemeente Amsterdam of het Algoritmeregister van het UWV. </li> <li>Zorg na publicatie dat de informatie in het Algoritmeregister up-to-date blijft en indien nodig regelmatig wordt aangepast. </li> </ul>"},{"location":"maatregelen/6-imp-04-publiceren-algoritmeregister/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebzk-01 - Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisteraia-08 - Transparantie in ontwerp voor hoog-risico AIavg-07 - Transparantie bij verwerking persoonsgegevensawb-01 - Relevante feiten en belangen zijn bekend"},{"location":"maatregelen/6-imp-04-publiceren-algoritmeregister/#risico","title":"Risico","text":"<p>Betrokkenen zijn niet op de hoogte dat hun persoonsgegevens worden verwerkt met een algoritme of AI-systeem, waardoor zij hier geen controle over hebben. </p>"},{"location":"maatregelen/6-imp-04-publiceren-algoritmeregister/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking Algoritmeregister</li> <li>Algoritmeregister Publicatiestandaard</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.12, 3.14, 3.16 </li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.14, PRI.8 </li> </ul>"},{"location":"maatregelen/6-imp-04-publiceren-algoritmeregister/#voorbeeld","title":"Voorbeeld","text":"<ul> <li>Gemeente Groningen, Algoritmeregister: Eerste Hulp bij Geldzaken</li> <li>Gemeente Amsterdam, Algoritemregister: Blurring as a Service</li> <li>Juryrapport Best Beschreven Algoritme</li> </ul>"},{"location":"maatregelen/6-imp-05-werkinstructies-medewerkers/","title":"Spreek af hoe medewerkers omgaan met het algoritme of AI-systeem","text":"<p>imp-05ImplementatieProjectleiderBeleid en adviesGovernanceMenselijke controle</p>"},{"location":"maatregelen/6-imp-05-werkinstructies-medewerkers/#maatregel","title":"Maatregel","text":"<p>Stel duidelijke werkinstructies op voor de medewerkers die het algoritme gaan gebruiken. </p>"},{"location":"maatregelen/6-imp-05-werkinstructies-medewerkers/#toelichting","title":"Toelichting","text":"<ul> <li>Maak keuzes rondom de rol van het systeem in de werkwijze van medewerkers.</li> <li>Gebruik duidelijke werkinstructies en protocollen om te voorkomen dat beslissingen, gebaseerd op de output van het systeem, door (automation) bias worden be\u00efnvloed.</li> <li>Stel een structuur op voor het melden van mogelijke problemen die medewerkers ervaren met het systeem.</li> <li> <p>Opleiding van medewerkers over:</p> <ul> <li>AI en algoritmes;</li> <li>het systeem waarmee ze gaan werken;</li> <li>de rol van het systeem in hun werkwijze;</li> <li>de risico's die aan het gebruik van een systeem verbonden zijn (bijv. (automation) bias, false positives/negatives);</li> <li>de maatregelen die genomen zijn om deze risico\u2019s te beperken (bijv. willekeurige of fictieve casussen, transparantie over de output).</li> </ul> </li> <li> <p>Bespreek regelmatig de uitdagingen die medewerkers ondervinden bij het werken met het systeem (bijv. tijdsdruk).</p> </li> <li> <p>Documenteer alle keuzes en de onderliggende redenen/afwegingen rondom menselijke tussenkomst en overzicht. Evalueer en pas gemaakte keuzes waar nodig aan.</p> </li> <li> <p>Goede samenwerking tussen medewerkers en systemen helpt bij het voorkomen van (automation) bias en discriminatie, het signaleren van algoritmische problemen, en het vermijden van de facto automatische besluitvorming.</p> </li> </ul>"},{"location":"maatregelen/6-imp-05-werkinstructies-medewerkers/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistegrw-02 - AI-systemen en algoritmes mogen niet discriminerenaia-09 - Toezichtmogelijkheden voor gebruikers"},{"location":"maatregelen/6-imp-05-werkinstructies-medewerkers/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.07</li> <li>Handreiking non-discriminatie by design </li> <li>Impact Assessment Mensenrechten en Algoritmes </li> <li>Ethics Guidelines of Trustworthy AI</li> </ul>"},{"location":"maatregelen/6-imp-05-werkinstructies-medewerkers/#risico","title":"Risico","text":"<p>Bias, discriminatie, de facto automatische besluitvorming.</p>"},{"location":"maatregelen/6-imp-05-werkinstructies-medewerkers/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/6-imp-06-proces-privacyrechten/","title":"Spreek af hoe de organisatie omgaat met privacy-verzoeken","text":"<p>imp-06OrganisatieverantwoordelijkhedenOntwikkelenProjectleiderBeleid en adviesJuristPrivacy en gegevensbeschermingGovernanceData</p>"},{"location":"maatregelen/6-imp-06-proces-privacyrechten/#maatregel","title":"Maatregel","text":"<p>Richt een proces in waarmee betrokkenen hun privacyrechten kunnen inroepen als algoritmes of AI-systemen worden ontwikkeld of gebruikt.</p>"},{"location":"maatregelen/6-imp-06-proces-privacyrechten/#toelichting","title":"Toelichting","text":"<ul> <li>Betrokkenen moeten hun persoonsgegevens kunnen inzien, rectificeren, laten verwijderen of het gebruik ervan beperken bij het toepassen van algorimtes en AI-systemen.</li> <li>Betrokkenen moeten hun verzoek kunnen indienen bij de betreffende organisatie. Denk hierbij aan het inrichten van een privacyloket.</li> <li>Er zullen  afspraken moeten worden gemaakt door servicemanagement in te richten hoe deze verzoeken effectief kunnen worden behandeld door bijvoorbeeld door het ontwikkel- of beheerteam (aanbieder).</li> <li>Bij het inrichten van  servicemanagement moet zijn nagedacht over hoe een verzoek tot het inzien, rectificeren, verwijderen of beperken van de verwerking van persoonsgegevens op een betekenisvolle manier kan of moet worden behandeld.</li> </ul>"},{"location":"maatregelen/6-imp-06-proces-privacyrechten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-09 - Privacyrechten"},{"location":"maatregelen/6-imp-06-proces-privacyrechten/#risico","title":"Risico","text":"<p>Betrokkenen hebben geen controle over hun persoonsgegevens doordat ze geen beroep kunnen doen op hun privacyrechten. </p>"},{"location":"maatregelen/6-imp-06-proces-privacyrechten/#bronnen","title":"Bronnen","text":"<p>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.9 </p>"},{"location":"maatregelen/6-imp-06-proces-privacyrechten/#voorbeeld","title":"Voorbeeld","text":"<p>Privacyverzoek Gemeente Amsterdam</p>"},{"location":"maatregelen/6-imp-07-vermelding-in-privacyverklaring/","title":"Vermeld het gebruik van persoonsgegevens in een privacyverklaring","text":"<p>imp-07ImplementatieProjectleiderJuristPrivacy en gegevensbescherming</p>"},{"location":"maatregelen/6-imp-07-vermelding-in-privacyverklaring/#maatregel","title":"Maatregel","text":"<p>Neem het gebruik van een algoritme of AI-systeem op in de privacyverklaring als hierbij persoonsgegevens worden verwerkt.  </p>"},{"location":"maatregelen/6-imp-07-vermelding-in-privacyverklaring/#toelichting","title":"Toelichting","text":"<ul> <li>Door in een privacyverklaring te vermelden welke persoonsgegevens worden verwerkt voor het gebruik van een algoritme of AI-systeem, wordt een betrokkene ge\u00efnformeerd over de verwerking van diens persoonsgegevens.</li> <li>Een privacyverklaring kan op organistieniveau worden opgesteld en ook voor specifieke verwerkingen.</li> <li> <p>In een privacyverklaring wordt in ieder geval het volgende opgenomen:</p> </li> <li> <p>de identiteit en contactgegevens van uw organisatie. En ook die van vertegenwoordiger in de Europese Unie (EU), als deze er zijn.</p> </li> <li>de contactgegevens van de functionaris gegevensbescherming (FG), als een organistie deze heeft.</li> <li>de doeleinden van de verwerking en de AVG-grondslag. </li> <li>de (categorie\u00ebn van) ontvangers van de persoonsgegevens.</li> <li>of de persoonsgegevens door worden geven buiten de EER of aan een internationale organisatie. En zo ja, op welke juridische grond.</li> <li>de bewaartermijn van de gegevens.</li> <li>de privacyrechten van de betrokkenen, zoals het recht op inzage, rectificatie en gegevens verwijderen.</li> <li>het recht van de betrokkenen om de toestemming die zij voor een bepaalde verwerking hebben gegeven, altijd weer te mogen intrekken.</li> <li>dat de betrokkenen een klacht kunnen indienen bij de privacytoezichthouder. In Nederland is dat de Autoriteit Persoonsgegevens (AP).</li> <li>of de betrokkenen verplicht zijn de persoonsgegevens te verstrekken. En zo ja, waarom. Vermeld dan ook wat de gevolgen zijn als zij de gegevens niet verstrekken.</li> <li>of er sprake is van geautomatiseerde besluitvorming, inclusief profilering. En zo ja, hoe deze beslissing wordt genomen.</li> <li> <p>als persoonsgegevens van een andere organisatie zijn ontvangen: de bron waar de persoonsgegevens vandaan komen. En of de gegevens afkomstig zijn van openbare bronnen.</p> </li> <li> <p>Het is denkbaar dat in een specifieke privacyverklaring informatie over onderliggende logica van het algoritme of AI-systeem, alsmede het belang en de verwachte gevolgen van die verwerking voor de betrokkene. Het is ook denkbaar dat deze informatie in het algoritmeregister wordt opgenomen.</p> </li> <li>Als ervoor wordt gekozen om het algoritme uit te faseren, dan moet informatie in het algoriteregister hierop worden aangepast. </li> </ul>"},{"location":"maatregelen/6-imp-07-vermelding-in-privacyverklaring/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-07 - Transparantie bij verwerking persoonsgegevens"},{"location":"maatregelen/6-imp-07-vermelding-in-privacyverklaring/#risico","title":"Risico","text":"<p>Betrokkenen zijn niet op de hoogte dat hun persoonsgegevens worden verwerkt met een algoritme of AI-systeem, waardoor zij hier geen controle over hebben en zich niet kunnen beroepen op hun privacyrechten.</p>"},{"location":"maatregelen/6-imp-07-vermelding-in-privacyverklaring/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.8</li> <li>Autoriteit Persoonsgegevens  Algoritmekader </li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.12 </li> </ul>"},{"location":"maatregelen/6-imp-07-vermelding-in-privacyverklaring/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/6-imp-08-vermelding-in-verwerkingsregister/","title":"Vermeld het gebruik van persoonsgegevens in het verwerkingsregister","text":"<p>imp-08ImplementatieProjectleiderJuristTransparantiePrivacy en gegevensbescherming</p>"},{"location":"maatregelen/6-imp-08-vermelding-in-verwerkingsregister/#maatregel","title":"Maatregel","text":"<p>Neem de ontwikkeling en gebruik van een algoritme of AI-systeem op in het verwerkingsregister als persoonsgegevens worden verwerkt.  </p>"},{"location":"maatregelen/6-imp-08-vermelding-in-verwerkingsregister/#toelichting","title":"Toelichting","text":"<ul> <li>Door in het verwerkingsregister te vermelden welke persoonsgegevens worden verwerkt voor het gebruik van een algoritme of AI-systeem, wordt een betrokkene ge\u00efnformeerd over de verwerking van diens persoonsgegevens</li> <li>Hiermee is ook voor de organisatie intern inzichtelijk welke persoonsgegevens voor welke toepassingen worden verwerkt;</li> <li>Het is van belang dat vanaf het moment dat persoonsgegevens worden verwerkt, meteen een vermelding hiervan wordt gemaakt in het verwerkingsregister;</li> <li>Dat betekent dat als persoonsgegevens worden verwerkt bij het ontwikkelen en trainen van het algoritme of AI-systeem, en deze nog niet in gebruik zijn genomen, al een vermelding moet worden gedaan in het verwerkingsregister;</li> <li>Bij be\u00ebindiging van het gebruik van het algoritme of AI-systeem, moet het verwerkingsregister worden aangepast. </li> <li>## Bijbehorende vereiste(n)</li> </ul> Vereisteavg-07 - Transparantie bij verwerking persoonsgegevens"},{"location":"maatregelen/6-imp-08-vermelding-in-verwerkingsregister/#risico","title":"Risico","text":"<p>Betrokkenen en de interne organisatie zijn niet op de hoogte welke persoonsgegevens worden verwerkt met een algoritme of AI-systeem, waardoor zij hier geen controle over hebben. </p>"},{"location":"maatregelen/6-imp-08-vermelding-in-verwerkingsregister/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.8</li> <li>Autoriteit Persoonsgegevens</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.04</li> </ul>"},{"location":"maatregelen/6-imp-08-vermelding-in-verwerkingsregister/#voorbeeld","title":"Voorbeeld","text":"<ul> <li>Blurring as a Service, Verwerkingsregister gemeente Amsterdam</li> </ul>"},{"location":"maatregelen/6-imp-09-klacht-bezwaar-beroep/","title":"Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.","text":"<p>imp-09ImplementatieMonitoring en beheerProjectleiderOntwikkelaarGovernance</p>"},{"location":"maatregelen/6-imp-09-klacht-bezwaar-beroep/#maatregel","title":"Maatregel","text":"<p>Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme. Zorg voor goede monitoring van dit proces zodat het projectteam op de hoogte is van klachten, bezwaren en beroepen over het systeem. </p>"},{"location":"maatregelen/6-imp-09-klacht-bezwaar-beroep/#toelichting","title":"Toelichting","text":"<ul> <li>Een goede datahuishouding van de binnengekomen bezwaren, klachten en beroepen is essentieel om de informatie rondom de klachten, bezwaren en beroepen vanuit datagedreven perspectief te kunnen monitoren.</li> <li>Goede monitoring kan ervoor zorgen dat eventuele patronen in bezwaar, klacht en beroep snel gesignaleerd worden. Eventuele patronen in klacht, bezwaar en beroep kunnen duiden op problemen in het functioneren van het algoritme. Dit kan bijvoorbeeld duiden op discriminerende effecten van het algoritme, waardoor nader onderzoek wenselijk is. </li> </ul>"},{"location":"maatregelen/6-imp-09-klacht-bezwaar-beroep/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-09 - Privacyrechtenaia-28 - Recht op uitleg AI-besluiten"},{"location":"maatregelen/6-imp-09-klacht-bezwaar-beroep/#risico","title":"Risico","text":""},{"location":"maatregelen/6-imp-09-klacht-bezwaar-beroep/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, SV.17, PRI.9</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.08</li> <li>Onderzoek misbruik uitwonendenbeurs, PricewaterhouseCoopers</li> <li>Intern onderzoek controle uitwonendenbeurs, DUO</li> </ul>"},{"location":"maatregelen/6-imp-09-klacht-bezwaar-beroep/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/7-mon-01-backups-maken/","title":"Maak back-ups van algoritmes","text":"<p>mon-01OntwikkelenMonitoring en beheerOntwikkelaarBeleid en adviesTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/7-mon-01-backups-maken/#maatregel","title":"Maatregel","text":"<p>Back-up kopie\u00ebn van informatie, software en systeemafbeeldingen dienen regelmatig te worden gemaakt en getest. Idealiter gebeurt dit in overeenstemming met een afgesproken back-up beleid. Maak back-ups van de omgeving van het algoritme en zorg ervoor dat het algoritme en de data hersteld kunnen worden.</p>"},{"location":"maatregelen/7-mon-01-backups-maken/#toelichting","title":"Toelichting","text":"<p>Er is een back-up beleid waarin de eisen voor het bewaren en beschermen zijn gedefinieerd en vastgesteld. Dit beleid moet vervolgens worden vertaald naar (technische) maatregelen om het kunnen maken van back-ups te realiseren.</p>"},{"location":"maatregelen/7-mon-01-backups-maken/#risico","title":"Risico","text":"<p>Als er geen regelmatige back-ups worden gemaakt en de restore-procedure niet regelmatig wordt getest, bestaat het risico dat er geen hersteloptie is en mogelijkheid van gegevensverlies.</p>"},{"location":"maatregelen/7-mon-01-backups-maken/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemen"},{"location":"maatregelen/7-mon-01-backups-maken/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, 12.3.1.1, 12.3.1.4, 12.3.1.5.</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.26</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.08 </li> </ul>"},{"location":"maatregelen/7-mon-01-backups-maken/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/7-mon-02-beveiliging-algoritme/","title":"Beveilig de software","text":"<p>mon-02Dataverkenning en datapreparatieOntwikkelenMonitoring en beheerProjectleiderBeleid en adviesOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/7-mon-02-beveiliging-algoritme/#maatregel","title":"Maatregel","text":"<p>Zorg voor een goede beveiliging van de verschillende softwarecomponenten van een algoritme of AI-systeem. Bepaal of de data voldoende is beveiligd en maak hierin onderscheid tussen de inputdata en de outputdata.</p>"},{"location":"maatregelen/7-mon-02-beveiliging-algoritme/#toelichting","title":"Toelichting","text":"<p>Er zijn beheersmaatregelen die kunnen helpen bij het zorgen voor een goede beveiliging van verschillende (software-)componenten van een algoritme of systeem. Hierbij kan worden gedacht aan: Het toepassen van wachtwoordbeheer. Baseline Informatiebeveiliging Overheid, de NCSC Handreiking voor implementatie van detectieoplossingen en het Impact Assessment Mensenrechten en Algoritmes.</p> <ul> <li>Inzicht cre\u00ebren in de beoogde opzet van de IT-infrastructuur (de architectuur) en de werkelijk geconfigureerde hard- en software. (CIS Control 1, BIO 8.1.1).</li> <li>Inrichten van een formeel proces voor het beheer van technische kwetsbaarheden. Dit omvat minimaal periodieke (geautomatiseerde) controle op de aanwezigheid van kwetsbaarheden in de te toetsen systemen, een risicoafweging en navolgbare afwerking daarvan of risicoacceptatie (BIO 12.6).</li> <li>Beoordelen, patchen en updaten van kwetsbaarheden in IT-systemen als deze bekend zijn. (BIO 12.6.1)</li> <li>Verwijderen of deactiveren van softwarecomponenten en services die niet noodzakelijk zijn voor het functioneren van het algoritme om beveiligingsrisico\u2019s te beperken. (BIO 12.6.1)</li> <li>Er vindt zonering plaats binnen de technische infrastructuur conform de uitgangspunten die zijn vastgelegd in een operationeel beleidsdocument, waarbij minimaal sprake is van scheiding tussen vertrouwde en onvertrouwde netwerken (BIO 9.4.2). Denk ook aan het scheiden in netwerken (BIO 13.1.3).</li> <li>Actieve monitoring van de algoritme data vindt plaats zodat beveiligingsincidenten en -gebeurtenissen in een vroeg stadium worden gedetecteerd. (BIO 12.4.1, NCSC Handreiking voor implementatie van detectieoplossingen).</li> <li>Netwerkverkeer en componenten worden actief gemonitord. (BIO 12.4.1).</li> <li>Beoordeel of de data ten behoeve van het ontwikkelen en gebruiken van het algoritme voldoende is beveiligd. Maak hierin onderscheid tussen de trainingsdata, inputdata en de outputdata.</li> </ul>"},{"location":"maatregelen/7-mon-02-beveiliging-algoritme/#risico","title":"Risico","text":"<p>Oneigenlijke toegang van buitenaf kan plaatsvinden via zwakheden in het systeem.</p>"},{"location":"maatregelen/7-mon-02-beveiliging-algoritme/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemenavg-12 - Beveiliging van de verwerkingaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging"},{"location":"maatregelen/7-mon-02-beveiliging-algoritme/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.18 t/m IB.25</li> <li>NCSC Handreiking voor implementatie van detectieoplossingen</li> <li>Handleiding Quickscan Information Security</li> </ul>"},{"location":"maatregelen/7-mon-02-beveiliging-algoritme/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/7-mon-03-informatiebeveiligingsincidenten/","title":"Maak een noodplan voor beveiligingsincidenten","text":"<p>mon-03OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderBeleid en adviesJuristTechnische robuustheid en veiligheidGovernance</p>"},{"location":"maatregelen/7-mon-03-informatiebeveiligingsincidenten/#maatregel","title":"Maatregel","text":"<p>Richt een proces in waarmee beveiligingsincidenten m.b.t. algoritmes en data zo spoedig mogelijk worden opgelost.</p>"},{"location":"maatregelen/7-mon-03-informatiebeveiligingsincidenten/#toelichting","title":"Toelichting","text":"<p>Er zijn procedures aanwezig die borgen dat beveiligingsincidenten m.b.t. algoritmes en data zo spoedig mogelijk, afhankelijk van de kwalificatie van het incident, worden opgepakt.</p>"},{"location":"maatregelen/7-mon-03-informatiebeveiligingsincidenten/#risico","title":"Risico","text":"<p>Te late reactie op incidenten kan ervoor zorgen dat de BIV (beschikbaarheid, integriteit en vertrouwelijkheid) van het algoritme of data kan worden aangetast.</p>"},{"location":"maatregelen/7-mon-03-informatiebeveiligingsincidenten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemenaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingavg-12 - Beveiliging van de verwerking"},{"location":"maatregelen/7-mon-03-informatiebeveiligingsincidenten/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, BIO 12.3.1.1, 12.3.1.4, 12.3.1.5</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.30</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.06</li> </ul>"},{"location":"maatregelen/7-mon-03-informatiebeveiligingsincidenten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/7-mon-04-evalueer-bij-veranderingen-in-data/","title":"Veranderingen in de data","text":"<p>Monitoring en beheerDataTechnische robuustheid en veiligheid</p>"},{"location":"maatregelen/7-mon-04-evalueer-bij-veranderingen-in-data/#maatregel","title":"Maatregel","text":"<p>Monitor regelmatig op veranderingen in de inputdata. Bij geconstateerde veranderingen evalueer je de prestaties en de output van het algoritme.</p>"},{"location":"maatregelen/7-mon-04-evalueer-bij-veranderingen-in-data/#toelichting","title":"Toelichting","text":"<p>De inputdata kan voortdurend veranderen.  Dat kan komen doordat de context waarin het algoritme wordt gebruikt verandert, of door een technische fout wanneer de data bijvoorbeeld niet goed is ingelezen of aangeleverd.  Het te laat opmerken van zo'n verandering kan grote gevolgen hebben.  Daarom is het belangrijk om regelmatig te controleren en evalueren of:</p> <ul> <li>de data van voldoende kwaliteit is voor de beoogde toepassing</li> <li>of het algoritme nog presteert in lijn met de vastgestelde doelen</li> <li>de gegevens op de juiste en volledige manier worden verwerkt. </li> </ul> <p>Zeker wanneer er gebruikt wordt gemaakt van informatie van derden, is het belangrijk om regelmatig te controleren of er veranderingen in de data zijn. Goede monitoring op datakwaliteit zorgt ervoor dat je voldoende controle hebt over de kwaliteit van de data, zelfs als je hiervoor afhankelijk bent van andere partijen. </p>"},{"location":"maatregelen/7-mon-04-evalueer-bij-veranderingen-in-data/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingavg-05 - Juistheid en actualiteit van gegevens"},{"location":"maatregelen/7-mon-04-evalueer-bij-veranderingen-in-data/#risico","title":"Risico","text":"<p>Door veranderingen in de data presteert het model niet meer zoals verwacht.</p>"},{"location":"maatregelen/7-mon-04-evalueer-bij-veranderingen-in-data/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, DM.8</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.02, 1.08, 2.06, 2.08, 2.13 </li> </ul>"},{"location":"maatregelen/7-mon-04-evalueer-bij-veranderingen-in-data/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/","title":"Meten, monitoren en rapporteren van milieu-impact van algoritmes","text":"<p>mon-05OntwerpMonitoring en beheerOntwikkelaarBeleid en adviesProjectleiderDuurzaamheid</p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#maatregel","title":"Maatregel","text":"<p>Inventariseer en monitor de milieu-impact van algoritmes (bijvoorbeeld door het doen van een impact-assessment), zowel tijdens ontwerp als bij het gebruik, en rapporteer deze om duurzame keuzes mogelijk te maken.</p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#toelichting","title":"Toelichting","text":""},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#digital-product-passports","title":"Digital Product Passports","text":"<p>De milieu-impact van algoritmes kan worden gemeten en geoptimaliseerd door een Digital Product Passport (DPP) te overwegen. DPP's bieden een platform voor duurzame rapportage door middel van real-time informatie over onder andere CO\u2082-uitstoot, herkomst en energiegebruik, wat kan helpen om de ecologische voetafdruk van een algoritme transparant te maken. Door deze gegevens structureel te verzamelen en te delen, kunnen gebruikers en bedrijven inzicht krijgen in de duurzaamheidsprestaties. De milieu-impact van verschillende algoritmes/modellen kan een rol spelen bij het kiezen van een model in de ontwerpfase.</p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#milieu-impact-assessments","title":"Milieu-impact assessments","text":"<p>Wanneer de milieu-impact (in bepaalde mate) inzichtelijk is, kan er een milieu-impact assessment worden gedaan. Ga na of je organisatie die een heeft of overweeg deze te ontwikkelen.</p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#periodieke-monitoring","title":"Periodieke monitoring","text":"<p>Probeer ook periodieke monitoringsrapporten op te stellen waarin de milieu-impact van algoritmes wordt bijgehouden. Hiermee vergroot je de duurzaamheid door tijdig verbeteringen te signaleren en door te voeren. Hierbij kan ook een onderscheid worden gemaakt in de impact tijdens de trainingsfase van het algoritme en de gebruiksfase. </p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"<p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#risico","title":"Risico","text":"<p>Wanneer in de ontwerpfase niet wordt nagedacht over milieu-impact kan onbewust voor een algoritme of model worden gekozen dat meer energie verbruikt (en wellicht hogere kosten met zich mee brengt) dan een model dat misschien even goed presteert voor het gekozen doel. Zonder structurele monitoring van de milieu-impact kan de organisatie onbewust bijdragen aan een hoge CO\u2082-uitstoot en hoge energieverbruikskosten.</p>"},{"location":"maatregelen/7-mon-05-meten-milieu-impact/#bronnen","title":"Bronnen","text":"<ul> <li>Coalitie Duurzame Digitalisering - Digital Product Passport</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk - DM.24</li> <li>Ethische richtsnoeren voor betrouwbare KI, Hoofdstuk II 1.6: Maatschappelijk en milieuwelzijn</li> </ul>"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/","title":"Aansprakelijkheidsvoorwaarden worden beoordeeld in de aanbesteding","text":"<p>ProbleemanalyseImplementatieJuristPublieke inkoop</p>"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#maatregel","title":"Maatregel","text":"<p>Maak de aansprakelijkheidsvoorwaarden die een aanbieder ten aanzien van auteursrechten kan geven een vast onderdeel van de wedstrijd/inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan.</p>"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#toelichting","title":"Toelichting","text":"<p>Eindgebruikers kunnen er niet altijd op vertrouwen, en ook niet (eenvoudig) nagaan, of datgene wat zij door middel van een algoritme of AI-systeem laten genereren, inbreuk maakt op rechten van derden. Hoe groot de kans is dat zij vanwege het gebruik van gegenereerde output aansprakelijk worden gesteld, is in het verlengde daarvan evenmin vast te stellen. Er zijn wel voorbeelden waarbij gebruikers voor een eventuele inbreuk aansprakelijk kunnen worden gesteld.</p> <p>Op dit moment zijn ons (nog) geen gevallen of rechtszaken bekend waarin eindgebruikers (of hun werkgevers) aansprakelijk werden gesteld voor een inbreuk op het intellectuele-eigendomsrecht vanwege het gebruik van op basis van algoritme of AI gegenereerde inhoud. Feit is echter wel dat een dergelijke aansprakelijkstelling in voorkomende gevallen dus mogelijk zullen zijn, te meer nu de aanbieders van algoritmen en AI in hun algemene voorwaarden het risico voor aansprakelijkheid (waaronder vanwege inbreuken op intellectuele eigendom) volledig of grotendeels uitsluiten, of zelfs verlangen dat gebruikers hen vrijwaren voor de gevolgen van eventuele aansprakelijkstellingen.</p> <p>Maak een beoordeling in hoeverre de aansprakelijkheidsvoorwaarden van de aanbieder passend worden geacht gezien de toepassing. Maak een jurist onderdeel van de beoordeling hiervan.</p>"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat"},{"location":"maatregelen/aansprakelijkheidsvoorwaarden_aanbieder_onderdeel_beoordelingsmatrix/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/","title":"Bepaal of de output bepalende invloed heeft in een besluit richting personen","text":"<p>OntwikkelenMonitoring en beheerProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#maatregel","title":"Maatregel","text":"<p>Ga na of het algoritme of AI-systeem bepalende invloed heeft in een besluit richting personen en laat aanbieder onderbouwen in hoeverre dit wel of niet het geval is. Maak de mate van menselijke tussenkomst onderdeel van de inkoop-/beoordeelingsmatrix.</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#toelichting","title":"Toelichting","text":"<p>Maak een beoordeling in hoeverre de mate waarin menselijke tussenkomst is of kan worden gerealiseerd. Raadpleeg voor deze beoordeling verschillende experts, zoals een gebruiker, proceseigenaar, ethicus en jurist.</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-10 - Recht op niet geautomatiseerde besluitvorming"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#bronnen","title":"Bronnen","text":"<p>||</p>"},{"location":"maatregelen/bepalende_invloed_besluit_richting_personen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/","title":"Bespreek de vereiste met aanbieder of opdrachtnemer","text":"<p>OntwerpOntwikkelenProjectleiderPublieke inkoop</p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#maatregel","title":"Maatregel","text":"<p>Bespreek de vereiste met aanbieder. </p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#toelichting","title":"Toelichting","text":"<p>Ga met een aanbieder en/of met opdrachtnemers in gesprek over in hoeverre deze invulling heeft gegeven of gaat geven aan de vereiste. Op basis van nieuwe of gewijzigde wet- en regelgeving is het denkbaar dat een aanbieder van algoritmes of AI-systemen nog niet of niet meer voldoet aan deze vereiste. Indien van toepassing, laat de aanbieder inzichtelijk maken welke stappen deze gaat zetten om hieraan te gaan voldoen. Dit is ook relevant bij reeds afgesloten contracten.  </p>"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-02 - Documentatie beoordeling niet-hoog-risico AIaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06 - Technische documentatie voor hoog-risico AIaia-07 - Automatische logregistratie voor hoog-risico AIaia-08 - Transparantie in ontwerp voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-12 - Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13 - Bewaartermijn voor gegenereerde logsaia-14 - Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15 - Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-16 - Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17 - Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-18 - Corrigerende maatregelen voor non-conforme AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekaia-21-aantoonbaarheid-vereisten-hoog-risicoaia-28 - Recht op uitleg AI-besluitenaia-29 - Beoordeling van grondrechtenaia-30 - Transparantieverplichtingenaia-31 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32 - Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-35 - Verdere verwerking van persoonsgegevens in AI-testomgevingenaia-36 - Monitoring na het in handel brengenaia-37 - Melden van ernstige incidentenaia-38 - Veilig melden van inbreuk op AI verordeningaia-39 - Klachtrecht aanbieders verder in AI-waardeketenbzk-01 - Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisterarc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01 - Auteursrechten mogen niet worden geschondenavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02 - Beperkte bewaartermijn van persoonsgegevensavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-04 - Proportionaliteit en subsidiariteitavg-05 - Juistheid en actualiteit van gegevensavg-06 - Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-07 - Transparantie bij verwerking persoonsgegevensavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-09 - Privacyrechtenavg-10 - Recht op niet geautomatiseerde besluitvormingavg-11 - Privacy door ontwerpavg-12 - Beveiliging van de verwerkingavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01 - Relevante feiten en belangen zijn bekendawb-02 - Een besluit berust op een deugdelijke motiveringbio-01 - Beveiliging informatie en informatiesystemendat-01 - Verbod op schenden databankenrechtengrw-01 - Beschermen van fundamentele rechten en vrijhedengrw-02 - AI-systemen en algoritmes mogen niet discriminerenwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/bespreek_vereiste_met_aanbieder/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/","title":"Contractuele afspraken over data en artefacten","text":"<p>OntwerpMonitoring en beheerJuristPublieke inkoop</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#maatregel","title":"Maatregel","text":"<p>Maak (contractuele) afspraken met de aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmen en AI-systemen.</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#toelichting","title":"Toelichting","text":"<p>Hier kan worden gedacht aan de initi\u00eble trainingsdataset, outputdata (richting gebruikers) en nieuwe trainingsdata (vanuit gebruikers).</p>"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/contractuele_afspraken_data_en_artefacten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/","title":"Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.","text":"<p>OntwerpOntwikkelenProjectleiderPublieke inkoop</p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#maatregel","title":"Maatregel","text":"<p>Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.</p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#toelichting","title":"Toelichting","text":"<p>Om op een betekenisvolle manier invulling te geven aan bepaalde vereisten, kan het noodzakelijk zijn dat de opdrachtgever en aanbieder/opdrachtnemer (innovatief) moeten samenwerken. Op basis van nieuwe wet- en regelgeving (bv. AI-Verordening) kunnen aanbieders mogelijk nog niet voldoen aan deze nieuwe vereisten of is onduidelijk op welke manier hier invulling aan moet worden gegeven.  In de context van algoritmes en AI kan het voor bepaalde onderwerpen zoals non-discriminatie, transparantie en eerbiedigen van fundamentele rechten van belang zijn om samen te verkennen hoe hier invulling aan moet worden gegeven. Het is belangrijk om bij de behoeftestelling al te verkennen op welke onderwerpen dit mogelijk van toepassing is. </p>"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-02 - Documentatie beoordeling niet-hoog-risico AIaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06 - Technische documentatie voor hoog-risico AIaia-07 - Automatische logregistratie voor hoog-risico AIaia-08 - Transparantie in ontwerp voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-12 - Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13 - Bewaartermijn voor gegenereerde logsaia-14 - Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15 - Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-16 - Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17 - Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-18 - Corrigerende maatregelen voor non-conforme AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekaia-21-aantoonbaarheid-vereisten-hoog-risicoaia-28 - Recht op uitleg AI-besluitenaia-29 - Beoordeling van grondrechtenaia-30 - Transparantieverplichtingenaia-31 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32 - Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-35 - Verdere verwerking van persoonsgegevens in AI-testomgevingenaia-36 - Monitoring na het in handel brengenaia-37 - Melden van ernstige incidentenaia-38 - Veilig melden van inbreuk op AI verordeningaia-39 - Klachtrecht aanbieders verder in AI-waardeketenbzk-01 - Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisterarc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01 - Auteursrechten mogen niet worden geschondenavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02 - Beperkte bewaartermijn van persoonsgegevensavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-04 - Proportionaliteit en subsidiariteitavg-05 - Juistheid en actualiteit van gegevensavg-06 - Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-07 - Transparantie bij verwerking persoonsgegevensavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-09 - Privacyrechtenavg-10 - Recht op niet geautomatiseerde besluitvormingavg-11 - Privacy door ontwerpavg-12 - Beveiliging van de verwerkingavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01 - Relevante feiten en belangen zijn bekendawb-02 - Een besluit berust op een deugdelijke motiveringbio-01 - Beveiliging informatie en informatiesystemendat-01 - Verbod op schenden databankenrechtengrw-01 - Beschermen van fundamentele rechten en vrijhedengrw-02 - AI-systemen en algoritmes mogen niet discriminerenwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Ruimte voor Innovatie in het contract"},{"location":"maatregelen/creeer_ruimte_voor_samenwerking_in_contract/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/","title":"Verken maatregelen van aanbieder om schending auteursrechten te voorkomen","text":"<p>ProbleemanalyseImplementatieProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#maatregel","title":"Maatregel","text":"<p>Verken of aanbieder maatregelen heeft genomen om te voorkomen dat auteursrechten worden geschonden.</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#toelichting","title":"Toelichting","text":"<p>Als 'open gaten' worden ervaren, dan is het van belang om hierover met de aanbieder in gesprek te gaan, bijvoorbeeld door een marktconsultatie of algemene materie gerelateerde gesprekken. De ARVODI (24.7) en ARBIT (art 8.5 &amp; 8.6) adresseren het schenden van intellectueel eigendom.</p>"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#bronnen","title":"Bronnen","text":"Bron ARVODI (24.7) en ARBIT (art 8.5 &amp; 8.6) Algoritmekader"},{"location":"maatregelen/getroffen_maatregelen_van_aanbieder_voorkomen_schending_auteursrechten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/","title":"Bewijs laten leveren dat auteursrechten niet worden geschonden met de output","text":"<p>OntwerpMonitoring en beheerProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#maatregel","title":"Maatregel","text":"<p>Maak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden door de output een vast onderdeel van de inkoop/beoordeelingsmatrix als ook de vaste beoordeling.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#toelichting","title":"Toelichting","text":"<p>Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen of de output van een algoritme een (potenti\u00eble) inbreuk maakt op auteursrechten. Maak een jurist onderdeel van de beoordeling hiervan.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_output/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/","title":"Bewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdata","text":"<p>OntwerpMonitoring en beheerProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#maatregel","title":"Maatregel","text":"<p>Maak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden doordat de trainingsdata rechtmatig is verkregen een vast onderdeel van de inkoop/beoordeelingsmatrix als ook de vaste beoordeling hiervan door tenminste ook een jurist.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#toelichting","title":"Toelichting","text":"<p>Algoritmen en AI worden veelal getraind aan de hand van een omvangrijke hoeveelheid data. Op basis van de data wordt het algoritme of AI getraind om, op een later moment, de (door de eindgebruiker gewenste) uitkomsten te kunnen genereren.</p> <p>Wanneer grote hoeveelheden data, bijvoorbeeld door deze te scrapen van internet, worden gebruikt voor de training van algoritmen of AI, is het zeer aannemelijk (of: nagenoeg zeker) dat zich onder de gescrapete inhoud (ook) veel auteursrechtelijk beschermde werken bevinden, zoals bijvoorbeeld e-books en afbeeldingen. De gebruikte auteursrechtelijke werken kunnen soms bijvoorbeeld uit illegale bron verkregen zijn, en ook los daarvan zijn rechthebbenden veelal niet op de hoogte van het feit dat hun auteursrechtelijke werken voor de ontwikkeling van een algoritme of AI gebruikt worden.</p> <p>Onder auteursrechtjuristen wordt aangenomen dat het gebruik van auteursrechtelijke beschermde werken ter training van algoritme of AI (waarschijnlijk) een verveelvoudigingshandeling is die de rechthebbende kan verbieden. Dat betekent dat aanbieders van algoritmen en AI het gebruik van auteursrechtelijk beschermd materiaal in de inputfase steeds zullen moeten kunnen legitimeren op grond van (a) toestemming van de rechthebbende(n) of (b) een in de wet neergelegde exceptie op het auteursrechtelijke verveelvoudigingsrecht.</p> <p>Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen op welke manier de trainingsdata is verkregen en of dit rechtmatig was. Maak een jurist onderdeel van de beoordeling hiervan. Overweeg om een bronvermelding te laten opnemen.</p>"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat"},{"location":"maatregelen/leveren_bewijs_niet_schenden_auteursrechten_trainingsdata/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/","title":"Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving","text":"<p>OntwerpOntwikkelenProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#maatregel","title":"Maatregel","text":"<p>Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving</p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#toelichting","title":"Toelichting","text":"<p>Door de inschrijver/aanbieder bewijs te laten leveren dat deze voldoet aan de vereiste, kan worden beoordeeld door opdrachtgever in hoeverre daadwerkelijk wordt voldaan aan deze vereiste. Op deze manier worden inschrijvers/aanbieders aangespoord om te motiveren wat zij hebben gedaan om te voldoen aan de vereiste.  </p>"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-28 - Recht op uitleg AI-besluitenaut-01 - Auteursrechten mogen niet worden geschondendat-01 - Verbod op schenden databankenrechtenaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-01 - Bevorder AI-geletterdheid van personeel en gebruikersaia-18 - Corrigerende maatregelen voor non-conforme AIavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensgrw-01 - Beschermen van fundamentele rechten en vrijhedenaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-29 - Beoordeling van grondrechtengrw-02 - AI-systemen en algoritmes mogen niet discriminerenavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-11 - Privacy door ontwerpavg-10 - Recht op niet geautomatiseerde besluitvormingaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersaia-08 - Transparantie in ontwerp voor hoog-risico AIavg-07 - Transparantie bij verwerking persoonsgegevensaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/leveren_bewijs_onderdeel_beoordeling_inschrijving.md/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/","title":"Maak de vereiste onderdeel van het programma van eisen","text":"<p>OntwerpOntwikkelenProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van het programma van eisen</p>"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#toelichting","title":"Toelichting","text":"<p>Door de vereiste onderdeel te maken van het programma van eisen, is het voor aanbieders duidelijk dat hun oplossing hieraan moet voldoen.  Afhankelijk van de specifieke toepassing, context en noodzaak kan een vereiste in het programma van eisen concreet worden gemaakt.  Het is hierbij van belang om dit af te wegen tegen zaken die mogelijk al zijn geregeld door middel van algemene inkoopvoorwaarden die gelden voor algoritmes en AI.   </p>"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-02 - Documentatie beoordeling niet-hoog-risico AIaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06 - Technische documentatie voor hoog-risico AIaia-07 - Automatische logregistratie voor hoog-risico AIaia-08 - Transparantie in ontwerp voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-12 - Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13 - Bewaartermijn voor gegenereerde logsaia-14 - Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15 - Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-16 - Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17 - Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-18 - Corrigerende maatregelen voor non-conforme AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekaia-21-aantoonbaarheid-vereisten-hoog-risicoaia-28 - Recht op uitleg AI-besluitenaia-29 - Beoordeling van grondrechtenaia-30 - Transparantieverplichtingenaia-31 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32 - Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-35 - Verdere verwerking van persoonsgegevens in AI-testomgevingenaia-36 - Monitoring na het in handel brengenaia-37 - Melden van ernstige incidentenaia-38 - Veilig melden van inbreuk op AI verordeningaia-39 - Klachtrecht aanbieders verder in AI-waardeketenbzk-01 - Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisterarc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01 - Auteursrechten mogen niet worden geschondenavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02 - Beperkte bewaartermijn van persoonsgegevensavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-04 - Proportionaliteit en subsidiariteitavg-05 - Juistheid en actualiteit van gegevensavg-06 - Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-07 - Transparantie bij verwerking persoonsgegevensavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-09 - Privacyrechtenavg-10 - Recht op niet geautomatiseerde besluitvormingavg-11 - Privacy door ontwerpavg-12 - Beveiliging van de verwerkingavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01 - Relevante feiten en belangen zijn bekendawb-02 - Een besluit berust op een deugdelijke motiveringbio-01 - Beveiliging informatie en informatiesystemendat-01 - Verbod op schenden databankenrechtengrw-01 - Beschermen van fundamentele rechten en vrijhedengrw-02 - AI-systemen en algoritmes mogen niet discriminerenwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/maak_de_vereiste_onderdeel_van_programma_van_eisen/#voorbeeld","title":"Voorbeeld","text":""},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/","title":"Maak de vereiste onderdeel van de contractovereenkomst","text":"<p>OntwerpOntwikkelenProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van de contractovereenkomst </p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#toelichting","title":"Toelichting","text":"<p>Door de vereiste onderdeel te namen van de contractovereenkomst, zijn deze voorwaarden voor opdrachtgever richting aanbieder/opdrachtnemer afdwingbaar. Het is van belang dat bij de behoeftestelling een afweging wordt gemaakt in hoeverre de betreffende vereiste van toepassing is. </p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-02 - Documentatie beoordeling niet-hoog-risico AIaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06 - Technische documentatie voor hoog-risico AIaia-07 - Automatische logregistratie voor hoog-risico AIaia-08 - Transparantie in ontwerp voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-12 - Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13 - Bewaartermijn voor gegenereerde logsaia-14 - Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15 - Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-16 - Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17 - Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-18 - Corrigerende maatregelen voor non-conforme AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekaia-21-aantoonbaarheid-vereisten-hoog-risicoaia-28 - Recht op uitleg AI-besluitenaia-29 - Beoordeling van grondrechtenaia-30 - Transparantieverplichtingenaia-31 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32 - Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-35 - Verdere verwerking van persoonsgegevens in AI-testomgevingenaia-36 - Monitoring na het in handel brengenaia-37 - Melden van ernstige incidentenaia-38 - Veilig melden van inbreuk op AI verordeningaia-39 - Klachtrecht aanbieders verder in AI-waardeketenbzk-01 - Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisterarc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01 - Auteursrechten mogen niet worden geschondenavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02 - Beperkte bewaartermijn van persoonsgegevensavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-04 - Proportionaliteit en subsidiariteitavg-05 - Juistheid en actualiteit van gegevensavg-06 - Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-07 - Transparantie bij verwerking persoonsgegevensavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-09 - Privacyrechtenavg-10 - Recht op niet geautomatiseerde besluitvormingavg-11 - Privacy door ontwerpavg-12 - Beveiliging van de verwerkingavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01 - Relevante feiten en belangen zijn bekendawb-02 - Een besluit berust op een deugdelijke motiveringbio-01 - Beveiliging informatie en informatiesystemendat-01 - Verbod op schenden databankenrechtengrw-01 - Beschermen van fundamentele rechten en vrijhedengrw-02 - AI-systemen en algoritmes mogen niet discriminerenwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Contractvoorwaarden gemeente Amsterdam Europese Inkoopvoorwaarden Hoog Risico Europese Inkoopvoorwaarden Laag Risico"},{"location":"maatregelen/maak_vereiste_onderdeel_van_contractovereenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/","title":"Maak de vereiste onderdeel van Service Level Agreement","text":"<p>OntwerpOntwikkelenPublieke inkoop</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van Service Level Agreement</p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#toelichting","title":"Toelichting","text":"<p>Onderzoek of het relevant is om de vereiste onderdeel te maken van de Service Level Agreement (SLA).  Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening.  Hierbij kan worden gedacht aan onderwerpen als incidentmanagement, servicemanagement, verantwoordelijkheden matrix, hersteltijd, prestatiecriteria, reproduceerbaarheid, versiebeheer van de gebruikte algoritmes en AI-modellen en beveiliging.  Laat de aanbieder aangeven welke vormen van onderhoud aan het algoritme of AI-systeem nodig zijn en de snelheid waarmee signalen vanuit gebruik, ongeacht de bron, kunnen worden verwerkt in het systeem en welke expertise hiervoor beschikbaar is. </p>"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemenavg-12 - Beveiliging van de verwerkingaia-37 - Melden van ernstige incidentenaia-07 - Automatische logregistratie voor hoog-risico AIaia-01 - Bevorder AI-geletterdheid van personeel en gebruikersaia-18 - Corrigerende maatregelen voor non-conforme AIaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-36 - Monitoring na het in handel brengenaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersavg-07 - Transparantie bij verwerking persoonsgegevensaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#bronnen","title":"Bronnen","text":"Bron Onderzoekskader Algoritmes Auditdienst Rijk, SV.11 Algoritmekader"},{"location":"maatregelen/maak_vereiste_onderdeel_van_service_level_agreement/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/maak_vereisten_voor_algoritmes_en_AI-systemen_onder_van_contractvoorwaarden/","title":"Maak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaarden","text":"<p>OntwerpOntwikkelenProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"maatregelen/maak_vereisten_voor_algoritmes_en_AI-systemen_onder_van_contractvoorwaarden/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van contractvoorwaarden </p>"},{"location":"maatregelen/maak_vereisten_voor_algoritmes_en_AI-systemen_onder_van_contractvoorwaarden/#toelichting","title":"Toelichting","text":"<ul> <li>Er moeten heldere afspraken zijn gemaakt met de aanbieder van het algoritme of AI-systeem. Dit geldt in het bijzonder als het algorimte of AI-systeem is ontwikkeld door een externe aanbieder.</li> <li>Door vereisten die gelden voor algoritmes en AI-systemen onderdeel te maken van contractvoorwaarden, is voor aanbieder vooraf duidelijk aan welke voorwaarden zij moeten voldoen als zijn algoritmes en AI-systemen willen aanbieden aan overheidsorganisaties.</li> <li>Het is van belang om een afweging te maken in welke gevallen de contractvoorwaarden worden ingezet en welke vereisten daar onderdeel van moeten worden gemaakt.</li> <li>Welke vereisten onderdeel moeten worden gemaakt van contractvoorwaarden is afhankelijk van de beoogde toepassing, de technologie en de bijbehorende risicoclassificatie.</li> <li>Er zijn meer vereiste van toepassing bij impactvolle en hoog risico AI-systemen, waarmee burgers potentieel in aanmerkelijke mate kunnen worden getroffen dan bij geen impactvolle of laag risico AI-systemen. </li> </ul>"},{"location":"maatregelen/maak_vereisten_voor_algoritmes_en_AI-systemen_onder_van_contractvoorwaarden/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-02 - Documentatie beoordeling niet-hoog-risico AIaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06 - Technische documentatie voor hoog-risico AIaia-07 - Automatische logregistratie voor hoog-risico AIaia-08 - Transparantie in ontwerp voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-12 - Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13 - Bewaartermijn voor gegenereerde logsaia-14 - Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15 - Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-16 - Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17 - Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-18 - Corrigerende maatregelen voor non-conforme AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekaia-21-aantoonbaarheid-vereisten-hoog-risicoaia-28 - Recht op uitleg AI-besluitenaia-29 - Beoordeling van grondrechtenaia-30 - Transparantieverplichtingenaia-31 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32 - Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-35 - Verdere verwerking van persoonsgegevens in AI-testomgevingenaia-36 - Monitoring na het in handel brengenaia-37 - Melden van ernstige incidentenaia-38 - Veilig melden van inbreuk op AI verordeningaia-39 - Klachtrecht aanbieders verder in AI-waardeketenbzk-01 - Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisterarc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01 - Auteursrechten mogen niet worden geschondenavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02 - Beperkte bewaartermijn van persoonsgegevensavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-04 - Proportionaliteit en subsidiariteitavg-05 - Juistheid en actualiteit van gegevensavg-06 - Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-07 - Transparantie bij verwerking persoonsgegevensavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-09 - Privacyrechtenavg-10 - Recht op niet geautomatiseerde besluitvormingavg-11 - Privacy door ontwerpavg-12 - Beveiliging van de verwerkingavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01 - Relevante feiten en belangen zijn bekendawb-02 - Een besluit berust op een deugdelijke motiveringbio-01 - Beveiliging informatie en informatiesystemendat-01 - Verbod op schenden databankenrechtengrw-01 - Beschermen van fundamentele rechten en vrijhedengrw-02 - AI-systemen en algoritmes mogen niet discriminerenwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/maak_vereisten_voor_algoritmes_en_AI-systemen_onder_van_contractvoorwaarden/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Onderzoekskader Algoritmes Auditdienst Rijk, SV.11"},{"location":"maatregelen/maak_vereisten_voor_algoritmes_en_AI-systemen_onder_van_contractvoorwaarden/#voorbeeld","title":"Voorbeeld","text":"<ul> <li>Contractvoorwaarden gemeente Amsterdam</li> <li>Europese Inkoopvoorwaarden Hoog Risico </li> <li>Europese Inkoopvoorwaarden Laag Risico</li> </ul> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/","title":"Menselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocument","text":"<p>ProbleemanalyseOntwikkelenMonitoring en beheerProjectleiderBeleid en adviesGovernancePublieke inkoop</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#maatregel","title":"Maatregel","text":"<p>Neem het element van menselijke tussenkomst op in het projectplan en d\u00e9chargedocument.</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#toelichting","title":"Toelichting","text":"<p>Dit punt is onderdeel van een procesinrichting bij de gebruiksverantwoordelijke of gebruiker van het altgoritme of AI-systeem en zou technisch gefaciliteerd moeten kunnen worden. Het inrichten van menselijke tussenkomst ligt niet enkel bij de aanbieder en kan contractueel niet enkel bij de aanbieder worden neergelegd. Overweeg om een waarschuwingsplicht te expliciteren, in geval de aanbieder ziet dat geautomatiseerde besluiten aan geautomatiseerde berichtgeving is gekoppeld zonder menselijke tussenkomst. Ook dan ligt het in beginsel bij de gebruiksverantwoordelijke, maar maken de omstandigheden een grijzer gebied.</p>"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteavg-10 - Recht op niet geautomatiseerde besluitvorming"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/menselijke_tussenkomst_projectplan_en_dchargedocument/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/","title":"Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.","text":"<p>OntwerpOntwikkelenOntwikkelaarPublieke inkoop</p>"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#maatregel","title":"Maatregel","text":"<p>Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding. </p>"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#toelichting","title":"Toelichting","text":"<p>Door de vereiste op te nemen als subgunningscriteria, ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden. In de context van algoritmes en AI is dit in het bijzonder relevant, bijvoorbeeld in relatie tot vereisten als non-discriminatie, eerbiedigen privacyrechten of het verbod op schenden auteursrechten. Door vereisten te vertalen naar een subgunningscriteria, kan een inhoudelijke beoordeling worden gemaakt in hoeverre een aanbieder hier invulling aan geeft.</p>"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-28 - Recht op uitleg AI-besluitenaut-01 - Auteursrechten mogen niet worden geschondendat-01 - Verbod op schenden databankenrechtenaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-01 - Bevorder AI-geletterdheid van personeel en gebruikersaia-18 - Corrigerende maatregelen voor non-conforme AIavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensgrw-01 - Beschermen van fundamentele rechten en vrijhedenaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-29 - Beoordeling van grondrechtengrw-02 - AI-systemen en algoritmes mogen niet discriminerenavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-11 - Privacy door ontwerpavg-10 - Recht op niet geautomatiseerde besluitvormingaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-09 - Toezichtmogelijkheden voor gebruikersaia-08 - Transparantie in ontwerp voor hoog-risico AIavg-07 - Transparantie bij verwerking persoonsgegevensaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/neem_vereiste_op_als_subgunningscriteria/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/","title":"Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaakt","text":"<p>OntwikkelenVerificatie en validatieProjectleiderPublieke inkoop</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#maatregel","title":"Maatregel","text":"<p>Maak in de beoordelingsmatrix, beoordeling, beoordelingsproces en/of werkwijze van beoordelingscommissies helder op welke wijze c.q. volgens welk proces wordt omgegaan met mogelijke onvermijdelijk resterende auteursrechtelijke risico's, het vaststellen van de onvermijdelijkheid en hoe deze resterende risico's in de beoordeling werking hebben of kunnen hebben.</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat de resterende risico's inzichtelijk zijn gemaakt, zodat aanbieder en gebruiksverantwoordelijke maatregelen kunnen treffen en handelen als dit nodig is.</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#bronnen","title":"Bronnen","text":"<p>| |</p>"},{"location":"maatregelen/omgaan_restrisico%27s_aanbiede_onderdeel_beoordelingsmaatrix/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/risico-analyse_informatiebeveiliging_leverancier/","title":"Voer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstraject","text":"<p>OntwerpOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerProjectleiderTechnische robuustheid en veiligheidPublieke inkoop</p>"},{"location":"maatregelen/risico-analyse_informatiebeveiliging_leverancier/#maatregel","title":"Maatregel","text":"<p>Voer een risico-analyse uit op het gebied van informatiebeveiliging bij een uitbestedingstraject</p>"},{"location":"maatregelen/risico-analyse_informatiebeveiliging_leverancier/#toelichting","title":"Toelichting","text":"<ul> <li>Stel vast of een leverancier voldoet aan de Baseline Informatiebeveiliging Overheid.</li> <li>Bespreek de informatiebeveiligingseisen met een eventuele leverancier die verband houden met de beschikbaarheid, integriteit en vertrouwelijkheid van de informatie en de informatiesystemen.</li> <li>Bepaal of er, mede gezien de inzet van algoritmes en AI-systemen, aanvullende beveiligingsmaatregelen (door de leverancier of opdrachtgever) moeten worden getroffen om deze te beschermen.</li> </ul>"},{"location":"maatregelen/risico-analyse_informatiebeveiliging_leverancier/#risico","title":"Risico","text":"<p>Wanneer een (externe) leverancier beveiligingseisen niet op orde heeft, is er een risico op de BIV (beschikbaarheid, integriteit en vertrouwelijkheid) van het algoritme en/of de data.</p>"},{"location":"maatregelen/risico-analyse_informatiebeveiliging_leverancier/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereistebio-01 - Beveiliging informatie en informatiesystemen"},{"location":"maatregelen/risico-analyse_informatiebeveiliging_leverancier/#bronnen","title":"Bronnen","text":"Bron Baseline Informatiebeveiliging Overheid, BIO 15.1.1.1 Onderzoekskader Algoritmes Auditdienst Rijk, IB.29"},{"location":"maatregelen/risico-analyse_informatiebeveiliging_leverancier/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/","title":"Garantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de output","text":"<p>OntwikkelenMonitoring en beheerProjectleiderJuristPublieke inkoop</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#maatregel","title":"Maatregel","text":"<p>Neem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de output van het algoritme of AI-systeem en dat hij dit gedurende de ontwikkeling en levensduur actief bewaakt.</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#toelichting","title":"Toelichting","text":"<p>Laat de aanbieder die actieve bewaking in zijn aanbieding omschrijven en neem het op in de beoordeling. oor zover van toepassing, laat deze omschrijving helder onderscheid maken in bewaking tijdens ontwikkeling (richting aan de maker), selectie (richting aan de koper), gebruik (richting aan de gebruiker/exploitant) en/of de output (richting aan het algoritme/AI-systeem). Dit kan aanvullend als specialis op bijvoorbeeld voorwaarden die in de ARBIT of ARVODI zijn opgenomen.</p> <p>Het is moeilijk om te bepalen wanneer en of de output van een algoritme of AI een inbreuk maakt op auteursrechten. Reden hiervoor is dat onduidelijk is of de uiteindelijk gegenereerde output naar auteursrechtelijke maatstaven (of in andere gevallen: naar maatstaven van andere intellectuele-eigendomsrechten, zoals databankenrechten, merkrechten of modelrechten) voldoende afstand houdt van (onder andere) de originele werken die ooit aan de training van de generatieve AI-tool ten grondslag hebben gelegen. Is dat niet het geval, dan kan bij veel vormen van gebruik van de output immers sprake zijn van een inbreuk op intellectuele eigendomsrechten.</p>"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat"},{"location":"maatregelen/schending_auteursrechten_output_onderdeel_conceptovereenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/","title":"Garantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdata","text":"<p>OntwerpMonitoring en beheerProjectleiderJuristPublieke inkoop</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#maatregel","title":"Maatregel","text":"<p>Neem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten met de verwerkte of te verwerken trainingsdata niet zullen worden geschonden en deze dit gedurende de ontwikkeling en levensduur actief bewaakt.</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#toelichting","title":"Toelichting","text":"<p>Laat de aanbieder die actieve bewaking in zijn aanbieding omschrijven en neem het op in de beoordeling. Voor zover van toepassing, laat deze omschrijving helder onderscheid maken in bewaking tijdens ontwikkeling (richting aan de maker), selectie (richting aan de koper), gebruik (richting aan de gebruiker/exploitant) en/of de output (richting aan het algoritme/AI-systeem). Dit kan aanvullend als specialis op bijvoorbeeld voorwaarden die in de ARBIT of ARVODI zijn opgenomen.</p>"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaut-01 - Auteursrechten mogen niet worden geschonden"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#bronnen","title":"Bronnen","text":"Bron ARVODI (24.7) en ARBIT (art 8.5 &amp; 8.6) Algoritmekader"},{"location":"maatregelen/schending_auteursrechten_trainingsdata_onderdeel_conceptovereenkomst/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/","title":"Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst","text":"<p>OntwerpOntwikkelenProjectleiderJuristPublieke inkoop</p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#maatregel","title":"Maatregel","text":"<p>Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst </p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat opdrachtgever mogelijkheden heeft om te controleren in hoeverre door aanbieder/opdrachtnemer wordt voldaan aan naleving van de contractvoorwaarden</p>"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-02 - Documentatie beoordeling niet-hoog-risico AIaia-03 - Verplicht risicobeheersysteem voor hoog-risico AIaia-04 - Risicobeoordeling voor jongeren en kwetsbarenaia-05 - Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-06 - Technische documentatie voor hoog-risico AIaia-07 - Automatische logregistratie voor hoog-risico AIaia-08 - Transparantie in ontwerp voor hoog-risico AIaia-09 - Toezichtmogelijkheden voor gebruikersaia-10 - Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-11 - Kwaliteitsbeheersysteem voor hoog-risico AIaia-12 - Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13 - Bewaartermijn voor gegenereerde logsaia-14 - Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uitaia-15 - Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring opaia-16 - Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17 - Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-18 - Corrigerende maatregelen voor non-conforme AIaia-19 - Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-20-verstrekken-van-informatie-op-verzoekaia-21-aantoonbaarheid-vereisten-hoog-risicoaia-28 - Recht op uitleg AI-besluitenaia-29 - Beoordeling van grondrechtenaia-30 - Transparantieverplichtingenaia-31 - Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32 - Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijaia-34 - Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-35 - Verdere verwerking van persoonsgegevens in AI-testomgevingenaia-36 - Monitoring na het in handel brengenaia-37 - Melden van ernstige incidentenaia-38 - Veilig melden van inbreuk op AI verordeningaia-39 - Klachtrecht aanbieders verder in AI-waardeketenbzk-01 - Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisterarc-01 - De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01 - Auteursrechten mogen niet worden geschondenavg-01 - Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02 - Beperkte bewaartermijn van persoonsgegevensavg-03 - Persoonsgegevens verzamelen voor specifieke doeleindenavg-04 - Proportionaliteit en subsidiariteitavg-05 - Juistheid en actualiteit van gegevensavg-06 - Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-07 - Transparantie bij verwerking persoonsgegevensavg-08 - Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-09 - Privacyrechtenavg-10 - Recht op niet geautomatiseerde besluitvormingavg-11 - Privacy door ontwerpavg-12 - Beveiliging van de verwerkingavg-13 - Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personenawb-01 - Relevante feiten en belangen zijn bekendawb-02 - Een besluit berust op een deugdelijke motiveringbio-01 - Beveiliging informatie en informatiesystemendat-01 - Verbod op schenden databankenrechtengrw-01 - Beschermen van fundamentele rechten en vrijhedengrw-02 - AI-systemen en algoritmes mogen niet discriminerenwoo-01 - Eenieder heeft recht op toegang tot publieke informatie"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#bronnen","title":"Bronnen","text":"Bron Algoritmekader Contractvoorwaarden gemeente Amsterdam Europese Inkoopvoorwaarden Hoog Risico Europese Inkoopvoorwaarden Laag Risico"},{"location":"maatregelen/uitvoeren_audit_voor_naleving_vereiste/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/","title":"Vul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijke","text":"<p>OntwerpMonitoring en beheerProjectleiderOntwikkelaarPublieke inkoop</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#maatregel","title":"Maatregel","text":"<p>Bespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het algoritme of AI-systeem door welke partij (intern/extern) moeten worden ingevuld of aangevuld.</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#toelichting","title":"Toelichting","text":"<p>Bij publieke inkoop is het nodig duidelijke afspraken te hebben over wie dit document invult en welke informatie bij welke partij vandaan komt. De aanbieder zal een belangrijk deel van de technische documentatie moeten aanleveren, maar bij gebruik door de gebruiksverantwoordelijken zal deze informatie moeten worden aangevuld.</p> <p>Hierbij is het van belang dat de documentatie aansluit bij de verschillende gebruikers van het systeem, waarbij rekening wordt gehouden met verschillende toepassingen of versies.</p>"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-06:-technische-documentatie"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/vaststellen_aanleveren_informatie_technische_documentatie/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_en_ondersteuning/","title":"De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbesteding","text":"<p>OntwerpMonitoring en beheerProjectleiderPublieke inkoop</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_en_ondersteuning/#maatregel","title":"Maatregel","text":"<p>Laat de aanbieder aangeven welke mate van kennisoverdracht en ondersteuning bij de organisatorische implementatie onderdeel is van de aanbesteding en in hoeverre deze als opleiding of training zelfstandig herhaald kan worden na implementatie als het systeem in productie c.q. in gebruik is.</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_en_ondersteuning/#toelichting","title":"Toelichting","text":"<p>Sommige algoritmen of AI-systemen zijn zeer specialistisch, hierbij is het van belang dat afspraken worden gemaakt in hoeverre ondersteuning bij het gebruik onderdeel is van de inkoop. Hierbij is ook van belang dit onderdeel geactualiseerd wordt gedurende de contractperiode i.v.m. de technologische ontwikkelingen.</p>"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_en_ondersteuning/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-01 - Bevorder AI-geletterdheid van personeel en gebruikers"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_en_ondersteuning/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/vaststellen_benodigde_kennisoverdracht_en_ondersteuning/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/","title":"Vaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen","text":"<p>OntwerpMonitoring en beheerProjectleiderPublieke inkoop</p>"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#maatregel","title":"Maatregel","text":"<p>Laat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren training passend is voor het beoogde doel, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau, zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.</p>"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#toelichting","title":"Toelichting","text":""},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Vereisteaia-01 - Bevorder AI-geletterdheid van personeel en gebruikers"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#bronnen","title":"Bronnen","text":"Bron Algoritmekader"},{"location":"maatregelen/vaststellen_passend_trainingsniveau_door_aanbieder/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"onderwerpen/","title":"Onderwerpen","text":"<ul> <li> <p>Bias en non-discriminatie</p> <p>Hulp bij het voorkomen van bias en discriminatie in algoritmes en AI. Met aanbevelingen en hulpmiddelen zoals het toetsingskader van het College voor de Rechten van de Mens.</p> </li> <li> <p>Data</p> <p>Hulp bij het verantwoord selecteren en verwerken van data voor je algoritmes en AI-systemen. Gebruik bijvoorbeeld de toolbox verantwoord datagebruik.</p> </li> <li> <p>Duurzaamheid</p> <p>Hulp bij het maken van duurzame keuzes voor hardware en software. Bijvoorbeeld voor de aanschaf van apparaten of het energieverbruik van trainen en data-opslag.</p> </li> <li> <p>Governance</p> <p>Hulp bij het verantwoordelijk omgaan met algoritmes en AI-systemen. Bijvoorbeeld het vastleggen van rollen en verantwoordelijkheden.</p> </li> <li> <p>Fundamentele rechten</p> <p>Hulp bij het beschermen van grondrechten en mensenrechten in algoritmes of AI. Bijvoorbeeld het beoordelen van de gevolgen per grondrecht.</p> </li> <li> <p>Menselijke controle</p> <p>Hulp bij de controle als mens over algoritmes en AI-systemen. Bijvoorbeeld kunnen ingrijpen bij onbetrouwbare resultaten.</p> </li> <li> <p>Privacy en gegevensbescherming</p> <p>Hulp bij verantwoord gebruik van gegevens voor algoritmes en AI-systemen, zoals persoonsgegevens en privacygevoelige gegevens.</p> </li> <li> <p>Publieke inkoop</p> <p>Hulp bij het publiek inkopen van software met algoritmen en AI. Met hulpmiddelen zoals modelcontracten en de PIANOo-handreiking Inkoop van algoritmes en AI.</p> </li> <li> <p>Technische robuustheid en veiligheid</p> <p>Hulp bij het bewaken van de prestaties van algoritmes en AI. En beveiliging van de systemen tegen bijvoorbeeld cyberaanvallen.</p> </li> <li> <p>Transparantie</p> <p>Hulp bij transparant zijn over algoritmes en AI-systemen, zoals gebruikers informeren en publiceren in het algoritmeregister.</p> </li> </ul>"},{"location":"onderwerpen/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/","title":"Bias en non-discriminatie","text":"<p>Algoritmes worden binnen de overheid veelvuldig ingezet om publieke taken uit te voeren. Dit biedt veel kansen, maar er zijn ook risico's aan verbonden. Hoewel algoritmes in sommige gevallen kunnen bijdragen aan het tegengaan van discriminatie, kan bias in het algoritme leiden tot een ongelijke en oneerlijke behandeling van burgers of groepen, en kan er sprake zijn van discriminerende effecten.  In dit bouwblok van het algoritmekader besteden we aandacht aan de onderwerpen bias, eerlijkheid en non-discriminatie.  We werken uit wat bias is, hoe bias kan ontstaan, hoe we dit kunnen signaleren, welke maatregelen er genomen kunnen worden om dit te voorkomen en geven we handvatten wat te doen wanneer een (onwenselijke) bias is gesignaleerd. </p> <p>Hierbij is het goed om op te merken dat het omgaan met het thema bias gedurende het ontwikkelen, inkopen of gebruik van het algoritme vraagt om continue aandacht voor dit onderwerp.  Het betreft geen probleem dat eenmalig kan worden weggenomen. Het vraagt voortdurend om reflectie op eerlijkheid en rechtvaardigheid van het systeem. </p> <p>Dit bouwblok wordt uitgewerkt in vereisten die weergeven wat er vanuit wet- en regelgeving en bestaande toetsingskaders vereist is om bias en discriminatie tegen te gaan.  Daarbij worden er suggesties gedaan hoe deze vereisten kunnen worden nageleefd met concrete maatregelen, en welke actoren daarbij betrokken kunnen zijn.  Waar mogelijk worden concrete voorbeelden en best practices uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is. Deze vereisten en maatregelen worden ook gekoppeld aan de algoritme levenscyclus.  Dit geeft een beeld van wanneer bepaalde vereisten of maatregelen, bij het ontwikkelen van algoritmen en AI, moeten worden geadresseerd.   </p> <p>Door bij de ontwikkeling van algoritmes rekening te houden met vereisten die voorkomen uit wet- en regelgeving, het type algoritme of AI en de potenti\u00eble risico\u2019s die ontstaan bij het gebruiken ervan, kunnen negatieve gevolgen worden voorkomen. </p> <p>De onderwerpen bias en non-discriminatie spelen daarom een belangrijke rol bij de totstandkoming van verantwoord ontwikkelde algoritmen en AI en het gebruik daarvan door ambtenaren. </p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#wat-is-discriminatie-en-bias","title":"Wat is discriminatie en bias?","text":""},{"location":"onderwerpen/bias-en-non-discriminatie/#discriminatie","title":"Discriminatie","text":"<p>Artikel 1 van de Nederlandse Grondwet verbiedt discriminatie: </p> <p>Allen die zich in Nederland bevinden, worden in gelijke gevallen gelijk behandeld. Discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, handicap, seksuele gerichtheid of op welke grond dan ook, is niet toegestaan. </p> <p>De prominente positie in de Grondwet benadrukt het belang van het mensenrecht in Nederland.  De afgelopen jaren hebben incidenten in de praktijk de aandacht gericht op de discriminatoire effecten die algoritmes en AI-systemen kunnen hebben.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#bias","title":"Bias","text":"<p>Bias is een Engelse term die in het Nederlands wordt vertaald als vooroordeel, vooringenomenheid of neiging.  Omdat niet \u00e9\u00e9n van die termen helemaal de lading van het begrip bias dekt, maken we in het Algoritmekader gebruik van de term bias.  De term bias heeft verschillende betekenissen afhankelijk van de context waarin het gebruikt wordt en de disciplines die daarbij betrokken zijn.  Vaak wordt er naar bias gekeken als een technisch concept, maar het omvat daarnaast ook menselijke aspecten.  We starten met een verduidelijking hoe het begrip bias in algoritmische context gebruikt wordt en hoe dit in verhouding staat tot discriminatie.  Vervolgens maken we onderscheid tussen drie verschillende aspecten van bias: statistische bias, systemische bias en menselijke bias.  Deze drie aspecten van bias kunnen los van elkaar bestaan, maar kunnen juist in combinatie met elkaar tot problemen leiden. </p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#bias-in-algoritmische-context","title":"Bias in algoritmische context","text":"<p>Het concept bias wordt in algoritmische context gedefinieerd als een systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen.<sup>1</sup></p> <p>Dit systematische verschil of onderscheid kan zowel op een directe als op een indirecte manier ontstaan. </p> <p>De Algemene wet gelijke behandeling spreekt van direct onderscheid wanneer een persoon op een andere wijze wordt behandeld dan een ander in een vergelijkbare situatie wordt, is of zou worden behandeld, op grond van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid <sup>2</sup> of burgerlijke staat.</p> <p>De Algemene wet gelijke behandeling spreekt van indirect onderscheid indien een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaalde godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid <sup>2</sup> of burgerlijke staat in vergelijking met andere personen bijzonder treft. </p> <p>Een geconstateerd systematische onderscheid is niet altijd fout en is niet altijd verboden, maar het vraagt wel altijd om aandacht en zorgvuldigheid.  Het geconstateerde onderscheid kan in bepaalde situaties en onder bepaalde strikte voorwaarden gerechtvaardigd zijn.  Voor direct onderscheid kan er bijvoorbeeld sprake zijn van een wettelijke uitzondering die het gemaakte onderscheid toelaat.  Voor indirect onderscheid geldt dat behalve een wettelijke uitzondering er ook een objectieve rechtvaardiging kan bestaan, waarmee het geconstateerde onderscheid in bepaalde gevallen toelaatbaar kan zijn. </p> <p>Het maken van een eventueel onderscheid is in sommige gevallen nauw verbonden met het gebruik van algoritmes en AI.  Soms worden algoritmes en AI bijvoorbeeld juist ingezet om op een zo objectief mogelijke manier te bepalen welke groepen meer of minder belang hebben bij een andere behandeling.  In deze gevallen zal er altijd na moeten worden gegaan of er sprake is van een objectieve rechtvaardiging voor het gemaakte onderscheid.</p> <p>Wanneer er geen rechtvaardiging is voor het gemaakte onderscheid, spreken we van een verboden direct of indirect onderscheid, ofwel discriminatie.  Het algoritme of AI-systeem mag in dat geval niet gebruikt worden. Bias vormt daarmee een risico op discriminatie.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#fairness","title":"Fairness","text":"<p>In de context van algoritmes en AI wordt de term unfairness gebruikt wanneer er sprake is van een ongerechtvaardigd onderscheid waarbij bepaalde groepen meer bevoordeeld worden dan andere.<sup>3</sup>  In de Nederlandse taal spreken we dan van oneerlijkheid of onrechtvaardigheid (of in positieve zin van respectievelijk fairness, eerlijkheid en rechtvaardigheid).  Wanneer we het hebben over fairness hebben we het minder over de juridische kant van discriminatie en verboden onderscheid.  Ook als er wel een objectieve rechtvaardiging bestaat voor een gemaakt onderscheid, kan afgevraagd worden of het gemaakte onderscheid ethisch wenselijk is. </p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#statistische-bias","title":"Statistische bias","text":"<p>Statistische bias wordt gedefinieerd als een consistente numerieke afwijking van een schatting ten opzichte van de werkelijke onderliggende waarde.<sup>1</sup> Dit fenomeen kan in allerlei verschillende contexten plaatsvinden, niet alleen bij het gebruik van algoritmes of AI.  Een voorbeeld is wanneer een bepaalde meting van een waarde niet goed gekalibreerd is en er sprake is van een consistente afwijking van de te meten waarde (bijvoorbeeld dat we consistent 10% hoger meten). </p> <p>In de context van algoritmes en AI kan deze vorm van bias voorkomen wanneer er een steekproef wordt gebruikt die niet representatief is voor de populatie, en de schattingen op basis van de steekproef vervolgens systematisch afwijken van de werkelijke waarde in de gebruikte doelpopulatie. Statistische bias duidt op een systematische fout die gemaakt wordt door het algoritme.  Deze fout kan hetzelfde zijn voor alle groepen en hoeft daardoor niet in alle gevallen te duiden op ongelijke behandeling of discriminerende effecten.  Voorbeelden van statistische bias zijn meetfouten (measurement bias), foute data of data op een te simpele manier representeren (representatie bias).</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#systemische-bias","title":"Systemische bias","text":"<p>We spreken van systemische bias wanneer bepaalde processen of systemen op zo'n wijze worden gebruikt dat bepaalde groepen bevoordeeld worden en andere groepen benadeeld worden. Dit is vaak geen bewuste vorm van vooringenomenheid, maar kan bijvoorbeeld ontstaan doordat de meerderheid bestaande regels of normen volgt, en het systeem geoptimaliseerd is op de meerderheid. Systemische bias heeft een sterk institutioneel karakter. Systemische bias wordt daarom ook wel institutionele vooringenomenheid genoemd.  Deze vooroordelen zijn vaak verweven in de bredere cultuur en samenleving, en zitten daardoor ook in veel datasets.  Een veel voorkomend voorbeeld van systemische bias is historische bias. </p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#menselijke-bias","title":"Menselijke bias","text":"<p>Menselijke bias omvat systematische fouten in het menselijk denken.  Deze (onbewuste) menselijke vooroordelen zijn vaak impliciet van aard en hebben betrekking op de manier waarop een individu bepaalde informatie waarneemt en verwerkt om bijvoorbeeld een beslissing te nemen.  In de context van algoritmes kan deze vorm van bias invloed hebben op de verzamelde data, op de wijze waarop het algoritme wordt geoptimaliseerd en de besluiten die door mensen worden genomen op basis van het algoritme. Voorbeelden van vormen menselijke bias zijn wanneer er voorkeur wordt geven aan de voorspellingen van een algoritme die reeds bestaande overtuigingen bevestigen (bevestigingsbias), of wanneer mensen de neiging hebben om voorkeur te geven aan suggesties die door het algoritme worden gedaan (automatiseringsbias)</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#overzicht-van-gebruikte-definities","title":"Overzicht van gebruikte definities","text":"<p>Onderstaand bieden we een overzicht van de gebruikte definities in het algoritmekader die betrekking hebben op het onderwerp bias en non-discriminatie. </p> Term of begrip Definitie Bron direct onderscheid indien een persoon op een andere wijze wordt behandeld dan een ander in een vergelijkbare situatie wordt, is of zou worden behandeld, op grond van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid<sup>2</sup> of burgerlijke staat Algemene wet gelijke behandeling indirect onderscheid indien een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaalde godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid<sup>2</sup> of burgerlijke staat in vergelijking met andere personen bijzonder treft. Algemene wet gelijke behandeling discriminatie mensen anders behandelen, achterstellen of uitsluiten op basis van (persoonlijke) kenmerken. College voor de rechten van de mens directe discriminatie de ongelijke behandeling van een persoon of groep personen ten opzichte van andere personen in een vergelijkbare situatie, op grond van een beschermd persoonskenmerk (discriminatiegrond). College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader indirecte discriminatie wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaald beschermd persoonskenmerk (discriminatiegrond) in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat. College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader algoritmische fairness het vakgebied dat bestudeert hoe algoritmische systemen zich moeten gedragen om mensen eerlijk te behandelen, dat wil zeggen zonder discriminatie op grond van beschermde gevoelige kenmerken zoals leeftijd, geslacht, handicap, etnische of raciale afkomst, religie of geloofsovertuiging, of seksuele geaardheid The fairness handbook ground truth (NL vertaling?) waarde van de doelvariabele voor een bepaald item van gelabelde invoergegevens. <sup>5</sup> NEN-EN-ISO/IEC 22989:2023 en <sup>4</sup> etnisch profileren Het gebruik door overheidsinstanties van selectiecriteria als ras, huidskleur, taal, religie, nationaliteit of nationale of etnische afkomst bij de uitoefening van toezichts-, handhavings- en opsporingsbevoegdheden, zonder dat daarvoor een objectieve en redelijke rechtvaardiging bestaat. College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader discriminatiegrond Beschermde persoonskenmerken op basis waarvan het maken van onderscheid tussen personen verboden is. Bijvoorbeeld: ras, nationaliteit, religie, geslacht, seksuele gerichtheid, handicap of chronische ziekte College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader risicoprofiel Een verzameling van \u00e9\u00e9n of meer selectiecriteria op basis waarvan een bepaald risico op normovertreding wordt ingeschat en een selectiebeslissing wordt gemaakt. College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader groep deelverzameling van objecten in een domein die zijn gekoppeld omdat ze gemeenschappelijke kenmerken hebben. ISO/IEC TR 24027:2021 en <sup>4</sup>"},{"location":"onderwerpen/bias-en-non-discriminatie/#verschillende-vormen-van-bias","title":"Verschillende vormen van bias","text":"<p>Omdat bias op verschillende manieren kan ontstaan, zijn er allerlei verschillende vormen van bias, die hieronder gedefinieerd worden. Deze lijst is niet uitputtend. </p> Begrip Definitie Bron automatiseringsbias de neiging van mensen om de voorkeur te geven aan suggesties van geautomatiseerde besluitvormingssystemen en om tegenstrijdige informatie te negeren die zonder automatisering is verkregen, zelfs als deze correct is ISO/IEC TR 24027:2021 en <sup>4</sup> data bias dataeigenschappen die, als ze niet worden aangepakt, leiden tot AI-systemen die beter of slechter presteren voor verschillende groepen ISO/IEC TR 24027:2021 en <sup>4</sup> statistische bias soort consistente numerieke afwijking in een schatting ten opzichte van de werkelijke onderliggende waarde, inherent aan de meeste schattingen ISO/IEC TR 24027:2021 en <sup>4</sup> historische bias verwijzend naar de langdurige vooroordelen die in de loop der tijd in de samenleving zijn gecodeerd. Verwant aan, maar verschillend van, vooroordelen in historische beschrijving, of de interpretatie, analyse en verklaring van de geschiedenis. Een veel voorkomend voorbeeld van historische vooringenomenheid is de neiging om de wereld te bekijken vanuit een Westers of Europees perspectief NIST, Towards a Standard for identifying and managing bias in artificial intelligence activiteitenbias een soort selectievooroordeel dat optreedt wanneer systemen/platforms hun trainingsgegevens krijgen van de meest actieve gebruikers, in plaats van minder actieve (of inactieve) gebruikers. NIST, Towards a Standard for identifying and managing bias in artificial intelligence versterkingsbias ontstaat wanneer de verdeling over voorspellingsoutputs scheef is in vergelijking met de prior-verdeling van het voorspellingsdoel. NIST, Towards a Standard for identifying and managing bias in artificial intelligence cognitieve bias een brede term die in het algemeen verwijst naar een systematisch patroon van afwijking van rationele oordeels- en besluitvorming. In vele decennia van onderzoek naar oordeelsvorming en besluitvorming is een grote verscheidenheid aan cognitieve vertekeningen ge\u00efdentificeerd, waarvan sommige adaptieve mentale snelkoppelingen zijn die bekend staan als heuristieken. NIST, Towards a Standard for identifying and managing bias in artificial intelligence bevestigingsbias soort menselijke cognitieve bias die de voorkeur geeft aan voorspellingen van AI-systemen die reeds bestaande overtuigingen of hypotheses bevestigen ISO/IEC TR 24027:2021 en <sup>4</sup> implementatie bias ontstaat wanneer systemen worden gebruikt als beslissingshulp voor mensen, omdat de menselijke tussenpersoon kan handelen op voorspellingen op manieren die meestal niet zijn gemodelleerd in het systeem. Het zijn echter nog steeds individuen die het gebruikte systeem gebruiken NIST, Towards a Standard for identifying and managing bias in artificial intelligence evaluatie bias ontstaat wanneer de test- of externe benchmarkpopulaties niet in gelijke mate de verschillende delen van de gebruikerspopulatie vertegenwoordigen of door het gebruik van prestatiemaatstaven die niet geschikt zijn voor de manier waarop het model zal worden gebruikt NIST, Towards a Standard for identifying and managing bias in artificial intelligence meetbias ontstaat wanneer kenmerken en labels benaderingen zijn voor gewenste grootheden, waarbij mogelijk belangrijke factoren worden weggelaten of groeps- of ingangsafhankelijke ruis wordt ge\u00efntroduceerd die leidt tot differenti\u00eble prestaties. NIST, Towards a Standard for identifying and managing bias in artificial intelligence representatie bias ontstaat doordat subgroepen niet willekeurig worden geselecteerd in een steekproef, waardoor trends die voor \u00e9\u00e9n populatie worden geschat, niet generaliseerbaar zijn naar gegevens van een nieuwe populatie NIST, Towards a Standard for identifying and managing bias in artificial intelligence"},{"location":"onderwerpen/bias-en-non-discriminatie/#discriminatiegrond","title":"Discriminatiegrond","text":"<p>De discriminatiegrond beschrijft de beschermde persoonskenmerken op basis waarvan het maken van onderscheid tussen personen verboden is. Deze gronden zijn in verschillende bronnen vastgelegd. </p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#de-grondwet","title":"De grondwet","text":"<p>De Grondwet stelt dat discriminatie wegens:</p> <ul> <li>godsdienst </li> <li>levensovertuiging </li> <li>politieke gezindheid </li> <li>ras </li> <li>geslacht </li> <li>handicap</li> <li>seksuele gerichtheid</li> <li>of op welke grond dan ook</li> </ul> <p>niet is toegestaan. </p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#de-algemene-wet-gelijke-behandeling","title":"De Algemene wet gelijke behandeling","text":"<p>De Algemene wet gelijke behandeling legt een verbod onderscheid neer op grond van:</p> <ul> <li>godsdienst</li> <li>levensovertuiging</li> <li>politieke gezindheid</li> <li>ras</li> <li>geslacht</li> <li>nationaliteit</li> <li>hetero- of homoseksuele gerichtheid <sup>2</sup></li> <li>of burgelijke staat. </li> </ul> <p>Het in deze wet neergelegde verbod van onderscheid geldt niet ten aanzien van indirect onderscheid indien dat onderscheid objectief gerechtvaardigd wordt door een legitiem doel en de middelen voor het bereiken van dat doel passend en noodzakelijk zijn.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#europees-verdrag-voor-de-rechten-van-de-mens","title":"Europees Verdrag voor de Rechten van de Mens","text":"<p>Het Europees Verdrag voor de Rechten van de Mens, artikel 14 stelt dat het genot van de rechten en vrijheden die in dat verdrag zijn vermeld, moet worden verzekerd zonder enig onderscheid op welke grond dan ook, zoals:</p> <ul> <li>geslacht</li> <li>ras</li> <li>kleur</li> <li>taal</li> <li>godsdienst</li> <li>politieke of andere mening</li> <li>nationale of maatschappelijke afkomst</li> <li>het behoren tot een nationale minderheid</li> <li>vermogen</li> <li>geboorte</li> <li>of andere status. </li> </ul>"},{"location":"onderwerpen/bias-en-non-discriminatie/#handvest-van-de-grondrechten-van-de-europese-unie","title":"Handvest van de grondrechten van de Europese Unie","text":"<p>Het Handvest van de grondrechten van de Europese Unie, artikel 21 stelt dat iedere discriminatie, met name op grond van:</p> <ul> <li>geslacht</li> <li>ras</li> <li>kleur</li> <li>etnische of sociale afkomst</li> <li>genetische kenmerken</li> <li>taal</li> <li>godsdienst</li> <li>politieke of andere denkbeelden</li> <li>het behoren tot een nationale minderheid</li> <li>vermogen</li> <li>geboorte</li> <li>een handicap</li> <li>leeftijd</li> <li>of seksuele gerichtheid</li> </ul> <p>is verboden. Daarnaast wordt expliciet vermeld dat binnen de werkingssfeer van de Verdragen en onverminderd de bijzondere bepalingen ervan, iedere discriminatie op grond van nationaliteit verboden is.</p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#vereisten","title":"Vereisten","text":"idVereistenaia-04Risicobeoordeling voor jongeren en kwetsbarenavg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensgrw-02AI-systemen en algoritmes mogen niet discrimineren"},{"location":"onderwerpen/bias-en-non-discriminatie/#maatregelen","title":"Maatregelen","text":"idMaatregelenTrain-, validatie- en testdataver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isver-01Toets het algoritme op biasimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controleren"},{"location":"onderwerpen/bias-en-non-discriminatie/#mogelijke-hulpmiddelen-en-methoden","title":"Mogelijke hulpmiddelen en methoden","text":"<ul> <li>Fairness Handbook</li> <li>Handreiking non-discriminatie-by-design</li> <li>College voor de rechten van de mens, Discriminatie door risicoprofielen - een mensenrechtelijk toetsingskader</li> </ul> <ol> <li> <p>Zie ISO/IEC TR 24027:2021 en <sup>4</sup> \u21a9\u21a9</p> </li> <li> <p>Er is een wetsvoorstel om de term 'hetero- of homoseksuele gerichtheid' in de Algmemene wet gelijke behandeling (Awgb) te wijzigingen in 'seksuele gerichtheid'.  Met deze wijziging sluit de Awgb aan bij een eerdere wijziging van artikel 1 van de Grondwet.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Zie NEN-EN-ISO/IEC 22989:2023 en <sup>4</sup> \u21a9</p> </li> <li> <p>Hoewel het gebruik van de NEN-ISO-normen in het Algoritmekader auteursrechtelijk is beschermd, heeft het Nederlands Normalisatie Instituut (NEN) voor het gebruik in het Algoritmekader toestemming verleend. Zie nen.nl voor meer informatie over NEN en het gebruik van hun producten.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>De term ground truth impliceert niet dat de gelabelde invoergegevens consistent overeenkomen met de werkelijke waarde van de doelvariabelen.\u00a0\u21a9</p> </li> </ol>"},{"location":"onderwerpen/data/","title":"Data","text":"<p>Het ontwikkelen en gebruiken van algoritmes en AI-systemen kan niet gepaard gaan zonder het verwerken van data.  In het geval van AI wordt data gebruikt om het algoritme te trainen, te valideren en te testen. </p> <p>Wanneer beslissingen worden genomen op basis van de output van een algoritme of AI-systeem, dan wordt dit ook gedaan op basis van de onderliggende data.  Om algoritmes en AI-systemen op een verantwoorde manier toe te passen, dient dus ook de data op een verantwoorde en rechtmatige manier te worden gebruikt. </p> <p>In dit bouwblok werken we uit welke vereisten er zijn voor verantwoord datagebruik, en geven we praktische maatregelen hoe dit ingevuld kan worden binnen overheidsorganisaties.  We zoeken hierbij de aansluiting op bestaande instrumenten, zoals de Toolbox verantwoord datagebruik.  </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vind je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p>"},{"location":"onderwerpen/data/#vereisten","title":"Vereisten","text":"idVereistenaia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteriaaia-35Verdere verwerking van persoonsgegevens in AI-testomgevingenarc-01De archiefwet is ook van toepassing op algoritmes en AI-systemenaut-01Auteursrechten mogen niet worden geschondenavg-09Privacyrechtendat-01Verbod op schenden databankenrechten"},{"location":"onderwerpen/data/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-02Beschrijf welke data gebruikt wordt voor de beoogde toepassingdat-01Controleer de datakwaliteitdat-02Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.dat-06Controleer de auteursrechten van eigen dataTrain-, validatie- en testdataControle of eigenaarschap over de datadat-09Beperk de omvang van datasets voor energie-effici\u00ebntieimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenVeranderingen in de data"},{"location":"onderwerpen/data/#nuttige-informatie","title":"Nuttige informatie","text":"<ul> <li>FAIR data: GO FAIR Foundation.</li> </ul>"},{"location":"onderwerpen/duurzaamheid/","title":"Duurzaamheid","text":"<p>Onze impact op natuur en milieu is groot.  Er zijn grote doelen gesteld om duurzamer te gaan leven en werken. Binnen alle overheidsorganisaties, op allerlei verschillende gebieden, wordt gekeken hoe er duurzamer te werk kan worden gegaan, dus ook bij ICT-voorzieningen. </p> <p>Bij het duurzamer maken van ICT kan gedacht worden aan de fysieke kant (hardware) en de digitale kant (software, algoritmes). Met betrekking tot hardware kan men bijvoorbeeld zo duurzaam mogelijk hardware inkopen (circulariteit van apparaten en materialen) en proberen de levensduur van apparaten en onderdelen te maximaliseren. Bij ontwikkeling en inzet van software, zoals algoritmen, zal gekeken moeten worden naar andere zaken, zoals energieverbruik van het trainen van complexe modellen. In het Algoritmekader gaan we specifiek in op deze duurzaamheidsaspecten van algoritmes en AI-systemen. </p>"},{"location":"onderwerpen/duurzaamheid/#duurzaamheid-algoritmes-en-ai-systemen","title":"Duurzaamheid algoritmes en AI-systemen","text":"<p>Het concept duurzaamheid is een groot en generiek begrip, dat vele sub-thema\u2019s introduceert.  Deze thema\u2019s raken onder andere het ontwerp, de ontwikkeling en de inzet van algoritmes en AI-systemen.  Met de opkomst van grotere en ingewikkeldere modellen, grotere datasets, en de groeiende interesse in (generatieve) AI, groeit ook het energie- en waterverbruik. Dit verbruik ontstaat ook bij het trainen van grotere en complexere rekenmodellen zoals Large Language Models, en de opslag van zeer grote (vaak multimediale) datasets in datacenter. </p> <p>Dit bouwblok van het Algoritmekader biedt een gestructureerd overzicht van vereisten, maatregelen en instrumenten die ondersteunen bij het ontwikkelen en toepassen van algoritmes en AI-systemen op een duurzame wijze. Zo kunnen bewuste keuzes worden gemaakt die niet alleen voldoen aan de functionaliteiten, maar ook bijdragen aan de Sustainable Development Goals (SDG's) en de doelstellingen uit het Nederlandse klimaatakkoord. Bij duurzame ontwikkeling en toepassing van algoritmes kan bijvoorbeeld gedacht worden aan energie-effici\u00ebnte programmering en duurzaam datacenterbeheer. </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vindt je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p>"},{"location":"onderwerpen/duurzaamheid/#vereisten","title":"Vereisten","text":"idVereisten"},{"location":"onderwerpen/duurzaamheid/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-11Koop duurzaam algoritmes inowp-12Ontwerp eenvoudigere en minder complexe algoritmesdat-07Gebruik duurzame datacentersdat-09Beperk de omvang van datasets voor energie-effici\u00ebntieowk-05Kies energiezuinige programmeermethodenowk-06Optimaliseer AI-trainingsprocessen voor energie-effici\u00ebntiemon-05Meten, monitoren en rapporteren van milieu-impact van algoritmes"},{"location":"onderwerpen/fundamentele-rechten/","title":"Fundamentele rechten","text":"<p>Wanneer overheden publieke taken uitvoeren, dienen fundamentele rechten van burgers te worden beschermd.  Dat geldt ook als overheden gebruik maken van algoritmes of AI-systemen om hun plublieke taken uit te voeren.  </p> <p>In Nederland beschermen we onze grondrechten met de Grondwet en met (internationale) mensenrechtenverdragen, zoals het Europees Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden (EVRM). Mensenrechtenverdragen bevatten een aantal fundamentele rechten en vrijheden die niet in de Grondwet staan.  </p> <p>Afhankelijk van de werking van algoritmes en AI-systemen en de publieke taak die wordt ondersteund, kunnen verschillende grondrechten worden geraakt.  Denk hierbij aan het verbod op ongelijke behandeling of het recht op eerbiediging van de persoonlijke levenssfeer.  Het is van belang hier in een vroeg stadium aandacht aan te besteden door dit te analyseren.  Een zorgvuldige aanpak tijdens de ontwikkeling van een algoritme kan ervoor zorgen dat er tijdig wordt geanticipeerd en maatregelen worden getroffen om een ongerechtvaardigde inbreuk op grondrechten te voorkomen. </p> <p>Een aantal wezenlijke grondrechten die vaak worden geraakt met de inzet van algoritmen en AI, komen ook afzonderlijk in andere onderdelen van het Algoritmekader aan bod. </p> <p>Dit geldt bijvoorbeeld op het recht op persoonsgegevensbescherming in het bouwblok Privacy en gegevensbescherming of het verbod op ongelijke behandeling in het bouwblok Bias en non-discriminatie.  </p> <p>In dit bouwblok van het algoritmekader beschrijven we wat de vereisten zijn rondom het beschermen van fundamentele rechten.  Vervolgens worden deze vereisten ook vertaald in praktische maatregelen en instrumenten die overheden kunnen toepassen om invulling te geven aan deze vereisten.  </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vind je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p> <p>Onderdeel van het bouwblok Fundamentele rechten is het onderwerp Bias en non-discriminatie. </p>"},{"location":"onderwerpen/fundamentele-rechten/#vereisten","title":"Vereisten","text":"idVereistenaia-04Risicobeoordeling voor jongeren en kwetsbarenaia-28Recht op uitleg AI-besluitenaia-29Beoordeling van grondrechtenaia-39Klachtrecht aanbieders verder in AI-waardeketenavg-04Proportionaliteit en subsidiariteitawb-01Relevante feiten en belangen zijn bekendgrw-01Beschermen van fundamentele rechten en vrijheden"},{"location":"onderwerpen/fundamentele-rechten/#maatregelen","title":"Maatregelen","text":"idMaatregelenpba-04Overleg regelmatig met belanghebbendenowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-07Maak een lijst van de meest kwetsbare groepen en bescherm hen extra"},{"location":"onderwerpen/fundamentele-rechten/#instrumenten","title":"Instrumenten","text":"idInstrumentenImpact Assessment Mensenrechten en AlgoritmesHandreiking non-discriminatie by design"},{"location":"onderwerpen/menselijke-controle/","title":"Menselijke controle","text":"<p>Algoritmes van de overheid moeten onder controle blijven van mensen. Presteert het algoritme of AI-systeem niet goed, dan moet een mens dit kunnen aanpassen of stoppen.</p>"},{"location":"onderwerpen/menselijke-controle/#wat-is-menselijke-controle","title":"Wat is menselijke controle?","text":"<p>Je hebt menselijke controle over een algoritme of AI-systeem als mensen in staat zijn om de uitkomsten van een algoritme effectief te be\u00efnvloeden. </p> <p>Dit betekent dat mensen een algoritme of AI-systeem moeten kunnen aanpassen of stoppen tijdens het ontwerp of gebruik ervan. Zo kun je op tijd ingrijpen als er iets fout gaat.</p>"},{"location":"onderwerpen/menselijke-controle/#belang-van-menselijke-controle","title":"Belang van menselijke controle","text":"<p>Algoritmes kunnen schade veroorzaken in de maatschappij. Gebruik je een algoritme of AI-systeem voor een publieke taak, dan moet je dit continu op een of andere manier controleren. </p>"},{"location":"onderwerpen/menselijke-controle/#ontwerp","title":"Ontwerp","text":"<p>Tijdens het ontwerp van een algoritme of AI-systeem controleer je bijvoorbeeld of het algoritme of AI-systeem op de juiste manier \u2018getraind\u2019 wordt. Maakt het bijvoorbeeld gebruik van een goede dataset, zonder bias, die representatief is voor de samenleving? En je controleert of het algoritme bepaalde groepen niet benadeelt. </p> <p>Voordat je een algoritme of AI-systeem gaat gebruiken, is het belangrijk om het doel te bepalen. </p>"},{"location":"onderwerpen/menselijke-controle/#gebruik","title":"Gebruik","text":"<p>Tijdens het gebruik van een algoritme of AI-systeem is menselijke controle belangrijk omdat de werking verandert in de loop der tijd:</p> <ul> <li>Situaties kunnen veranderen. Het algoritme kan daarvan niet op de hoogte zijn. Een routeplanner kent bijvoorbeeld niet alle werkzaamheden of veranderingen aan de wegen.</li> <li>AI-systemen leren soms nog bij. En soms is het niet duidelijk op welke data de uitkomsten gebaseerd zijn. Een beeldherkenningssysteem herkent bijvoorbeeld honden op foto\u2019s op basis van de achtergrond in plaats van de hond zelf.</li> <li>Nieuwe mogelijkheden ontstaan door technologische ontwikkelingen. Zo maken leerlingen en studenten massaal gebruik van large language modellen (LLM\u2019s) zoals ChatGPT.</li> </ul>"},{"location":"onderwerpen/menselijke-controle/#mensen","title":"Mensen","text":"<p>Er is maatschappelijke consensus dat alleen natuurlijke personen in staat zijn om een goede (ethische) afweging te maken over wanneer en welke controle nodig is. Menselijke controle kan je dus niet automatiseren. Mensen mogen zich hierbij wel laten helpen door computers of andere technologie. </p>"},{"location":"onderwerpen/menselijke-controle/#aanpak-menselijke-controle","title":"Aanpak menselijke controle","text":"<p>Je kunt op verschillende manieren controle houden over de prestaties van een algoritme of AI-systeem:</p> <ul> <li>Technische controle: Controle uitoefenen op het algoritme zelf. Je bepaalt bijvoorbeeld dat een AI-systeem alleen mag 'bijleren\u2019 als de data voldoet aan bepaalde voorwaarden.</li> <li>Contextuele controle: Controle van de omgeving van het algoritme. Je verbiedt bijvoorbeeld het gebruik van een bepaald algoritme in een situatie met een hoog risico op schade.</li> <li>Controle door kennis: Je probeert de werking en risico\u2019s van je algoritmes zo goed mogelijk te begrijpen. Hiervoor moet de mens voldoende kennis hebben over AI (AI-geletterdheid).</li> </ul> <p>Wanneer en hoe je controle uitoefent, hangt af van het soort algoritme, de situatie (hoog risico of niet), de levenscyclusfase van je project en je rol.  Bij elke aanpak is er meer dan 1 persoon verantwoordelijk. En je oefent menselijke controle uit in verschillende fases, door verschillende mensen. </p> <p>Tijdens het gebruik kun je menselijke controle op de volgende manieren uitoefenen:</p> <ul> <li>Human in the loop: Mensen starten de acties van het algoritme of AI-systeem. Het werkt niet autonoom.</li> <li>Human on the loop: Mensen kunnen acties stoppen van het algoritme of AI-systeem.</li> <li>Human above the loop: Mensen houden overzicht en kunnen ingrijpen bij strategische en ethische beslissingen.</li> <li>Human before the loop: Een volledig autonoom algoritme of AI-systeem interpreteert morele modellen die mensen vooraf bedenken. </li> </ul>"},{"location":"onderwerpen/menselijke-controle/#vereisten","title":"Vereisten","text":"idVereistenaia-01Bevorder AI-geletterdheid van personeel en gebruikersaia-09Toezichtmogelijkheden voor gebruikersaia-18Corrigerende maatregelen voor non-conforme AIaia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuningaia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeemaia-38Veilig melden van inbreuk op AI verordening"},{"location":"onderwerpen/menselijke-controle/#maatregelen","title":"Maatregelen","text":"idMaatregelenpba-01Beschrijf het probleem dat het algoritme moet oplossenpba-02Beschrijf het doel van het algoritmepba-03Beschrijf waarom een algoritme het probleem moet oplossenowk-02Maak een noodplan voor het stoppen van het algoritmeimp-03Organiseer menselijke controle van het algoritmeimp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeem"},{"location":"onderwerpen/menselijke-controle/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/privacy-en-gegevensbescherming/","title":"Privacy en gegevensbescherming","text":"<p>Overheidsinstanties verwerken vaak persoonsgegevens om hun taken uit te voeren en maatschappelijke waarden te cre\u00ebren. Met de opkomst van algoritmes en kunstmatige intelligentie (AI) worden deze gegevens steeds vaker gebruikt om processen te optimaliseren, zoals bij het beoordelen van subsidieaanvragen of het verlenen van vergunningen.  </p> <p>Bij het gebruik van algoritmes en AI-systemen is van groot belang om aandacht te besteden aan privacy en gegevensbescherming. Deze technologie\u00ebn vari\u00ebren van eenvoudige rekenregels tot complexe machine learning-modellen en generatieve AI, elk met hun eigen specifieke risico\u2019s.  Bijvoorbeeld, eenvoudige AI kan basisberekeningen uitvoeren, terwijl complexere AI-voorspellingen kan doen of informatie kan genereren. Ongeacht de complexiteit is het identificeren van risico\u2019s en het implementeren van passende beheersmaatregelen essentieel om de privacy van burgers te waarborgen en gevoelige gegevens te beschermen. </p> <p>Bij de inzet van AI in de publieke sector moeten overheidsinstanties rekening houden met de vereisten uit privacywetgeving, zoals de Algemene Verordening Gegevensbescherming (AVG). Dit omvat onder andere het minimaliseren van gegevensgebruik, implementeren van een privacy by design werkwijze waar mogelijk, en het transparant zijn over hoe en waarom (persoons)gegevens worden verwerkt.  Het toewijzen van verantwoordelijkheden en het opstellen van duidelijke richtlijnen voor gegevensverwerking zijn belangrijke stappen in dit proces. </p> <p>Het bouwblok privacy en gegevensbescherming van algoritmen en AI-systemen wordt ook ge\u00efntegreerd in de algoritmelevenscyclus.  Dit biedt inzicht in wanneer specifieke vereisten en maatregelen tijdens de ontwikkeling van algoritmen en AI-systemen moeten worden toegepast.  Door deze vereisten in de levenscyclus te integreren, kunnen de gebruikers inzichten opdoen wanneer deze maatregelen kunnen worden ge\u00efmplementeerd. </p>"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#vereisten","title":"Vereisten","text":"idVereistenaia-35Verdere verwerking van persoonsgegevens in AI-testomgevingenavg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvindenavg-02Beperkte bewaartermijn van persoonsgegevensavg-03Persoonsgegevens verzamelen voor specifieke doeleindenavg-04Proportionaliteit en subsidiariteitavg-05Juistheid en actualiteit van gegevensavg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerkingavg-07Transparantie bij verwerking persoonsgegevensavg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevensavg-09Privacyrechtenavg-10Recht op niet geautomatiseerde besluitvormingavg-11Privacy door ontwerpavg-12Beveiliging van de verwerkingavg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktdat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waaromdat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsproceduredat-05Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregerenowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenimp-07Vermeld het gebruik van persoonsgegevens in een privacyverklaringimp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregister"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#instrumenten","title":"Instrumenten","text":"idInstrumentenData Protection Impact Assessment"},{"location":"onderwerpen/publieke-inkoop/","title":"Publieke inkoop","text":"<p>Door middel van publieke inkoop wordt door overheidsinstellingen software ingekocht. Deze software wordt ingekocht om ambtenaren te ondersteunen met hun werkzaamheden om zo maatschappelijk waarden te cre\u00ebren. Het kan bijvoorbeeld gaan om het inkopen van een systeem waarmee een aanvraag voor een subsidie of vergunning kan worden behandeld. Het virtueel vergaderen of het digitaal samenwerken aan documenten zijn hier ook voorbeelden van. </p> <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p> <p>Software met algoritmen  en AI wordt vaak ontwikkeld door gespecialiseerde aanbieders en bevat steeds meer algoritmen en AI. Het komt ook voor dat de overheid deze technologie zelf ontwikkelt. Deze algoritmen en AI kunnen eenvoudig van aard zijn, zoals het maken van een eenvoudige berekening. Zij kunnen complexer van aard zijn, zoals een voorspelling geven of het genereren van informatie. In het laatste geval kan worden gedacht aan ChatGPT, Google Bard of Co-Pilot. Er zijn verschillende type technologie\u00ebn die vallen onder het bereik van algoritmen en AI. In dit kader drukken we deze uit als \u2018rekenregel\u2019, \u2018machine learning\u2019 en \u2018generatieve AI\u2019. Elke technologie heeft eigen bijzondere aandachtspunten. Ook de bijbehorende risico\u2019s kunnen per type verschillen. Het identificeren van deze risico\u2019s en het treffen van beheersmaatregelen is daarbij van belang. Dat geldt in het bijzonder als algoritmen en AI bijdragen aan de totstandkoming van overheidsbesluitvorming en impactvolle beslissingen die burgers en ondernemingen raken. </p> <p>Door bij publieke inkoop van software met algoritmen en AI rekening te houden met vereisten die voorkomen uit wet- en regelgeving, toepassen van publieke waarden, het type algoritme of AI en de potenti\u00eble risico\u2019s die ontstaan bij het gebruiken ervan, kunnen negatieve gevolgen worden voorkomen. Publieke inkoop speelt daarom een belangrijke rol bij de totstandkoming van verantwoord ontwikkelde algoritmen en AI en het gebruik daarvan door ambtenaren.  In dit deel van het Algoritmekader wordt nader ingegaan op deze vereisten. Er worden suggesties gedaan hoe deze vereisten kunnen worden nageleefd en welke rollen daarbij betrokken kunnen zijn. Waar mogelijk worden concrete voorbeelden uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is.</p> <p>Het publiek inkopen van algoritmen en AI wordt ook gekoppeld aan de algoritme levenscyclus. Dit geeft een beeld van wanneer bepaalde vereisten en maatregelen, bij het ontwikkelen van algoritmen en AI, moeten worden geadresseerd. Door deze vereisten ook te vertalen naar het inkoopproces, zullen de rollen binnen het inkoopproces beter in staat zijn om te duiden wanneer en hoe dit kan worden geadresseerd. Dit moet bijdragen aan een goed samenspel met aanbieders, zodat de kansen van algoritmen en AI worden benut en de negatieve gevolgen worden voorkomen.  </p>"},{"location":"onderwerpen/publieke-inkoop/#algoritme-levenscyclus","title":"Algoritme levenscyclus","text":"<p>Algoritmen en AI kunnen een grote impact hebben op onze maatschappij. Daarom is het van belang dat deze op een verantwoorde manier worden ontwikkeld en gebruikt. Het toepassen van de algoritme levenscyclus is hierover een bruikbare leidraad. De algoritme levenscyclus bestaat uit meerdere fasen. De werkzaamheden die noodzakelijk zijn om een verantwoord algoritme of AI te ontwikkelen, kunnen logisch worden gekoppeld aan deze fasen.  Deze levenscyclus kan worden gebruikt voor alle typen algoritmen en AI. Het verschilt uiteraard wel per type wat moet worden gedaan en dit is mede afhankelijk van de risico classificatie. Bij hoge risico toepassing zal meer moeten worden gedaan om risico\u2019s te mitigeren dan als er sprake is van lage risico toepassingen. De levenscyclus geeft een bruikbaar overzicht voor leveranciers en opdrachtgevers wanneer welke werkzaamheden moeten worden uitgevoerd. Het laat ook zien welke werkzaamheden moeten zijn afgerond als algoritmen en AI in de markt mogen worden gezet en klaar zijn voor gebruik. </p> <p>Bij het publiek inkopen van software met bijbehorende algoritmen en AI zijn de wensen van de behoeftesteller en de doelstellingen van de organisatie van groot belang. Dit kan tot verschillende situaties leiden:</p> <p>\u2022   Een al ontwikkelde kant-en-klare oplossing voldoet direct aan deze wensen en doelstellingen;</p> <p>\u2022   Een al ontwikkelde oplossing moet eerst worden aangepast voordat deze kan worden gebruikt;</p> <p>\u2022   Er moet een nieuwe oplossing worden ontwikkeld om te voldoen aan de wensen. </p> <p>Deze inschatting is dus bepalend wat wel en niet van een product mag worden verwacht. Dit is relevant voor zowel de leverancier als de opdrachtgever. Het is aannemelijk dat als het om risicovolle (nog te ontwikkelen) algoritmen of AI gaat, de opdrachtgever een intensieve bijdrage moet leveren aan de samenwerking om het product te kunnen gebruiken. De opdrachtgever zal bijvoorbeeld moeten aangeven wat de juridische en ethische grenzen zijn van de uiteindelijk werking van het algoritme of AI. Als een kant-en-klare oplossing wordt afgenomen, dan zal de leverancier moeten laten zien dat de ontwikkelde algoritmen en AI voldoen aan alle vereisten en moet dit kunnen aantonen. </p> <p>De inzichten uit de algoritme levenscyclus kunnen ondersteunen bij bijvoorbeeld de behoeftestelling, het maken van make-or-buy beslissingen, de te hanteren aanbestedingsvorm, de totstandkoming van de selectie- en gunningseisen, contractspecificaties en de uitvoering en management van het contract. De algoritme levenscyclus kan worden geraadpleegd via het tabblad boven aan deze pagina. Per fase en per type algoritme of AI kan worden bekeken aan welke vereisten moet worden voldaan en welke beheersmaatregelen kunnen worden getroffen. </p>"},{"location":"onderwerpen/publieke-inkoop/#vereisten","title":"Vereisten","text":"<p>Nagenoeg alle vereisten die gelden voor algoritmen en AI kunnen een plek krijgen in het publiek inkoopproces.  Daarom is ervoor gekozen om hier niet een opsomming te geven van al deze vereisten, maar verwijzen we naar het onderdeel vereisten in het Algoritmekader.</p> <p>In de laag van 'maatregelen' wordt ook uitgewerkt wat vanuit publieke inkoop kan worden gedaan om op een betekenisvolle wijze invulling aan te geven aan de betreffende vereiste.  Daarvoor kan ook op het tabblad 'publieke inkoop' worden geklikt om deze maatregelen te filteren.</p> <p>Zie hieronder bij bruikbare informatie en bronnen in het bijzonder de Europese modelcontractbepaling voor (niet) hoog risico AI-systemen en contractvoorwaarden voor algoritmen.  Dit geeft een beeld hoe de vereisten onderdeel kunnen worden gemaakt van contractvoorwaarden.   </p>"},{"location":"onderwerpen/publieke-inkoop/#maatregelen","title":"Maatregelen","text":"<p>Hieronder volgt een overzicht van de maatregelen die (voor zover zijn uitgewerkt) kunnen worden getroffen om invulling te geven aan de vereisten. </p> idMaatregelenowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenowp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesowp-11Koop duurzaam algoritmes inControle of eigenaarschap over de dataAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingBepaal of de output bepalende invloed heeft in een besluit richting personenBespreek de vereiste met aanbieder of opdrachtnemerContractuele afspraken over data en artefactenCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenBewijs laten leveren dat auteursrechten niet worden geschonden met de outputBewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputGarantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeDe mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingVaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Er wordt momenteel hard gewerkt, mede door de Werkgroep Publieke Inkoop, om maatregelen te defini\u00ebren vanuit het perspectief publieke inkoop bij de vereisten. Mocht er iets niet kloppen, laat het ons weten via GitHub of via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/publieke-inkoop/#instrumenten","title":"Instrumenten","text":"<p>Hieronder volgt een overzicht van instrumenten die kunnen worden gebruikt om invulling te geven aan de vereisten en maatregelen.</p> ZoekenRollenjuristLevenscyclusdataverkenning-en-datapreparatieontwerpprobleemanalyseverificatie-en-validatieOnderwerpenpublieke-inkoopidInstrumentenRollenLevenscyclusOnderwerpenModelcontractbepalingen                  jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               publieke-inkoop"},{"location":"onderwerpen/publieke-inkoop/#bruikbare-informatie-en-bronnen","title":"Bruikbare informatie en bronnen","text":"<p>Europese modelcontractbepalingen AI-systemen (hoog risico)</p> <p>Europese modelcontractbepalingen AI-systemen (niet hoog risico)</p> <p>Contractvoorwaarden voor algoritmen gemeente Amsterdam</p> <p>Inkoopproces</p> <p>Community of Practise Digitale Innovatie</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/","title":"Technische robuustheid en veiligheid","text":"<p>Algoritmes van de overheid moeten robuust en veilig zijn. Dit betekent dat je algoritmes in elke situatie goed moeten presteren. Ook als er iets onverwachts gebeurt. En er moet een plan zijn voor als er toch iets misgaat.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#wat-is-technisch-robuust-en-veilig","title":"Wat is technisch robuust en veilig?","text":"<p>Een technisch robuust en veilig algoritme presteert onder elke omstandigheid zoals het bedoeld is.  Een robuust algoritme is:</p> <ul> <li>Nauwkeurig: Het geeft de juiste uitkomst voor het gewenste doel, maar kan ook aangeven wanneer het daar niet zeker over is.</li> <li>Betrouwbaar: Het geeft de juiste uitkomst in nieuwe of onverwachte situaties.</li> <li>Reproduceerbaar: Het vertoont hetzelfde gedrag in dezelfde situaties.</li> </ul> <p>Algoritmes zijn veilig onder deze omstandigheden:</p> <ul> <li>Alleen geautoriseerde personen en systemen kunnen het algoritme gebruiken.</li> <li>Het algoritme is op elk moment beschikbaar voor de werking waarvoor het bedoeld is. Is het algoritme toch beperkt beschikbaar, dan is de mogelijke schade hiervan te overzien.</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#belang-van-robuuste-veilige-algoritmes","title":"Belang van robuuste, veilige algoritmes","text":"<p>Algoritmes kunnen grote schade veroorzaken aan de maatschappij. Met een technisch robuust en goed beveiligd algoritme voorkom je:</p> <ul> <li>onverwachte schadelijke fouten, zoals verkeerde beslissingen door onvoldoende nauwkeurigheid, discriminatie of het uitvallen het systeem</li> <li>lekken van informatie, zoals persoonsgegevens</li> <li>gebruik van het algoritme voor verkeerde doeleinden</li> <li>schade door misbruik of aanvallen van buitenaf</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#gebruik-het-algoritme-waarvoor-het-bedoeld-is","title":"Gebruik het algoritme waarvoor het bedoeld is","text":"<p>Gebruik het algoritme alleen op de manier zoals het bedoeld is. Dit is de manier die is getest en gecontroleerd. Wanneer het algoritme voor een ander doel wordt gebruikt of in een verkeerde context wordt gebruikt, zijn de resultaten niet meer betrouwbaar. </p> <p>Voorkom dat medewerkers op de verkeerde manier werken met het algoritme. Zij moeten weten wat het algoritme wel en niet kan. En wat ze moeten doen als het algoritme fouten maakt of niet goed werkt. Denk aan technische als organisatorische ondersteuning:</p> <ul> <li>Leid medewerkers op.</li> <li>Zorg voor duidelijke processen (governance), zodat gebruikers weten wat de beperkingen zijn en weten wat ze kunnen doen als het algoritme niet werkt zoals bedoeld.</li> <li>Zorg voor technische interventies in het ontwerp en interactie met de gebruiker, die gebruikers sturen in het juiste gebruik.</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#controleer-regelmatig","title":"Controleer regelmatig","text":"<p>Begin zo vroeg mogelijk met het testen en controleren van de gegevens die je gebruikt en de verwachte en werkelijke uitkomsten. In de praktijk verandert de omgeving en de situatie waarin het algoritme wordt gebruikt. Controleer daarom regelmatig of het algoritme de verwachte output geeft:</p> <ul> <li>Nauwkeurig: Het geeft de juiste uitkomst voor het gewenste doel, maar kan ook aangeven wanneer het daar niet zeker over is.</li> <li>Betrouwbaar: Het geeft de juiste uitkomst in nieuwe of onverwachte situaties.</li> <li>Reproduceerbaar: Het vertoont hetzelfde gedrag in dezelfde situaties.</li> </ul> <p>Ontwikkel je zelf het algoritme, controleer dan tijdens de ontwikkeling al wat er gebeurt bij verwachte variaties. Zorg bijvoorbeeld dat je bent voorbereid op nieuwe combinaties van de inputdata. Gebruik verschillende test-sets en zorg voor goede monitoring van de gebruikte data, zodat veranderingen in de data snel gesignaleerd worden. </p> <p>In de eerste fases probleemanalyse, ontwerp en dataverkenning en datapreparatie focus je op een goede voorbereiding. Verken de context waarin het algoritme gebruikt wordt, identificeer de risico\u2019s, concretiseer waarop het algoritme ge\u00ebvalueerd moet worden, analyseer de data, en ontwerp preventieve maatregelen en evaluatiemethoden. </p> <p>Vervolgens voer je dit uit in de ontwikkelfase en de verificatie- en validatiefase. Zorg dat het algoritme goed getest wordt en evalueer het algoritme op de drie aspecten van robuustheid. Waar nodig verbeter je het algoritme. Zorg dat je een uitwijkplan hebt, zodat je weet wat je moet doen als blijkt dat het algoritme niet meer werkt zoals beoogd.</p> <p>Is het algoritme in gebruik (implementatie en monitoring en beheer, dan blijf je regelmatig controleren. Presteert het algoritme niet goed, los het probleem dan op of stop het gebruik. </p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#voorbeelden","title":"Voorbeelden","text":"<p>Een algoritme leest kentekens tijdens parkeercontroles. Het herkent de juiste letters en cijfers op elk kenteken. Ook als het bord een andere kleur heeft, op een andere plek zit of vies is. Het algoritme is nauwkeurig en dus robuust. Een algoritme berekent het risico op fraude door mensen. Maar bij personen uit dezelfde groep geeft het algoritme de ene keer als uitkomst \u2018hoog risico\u2019 en de andere keer \u2018geen risico\u2019. De uitkomst is niet reproduceerbaar. Hierdoor is het algoritme niet robuust.</p> <p>Tip</p> <p>Houd rekening met 'concept drift'. Dit betekent dat de eigenschappen van je data in de loop van de tijd kunnen veranderen. Hierdoor trekt je algoritme mogelijk verkeerde conclusies. Zo was er v\u00f3\u00f3r 2020 een verband tussen thuiswerken en ziek zijn. Maar sinds de coronacrisis in 2020 is dit verband minder sterk, omdat gezonde mensen vaker thuiswerken. </p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#bescherm-algoritmes-tegen-aanvallen-en-bedreigingen","title":"Bescherm algoritmes tegen aanvallen en bedreigingen","text":"<p>Beveilig het ICT-systeem waarin het algoritme wordt gebruikt. Dit zijn bijvoorbeeld maatregelen uit de Baseline Informatiebeveiliging Overheid (BIO) die je standaard neemt voor beveiliging van ICT-systemen tegen cyberaanvallen.</p> <p>Begin zo vroeg mogelijk met beveiligen. Beveilig in elk geval in de fases ontwikkelen, verificatie en validatie, implementatie, monitoring en beheer en uitfaseren.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#verklein-de-kans-op-schade","title":"Verklein de kans op schade","text":"<p>Veroorzaak zo min mogelijk schade als het toch fout gaat. </p> <p>Maak een uitwijkplan voor incidenten. Het doel van dit plan is ervoor zorgen dat de fout zo min mogelijk gevolgen heeft voor de organisatie en de maatschappij. In het plan staat bijvoorbeeld wie wat moet doen als het systeem uitvalt.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#vereisten","title":"Vereisten","text":"idVereistenaia-06Technische documentatie voor hoog-risico AIaia-07Automatische logregistratie voor hoog-risico AIaia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiligingaia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13Bewaartermijn voor gegenereerde logsaia-18Corrigerende maatregelen voor non-conforme AIaia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisenaia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerdaia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiligingaia-36Monitoring na het in handel brengenavg-12Beveiliging van de verwerkingbio-01Beveiliging informatie en informatiesystemen"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-04Maak afspraken over het wijzigen van de codeorg-05Maak afspraken over het beheer van gebruikersorg-06Maak afspraken over het beheer van wachtwoordenowp-04Beschrijf welke techniek gebruikt wordt voor de beoogde toepassingowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesdat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedureTrain-, validatie- en testdataowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019owk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de codever-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenmon-01Maak back-ups van algoritmesmon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenVeranderingen in de dataVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstraject"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#bronnen","title":"Bronnen","text":"<ul> <li>Natalia D\u00edaz-Rodr\u00edguez et al, 2023, Connecting the dots in trustworthy Artificial Intelligence: From AI principles, ethics, and key requirements to responsible AI systems and regulation, Information Fusion 99.</li> <li>Andrea Tocchetti, Lorenzo Corti, Agathe Balayn, Mireia Yurrita, Philip Lippmann, Marco Brambilla, and Jie Yang. 2022. A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities. In ACM, New York, NY, USA</li> <li>Ronan Hamon, Henrik Junklewitz, Ignacio Sanchez, 2020, Robustness and Explainability of Artificial Intelligence: from technical to policy solutions, JRC Technical Report, EUR 30040 EN</li> <li>Bhanu Chander, Chinju John, Lekha Warrier, Gopalakrishnan Kumaravelan, 2024, Toward Trustworthy AI in the Context of Explainability and Robustness, ACM Computing Surveys</li> <li>Niels Brink, Yori Kamphuis, Yuri Maas, Gwen Jansen-Ferdinandus, Jip van Stijn, Bram Poppink, Puck de Haan, Irina Chiscop, 2023, Adversarial AI in de cyber domain, TNO-2023-R10292-EN</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/transparantie/","title":"Transparantie","text":"<p>Om openheid te bieden en controleerbaar te zijn moeten overheidsinstanties transparant zijn over inzet van algoritmen en AI-systemen. </p> <p>Het is van belang dat overheden nadenken over hun besluitvormingsprocessen en dat zij de werking en toegevoegde waarde van het inzetten van een algoritme kunnen uitleggen. Dit is bijzonder relevant als een algoritme of AI-systeem, al dan niet geautomatiseerd, impact heeft op besluitvorming die burgers raakt.  </p> <p>Als burgers geen kennis kunnen nemen van de gebruikte algoritmes en in hoeverre diens output hen raakt, worden ze onrechtmatig beperkt in de mogelijkheid om zicht te verdedigen tegen nadelige gevolgen zoals discriminatie of een onjuist genomen beslissing of besluit. Daarnaast versterkt transparantie de controlerende functie van burgers en journalistiek, omdat burgers kunnen aangeven of een uitleg over een algoritmisch systeem duidelijk is en of zij de werking van het systeem hetzelfde ervaren. </p> <p>Transparantie bij algoritmes en AI gaat zowel over het bekendmaken van de inzet en bijbehorende doelen, als ook over openheid van het type model en de gebruikte factoren.  Gebruikers moeten in staat zijn om de werking en de output van een algoritme of AI-systeem te begrijpen, zodat zij onderbouwde beslissingen of besluiten kunnen nemen.  Dit betekent bijvoorbeeld ook dat gebruikers bewust moet worden gemaakt dat zij communiceren of samenwerken met een algoritme of AI-systeem, dat zij worden ge\u00efnformeerd over de mogelijkheden en beperkingen van een systeem en dat betrokkenen worden ge\u00efnformeerd over hun rechten. </p> <p>In dit bouwblok van het algoritmekader besteden we aandacht aan transparantie naar gebruikers en betrokkenen, transparantie door documentatie en opname in het algoritmeregister, uitlegbaarheid en traceerbaarheid van een besluit.   Hier worden de vereisten uitgewerkt die bestaan op basis van wet- en regelgeving en bestaand beleid met betrekking tot transparantie van algoritmen en AI.   Er worden suggesties gedaan hoe deze vereisten kunnen worden nageleefd met concrete maatregelen en welke rollen betrokken kunnen zijn.   Waar mogelijk worden voorbeelden en best practices uit de praktijk gegeven en zal worden aangegeven bij welk type algoritmen of AI dit relevant is.  Deze vereisten en maatregelen worden ook gekoppeld aan de levenscyclus van een algoritme.   Dit geeft een beeld van wanneer vereisten of maatregelen met betrekking tot transparantie, bij het ontwikkelen en gebruiken van algoritmen en AI, moeten en kunnen worden geadresseerd. </p> <p>Opmerking</p> <p>Dit bouwblok moet nog ontwikkeld worden. Deze pagina is dus nog niet volledig. Op deze pagina vind je mogelijk wel al onderdelen waar we aandacht aan willen besteden in dit bouwblok. </p>"},{"location":"onderwerpen/transparantie/#vereisten","title":"Vereisten","text":"idVereistenaia-02Documentatie beoordeling niet-hoog-risico AIaia-06Technische documentatie voor hoog-risico AIaia-07Automatische logregistratie voor hoog-risico AIaia-08Transparantie in ontwerp voor hoog-risico AIaia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatieaia-13Bewaartermijn voor gegenereerde logsaia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeemaia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risicoaia-26Informeren werknemersaia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeemaia-28Recht op uitleg AI-besluitenaia-30Transparantieverplichtingenaia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleindenaia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisicoaia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bijavg-07Transparantie bij verwerking persoonsgegevensawb-02Een besluit berust op een deugdelijke motiveringbzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregisterwoo-01Eenieder heeft recht op toegang tot publieke informatie"},{"location":"onderwerpen/transparantie/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten wordenver-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidimp-01Maak een openbaar besluit over de inzet van het algoritmeimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregisterimp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregister"},{"location":"onderwerpen/transparantie/#instrumenten","title":"Instrumenten","text":"idInstrumentenImpact Assessment Mensenrechten en AlgoritmesAlgoritmeregister"},{"location":"overhetalgoritmekader/","title":"Over het Algoritmekader","text":"<p>Het Algoritmekader is een hulpmiddel voor overheden die algoritmes of AI (artifici\u00eble intelligentie) gebruiken. Hierin vind je de wetten en regels, hulpmiddelen en adviezen per situatie. De informatie in het Algoritmekader is nog niet betrouwbaar. Het is een b\u00e8taversie. De definitieve versie verschijnt eind 2024.</p>"},{"location":"overhetalgoritmekader/#verantwoord-gebruik-van-algoritmes-en-ai","title":"Verantwoord gebruik van algoritmes en AI","text":"<p>In het Algoritmekader vind je informatie over verantwoord gebruik van algoritmes en AI. Bijvoorbeeld:</p> <ul> <li>Wie is waarvoor verantwoordelijk?</li> <li>Hoe voorkom je discriminatie (bias) in een algoritme?</li> <li>Hoe verwerk je gegevens op een veilige manier?</li> <li>Hoe voorkom je mensenrechtenschendingen?</li> <li>Welke inkoopvoorwaarden spreek je af voor algoritmes van een externe partij?</li> </ul> <p>De informatie is bedoeld voor medewerkers van de rijksoverheid, provincies, gemeentes en waterschappen.</p>"},{"location":"overhetalgoritmekader/#informatie-van-de-overheid","title":"Informatie van de overheid","text":"<p>Het Algoritmekader is een website van het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties. Het team Data, AI en Algoritmes stelt de informatie samen, op basis van:</p> <ul> <li> <p>alle wetten en regels, zoals de AI-verordening en de Algemene wet bestuursrecht</p> </li> <li> <p>belangrijke instrumenten, zoals de IAMA (Impact Assessment Mensenrechten en Algoritmes)</p> </li> <li>adviezen en ervaringen van experts, zoals wetenschappers</li> </ul>"},{"location":"overhetalgoritmekader/#versies","title":"Versies","text":"<p>Algoritmekader is de nieuwe naam van het Implementatiekader 'Verantwoorde inzet van algoritmen'. Dit rapport is de eerste versie. Door het verder ontwikkelen van dit rapport ontstond de website Algoritmekader.</p> <p>Sindsdien verschijnt elke maand een nieuwe b\u00e8taversie van het Algoritmekader. Deze b\u00e8taversies zijn nog niet betrouwbaar. De informatie is onvolledig. Er kunnen fouten in staan.</p> <p>Versie 2.0 is de definitieve, betrouwbare versie van het Algoritmekader. Deze versie verschijnt eind 2024.</p>"},{"location":"overhetalgoritmekader/#iedereen-mag-meedenken","title":"Iedereen mag meedenken","text":"<p>De informatie in het Algoritmekader komt open source tot stand. Dat betekent dat iedereen kan meekijken en zijn mening mag geven, of een voorstel mag doen:</p> <ul> <li>Geef je vraag of wijziging door.</li> <li>Sluit je aan bij een werkgroep.</li> <li>Doe mee aan een (online) vergadering zoals onze demo na een nieuwe release van het Algoritmekader.</li> </ul>"},{"location":"overhetalgoritmekader/#nieuwsbrief","title":"Nieuwsbrief","text":"<p>Via onze maandelijkse Nieuwsbrief Algoritmes blijf je op de hoogte over de ontwikkelingen van het Algoritmekader.</p>"},{"location":"overhetalgoritmekader/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/","title":"Bijdragen aan het Algoritmekader","text":"<p>Allereerst, bedankt dat je de tijd hebt genomen om een bijdrage te leveren! \u2764\ufe0f</p> <p>We waarderen alle soorten bijdragen enorm. Zie die Inhoudsopgave voor verschillende manieren waarop je kan bijdragen aan het Algoritmekader. Zorg ervoor dat je de relevante hoofdstukken even leest voordat je een bijdrage levert. Het zal het voor het team van het Algoritmekader een stuk makkelijker maken en de ervaring voor alle betrokkenen soepeler laten verlopen. We kijken uit naar alle bijdragen! \ud83c\udf89</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#opmerking","title":"Opmerking","text":"<p>Werken in Github is voor het team Algoritmekader nieuw en experimenteel. Dit vraagt voor ons om een aangepaste werkwijze en hier is bepaalde expertise voor nodig.  Het begin is gemaakt en het team Algoritmekader is nog lerende om hier optimaal invulling aan te geven.  Hierdoor kan het iets langer duren voordat er wordt gereageerd op suggesties of toevoegingen.  We werken aan een duidelijk proces om hier goed mee om te gaan (deze guidelines zijn daar een voorbeeld van). Daarnaast werken we niet aan alle bouwblokken tegelijk. Deze worden \u00e9\u00e9n voor \u00e9\u00e9n opgepakt.  Aanbevelingen over onderwerpen die later op de planning staan kunnen daardoor ook iets langer duren om te verwerken, en worden mogelijk pas verwerkt wanneer dit bouwblok wordt uitgewerkt.  </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#inhoudsopgave","title":"Inhoudsopgave","text":"<ul> <li>Code of Conduct</li> <li>Ik heb een vraag</li> <li>Ik wil iets bijdragen</li> <li>Ik wil een fout of bug melden</li> <li>Hoe we werken op GitHub</li> </ul>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>Dit project en iedereen die eraan deelneemt, valt onder de Code of Conduct. Door deel te nemen, wordt van je verwacht dat je je aan deze code houdt. Meld onacceptabel gedrag aan algoritmes@minbzk.nl.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-heb-een-vraag","title":"Ik heb een vraag","text":""},{"location":"overhetalgoritmekader/CONTRIBUTING/#maak-een-issue-aan","title":"Maak een issue aan","text":"<p>Voordat je een Issues gaat aanmaken, kan je bekijken of jouw vraag al tussen de bestaande Issues staat. Wellicht staat er al een issue tussen die jou vraag kan beantwoorden. </p> <p>Als je jouw vraag nog steeds wilt stellen, kan je een Issue aanmaken. </p> <ol> <li>Gebruik daarvoor de knop new issue.</li> <li>Schrijf je vraag of opmerking is en geef een heldere toelichting.</li> <li>Anderen kunnen nu opmerkingen toevoegen aan jouw issue.</li> <li>Het team van het Algoritmekader zal deze issue labelen als <code>question</code> en pakt jouw issue zo snel mogelijk op. Mogelijk neemt het team van het Algoritmekader contact op voor een verduidelijking of een oplossing.</li> </ol>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#stel-een-vraag-via-mail","title":"Stel een vraag via mail","text":"<p>Je kan je vragen ook altijd stellen door een mail te sturen naar algoritmes@minbzk.nl.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-wil-iets-bijdragen","title":"Ik wil iets bijdragen","text":"<p>Er zijn verschillende manieren waarop je kan bijdragen. Zie hieronder de mogelijkheden. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ter-kennisgeving","title":"Ter kennisgeving","text":"<p>Wanneer je bijdraagt aan dit project, moet je ermee akkoord gaan dat je 100% van de inhoud hebt geschreven, dat je de benodigde rechten op de inhoud hebt en dat de inhoud die je bijdraagt mag worden geleverd onder de Code of Conduct.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#sluit-je-aan-bij-een-werkgroep","title":"Sluit je aan bij een werkgroep","text":"<p>Voor sommige bouwblokken wordt er gewerkt met werkgroepen, om de informatie verder uit te werken. Deelname aan een werkgroep kost tijd. Werkgroepen komen regelmatig bij elkaar, en tussendoor worden bepaalde zaken uitgewerkt door werkgroepleden. Wil je op \u00e9\u00e9n van de onderwerpen meewerken? Stuur dan een bericht naar algoritmes@minbzk.nl.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#neem-deel-aan-een-sprint-review-klankbord-demo","title":"Neem deel aan een sprint review / klankbord / demo","text":"<p>Het team van het algoritmekader werkt in sprints van ongeveer 3 weken. Daarin werken we toe naar de volgende release van het Algoritmekader. Ongeveer eens in de 6 weken vindt er een nieuwe release plaats. Wanneer er een release is, wordt deze altijd toegelicht en gepresenteerd in een open online review / demo. Deze kan je vrijblijvend volgen. Zo blijf je op de hoogte en kun je een bijdrage leveren. Bekijk de agenda op Algoritmes Pleio voor de komende bijeenkomsten. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-wil-een-fout-of-bug-melden","title":"Ik wil een fout of bug melden","text":"<p>Heb je een foutje gevonden in het Algoritmekader? Dan kan je deze melden door een Issue aan te maken. </p> <p>Voordat je een Issues gaat aanmaken, kan je bekijken of jouw gevonden fout al tussen de bestaande Issues staat. </p> <p>Als je de gevonden fout nog steeds wilt melden, kan je een Issue aanmaken. </p> <ol> <li>Gebruik daarvoor de knop new issue.</li> <li>Beschrijf de fout duidelijk en geef een heldere toelichting. Voeg waar mogelijk een screenshot toe. </li> <li>Het team van het Algoritmekader zal deze issue labelen als <code>bug</code> en pakt jouw issue zo snel mogelijk op. Mogelijk neemt het team van het Algoritmekader contact op voor een verduidelijking of een oplossing.</li> </ol>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#ik-wil-een-verbetering-voorstellen","title":"Ik wil een verbetering voorstellen","text":"<p>Heb je een suggestie of wil je een verbetering voorstellen? Dat kan gaan om een compleet nieuwe functionaliteit van de site of om kleine verbeteringen. Het volgen van onderstaande instructie helpt het team van het algoritmekader om je suggestie te begrijpen en gerelateerde suggesties te vinden.</p> <p>Je kan een suggestie doen door een Issue aan te maken of door een Pull Request te maken.</p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#voordat-je-een-suggestie-gaat-maken","title":"Voordat je een suggestie gaat maken","text":"<ul> <li>Voordat je een suggestie gaat maken, kan je bekijken of jouw suggestie al tussen de bestaande Issues staat. Wellicht bestaat er al een issue die jouw suggestie beschrijft, en zijn we er al mee bezig.</li> <li>Zoek uit of jouw idee past binnen het doel en de scope van het project. Wat zijn de voordelen van deze functionaliteit of toevoeging? Het is aan jou om het team van het Algoritmekader en de community te overtuigen dat dit een nuttige toevoeging is aan het Algoritmekader. Houd in gedachten dat we functioanliteiten willen die nuttig zijn voor de meerderheid van onze gebruikers en niet slechts voor een kleine groep.</li> </ul>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#een-issue-aanmaken","title":"Een issue aanmaken","text":"<p>Als je jouw suggestie nog steeds wilt doen, kan je een Issue aanmaken. </p> <ol> <li>Gebruik daarvoor de knop new issue.</li> <li>Beschrijf duidelijk jouw suggestie en geef een heldere toelichting en onderbouwing waarom dit een goede toevoeging zal zijn aan het Algoritmekader</li> <li>Het team van het Algoritmekader zal deze issue labelen als <code>enhancement</code> en pakt jouw issue zo snel mogelijk op. Mogelijk neemt het team van het Algoritmekader contact op voor een verduidelijking of een oplossing.</li> </ol> <p>Afhankelijk van de complexiteit en het onderwerp van jouw suggestie kan het even duren voordat deze wordt opgepakt door het team van het Algoritmekader. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#een-pull-request-maken","title":"Een pull-request maken","text":"<p>Kun je niet uit de voeten met de issues?  Bijvoorbeeld omdat je verschillende wijzigingsvoorstellen wilt doen? Je kan ook gebruik maken van een Fork en een Pull Request.</p> <p>Het team van Algoritmekader bekijkt daarna jouw aanpassingen en kan bij akkoord jouw aanpassingen mergen. Er zijn ook andere manieren om een pull request te doen. Meer daarover. </p> <p>Afhankelijk van de complexiteit en het onderwerp van jouw suggestie kan het even duren voordat deze wordt opgepakt door het team van het Algoritmekader. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#preview-van-een-pull-request","title":"Preview van een pull-request","text":"<p>We maken gebruik van de tool pr-preview-action om automatisch previews te maken van een pull-request.  Dit maakt het mogelijk om de wijzigingen die zijn gedaan in een pull-request al te bekijken in de uiteindelijke omgeving.  Wanneer er een pull-request gedaan wordt via een fork, leidt dit helaas tot een error, zie Issue #79. Dit blokkeert de pull-request niet. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#hoe-we-werken-op-github","title":"Hoe we werken op Github","text":"<p>We werken met Markdown bestanden.  Dit is bestandsformaat voor platte tekstbestanden en wordt door veel verschillende tools ondersteund. Dit maakt het eenvoudig om versiebeheer op het Algoritmekader toe te passen. </p> <p>Daarnaast maken gebruik van mkdocs en material for mkdocs om de informatie op een interactieve wijze inzichtelijk te maken op de website van het Algoritmekader. </p>"},{"location":"overhetalgoritmekader/CONTRIBUTING/#wil-je-een-nieuwe-pagina-aanmaken","title":"Wil je een nieuwe pagina aanmaken?","text":"<p>In het mkdocs.yml bestand staan de settings voor deze website.  In principe hoef je hier niets aan aan te passen, maar als je een nieuwe pagina wilt aanmaken kan het nodig zijn om hier een aanpassing in te doen. Onderdeel van deze settings is namelijk de navigatie voor de site (welke pagina's zijn zichtbaar, en welke pagina's vallen daaronder). Dit staat in de nav: sectie.  Indien je een nieuwe pagina wilt toevoegen, is het vaak nodig deze wijziging ook door te voeren in het mkdocs.yml bestand.</p>"},{"location":"overhetalgoritmekader/definities/","title":"Woordenlijst","text":"Begrip Definitie aanbieder Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling. aanbieders Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merknaam, al dan niet tegen betaling. aanbieder verder in de AI-waardeketen Een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is ge\u00efntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en verticaal ge\u00efntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen aangemelde instantie Een conformiteitsbeoordelingsinstantie die overeenkomstig de AI-verordening en andere relevante harmonisatiewetgeving van de Unie is aangemeld aanmeldende autoriteit De nationale autoriteit die verantwoordelijk is voor het opzetten en uitvoeren van de noodzakelijke procedures voor de beoordeling, aanwijzing en kennisgeving van de conformiteitsbeoordelingsinstanties en de monitoring hiervan AI-bureau De taak van de Commissie waarbij zij bijdraagt aan de uitvoering van, de monitoring van en het toezicht op AI-systemen en AI-modellen voor algemene doeleinden, en AI-governance, als bepaald in het besluit van de Commissie van 24 januari 2024; verwijzingen in deze verordening naar het AI-bureau worden begrepen als verwijzingen naar de Commissie AI-geletterheid Vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van de de AI-verordening, in staat stellen met kennis van zaken AI-systemen in te zetten en zich bewuster te worden van de kansen en risico\u2019s van AI en de mogelijke schade die zij kan veroorzaken AI-model voor algemene doeleinden Een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden ge\u00efntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht. AI-systeem een op een machine gebaseerd systeem dat is ontworpen om met verschillende niveaus van autonomie te werken en dat na het inzetten ervan aanpassingsvermogen kan vertonen, en dat, voor expliciete of impliciete doelstellingen, uit de ontvangen input afleidt hoe output te genereren zoals voorspellingen, inhoud, aanbevelingen of beslissingen die van invloed kunnen zijn op fysieke of virtuele omgevingen; AI-systeem voor algemene doeleinden Een AI-systeem dat is gebaseerd op een AI-model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen AI-testomgeving voor regelgeving Een door een bevoegde autoriteit opgezet gecontroleerd kader dat aanbieders of toekomstige aanbieders van AI-systemen de mogelijkheid biedt een innovatief AI-systeem te ontwikkelen, trainen, valideren en testen, zo nodig onder re\u00eble omstandigheden, volgens een testomgevingsplan, voor een beperkte periode en onder begeleiding van een toezichthouder. algoritme Een set van regels en instructies die een computer geautomatiseerd volgt bij het maken van berekeningen om een probleem op te lossen of een vraag te beantwoorden auteursrecht Het auteursrecht is het uitsluitend recht van den maker van een werk van letterkunde, wetenschap of kunst, of van diens rechtverkrijgenden, om dit openbaar te maken en te verveelvoudigen, behoudens de beperkingen, bij de wet gesteld. beoogd doel Het gebruik waarvoor een AI-systeem door de aanbieder is bedoeld, met inbegrip van de specifieke context en voorwaarden van het gebruik, zoals gespecificeerd in de informatie die door de aanbieder in de gebruiksinstructies, reclame- of verkoopmaterialen en verklaringen, alsook in de technische documentatie is verstrekt bijzondere categorie\u00ebn persoonsgegevens De categorie\u00ebn persoonsgegevens als bedoeld in artikel 9, lid 1, van Verordening (EU) 2016/679, artikel 10 van Richtlijn (EU) 2016/680 en artikel 10, lid 1, van Verordening (EU) 2018/1725 biometrische gegevens Persoonsgegevens die het resultaat zijn van een specifieke technische verwerking met betrekking tot de fysieke, fysiologische of gedragsgerelateerde kenmerken van een natuurlijk persoon, zoals gezichtsafbeeldingen of vingerafdrukgegevens biometrische identificatie De geautomatiseerde herkenning van fysieke, fysiologische, gedragsgerelateerde of psychologische menselijke kenmerken om de identiteit van een natuurlijk persoon vast te stellen door biometrische gegevens van die persoon te vergelijken met in een databank opgeslagen biometrische gegevens van personen biometrische verificatie De geautomatiseerde \u00e9\u00e9n-op-\u00e9\u00e9nverificatie, met inbegrip van de authenticatie, van de identiteit van natuurlijke personen door hun biometrische gegevens te vergelijken met eerder verstrekte biometrische gegevens capaciteiten met een grote impact Capaciteiten die overeenkomen met of groter zijn dan de capaciteiten die worden opgetekend bij de meest geavanceerde AI-modellen voor algemene doeleinden. CE-markering Een markering waarmee een aanbieder aangeeft dat een AI-systeem in overeenstemming is met de voorschriften van hoofdstuk III, afdeling 2, van de AI-Verordening en andere toepasselijke harmonisatiewetgeving van de Unie, die in het aanbrengen ervan voorzien conformiteitsbeoordeling Het proces waarbij de naleving wordt aangetoond van de voorschriften van hoofdstuk III, afdeling 2 van de AI-Verordening in verband met een AI-systeem met een hoog risico deepfake Door AI gegenereerd of gemanipuleerd beeld-, audio- of videomateriaal dat een gelijkenis vertoont met bestaande personen, voorwerpen, plaatsen, entiteiten of gebeurtenissen, en door een persoon ten onrechte voor authentiek of waarheidsgetrouw zou worden aangezien direct onderscheid Indien een persoon op een andere wijze wordt behandeld dan een ander in een vergelijkbare situatie wordt, is of zou worden behandeld, op grond van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat; directe discriminatie De ongelijke behandeling van een persoon of groep personen ten opzichte van andere personen in een vergelijkbare situatie, op grond van een beschermd persoonskenmerk (discriminatiegrond). discriminatiegrond Beschermde persoonskenmerken op basis waarvan het maken van onderscheid tussen personen verboden is. Bijvoorbeeld: ras, nationaliteit, religie, geslacht, seksuele gerichtheid, handicap of chronische ziekte. distributeur Een andere natuurlijke persoon of rechtspersoon in de toeleveringsketen dan de aanbieder of de importeur, die een AI-systeem in de Unie op de markt aanbiedt downstreamaanbieder Een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is ge\u00efntegreerd, ongeacht of het model door hemzelf wordt verstrekt en verticaal ge\u00efntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen etnisch profileren Het gebruik door overheidsinstanties van selectiecriteria als ras, huidskleur, taal, religie, nationaliteit of nationale of etnische afkomst bij de uitoefening van toezichts-, handhavings- en opsporingsbevoegdheden, zonder dat daarvoor een objectieve en redelijke rechtvaardiging bestaat geharmoniseerde norm Een geharmoniseerde norm zoals gedefinieerd in artikel 2, lid 1,punt c), van Verordening (EU) nr. 1025/2012 gemeenschappelijke specificatie een reeks technische specificaties zoals gedefinieerd in artikel 2, punt 4, van Verordening (EU) nr. 1025/2012, om te voldoen aan bepaalde voorschriften zoals vastgelegd in de AI-verordening gebruiksinstructies de door de aanbieder verstrekte informatie om de gebruiksverantwoordelijke te informeren over met name het beoogde doel en juiste gebruik van een AI-systeem gebruiksverantwoordelijke Een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een persoonlijke niet- beroepsactiviteit. geharmoniseerde norm Een Europese norm die op verzoek van de Commissie is vastgesteld met het oog op de toepassing van harmonisatiewetgeving van de Unie ge\u00efnformeerde toestemming De vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder re\u00eble omstandigheden, na ge\u00efnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing om deel te nemen gemachtigde Een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een schriftelijke machtiging heeft gekregen en aanvaard van een aanbieder van een AI-systeem of een AI-model voor algemene doeleinden om namens die aanbieder de verplichtingen en procedures van deze verordening respectievelijk na te komen en uit te voeren; gemeenschappelijke specificatie Een reeks technische specificaties zoals gedefinieerd in artikel 2, punt 4, van Verordening (EU) nr. 1025/2012, om te voldoen aan bepaalde voorschriften zoals vastgelegd in deze verordening gevoelige operationele gegevens Operationele gegevens met betrekking tot activiteiten op het gebied van preventie, opsporing, onderzoek of vervolging van strafbare feiten waarvan de openbaarmaking de integriteit van strafprocedures in het gedrang zou kunnen brengen governance Governance gaat over de inrichting van een organisatie en daar bijbehorende processen, regels, gebruiken en bijbehorende verantwoordelijkheden importeur Een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een AI-systeem in de handel brengt dat de naam of merknaam van een in een derde land gevestigde natuurlijke of rechtspersoon draagt in de handel brengen Het voor het eerst in de Unie op de markt aanbieden van een AI-systeem of een AI-model voor algemene doeleinden in gebruik stellen De directe levering van een AI-systeem door de aanbieder aan de gebruiksverantwoordelijke voor het eerste gebruik of voor eigen gebruik in de Unie voor het beoogde doel indirect onderscheid Indien een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaalde godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid of burgerlijke staat in vergelijking met andere personen bijzonder treft. indirecte discriminatie Wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een bepaald beschermd persoonskenmerk (discriminatiegrond) in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat. inputdata Data die in een AI-systeem worden ingevoerd of direct door een AI-systeem worden verworven en op basis waarvan het systeem een output genereert kritieke infrastructuur Kritieke infrastructuur zoals gedefinieerd in artikel 2, punt 4, van Richtlijn (EU) 2022/2557 legaliteitsbeginsel Het legaliteitsbeginsel houdt in dat alle overheidsoptreden moet berusten op een overeenstemmen met - kenbare en voldoende specifieke - algemene regels. markttoezichtautoriteit De nationale autoriteit die de activiteiten verricht en maatregelen neemt als bedoeld in Verordening (EU) 2019/1020 nationale bevoegde autoriteit Een aanmeldende autoriteit of een de markttoezichtautoriteit; wat betreft AI-systemen die door instellingen, organen en instanties van de EU in gebruik worden gesteld of worden gebruikt, worden verwijzingen naar nationale bevoegde autoriteiten of markttoezichtautoriteiten in deze verordening begrepen als verwijzingen naar de Europese Toezichthouder voor gegevensbescherming norm Een norm is een vrijwillige afspraak tussen partijen over een product, dienst of proces. Normen zijn geen wetten, maar \u2019best practices\u2019. Iedereen kan - op vrijwillige basis - hier zijn voordeel mee doen. In zakelijke overeenkomsten hebben normen een belangrijke functie. Ze bieden marktpartijen duidelijkheid over en vertrouwen in producten, diensten of organisaties en dagen de maatschappij uit te innoveren. NEN-normen worden ontwikkeld door inhoudsexperts en specialisten op het gebied van normontwikkeling. normalisatie Normalisatie is het proces om te komen tot een norm. Dit proces is open, transparant en gericht op consensus en vindt plaats in normcommissies die bestaan uit vertegenwoordigers van alle betrokken partijen. Dit gebeurt niet alleen op nationaal niveau, maar ook in Europees en mondiaal verband. objectieve rechtvaardiging Van een objectieve rechtvaardiging voor onderscheid is sprake wanneer onderscheid een legitiem doel nastreeft en er een redelijke relatie van evenredigheid bestaat tussen het gemaakte onderscheid en het nagestreefde doel. op de markt aanbieden Het in het kader van een handelsactiviteit, al dan niet tegen betaling, verstrekken van een AI-systeem of een AI-model voor algemene doeleinden met het oog op distributie of gebruik op de markt van de Unie operator Een aanbieder, productfabrikant, gebruiksverantwoordelijke, gemachtigde, importeur of distributeur prestaties van een AI-systeem Het vermogen van een AI-systeem om het beoogde doel te verwezenlijken plan voor testen onder re\u00eble omstandigheden Een document waarin de doelstellingen, methode, geografische reikwijdte, betrokken personen, duur, monitoring, organisatie en wijze van uitvoering van een test onder re\u00eble omstandigheden worden omschreven proceseigenaar De proceseigenaar is verantwoordelijk voor de kwaliteit van het proces en de vastlegging daarvan in een processchema proefpersoon In het kader van tests onder re\u00eble omstandigheden: een natuurlijk persoon die deelneemt aan een test onder re\u00eble omstandigheden publieke inkoop De verwerving van werken, leveringen of diensten door een overheid of publieke organisatie, van de markt of een andere externe instantie, terwijl zij tegelijkertijd publieke waarde cre\u00ebren en waarborgen vanuit het perspectief van de eigen organisatie. redelijkerwijs te voorzien misbruik Het gebruik van een AI-systeem op een wijze die niet in overeenstemming is met het beoogde doel, maar die kan voortvloeien uit redelijkerwijs te voorzien menselijk gedrag of redelijkerwijs te voorziene interactie met andere systemen, waaronder andere AI-systemen risico De combinatie van de kans op schade en de ernst van die schade; substanti\u00eble wijziging Een verandering van een AI-systeem nadat dit in de handel is gebracht of in gebruik is gesteld, die door de aanbieder niet is voorzien of gepland in de initi\u00eble conformiteitsbeoordeling en als gevolg waarvan de overeenstemming van het AI-systeem met de voorschriften van hoofdstuk III, afdeling 2, AI-Verordening wordt be\u00efnvloed, of die leidt tot een wijziging van het beoogde doel waarvoor het AI-systeem is beoordeeld systeem voor monitoring na het in de handel brengen Alle door aanbieders van AI-systemen verrichte activiteiten voor het verzamelen en evalueren van ervaringen met door hen in de handel gebrachte of in gebruik gestelde AI-systemen, teneinde te kunnen vaststellen of er onmiddellijk corrigerende dan wel preventieve maatregelen nodig zijn systeem voor het herkennen van emoties Een AI-systeem dat is bedoeld voor het vaststellen of afleiden van de emoties of intenties van natuurlijke personen op basis van hun biometrische gegevens systeem voor biometrische categorisering Een AI-systeem dat is bedoeld voor het indelen van natuurlijke personen in specifieke categorie\u00ebn op basis van hun biometrische gegevens, tenzij dit een aanvulling vormt op een andere commerci\u00eble dienst en om objectieve technische redenen strikt noodzakelijk is systeem voor biometrische identificatie op afstand Een AI-systeem dat is bedoeld voor het identificeren van natuurlijke personen, zonder dat zij daar actief bij betrokken zijn en doorgaans van een afstand, door middel van vergelijking van de biometrische gegevens van een persoon met de biometrische gegevens die zijn opgenomen in een referentiedatabank systeem voor biometrische identificatie op afstand in real time Een systeem voor biometrische identificatie op afstand, waarbij het vastleggen van biometrische gegevens, de vergelijking en de identificatie zonder significante vertraging plaatsvinden, zowel wanneer de identificatie niet enkel onmiddellijk plaatsvindt, maar ook wanneer de identificatie met beperkte korte vertragingen plaatsvindt, om omzeiling te voorkomen systeem voor biometrische identificatie op afstand achteraf Een ander biometrisch systeem voor de identificatie op afstand dan een systeem voor biometrische identificatie op afstand in real time systeemrisico Een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleinden, die aanzienlijke gevolgen hebben voor de markt van de Unie vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid terugroepen van een AI-systeem Een maatregel gericht op het retourneren aan de aanbieder, het buiten gebruik stellen of het onbruikbaar maken van een AI-systeem dat aan gebruiksverantwoordelijken ter beschikking is gesteld testdata Data die worden gebruikt voor het verrichten van een onafhankelijke evaluatie van het AI-systeem om de verwachte prestaties van dat systeem te bevestigen voordat het in de handel wordt gebracht of in gebruik wordt gesteld testomgevingsplan Tussen de deelnemende aanbieder en de bevoegde autoriteit overeengekomen document waarin de doelstellingen, de voorwaarden, het tijdschema, de methode en de vereisten voor de in de testomgeving uitgevoerde activiteiten worden beschreven testen onder re\u00eble omstandigheden Het tijdelijk testen van een AI-systeem voor zijn beoogde doel onder re\u00eble omstandigheden buiten een laboratorium of anderszins gesimuleerde omgeving teneinde betrouwbare en robuuste gegevens te verkrijgen, en te beoordelen en te verifi\u00ebren of het AI-systeem overeenstemt met de voorschriften van de AI-verordening en het wordt niet aangemerkt als het in de handel brengen of in gebruik stellen van het AI-systeem in de zin van de AI-verordening, mits aan alle in artikel 57 of 60 vastgestelde voorwaarden is voldaan toestemming met kennis van zaken De vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder re\u00eble omstandigheden, na ge\u00efnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing deel te nemen trainingsdata Data die worden gebruikt voor het trainen van een AI-systeem door de leerbare parameters hiervan aan te passen uit de handel nemen van een AI-systeem Een maatregel waarmee wordt beoogd te voorkomen dat een AI-systeem dat zich in de toeleveringsketen bevindt, op de markt wordt aangeboden validatiedata Data die worden gebruikt voor het verrichten van een evaluatie van het getrainde AI-systeem en voor het afstemmen van onder andere de niet-leerbare parameters en het leerproces ervan, om underfitting of overfitting te voorkomen validatiedataset Een afzonderlijke dataset of deel van de trainingsdataset, als vaste of variabele opdeling. veiligheidscomponent Een component van een product of systeem die een veiligheidsfunctie voor dat product of systeem vervult of waarvan het falen of gebrekkig functioneren de gezondheid en veiligheid van personen of eigendom in gevaar brengt verwerker Een .. rechtspersoon, een overheidsinstantie, een dienst of een ander orgaan die/dat ten behoeve van de verwerkingsverantwoordelijke persoonsgegevens verwerkt. verwerkersverantwoordelijke Een rechtspersoon of overheidsinstantie die, alleen of samen met anderen, het doel van en de middelen voor de verwerking van persoonsgegevens vaststelt zwevendekommabewerking of \u201cfloating-point operation (FLOP) Elke wiskundige bewerking of toewijzing met zwevendekommagetallen, die een subset vormen van de re\u00eble getallen die gewoonlijk op computers worden gerepresenteerd door een geheel getal met een vaste precisie, geschaald door een gehele exponent van een vaste basis <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/","title":"Soorten algoritmes","text":"<p>Om te voldoen aan de vereisten, moet je weten met welk soort algoritme je werkt. Gaat het om simpele rekenregels of een AI-systeem? En wat voor impact hebben je algoritmes?</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#wanneer-is-het-een-algoritme","title":"Wanneer is het een algoritme?","text":"<p>Met een algoritme bedoelen we een set regels en instructies die een computer uitvoert, met 1 of meer van deze doelen:</p> <ul> <li>problemen oplossen</li> <li>vragen beantwoorden</li> <li>taken of processen uitvoeren</li> <li>besluiten nemen</li> </ul>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#rekenregels","title":"Rekenregels","text":"<p>Rekenregels (ook wel: regelgebaseerde algoritmes) zijn de meest eenvoudige algoritmes. Dit zijn door mensen bedachte regels die het computersysteem precies moet opvolgen: als x gebeurt, dan doe je y.</p> <p>Rekenregels:</p> <ul> <li>zijn expliciet geprogrammeerd en bedacht door mensen</li> <li>bestaan uit vaste stappen om een taak uit te voeren</li> </ul> <p>Rekenregels zijn niet kunstmatig intelligent (AI). Rekenregels kunnen wel onderdeel zijn van een AI-systeem. </p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#voorbeelden","title":"Voorbeelden","text":"<ul> <li>Eenvoudige chatbots die burgers advies geven op basis van door mensen bedachte beslisbomen.</li> <li>Ondersteuning berekening uitkering dat adviseert over uitkeringen, op basis van door mensen bedachte beslisbomen. </li> <li>Prestatiemonitor dat risicoscores berekent van scholen, op basis van door mensen bedachte regels.</li> </ul>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#zelflerende-algoritmes","title":"Zelflerende algoritmes","text":"<p>Zelflerende algoritmes zijn algoritmes die zichzelf trainen. Dit proces heet machinelearning. Hierdoor worden computers intelligent zonder dat mensen dit precies zo programmeren. Dit is een veel voorkomende vorm van AI. </p> <p>Zelflerende technieken zijn in elk geval:</p> <ul> <li>Supervised learning (gecontroleerd leren): Je algoritme leert van gegevens die je labelt met informatie. Je biedt bijvoorbeeld foto\u2019s aan met de labels: dit is wel een kat, dit is geen kat. Voorbeeld: Virtuele assistent Gem.</li> <li>Unsupervised learning (ongecontroleerd leren): Je laat het algoritme zelf patronen en structuren ontdekken in ongestructureerde gegevens zonder labels. Je biedt bijvoorbeeld foto\u2019s aan van dieren die het algoritme zelf moet groeperen. Voorbeeld: Polis voor participatieplatformen.</li> <li>Reinforcement learning (bekrachtiginsleren): Het algoritme leert door straf en beloning. Het doel is zo hoog mogelijk scoren in zo min mogelijk tijd. Je geeft bijvoorbeeld punten als het algoritme foto\u2019s sorteert die op katten lijken. Voorbeeld: I-VRI voor verkeerslichten.</li> <li>Deep learning: Supervised, unsupervised of reinforcement learning gecombineerd met diepe neurale netwerken. Dit zijn kunstmatige neurale netwerken met veel verschillende lagen. Hierdoor kun je nog ingewikkeldere problemen oplossen. Voorbeeld: Geautomatiseerde gezichtsvergelijking bij het RNI-inschrijfproces.</li> </ul>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#ai-systeem","title":"AI-systeem","text":"<p>Met een AI-systeem bedoelen we een systeem dat kunstmatig intelligent is volgens de Europese AI-verordening. Dit zijn in elk geval systemen die gebruik maken van:</p> <ul> <li>supervised learning</li> <li>unsupervised learning</li> <li>reinforcement learning</li> <li>deep learning</li> </ul> <p>Symbolische AI valt mogelijk onder een AI-systeem. Dit is nog onduidelijk in de EU-verordening.</p> <p>Tip</p> <p>Twijfel je of je algoritme onderdeel is van een AI-systeem? Raadpleeg een expert. Of beschouw het systeem voor de zekerheid als een AI-systeem.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#risicogroepen-ai-systemen","title":"Risicogroepen AI-systemen","text":"<p>AI-systemen vallen mogelijk onder een risicogroep uit de EU-verordening. Het hangt ervan af waarvoor je dit AI-systeem gebruikt.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#risico-op-misleiding","title":"Risico op misleiding","text":"<p>Dit zijn AI-systemen die je gebruikt voor:</p> <ul> <li>interactie met mensen, zoals AI-chatbots</li> <li>genereren van content, zoals afbeeldingen laten maken door Dall-E </li> </ul> <p>Over deze systemen moet je transparant zijn. Gebruikers mogen niet denken dat zij te maken hebben met echte mensen of originele content.</p> <p>Zie AI-verordening, hoofdstuk IV.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#hoog-risico-ai-systemen","title":"Hoog-risico-AI-systemen","text":"<p>Dit zijn AI-systemen die je gebruikt als veiligheidsonderdeel van bepaalde producten of AI-systemen die je gebruikt voor bepaalde diensten of processen.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#veiligheidsonderdeel","title":"Veiligheidsonderdeel","text":"<p>Je AI-systeem speelt een belangrijke rol in de veiligheid van een product. En dit product valt onder de harmonisatiewetgeving van de EU, zoals:</p> <ul> <li>machines</li> <li>speelgoed</li> <li>liften</li> <li>uitrusting en beveiligingssystemen voor plaatsen met ontploffingsgevaar</li> <li>radioapparatuur</li> <li>drukapparatuur</li> <li>pleziervaartuigen</li> <li>kabelbaaninstallaties</li> <li>gastoestellen</li> <li>medische hulpmiddelen</li> <li>hulpmiddelen voor het testen van menselijk materiaal (in-vitrodiagnostiek)</li> <li>auto-industrie</li> <li>luchtvaartindustrie</li> </ul> <p>Zie AI-verordening, bijlage I.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#diensten-of-processen","title":"Diensten of processen","text":"<p>Je gebruikt het AI-systeem voor:</p> <ul> <li>Biometrie, zoals het herkennen of indelen van mensen op basis van hun vingerafdruk, gezicht of andere lichamelijke kenmerken.</li> <li>Kritieke infrastructuur, zoals het veilig houden van digitale netwerken en verkeersnetwerken en het leveren van elektriciteit, water, gas en warmte.</li> <li>Onderwijs en beroepsopleiding, zoals het bepalen welke studenten je toelaat en het beoordelen van hun prestaties of gedrag.</li> <li>Werkgelegenheid, personeelsbeheer en toegang tot zelfstandige arbeid, zoals het werven en selecteren van mensen, besluiten nemen die invloed hebben op hun contract en het beoordelen van hun prestaties of gedrag.  </li> <li>Essenti\u00eble particuliere en openbare diensten, zoals bepalen wie recht heeft op uitkeringen, gezondheidszorg en andere belangrijke diensten en wie noodhulp krijgt van politie, brandweer en ambulance, het beoordelen van iemands financi\u00eble situatie, fraude opsporen en het bepalen van risico\u2019s en prijzen voor levensverzekeringen en ziektekostenverzekeringen.</li> <li>Rechtshandhaving, zoals iemands kans inschatten om slachtoffer of dader te worden, het gebruik van een leugendetector, het beoordelen van bewijsmateriaal en het opsporen van verdachten.</li> <li>Migratie, asiel en grenzen, zoals inschatten wat de kans is dat iemand gevaarlijk of illegaal is, het behandelen van aanvragen en klachten en het herkennen of opsporen van mensen.</li> <li>Rechtsbedeling en democratische processen, zoals het uitleggen van de wet aan een rechtbank, gerechtshof of de Hoge Raad, advies geven bij een geschil of het be\u00efnvloeden van de uitslag van een verkiezing.</li> </ul> <p>Zie AI-verordening, bijlage III.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#verboden-ai-systemen","title":"Verboden AI-systemen","text":"<p>Dit zijn AI-systemen die:</p> <ul> <li>misleiden</li> <li>misbruik maken van kwetsbaarheden of gevoelige situaties, zoals het overhalen van mensen met schulden om iets te kopen</li> <li>sociale scores bijhouden voor gedrag van mensen en hen hiervoor straffen</li> <li>beoordelen hoe groot het risico is dat iemand een strafbaar feit pleegt</li> <li>afbeeldingen van gezichten \u2018scrapen\u2019 (verzamelen) via internet of bewakingscamera\u2019s en deze opslaan in een databank</li> <li>emoties herkennen van mensen op hun werkplek of op school</li> <li>biometrisch categoriseren: mensen indelen in gevoelige categorie\u00ebn zoals ras en geloof, op basis van lichamelijke kenmerken zoals huidskleur</li> <li>biometrisch identificeren op afstand voor rechtshandhaving, zoals gezichten herkennen via camera\u2019s op een openbaar plein (hiervoor gelden uitzonderingen in ernstige situaties zoals ontvoeringen en terrorisme)</li> </ul> <p>Zie AI-verordening, artikel 5.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#impact-van-algoritmes","title":"Impact van algoritmes","text":"<p>Impactvolle algoritmes moet je publiceren in het Algoritmeregister. Dat moet in elk geval in deze situaties:</p> <ul> <li>Je algoritme is onderdeel van een hoog-risico-AI-systeem. </li> <li>Je algoritme heeft invloed op een proces met rechtsgevolgen voor burgers of organisaties. Bijvoorbeeld het wel of niet krijgen van boetes of subsidies.</li> <li>Je algoritme heeft invloed op de manier waarop de overheid burgers of organisaties indeelt, of contact met hen zoekt. Bijvoorbeeld bij het inschatten van risico\u2019s of het signaleren van fraude.</li> <li>Je overheidsorganisatie vindt zelf dat het algoritme impact heeft op de maatschappij. Bijvoorbeeld omdat het algoritme ingewikkeld is, veel data gebruikt, vaak in de media komt of onderzocht wordt door een toezichthouder.</li> </ul> <p>Een impactvol algoritme kan schade veroorzaken aan de maatschappij. Daarom zijn de regels strenger voor impactvolle dan voor niet-impactvolle algoritmes. </p> <p>Tip</p> <p>Twijfel je of je algoritme impactvol is of niet? Beschouw het algoritme dan als impactvol.</p> <p>Meer uitleg en voorbeelden vind je in de Handreiking Algoritmeregister.</p>"},{"location":"overhetalgoritmekader/soorten-algoritmes/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"rollen/","title":"Rollen","text":"<p>Verantwoord gebruik van algoritmes en AI-systemen is mogelijk als mensen in verschillende rollen goed samenwerken, op het juiste moment.</p>"},{"location":"rollen/#bepaal-zelf-rollen-en-verantwoordelijkheden","title":"Bepaal zelf rollen en verantwoordelijkheden","text":"<p>Als organisatie bepaal je zelf de namen van je rollen of functies en de taken en verantwoordelijkheden die hierbij horen.  Misschien heb je bijvoorbeeld minder rollen, omdat je verschillende expertises combineert in 1 rol. Of rollen hebben andere namen.</p>"},{"location":"rollen/#voorbeelden-van-rollen","title":"Voorbeelden van rollen","text":"<p>We adviseren de volgende rollen bij het gebruik van algoritmes. Andere rollen zijn ook mogelijk.</p>"},{"location":"rollen/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"rollen/beleid-en-advies/","title":"Beleid en advies","text":"<p>Dit is degene die gaat over wat wenselijk is en adviseert bij de ontwikkeling en/of inzet van een algoritme. Hierbij horen rollen zoals de beleidsmedewerker, ethicus, CIO-adviseur, architect.</p>"},{"location":"rollen/beleid-en-advies/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-01Bepaal of er genoeg experts beschikbaar zijnorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesorg-03Maak een plan voor het omgaan met risico\u2019sorg-04Maak afspraken over het wijzigen van de codeorg-05Maak afspraken over het beheer van gebruikersorg-06Maak afspraken over het beheer van wachtwoordenorg-07Controleer en verbeter regelmatig de kwaliteit van het algoritmepba-01Beschrijf het probleem dat het algoritme moet oplossenpba-02Beschrijf het doel van het algoritmepba-03Beschrijf waarom een algoritme het probleem moet oplossenpba-04Overleg regelmatig met belanghebbendenowp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrixowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten wordenowp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesowp-11Koop duurzaam algoritmes indat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waaromdat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsproceduredat-07Gebruik duurzame datacentersdat-09Beperk de omvang van datasets voor energie-effici\u00ebntieowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019owk-02Maak een noodplan voor het stoppen van het algoritmeowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isver-01Toets het algoritme op biasimp-01Maak een openbaar besluit over de inzet van het algoritmeimp-03Organiseer menselijke controle van het algoritmeimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregisterimp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeemimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenimp-07Vermeld het gebruik van persoonsgegevens in een privacyverklaringimp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregisterimp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.mon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenmon-05Meten, monitoren en rapporteren van milieu-impact van algoritmesBepaal of de output bepalende invloed heeft in een besluit richting personenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenBewijs laten leveren dat auteursrechten niet worden geschonden met de outputBewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentRestrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputGarantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeDe mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingVaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/jurist/","title":"Jurist","text":""},{"location":"rollen/jurist/#maatregelen","title":"Maatregelen","text":"idMaatregelenpba-05Beschrijf de wettelijke grondslag voor de inzet van het algoritmeowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten wordendat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsproceduredat-05Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregerendat-06Controleer de auteursrechten van eigen dataowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenver-01Toets het algoritme op biasver-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenimp-07Vermeld het gebruik van persoonsgegevens in een privacyverklaringimp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregistermon-03Maak een noodplan voor beveiligingsincidentenAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingContractuele afspraken over data en artefactenGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputGarantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/ontwikkelaar/","title":"Ontwikkelaar","text":""},{"location":"rollen/ontwikkelaar/#maatregelen","title":"Maatregelen","text":"idMaatregelen <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"rollen/projectleider/","title":"Projectleider","text":""},{"location":"rollen/projectleider/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-01Bepaal of er genoeg experts beschikbaar zijnorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesorg-03Maak een plan voor het omgaan met risico\u2019sorg-04Maak afspraken over het wijzigen van de codeorg-05Maak afspraken over het beheer van gebruikersorg-06Maak afspraken over het beheer van wachtwoordenorg-07Controleer en verbeter regelmatig de kwaliteit van het algoritmepba-01Beschrijf het probleem dat het algoritme moet oplossenpba-02Beschrijf het doel van het algoritmepba-03Beschrijf waarom een algoritme het probleem moet oplossenpba-04Overleg regelmatig met belanghebbendenowp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrixowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten wordenowp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesowp-11Koop duurzaam algoritmes indat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waaromdat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsproceduredat-07Gebruik duurzame datacentersdat-09Beperk de omvang van datasets voor energie-effici\u00ebntieowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019owk-02Maak een noodplan voor het stoppen van het algoritmeowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isver-01Toets het algoritme op biasimp-01Maak een openbaar besluit over de inzet van het algoritmeimp-03Organiseer menselijke controle van het algoritmeimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregisterimp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeemimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenimp-07Vermeld het gebruik van persoonsgegevens in een privacyverklaringimp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregisterimp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.mon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenmon-05Meten, monitoren en rapporteren van milieu-impact van algoritmesBepaal of de output bepalende invloed heeft in een besluit richting personenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenBewijs laten leveren dat auteursrechten niet worden geschonden met de outputBewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentRestrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputGarantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomstVul technische documentatie van aanbieder aan met informatie vanuit de gebruiksverantwoordelijkeDe mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingVaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen <p>Disclaimer</p> <p>Het Algoritmekader is nog volop in ontwikkeling. Op deze plek willen we vooral aan de slag gaan op een open en transparante wijze. Het is dus niet definitief. Dat betekent dat er dingen opstaan die niet af zijn en soms zelfs fout. Mocht er iets niet kloppen, laat het ons weten via GitHub.</p>"},{"location":"vereisten/","title":"Vereisten","text":"<p>Overzicht van vereisten voor overheden die algoritmes of AI-systemen ontwikkelen of gebruiken. </p>"},{"location":"vereisten/#wetten-en-regels","title":"Wetten en regels","text":"<p>De vereisten zijn gebaseerd op de wetten en regels voor het uitvoeren van wettelijke taken, zoals de:</p> <ul> <li>AI-verordening</li> <li>Algemene verordening gegevensbescherming (AVG)</li> <li>Algemene wet bestuursrecht (Awb)</li> <li>Algemene wet gelijke behandeling (Awgb) </li> <li>Auteurswet</li> <li>Baseline Informatiebeveiliging Overheid (BIO)</li> <li>Grondwet</li> </ul> <p>Bij elke vereiste staat dit er duidelijk bij.</p>"},{"location":"vereisten/#aantal-vereisten-verschilt-per-situatie","title":"Aantal vereisten verschilt per situatie","text":"<p>Welke vereisten gelden voor jouw organisatie, hangt af van:</p> <ul> <li>de technologie die je gebruikt: rekenregels, machinelearning of generatieve AI</li> <li>de risicoclassificatie van het algoritme dat je gebruikt</li> <li>je rol: ben je ontwikkelaar of alleen gebruiker van het algoritme?</li> </ul>"},{"location":"vereisten/#voorbeeld","title":"Voorbeeld","text":"<p>Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregister.</p> <p>Deze vereiste geldt alleen voor impactvolle algoritmes en hoog-risico-AI-systemen. Een niet-impactvolle rekenregel hoef je niet te registreren.</p>"},{"location":"vereisten/#overzicht-vereisten","title":"Overzicht vereisten","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieidVereistenRollenLevenscyclusOnderwerpenaia-01Bevorder AI-geletterdheid van personeel en gebruikers                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              aia-02Documentatie beoordeling niet-hoog-risico AI                  projectleider                               ontwerp                               governance                               transparantie              aia-03Verplicht risicobeheersysteem voor hoog-risico AI                  projectleider                               organisatieverantwoordelijkheden                               governance              aia-04Risicobeoordeling voor jongeren en kwetsbaren                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              aia-05Data van hoog-risico ai moet voldoen aan kwaliteitscriteria                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              aia-06Technische documentatie voor hoog-risico AI                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie                               technische-robuustheid-en-veiligheid              aia-07Automatische logregistratie voor hoog-risico AI                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               transparantie                               technische-robuustheid-en-veiligheid              aia-08Transparantie in ontwerp voor hoog-risico AI                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-09Toezichtmogelijkheden voor gebruikers                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              aia-10Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-11Kwaliteitsbeheersysteem voor hoog-risico AI                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              aia-12Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-13Bewaartermijn voor gegenereerde logs                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              aia-14Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-15Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              aia-16Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem                  projectleider                               implementatie                               transparantie              aia-17Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico                  projectleider                               implementatie                               governance                               transparantie              aia-18Corrigerende maatregelen voor non-conforme AI                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-19Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              aia-22Maatregelen van gebruiksverantwoordelijken voor gebruik                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               implementatie                               governance              aia-23Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              aia-24Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem                  projectleider                               monitoring-en-beheer                               menselijke-controle              aia-25Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-26Informeren werknemers                  projectleider                               implementatie                               transparantie              aia-27Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie                               governance              aia-28Recht op uitleg AI-besluiten                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              aia-29Beoordeling van grondrechten                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              aia-30Transparantieverplichtingen                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              aia-31Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              aia-32Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               transparantie              aia-33Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij                  projectleider                               monitoring-en-beheer                               governance                               transparantie              aia-34Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               governance                               technische-robuustheid-en-veiligheid              aia-35Verdere verwerking van persoonsgegevens in AI-testomgevingen                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              aia-36Monitoring na het in handel brengen                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              aia-37Melden van ernstige incidenten                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              aia-38Veilig melden van inbreuk op AI verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              aia-39Klachtrecht aanbieders verder in AI-waardeketen                  projectleider                               organisatieverantwoordelijkheden                               governance                               fundamentele-rechten              arc-01De archiefwet is ook van toepassing op algoritmes en AI-systemen                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               governance                               data              aut-01Auteursrechten mogen niet worden geschonden                  jurist                               dataverkenning-en-datapreparatie                               ontwerp                               data                               governance              avg-01Verwerking van persoonsgegevens moet rechtmatig plaatsvinden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-02Beperkte bewaartermijn van persoonsgegevens                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               uitfaseren                               privacy-en-gegevensbescherming              avg-03Persoonsgegevens verzamelen voor specifieke doeleinden                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              avg-04Proportionaliteit en subsidiariteit                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              avg-05Juistheid en actualiteit van gegevens                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-06Verantwoordingsplicht voor de rechtmatigheid van de verwerking                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              avg-07Transparantie bij verwerking persoonsgegevens                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              avg-08Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              avg-09Privacyrechten                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              avg-10Recht op niet geautomatiseerde besluitvorming                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming              avg-11Privacy door ontwerp                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              avg-12Beveiliging van de verwerking                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              avg-13Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              awb-01Relevante feiten en belangen zijn bekend                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten              awb-02Een besluit berust op een deugdelijke motivering                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              bio-01Beveiliging informatie en informatiesystemen                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              bzk-01Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              dat-01Verbod op schenden databankenrechten                  jurist                               dataverkenning-en-datapreparatie                               data              grw-01Beschermen van fundamentele rechten en vrijheden                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              grw-02AI-systemen en algoritmes mogen niet discrimineren                  projectleider                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              woo-01Eenieder heeft recht op toegang tot publieke informatie                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"vereisten/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"vereisten/aia-01-ai-geletterdheid/","title":"Bevorder AI-geletterdheid van personeel en gebruikers","text":"<p>aia-01OrganisatieverantwoordelijkhedenProjectleiderMenselijke controleGovernance</p>"},{"location":"vereisten/aia-01-ai-geletterdheid/#vereiste","title":"Vereiste","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om, zoveel als mogelijk, te zorgen voor een toereikend niveau van AI-geletterdheid bij hun personeel en andere personen die namens hen AI-systemen exploiteren en gebruiken, en houden daarbij rekening met hun technische kennis, ervaring, onderwijs en opleiding en de context waarin de AI-systemen zullen worden gebruikt, evenals met de personen of groepen personen ten aanzien van wie de AI-systemen zullen worden gebruikt.</p>"},{"location":"vereisten/aia-01-ai-geletterdheid/#toelichting","title":"Toelichting","text":"<p>Aanbieders en exploitanten van AI-systemen nemen maatregelen om ervoor te zorgen dat hun personeel en andere betrokkenen voldoende kennis hebben van AI. Dit omvat het bevorderen van kennis over de techniek, evenals kennis over de context waarin de AI-systemen worden gebruikt en de gebruikers van deze systemen.  Daarnaast moet er worden ingezet op het delen van ervaringen, passend onderwijs en opleiding van inidividuen. Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.</p>"},{"location":"vereisten/aia-01-ai-geletterdheid/#bronnen","title":"Bronnen","text":"<p>Artikel 4 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-01-ai-geletterdheid/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-01-ai-geletterdheid/#risico","title":"Risico","text":"<p>Onvoldoende AI-geletterdheid kan leiden tot misbruik of onjuist gebruik van AI-systemen en tot situaties waarin AI-systemen verkeerd worden ingezet, onbedoeld gebruikt worden voor taken waar ze niet geschikt voor zijn, of dat de veiligheid en effectiviteit van de systemen in het gedrang komt. Dit kan leiden tot ineffici\u00ebntie, fouten, en mogelijk schade aan organisaties, gebruikers of betrokkenen.</p>"},{"location":"vereisten/aia-01-ai-geletterdheid/#maatregelen","title":"Maatregelen","text":"idMaatregelenMaak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van Service Level AgreementNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.De mate waarin aanbieder kennisoverdracht en ondersteuning bij implementatie biedt is onderdeel van de aanbestedingVaststellen niveau van benodigde training voor gebruik algoritmen en AI-systemen"},{"location":"vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/","title":"Documentatie beoordeling niet-hoog-risico AI","text":"<p>aia-02OntwerpProjectleiderGovernanceTransparantie</p>"},{"location":"vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#vereiste","title":"Vereiste","text":"<p>Een aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.</p>"},{"location":"vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#toelichting","title":"Toelichting","text":"<p>Een aanbieder die oordeelt dat een AI-systeem niet valt onder hoog-risico zoals gefedinieerd in bijlage III van de AI-verordening, documenteert deze beoordeling voorafgaand aan het in de handel brengen of in gebruik nemen van het systeem. Op verzoek van de nationale autoriteiten verstrekt de aanbieder de documentatie van de beoordeling. De aanbieder of in voorkomend geval de gemachtigd registreert zichzelf en het betreffende AI-systeem in de EU-databank (artikel 71 AI-verordening). AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III (kritieke infrastructuur) worden op nationaal niveau geregistreerd.</p>"},{"location":"vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 6(4) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 49(2) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 71 Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage III Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#risico","title":"Risico","text":"<p>Gebrek aan transparantie en verantwoording bij risicobeoordeling kan leiden tot onrechtmatig in de markt brengen en onrechtmatig gebruik van risicovolle AI-systemen.</p>"},{"location":"vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-03-risicobeheersysteem/","title":"Verplicht risicobeheersysteem voor hoog-risico AI","text":"<p>aia-03OrganisatieverantwoordelijkhedenProjectleiderGovernance</p>"},{"location":"vereisten/aia-03-risicobeheersysteem/#vereiste","title":"Vereiste","text":"<p>Voor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.</p>"},{"location":"vereisten/aia-03-risicobeheersysteem/#toelichting","title":"Toelichting","text":"<p>Het systeem voor risicobeheer moet bestaan uit een tijdens de gehele levensduur van een AI-systeem met een hoog risico doorlopend en gepland iteratief proces. Dit proces moet gericht zijn op het vaststellen en beperken van de relevante risico\u2019s van AI-systemen voor de gezondheid, veiligheid en grondrechten. Het systeem voor risicobeheer moet periodiek worden ge\u00ebvalueerd en geactualiseerd om de blijvende doeltreffendheid ervan te waarborgen, alsook de motivering en de documentatie van eventuele significante besluiten en maatregelen die op grond van de AI-verordening zijn genomen.</p> <p>Dit proces moet ervoor zorgen dat de aanbieder de risico\u2019s of negatieve effecten vaststelt en risicobeperkende maatregelen uitvoert voor de bekende en de redelijkerwijs te voorziene risico\u2019s van AI-systemen voor de gezondheid, veiligheid en grondrechten. Hierin moeten ook maatregelen zitten voor redelijkerwijs te voorzien misbruik, met inbegrip van de mogelijke risico\u2019s die voortvloeien uit de wisselwerking tussen het AI-systeem en de omgeving waarin het werkt. Het systeem voor risicobeheer moet de passendste risicobeheersmaatregelen vaststellen. Bij het vaststellen van de passendste risicobeheersmaatregelen moet de aanbieder de gemaakte keuzes documenteren en toelichten en, in voorkomend geval, deskundigen en externe belanghebbenden betrekken. Bij het vaststellen van het redelijkerwijs te voorzien misbruik van AI-systemen met een hoog risico moet de aanbieder aandacht hebben voor het gebruik van AI-systemen waarvan, hoewel zij niet rechtstreeks onder het beoogde doel vallen en niet in de gebruiksinstructies worden vermeld, mag worden verwacht dat zij kunnen voortvloeien uit gemakkelijk voorspelbaar menselijk gedrag.</p>"},{"location":"vereisten/aia-03-risicobeheersysteem/#bronnen","title":"Bronnen","text":"<p>Artikel 9(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-03-risicobeheersysteem/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-03-risicobeheersysteem/#risico","title":"Risico","text":"<p>Het ontbreken van risicobeheer kan leiden tot schade aan gebruikers of derden en wettelijke aansprakelijkheid voor de aanbieder.</p>"},{"location":"vereisten/aia-03-risicobeheersysteem/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesorg-03Maak een plan voor het omgaan met risico\u2019sBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/","title":"Risicobeoordeling voor jongeren en kwetsbaren","text":"<p>aia-04OntwerpMonitoring en beheerProjectleiderBeleid en adviesFundamentele rechtenBias en non discriminatie</p>"},{"location":"vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#vereiste","title":"Vereiste","text":"<p>Bij het doorlopen, periodieke systematische toetsing en actualisatie van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.</p>"},{"location":"vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#toelichting","title":"Toelichting","text":"<p>Bij de uitvoering van het in de leden 1 tot en met 7 van art. 9 AI-Verordening bedoelde systeem voor risicobeheer houden aanbieders rekening met de vraag of het beoogde doel van het AI-systeem met een hoog risico waarschijnlijk negatieve gevolgen zal hebben voor personen jonger dan 18 jaar en, in voorkomend geval, voor andere groepen kwetsbare personen. Er moet een grondige risicoanalyse plaatsvinden en worden vertaald naar mitigerende maatregelen om het risico te elimineren of te mitigeren.</p>"},{"location":"vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#bronnen","title":"Bronnen","text":"<p>Artikel 9(9) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#risico","title":"Risico","text":"<p>Niet adequaat adresseren van risico's voor jongeren en kwetsbare groepen kan leiden tot ernstige ethische en maatschappelijke schade.</p>"},{"location":"vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-07Maak een lijst van de meest kwetsbare groepen en bescherm hen extraBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-05-data-kwaliteitscriteria/","title":"Data van hoog-risico ai moet voldoen aan kwaliteitscriteria","text":"<p>aia-05Dataverkenning en datapreparatieVerificatie en validatieProjectleiderOntwikkelaarData</p>"},{"location":"vereisten/aia-05-data-kwaliteitscriteria/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico die technieken gebruiken die het trainen van AI-modellen met data omvatten, worden ontwikkeld op basis van datasets voor training, validatie en tests die voldoen aan de kwaliteitscriteria telkens wanneer dergelijke datasets worden gebruikt.</p>"},{"location":"vereisten/aia-05-data-kwaliteitscriteria/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria. Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt.</p> <p>Deze vereiste houdt in dat de gebruikte datasets onder meer moeten voldoen aan:</p> <ul> <li>datasets voor training, validatie en tests worden onderworpen aan praktijken op het gebied van databeheer die stroken met het beoogde doel van het AI-systeem met een hoog risico. Dit heeft in het bijzonder betrekking op relevante ontwerpkeuzes, processen voor dataverzameling, verwerkingsactiviteiten voor datavoorbereiding, het opstellen van aannames met name betrekking tot de informatie die de data moeten meten en vertegenwoordigen, beschikbaarheid, kwantiteit en geschiktheid van de datasets en een beoordeling op mogelijke vooringenomenheid en passende maatregelen om deze vooringenomenheid op te sporen, te voorkomen en te beperken. </li> <li>datasets voor training, validatie en tests zijn relevant, voldoende representatief en zoveel mogelijk foutenvrij en volledig met het oog op het beoogde doel.</li> <li>Er wordt rekening gehouden met de eigenschappen of elementen die specifiek zijn voor een bepaalde geografische, contextuele, functionele of gedragsomgeving waarin het AI-systeem wordt gebruikt.</li> </ul>"},{"location":"vereisten/aia-05-data-kwaliteitscriteria/#bronnen","title":"Bronnen","text":"<p>Artikel 10(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-05-data-kwaliteitscriteria/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-05-data-kwaliteitscriteria/#risico","title":"Risico","text":"<p>Gebruik van laagkwalitatieve of bevooroordeelde datasets kan leiden tot onbetrouwbare en oneerlijke AI-besluitvorming. Onvoldoende kwaliteitsborging van testdata kan leiden tot vertekende resultaten en gebrekkige prestaties van het AI-systeem bij gebruik in de praktijk.</p>"},{"location":"vereisten/aia-05-data-kwaliteitscriteria/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesowp-02Beschrijf welke data gebruikt wordt voor de beoogde toepassingdat-01Controleer de datakwaliteitControle of eigenaarschap over de dataver-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidVeranderingen in de dataBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-06-technische-documentatie/","title":"Technische documentatie voor hoog-risico AI","text":"<p>aia-06Dataverkenning en datapreparatieOntwikkelenVerificatie en validatieProjectleiderOntwikkelaarTransparantieTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-06-technische-documentatie/#vereiste","title":"Vereiste","text":"<p>De technische documentatie van een AI-systeem met een hoog risico wordt opgesteld voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld, en wordt geactualiseerd. De technische documentatie wordt op zodanige wijze opgesteld dat wordt aangetoond dat het AI-systeem met een hoog risico in overeenstemming is met de eisen van Afdeling 2 van de AI-verordening en dat nationale bevoegde autoriteiten en aangemelde instanties over de noodzakelijke, op heldere en begrijpelijke wijze gestelde informatie beschikken om de overeenstemming van het AI-systeem met deze voorschriften te kunnen beoordelen.</p>"},{"location":"vereisten/aia-06-technische-documentatie/#toelichting","title":"Toelichting","text":"<p>De technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt. Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van de verordening, zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen.</p> <p>De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV:</p> <ol> <li>Een algemene beschrijving van het AI-syseem.</li> <li>Een gedetailleerde beschrijving van de elementen van het AI-systeem en het proces voor de ontwikkeling ervan.</li> <li>Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem.</li> <li>Een beschrijving van de geschiktheid van de prestatiestatistieken.</li> <li>Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening.</li> <li>Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht.</li> <li>Een lijst van normen die worden toegepast.</li> <li>Een exemplaar van de EU-conformiteitsverklaring.</li> <li>Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI-verordening.</li> </ol> <p>De documentatie kan opgevraagd worden door een bevoegde autoriteit met een met redenen omkleed verzoek, zoals toegelicht in artikel 21 van de AI-verordening.</p>"},{"location":"vereisten/aia-06-technische-documentatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 11 Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage IV Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-06-technische-documentatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-06-technische-documentatie/#risico","title":"Risico","text":"<p>Het ontbreken van de benodigde informatie over de algoritmische toepassing of AI-systeem kan ertoe leiden dat de technische functionering onduidelijk is. Dat kan tot problemen leiden bij de verantwoording, controle en het beheer. Onvolledige of ontoereikende technische documentatie kan leiden tot onduidelijkheid over de conformiteit van het AI-systeem met de regelgeving, wat de veiligheid en naleving in gevaar kan brengen.</p>"},{"location":"vereisten/aia-06-technische-documentatie/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-04Beschrijf welke techniek gebruikt wordt voor de beoogde toepassingBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-07-automatische-logregistratie/","title":"Automatische logregistratie voor hoog-risico AI","text":"<p>aia-07OntwikkelenMonitoring en beheerOntwikkelaarProjectleiderTransparantieTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-07-automatische-logregistratie/#vereiste","title":"Vereiste","text":"<p>Algoritmes en AI-systemen zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende hun levenscyclus automatisch worden geregistreerd (\u201clogs\u201d). </p>"},{"location":"vereisten/aia-07-automatische-logregistratie/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren. Dit wordt vaak aangeduid als \"logs\". Deze logs bieden een traceerbaarheidsmechanisme waarmee gebruiksverantwoordelijken en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken. Het doel van deze registratie is om de transparantie en verantwoordingsplicht van AI-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetert.</p> <p>Voor AI-systemen met een hoog-risico voorziet de loggingcapaciteit ten minste in: a) de registratie van de duur van elk gebruik van het systeem; b) de referentiedatabank aan de hand waarvan de inputdata zijn gecontroleerd door het systeem; c) de inputdata ten aanzien waarvan de zoekopdracht een match heeft opgeleverd; d) de identificatie van natuurlijke personen die betrokken zijn bij de verificatie van de resultaten.</p> <p>Voor AI-systemen die door bestuursorganen worden gebruikt of AI-systmen die persoonsgegevens verwerken leveren de BIO en AVG vergelijkbare verplichingen op die ook van toepassing zijn op AI-systmen die niet gezien worden als een AI-systeem met hoog risico. Daarbij komen nog verplichtingen om de logs doorlopend of periodiek te monitoren op incidenten.</p>"},{"location":"vereisten/aia-07-automatische-logregistratie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 12 Verordening Artifici\u00eble Intelligentie</li> <li>Hoofdstuk 12.4 Baseline Informatiebeveiliging Overheid </li> <li>Artikel 5 en 32 Algemene Verordening Gegevensbescherming</li> </ul>"},{"location":"vereisten/aia-07-automatische-logregistratie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-07-automatische-logregistratie/#risico","title":"Risico","text":"<p>Ontbreken van automatische logregistratie kan leiden tot een gebrek aan transparantie en traceerbaarheid van het AI-systeem, wat het vermogen om verantwoordelijkheid te nemen en eventuele problemen aan te pakken belemmert en betrokkenen wiens persoonsgegevens worden verwerkt of geraakt worden door beslissingen van het AI-systeem in hun rechten kunnen worden beperkt.</p>"},{"location":"vereisten/aia-07-automatische-logregistratie/#maatregelen","title":"Maatregelen","text":"idMaatregelenowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019owk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de codeBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/","title":"Transparantie in ontwerp voor hoog-risico AI","text":"<p>aia-08OntwerpOntwikkelenMonitoring en beheerProjectleiderOntwikkelaarBeleid en adviesTransparantie</p>"},{"location":"vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat de werking ervan voldoende transparant is om gebruiksverantwoordelijken in staat te stellen de output van een systeem te interpreteren en op passende wijze te gebruiken. Een passende soort en mate van transparantie wordt gewaarborgd met het oog op de naleving van de relevante verplichtingen van de aanbieder en de gebruiksverantwoordelijke zoals uiteengezet in afdeling 3 van Artikel 13 van de AI verordening.</p>"},{"location":"vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken. Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd. In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.</p>"},{"location":"vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#bronnen","title":"Bronnen","text":"<p>Artikel 13(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#risico","title":"Risico","text":"<p>Onvoldoende transparantie kan leiden tot een gebrek aan begrip over hoe het AI-systeem functioneert, wat de effectiviteit van de inzet ervan kan belemmeren en de naleving van wettelijke verplichtingen in gevaar kan brengen.</p>"},{"location":"vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenver-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidimp-01Maak een openbaar besluit over de inzet van het algoritmeimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het AlgoritmeregisterBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-09-menselijk-toezicht/","title":"Toezichtmogelijkheden voor gebruikers","text":"<p>aia-09OntwerpOntwikkelenMonitoring en beheerProjectleiderMenselijke controle</p>"},{"location":"vereisten/aia-09-menselijk-toezicht/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.</p>"},{"location":"vereisten/aia-09-menselijk-toezicht/#toelichting","title":"Toelichting","text":"<p>Het menselijk toezicht is gericht op het voorkomen of beperken van de risico\u2019s voor de gezondheid, veiligheid of grondrechten die zich kunnen voordoen wanneer een AI-systeem met een hoog risico wordt gebruikt in overeenstemming met het beoogde doel ervan of in een situatie van redelijkerwijs te voorzien misbruik, met name wanneer dergelijke risico\u2019s blijven bestaan ondanks de toepassing van andere eisen van deze afdeling.</p> <p>De toezichtmaatregelen staan in verhouding met de risico's, de mate van autonomie en de gebruikscontext van het AI-systeem met een hoog risico. Hierbij kan het gaan om:</p> <ol> <li>door de aanbieder bepaalde maatregelen die waar technisch haalbaar in het AI-systeem met een hoog risico worden ingebouwd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld;</li> <li>door de aanbieder bepaalde maatregelen voordat het AI-systeem met een hoog risico in de handel wordt gebracht of in gebruik wordt gesteld en die passend zijn om door de gebruiksverantwoordelijke te worden uitgevoerd.</li> </ol> <p>De natuurlijke personen die verantwoordelijk zijn voor het menselijk toezicht, moeten in staat worden gesteld om waar passend en in verhouding tot de omstandigheden het volgende te kunnen doen:</p> <ol> <li>Goed kunnen begrijpen van de relevante capaciteiten en beperkingen van het AI-systeem met een hoog risico. Met het oog op het opsporen en aanpakken van onregelmatigheden, storingen en onverwachte prestaties moet de werking van het AI-systeem goed kunnen worden begrepen;</li> <li>Bewust blijven van de mogelijke neiging om automatisch of te veel te vertrouwen op de output van een AI-systeem met hoog risico (automation bias). Dit geldt in het bijzonder voor het gebruik van een hoog risico AI-systeem dat wordt gebruikt om informatie of aanbevelingen te versterkken voor beslisisngen die door natuurlijke personen moeten worden genomen;</li> <li>De output juist kunnen interpreteren, bijvoorbeeld met behulp van de juiste instrumenten en methoden voor interpretatie;</li> <li>In alle specifieke situaties kunnen besluiten om het hoog risico AI-systeem niet te gebruiken of de output op een andere wijze te negeren, door een andere beslissing te vervangen of terug te draaien;</li> <li>ingrijpen in de werking van het hoog risico AI-systeem of het systeem onderbreken door middel van een stopknop of een vergelijkbare procedure waarmee het systeem op een veilige wijze kan worden stopgezet.</li> </ol> <p>In het geval van een hoog risico systeem als bedoeld in bijlage III, punt 1, a  (systemen voor biometrische identificatie op afstand) geldt het vereiste dat twee natuurlijke personen met de nodige bekwaamheid, opleiding en bevoegdheid apart de indentificatie van het systeem verifici\u00ebren en bevestigen, tenzij het wordt gebruikt voor rechtshandhaving, migratie, grenstoezicht of asiel, in gevallen waarin het Unierecht of het nationale recht de toepassing van dit vereiste onevenredig acht.</p>"},{"location":"vereisten/aia-09-menselijk-toezicht/#bronnen","title":"Bronnen","text":"<p>Artikel 14 verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-09-menselijk-toezicht/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-09-menselijk-toezicht/#risico","title":"Risico","text":"<p>Ontbreken van betekenisvol menselijk toezicht kan leiden tot gebrek aan controle en begrip over het functioneren van het AI-systeem, wat kan resulteren in ongewenste of onvoorspelbare uitkomsten.</p>"},{"location":"vereisten/aia-09-menselijk-toezicht/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesowk-02Maak een noodplan voor het stoppen van het algoritmeimp-03Organiseer menselijke controle van het algoritmeimp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeemBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/","title":"Ontwerp voor nauwkeurigheid, robuustheid en cyberbeveiliging","text":"<p>aia-10OntwerpOntwikkelenVerificatie en validatieMonitoring en beheerProjectleiderBeleid en adviesOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.</p>"},{"location":"vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden. Dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgd.</p> <p>Technische robuustheid is een essenti\u00eble eis voor AI-systemen met een hoog risico. Deze systemen moeten bestand zijn tegen schadelijk of anderszins ongewenst gedrag dat kan voortvloeien uit de beperkingen binnen de systemen of de omgeving waarin de systemen opereren (bijvoorbeeld fouten, onregelmatigheden, onverwachte situaties). Daarom moeten technische en organisatorische maatregelen worden getroffen om de robuustheid van AI-systemen met een hoog risico te waarborgen. Een technische oplossing kan bijvoorbeeld bestaan uit mechanismen die het systeem in staat stellen zijn werking veilig te onderbreken (storingsbeveiligingsplannen) wanneer zich bepaalde anomalie\u00ebn voordoen of wanneer de werking buiten bepaalde vooraf bepaalde grenzen plaatsvindt.</p> <p>Cyberbeveiliging is cruciaal om te waarborgen dat AI-systemen bestand zijn tegen pogingen van kwaadwillige derden die gebruikmaken van de kwetsbaarheden van het systeem om het gebruik, het gedrag of de prestaties ervan te wijzigen of de veiligheidskenmerken ervan in gevaar te brengen. Bij cyberaanvallen tegen AI-systemen kunnen AI-specifieke activa worden gebruikt, zoals trainingsdatasets (bv. datavervuiling) of getrainde modellen (bv. vijandige aanvallen of membership inference), of kwetsbaarheden in de digitale activa van het AI-systeem of de onderliggende ICT-infrastructuur worden benut. Om te zorgen voor een niveau van cyberbeveiliging dat aansluit op de risico\u2019s, moeten aanbieders van AI-systemen met een hoog risico passende maatregelen zoals veiligheidscontroles nemen, waarbij ook rekening wordt gehouden met de onderliggende ICT infrastructuur.</p>"},{"location":"vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#bronnen","title":"Bronnen","text":"<p>Artikel 15 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#risico","title":"Risico","text":"<p>Gebrek aan nauwkeurigheid, robuustheid of cyberbeveiliging kan leiden tot onbetrouwbare prestaties, kwetsbaarheid voor storingen en blootstelling aan beveiligingsrisico's, wat de effectiviteit en veiligheid van het AI-systeem in gevaar kan brengen.</p>"},{"location":"vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-04Beschrijf welke techniek gebruikt wordt voor de beoogde toepassingowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesTrain-, validatie- en testdataver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenmon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenVeranderingen in de dataBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-11-systeem-voor-kwaliteitsbeheer/","title":"Kwaliteitsbeheersysteem voor hoog-risico AI","text":"<p>aia-11OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening.</p>"},{"location":"vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten een kwaliteitsbeheersysteem implementeren om te garanderen dat ze voldoen aan de AI-verordening. Dit systeem omvat gedocumenteerde beleidslijnen, procedures en instructies, en behandelt beknopt de volgende aspecten:</p> <ol> <li>een strategie voor de naleving van de regelgeving, inclusief de naleving van de conformiteitsbeoordelingsprocedures en de procedures voor het beheer van de wijzigingen van het AI-systeem met een hoog risico;</li> <li>technieken, procedures en systematische maatregelen die moeten worden toegepast voor het ontwerp, de controle van het ontwerp en de verificatie van het ontwerp van het AI-systeem met een hoog risico;</li> <li>technieken, procedures en systematische maatregelen die moeten worden toegepast voor de ontwikkeling, de kwaliteitscontrole en de kwaliteitsborging van het AI-systeem met een hoog risico;</li> <li>procedures voor het inspecteren, testen en valideren die v\u00f3\u00f3r, tijdens en na de ontwikkeling van het AI-systeem met een hoog risico moeten worden uitgevoerd en de regelmaat waarmee zij moeten worden uitgevoerd;</li> <li>technische specificaties, met inbegrip van normen, die moeten worden toegepast en, wanneer de relevante geharmoniseerde normen niet volledig worden toegepast of geen betrekking hebben op alle relevante eisen van afdeling 2, de middelen die worden gebruikt om ervoor te zorgen dat het AI-systeem met een hoog risico in overeenstemming is met deze eisen;</li> <li>systemen en procedures voor databeheer, met inbegrip van dataverwerving, - verzameling, -analyse, -labeling, -opslag, -zuivering, -aggregatie en -behoud en datamining en eventuele andere operaties met betrekking tot de data die worden uitgevoerd voorafgaand aan en met het oog op het in de handel brengen of in gebruik stellen van AI-systemen met een hoog risico;</li> <li>het systeem voor risicobeheer zoals bedoeld in artikel 9 van de AI-verordening;</li> <li>het opzetten, toepassen en onderhouden van een systeem voor monitoring na het in de handel brengen, overeenkomstig artikel 72 AI-verordening;</li> <li>procedures in verband met het melden van een ernstig incident in overeenstemming met artikel 73 van de AI-verordening;</li> </ol>"},{"location":"vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 17 Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(c) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#risico","title":"Risico","text":"<p>Zonder toepassing van een kwaliteitsbeheersysteem kunnen risico's ontstaan voor de veiligheid, betrouwbaarheid en naleving van het AI-systeem en conformiteit met wet- en regelgeving.</p>"},{"location":"vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesorg-07Controleer en verbeter regelmatig de kwaliteit van het algoritmeowk-02Maak een noodplan voor het stoppen van het algoritmeVeranderingen in de dataBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-12-bewaartermijn-voor-documentatie/","title":"Hoog risico ai systemen voldoen aan bewaartermijn voor documentatie","text":"<p>aia-12OntwerpMonitoring en beheerUitfaserenProjectleiderTransparantieTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-12-bewaartermijn-voor-documentatie/#vereiste","title":"Vereiste","text":"<p>De aanbieder houdt gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld de volgende elementen ter beschikking van de nationale bevoegde autoriteiten: </p> <ol> <li>de technische documentatie als bedoeld in artikel 11 van de AI-verordening; </li> <li>de documentatie betreffende het in artikel 17 bedoelde systeem voor kwaliteitsbeheer; </li> <li>in voorkomend geval de documentatie betreffende de door aangemelde instanties goedgekeurde wijzigingen; </li> <li>in voorkomend geval de besluiten en andere documenten die door de aangemelde instanties zijn afgegeven; </li> <li>de EU-conformiteitsverklaring als bedoeld in artikel 47. </li> </ol>"},{"location":"vereisten/aia-12-bewaartermijn-voor-documentatie/#toelichting","title":"Toelichting","text":"<p>De aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten. Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn. Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.</p>"},{"location":"vereisten/aia-12-bewaartermijn-voor-documentatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 18(1) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(d) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-12-bewaartermijn-voor-documentatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-12-bewaartermijn-voor-documentatie/#risico","title":"Risico","text":"<p>Niet voldoen aan de bewaartermijn kan leiden tot juridische consequenties en kan het vermogen van de autoriteiten om toezicht te houden op de naleving van de regelgeving belemmeren.</p>"},{"location":"vereisten/aia-12-bewaartermijn-voor-documentatie/#maatregelen","title":"Maatregelen","text":"idMaatregelendat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedureBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/","title":"Bewaartermijn voor gegenereerde logs","text":"<p>aia-13OntwerpMonitoring en beheerUitfaserenProjectleiderTransparantieTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het Unie- of nationaal recht, met name de Uniewetgeving inzake de bescherming van persoonsgegevens.</p>"},{"location":"vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen. Deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door Unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplicht.</p>"},{"location":"vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 19(1) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(e) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 12(1) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#risico","title":"Risico","text":"<p>Het niet of onvoldoende bewaren van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#maatregelen","title":"Maatregelen","text":"idMaatregelenowk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de codeBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-14-conformiteitsbeoordeling/","title":"Aanbieders van AI-systemen met een hoog risico voeren een conformiteitsbeoordelingsprocedure uit","text":"<p>aia-14Verificatie en validatieImplementatieJuristProjectleiderGovernance</p>"},{"location":"vereisten/aia-14-conformiteitsbeoordeling/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld</p>"},{"location":"vereisten/aia-14-conformiteitsbeoordeling/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten ervoor zorgen dat de conformiteitsbeoordelingsprocedure wordt uitgevoerd voor het systeem op de markt wordt gebracht of in gebruik wordt genomen. Dit is mogelijk door middel van een interne controle (als bedoeld in bijlage VI van de AI-verordening) of met betrokkenheid van een aangemelde instantie voor de beoordeling van het systeem voor kwaliteitsbeheer en de technische documentatie (als bedoeld in bijlage VII van de AI-verordening).</p> <p>AI-systemen met een hoog risico die reeds aan een conformiteitsbeoordelingsprocedure zijn onderworpen, ondergaan een nieuwe conformiteitsbeoordelingsprocedure telkens wanneer zij substantieel zijn gewijzigd, ongeacht of het gewijzigde systeem bedoeld is om verder te worden gedistribueerd of door de huidige gebruiksverantwoordelijke gebruikt blijft worden.</p>"},{"location":"vereisten/aia-14-conformiteitsbeoordeling/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(f) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 43 Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage VI Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage VII Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-14-conformiteitsbeoordeling/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-14-conformiteitsbeoordeling/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/aia-14-conformiteitsbeoordeling/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-15-eu-conformiteitsverklaring/","title":"Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op","text":"<p>aia-15Verificatie en validatieImplementatieJuristProjectleiderGovernance</p>"},{"location":"vereisten/aia-15-eu-conformiteitsverklaring/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.</p>"},{"location":"vereisten/aia-15-eu-conformiteitsverklaring/#toelichting","title":"Toelichting","text":"<p>Een EU-conformiteitsverklaring is een verplicht document dat een fabrikant of gemachtigde vertegenwoordiger moet ondertekenen, waarmee wordt verklaard dat het product aan de EU-eisen voldoet. De aanbieder stelt voor elk AI-systeem met een hoog risico een schriftelijke machineleesbare, fysieke of elektronisch ondertekende EU-conformiteitsverklaring op en houdt deze verklaring tot tien jaar na het in de handel brengen of het in gebruik stellen van het AI-systeem met een hoog risico ter beschikking van de nationale bevoegde autoriteiten. De conformiteitsverklaring bevat de informatie zoals genoemd in bijlage V AI-verordening. Voorbeelden hiervan zijn de naam en type van het AI-systeem, naam en adres van de aanbieder, dat de EU-conformiteitsverklaring wordt versterkt onder verantwoordelijkheid van de aanbieder en de vermelding van eventuele toegepaste relevante geharmoniseerde normen of van andere gemeenschappelijke specificaties waarop de conformiteitsverklaring betrekking heeft.</p>"},{"location":"vereisten/aia-15-eu-conformiteitsverklaring/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(g) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 47(1) Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage V Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-15-eu-conformiteitsverklaring/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-15-eu-conformiteitsverklaring/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/aia-15-eu-conformiteitsverklaring/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-16-ce-markering/","title":"Aanbieders van AI-systemen met een hoog risico voegen een CE-markering toe aan het AI-systeem","text":"<p>aia-16ImplementatieProjectleiderTransparantie</p>"},{"location":"vereisten/aia-16-ce-markering/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.</p>"},{"location":"vereisten/aia-16-ce-markering/#toelichting","title":"Toelichting","text":"<p>Op AI-systemen met een hoog risico moet de CE-markering worden aangebracht om aan te geven dat zij in overeenstemming zijn met de AI-verordening, zodat het vrije verkeer ervan op de interne markt mogelijk is. Op AI-systemen met een hoog risico die in een product zijn ge\u00efntegreerd moet een fysieke CE-markering worden aangebracht, die kan worden aangevuld met een digitale CE-markering. Voor AI-systemen met een hoog risico die alleen digitaal worden verstrekt, moet een digitale CE-markering worden gebruikt. De lidstaten mogen het in de handel brengen en het in gebruik stellen van AI-systemen met een hoog risico die aan de in de AI-verordening vastgelegde eisen voldoen en waarop de CE-markering is aangebracht, niet op ongerechtvaardigde wijze belemmeren.</p>"},{"location":"vereisten/aia-16-ce-markering/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(h) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 48 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-16-ce-markering/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-16-ce-markering/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/aia-16-ce-markering/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-17-registratieverplichtingen/","title":"Registratieverplichtingen voor aanbieders van AI-systemen met een hoog risico","text":"<p>aia-17ImplementatieProjectleiderGovernanceTransparantie</p>"},{"location":"vereisten/aia-17-registratieverplichtingen/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico leven de registratieverplichtingen als bedoeld in artikel 49 na, wat betekent dat voor het in de handel brengen of in bedrijf te stellen van het hoog risico AI-systeem, de aanbieder of in voorkomende gevallen de gemachtigde het systeem registreert in de EU-databank.</p>"},{"location":"vereisten/aia-17-registratieverplichtingen/#toelichting","title":"Toelichting","text":"<p>V\u00f3\u00f3r de distributie of inbedrijfstelling van een AI-systeem met een hoog risico van bijlage III, met uitzondering van specifieke gevallen zoals beschreven in punt 2 van bijlage III, is het vereist dat de aanbieder of gemachtigde zichzelf en het systeem registreert in de EU-databank zoals genoemd in art. 71 AI-verordening.</p>"},{"location":"vereisten/aia-17-registratieverplichtingen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(i) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 49(1) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-17-registratieverplichtingen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-17-registratieverplichtingen/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/aia-17-registratieverplichtingen/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/","title":"Corrigerende maatregelen voor non-conforme AI","text":"<p>aia-18OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderMenselijke controleTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.</p>"},{"location":"vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem. Ze moeten ook alle relevante partijen, zoals distributeurs, gebruiksverantwoordelijken en importeurs, op de hoogte stellen van deze maatregelen.</p>"},{"location":"vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 20 Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(j) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#risico","title":"Risico","text":"<p>Niet reageren op non-conformiteit kan leiden tot risico's voor gebruikers en derden. Het kan leiden tot juridische procedures en reputatieschade voor organisaties.</p>"},{"location":"vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#maatregelen","title":"Maatregelen","text":"idMaatregelenowk-02Maak een noodplan voor het stoppen van het algoritmeBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-19-toegankelijkheidseisen/","title":"Aanbieders van AI-systemen met een hoog risico zorgen voor toegankelijkheidseisen","text":"<p>aia-19OntwerpProjectleiderOntwikkelaarMenselijke controleTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-19-toegankelijkheidseisen/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882</p>"},{"location":"vereisten/aia-19-toegankelijkheidseisen/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten ervoor zorgen dat hun systeem toegankelijk is volgens de EU-richtlijnen 2016/2102 en 2019/882. In het kader van Richtlijn 2016/2102 moet onder toegankelijkheid worden verstaan het geheel van principes en technieken die in acht moeten worden genomen bij het ontwerpen, bouwen, beheren en bijwerken van websites en mobiele applicaties om hen voor gebruikers toegankelijker te maken, met name voor personen met een beperking. Bijlage 1 bevat de toegankelijkheidsvoorschriften voor producten en diensten die moeten worden toegepast op hoog-risico AI-systemen.</p> <p>Richtlijn 2019/882 strekt ertoe een bijdrage te leveren tot het goed functioneren van de interne markt middels onderlinge  aanpassing van de wettelijke en bestuursrechtelijke bepalingen van de lidstaten inzake de toegankelijkheidsvoorschriften  voor bepaalde producten en diensten, in het bijzonder door het wegwerken en voorkomen van belemmeringen voor het vrije verkeer van onder deze richtlijn vallende producten en diensten ten gevolge van uiteenlopende toegankelijkheidsvoorschriften in de lidstaten</p>"},{"location":"vereisten/aia-19-toegankelijkheidseisen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(l) Verordening Artifici\u00eble Intelligentie</li> <li>EU-richtlijn 2016/2102</li> <li>EU-richtlijn 2019/882</li> </ul>"},{"location":"vereisten/aia-19-toegankelijkheidseisen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-19-toegankelijkheidseisen/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"vereisten/aia-19-toegankelijkheidseisen/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesowk-02Maak een noodplan voor het stoppen van het algoritmeBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-22-gebruiksverantwoordelijken-maatregelen/","title":"Maatregelen van gebruiksverantwoordelijken voor gebruik","text":"<p>aia-22OrganisatieverantwoordelijkhedenImplementatieProjectleiderOntwikkelaarGovernance</p>"},{"location":"vereisten/aia-22-gebruiksverantwoordelijken-maatregelen/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.</p>"},{"location":"vereisten/aia-22-gebruiksverantwoordelijken-maatregelen/#toelichting","title":"Toelichting","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico moeten geschikte maatregelen nemen om ervoor te zorgen dat zij deze systemen gebruiken volgens de bijgevoegde instructies. De gebruiksverantwoordelijke zorgt ervoor dat de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico, voor zover hij daar controle over heeft.</p>"},{"location":"vereisten/aia-22-gebruiksverantwoordelijken-maatregelen/#bronnen","title":"Bronnen","text":"<p>Artikel 26(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-22-gebruiksverantwoordelijken-maatregelen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-22-gebruiksverantwoordelijken-maatregelen/#risico","title":"Risico","text":"<p>Het niet naleven van deze maatregelen kan leiden tot onjuist gebruik van de AI-systemen, wat de effectiviteit en veiligheid ervan kan verminderen, en kan resulteren in risico's voor gebruikers en derden.</p>"},{"location":"vereisten/aia-22-gebruiksverantwoordelijken-maatregelen/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/aia-23-gebruiksverantwoordelijken-menselijk-toezicht/","title":"Natuurlijke personen die menselijk toezicht uitvoeren zijn bekwaam, opgeleid, beschikken over autoriteit en krijgen ondersteuning","text":"<p>aia-23OrganisatieverantwoordelijkhedenProjectleiderGovernanceMenselijke controle</p>"},{"location":"vereisten/aia-23-gebruiksverantwoordelijken-menselijk-toezicht/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.</p>"},{"location":"vereisten/aia-23-gebruiksverantwoordelijken-menselijk-toezicht/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat natuurlijke personen die het menselijk toezicht moeten uitvoeren over het AI-systeem met een hoog risico, daarvoor over de nodige bekwaamheid, opleiding en autoriteit beschikt. Daarbij kan het van belang zijn dat deze natuurlijke personen ondersteuning krijgen bij het uitvoeren van deze taak.</p>"},{"location":"vereisten/aia-23-gebruiksverantwoordelijken-menselijk-toezicht/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 26(2) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-23-gebruiksverantwoordelijken-menselijk-toezicht/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-23-gebruiksverantwoordelijken-menselijk-toezicht/#risico","title":"Risico","text":"<p>Als de natuurlijke toezichthouder geen effectief toezicht kan houden op het hoog risico AI-systeem, kunnen ongewenste, negatieve effecten onstaan voor betrokkenen en de organisatie.</p>"},{"location":"vereisten/aia-23-gebruiksverantwoordelijken-menselijk-toezicht/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/aia-24-gebruiksverantwoordelijken-monitoren-werking/","title":"Gebruiksverantwoordelijken monitoren werking hoog risico AI-systeem","text":"<p>aia-24Monitoring en beheerProjectleiderMenselijke controle</p>"},{"location":"vereisten/aia-24-gebruiksverantwoordelijken-monitoren-werking/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72 AI Verordening</p>"},{"location":"vereisten/aia-24-gebruiksverantwoordelijken-monitoren-werking/#toelichting","title":"Toelichting","text":"<p>Gebruiksverantwoordelijken moeten de werking van hoog risico AI-systemen monitoren. Dit is van belang om passende maatregelen te kunnen treffen als het systeem onbedoeld anders gaat functioneren.</p> <p>Wanneer gebruiksverantwoordelijken redenen hebben om aan te nemen dat het gebruik overeenkomstig de gebruiksaanwijzingen ertoe kan leiden dat dat AI-systeem een risico vormt in de zin van artikel 79, lid 1, stellen zij de aanbieder of distributeur en de betreffende markttoezichtautoriteit hiervan zonder onnodige vertraging in kennis en onderbreken zij het gebruik van dat systeem. Wanneer gebruiksverantwoordelijke een ernstig incident vaststellen, stellen zij ook onmiddellijk eerst de aanbieder hiervan in kennis, en vervolgens de importeur of distributeur en de betreffende markttoezichtautoriteiten van dat incident. Wanneer de gebruiksverantwoordelijke de aanbieder niet kan bereiken, is artikel 73 mutatis mutandis van toepassing. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijke van AI-systemen die de hoedanigheid van rechtshandhavingsinstanties hebben.</p> <p>Voor gebruiksverantwoordelijke die in de hoedanigheid van financi\u00eble instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financi\u00eble diensten, wordt de monitoringsverplichting overeenkomstig de eerste alinea geacht te zijn vervuld door te voldoen aan de regels inzake interne governance, regelingen of processen en -mechanismen uit hoofde van het desbetreffende recht inzake financi\u00eble diensten.</p>"},{"location":"vereisten/aia-24-gebruiksverantwoordelijken-monitoren-werking/#bronnen","title":"Bronnen","text":"<p>Artikel 26(5) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-24-gebruiksverantwoordelijken-monitoren-werking/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-24-gebruiksverantwoordelijken-monitoren-werking/#risico","title":"Risico","text":"<p>Zonder monitoring door gebruiksverantwoordelijken en (waar nodig) het informeren van aanbieder, distributeur of markttoezichtautoriteit, kan de foutieve werking van een hoog risico AI-systeem niet worden gesignaleerd en hersteld.</p>"},{"location":"vereisten/aia-24-gebruiksverantwoordelijken-monitoren-werking/#maatregelen","title":"Maatregelen","text":"idMaatregelenowk-02Maak een noodplan voor het stoppen van het algoritmeimp-03Organiseer menselijke controle van het algoritme"},{"location":"vereisten/aia-25-gebruiksverantwoordelijken-bewaren-logs/","title":"Gebruiksverantwoordelijken bewaren logs van een hoog risico AI-systeem die automatisch worden gegenereerd","text":"<p>aia-25OntwikkelenMonitoring en beheerProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-25-gebruiksverantwoordelijken-bewaren-logs/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevens</p>"},{"location":"vereisten/aia-25-gebruiksverantwoordelijken-bewaren-logs/#toelichting","title":"Toelichting","text":"<p>Anders dan in artikel 16(e) AI-verordening, waar een vergelijkbare vereiste geldt voor aanbieders, gaat het hier om een vereiste specifiek voor de gebruiksverantwoordelijken. Het is van belang dat de gebruiksverantwoordelijken een zelfstandige beoordeling maakt wat moet worden gelogd en voor welke periode gezien de doelstelling van de inzet van het AI-systeem. Daarbij is het van belang om te beoordelen in hoeverre een gebruiksverantwoordelijke hier 'controle' over heeft. De gebruiksverantwoordelijke zal, al dan niet samen met de aanbieder, (technische) maatregelen moeten treffen om dit te realiseren.</p> <p>Gebruiksverantwoordelijken die in de hoedanigheid van financi\u00eble instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financi\u00eble diensten bewaren de logs als onderdeel van de documentatie die bewaard wordt krachtens het desbetreffende Unierecht inzake financi\u00eble diensten.</p>"},{"location":"vereisten/aia-25-gebruiksverantwoordelijken-bewaren-logs/#bronnen","title":"Bronnen","text":"<p>Artikel 26(6) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-25-gebruiksverantwoordelijken-bewaren-logs/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-25-gebruiksverantwoordelijken-bewaren-logs/#risico","title":"Risico","text":"<p>Het niet of onvoldoende bewaren van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"vereisten/aia-25-gebruiksverantwoordelijken-bewaren-logs/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/aia-26-informeren-werknemers/","title":"Informeren werknemers","text":"<p>aia-26ImplementatieProjectleiderTransparantie</p>"},{"location":"vereisten/aia-26-informeren-werknemers/#vereiste","title":"Vereiste","text":"<p>Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.</p>"},{"location":"vereisten/aia-26-informeren-werknemers/#toelichting","title":"Toelichting","text":"<p>Dit vereiste benadrukt het belang van het informeren van werknemersvertegenwoordigers en betrokken werknemers over de inzet van een hoog risico AI-systeem op de werkplaats. Dit dient voorafgaand aan de inzet van het systeem plaats te vinden. De gebruiksverantwoordelijke als werknemer dient hier zorg voor te dragen.</p>"},{"location":"vereisten/aia-26-informeren-werknemers/#bronnen","title":"Bronnen","text":"<p>Artikel 26(7) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-26-informeren-werknemers/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-26-informeren-werknemers/#risico","title":"Risico","text":"<p>Als werknemersvertegenwoordigers en werknemers niet worden ge\u00efnformeerd over de inzet van een hoog risico AI-systeem, kunnen zij zich niet weren tegen mogelijk ongewenste en negatieve effecten van de inzet van het hoog risico AI-systeem.</p>"},{"location":"vereisten/aia-26-informeren-werknemers/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/aia-27-gebruiksverantwoordelijken-registratieverplichtingen/","title":"Gebruiksverantwoordelijken, zijnde overheidsinstanties of instellingen, organen of instanties van de Unie, leven de registratieverplichting na als het gaat om een hoog risico AI-systeem","text":"<p>aia-27ImplementatieMonitoring en beheerProjectleiderTransparantieGovernance</p>"},{"location":"vereisten/aia-27-gebruiksverantwoordelijken-registratieverplichtingen/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.</p>"},{"location":"vereisten/aia-27-gebruiksverantwoordelijken-registratieverplichtingen/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat gebruiksverantwoordelijken nagaan of het betreffende hoog risico AI-systeem door aanbieder is geregistreerd in de EU-databank (zoals omschreven in artikel 71 AI-verordening). Voordat het betreffende AI-systeem (bijlage III vermeld AI-systeem met een hoog risico) in gebruik te stellen of te gebruiken (met uitzondering van de in punt 2 van bijlage III vermelde AI-systemen met een hoog risico) registreren gebruiksverantwoordelijken die overheidsinstanties, instellingen, organen of instanties van de Unie, of personen die namens hen optreden, zichzelf en selecteren zij het systeem en registreren zij het gebruik ervan in de in artikel 71 bedoelde EU-databank.</p> <p>Heeft de aanbieder het betreffende hoog risico AI-systeem niet geregistreerd in de EU-Databank, dan mag het hoog risico AI-systeem niet worden gebruikt. De aanbieder of distributeur wordt door de gebruiksverantwoordelijke ge\u00efnformeerd dat het systeem niet is geregistreerd in de EU-databank.</p> <p>AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III (kritieke infrastructuur) worden op nationaal niveau geregistreerd.</p>"},{"location":"vereisten/aia-27-gebruiksverantwoordelijken-registratieverplichtingen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 26(8) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 49 (3) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 71 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-27-gebruiksverantwoordelijken-registratieverplichtingen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-27-gebruiksverantwoordelijken-registratieverplichtingen/#risico","title":"Risico","text":"<p>Zonder registratie van het hoge risico AI-systeem en het registreren welke organisaties of personen hier gebruik van maken, is het negatieve negatieve van het mogelijk onjuist of ongewenst functioneren van het AI-systeem niet te overzien en onduidelijk welke betrokken dit raakt.</p>"},{"location":"vereisten/aia-27-gebruiksverantwoordelijken-registratieverplichtingen/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/aia-28-recht-op-uitleg-ai-besluiten/","title":"Recht op uitleg AI-besluiten","text":"<p>aia-28OrganisatieverantwoordelijkhedenOntwerpMonitoring en beheerProjectleiderGovernanceFundamentele rechtenTransparantie</p>"},{"location":"vereisten/aia-28-recht-op-uitleg-ai-besluiten/#vereiste","title":"Vereiste","text":"<p>Elke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.</p>"},{"location":"vereisten/aia-28-recht-op-uitleg-ai-besluiten/#toelichting","title":"Toelichting","text":"<p>Getroffen personen moeten het recht hebben om uitleg te krijgen indien het besluit van een gebruiksverantwoordelijke voornamelijk is gebaseerd op de output van bepaalde AI-systemen met een hoog risico die binnen het toepassingsgebied van de AI-verordening vallen en indien dat besluit rechtsgevolgen of gelijkaardige aanzienlijke gevolgen heeft voor de gezondheid, veiligheid of grondrechten van die personen. Die uitleg moet duidelijk en zinvol zijn en moet de grondslag zijn waarop de getroffen personen zich kunnen baseren om hun rechten uit te oefenen. Het recht om uitleg te krijgen mag niet van toepassing zijn op het gebruik van AI-systemen waarvoor uitzonderingen of beperkingen voortvloeien uit het Unierecht of het nationale recht en moet alleen van toepassing zijn voor zover het Unierecht niet reeds in dit recht voorziet. Dit vereiste geldt bijvoorbeeld niet als het gaat om AI-systemen die bedoeld zijn om te worden gebruikt als veiligheidscomponent bij het beheer of de exploitatie van kritieke digitale infrastructuur, wegverkeer of bij de levering van water, gas, verwerking en electriciteit (punt 2 bij Bijlage III van AI-verordening).</p>"},{"location":"vereisten/aia-28-recht-op-uitleg-ai-besluiten/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 86(1) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 26(11) Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage III Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-28-recht-op-uitleg-ai-besluiten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-28-recht-op-uitleg-ai-besluiten/#risico","title":"Risico","text":"<p>Als gebruiksverantwoordelijke geen duidelijke, inhoudelijke toelichting geeft over de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen bij het genomen besluit, is het voor getroffen personen niet mogelijk zich te verdedigen tegen de rechtsgevolgen die hieruit voortkomen of de nadelige gevolgen voor gezondheid, veiligheid of diens grondrechten.</p>"},{"location":"vereisten/aia-28-recht-op-uitleg-ai-besluiten/#maatregelen","title":"Maatregelen","text":"idMaatregelenimp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.Bespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/","title":"Beoordeling van grondrechten","text":"<p>aia-29OntwerpVerificatie en validatieProjectleiderBeleid en adviesFundamentele rechten</p>"},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/#vereiste","title":"Vereiste","text":"<p>Voordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.</p>"},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/#toelichting","title":"Toelichting","text":"<p>Voordat een AI-systeem met een hoog risico in gebruik wordt genomen, moeten publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde AI-systemen, een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben. Deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen. Het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van AI-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiek.</p>"},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 27(1) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 6.2 Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage III.2 en III.5 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/#risico","title":"Risico","text":"<p>Het niet uitvoeren van deze beoordeling kan leiden tot schendingen van de grondrechten, juridische complicaties en verlies van vertrouwen van het publiek in het gebruik van AI-systemen door overheids- en openbare dienstverlenende entiteiten.</p>"},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-07Controleer en verbeter regelmatig de kwaliteit van het algoritmeowp-06Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowk-02Maak een noodplan voor het stoppen van het algoritmever-01Toets het algoritme op biasimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-29-beoordelen-gevolgen-grondrechten/#instrumenten","title":"Instrumenten","text":"idInstrumentenImpact Assessment Mensenrechten en Algoritmes"},{"location":"vereisten/aia-30-transparantieverplichtingen/","title":"Transparantieverplichtingen","text":"<p>aia-30OntwikkelenImplementatieProjectleiderOntwikkelaarTransparantie</p>"},{"location":"vereisten/aia-30-transparantieverplichtingen/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen zorgen dat AI-sytemen zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden ge\u00efnformeerd dat zij interacteren met een AI-systeem.  Gebruiksverantwoordelijken moeten betrokkenen informeren over de werking van het systeem en in het geval van een AI-systeem dat content gegenereert duidelijk kenbaar maken dat de content kunstmatig is gegenereerd of gemanipuleerd.</p>"},{"location":"vereisten/aia-30-transparantieverplichtingen/#toelichting","title":"Toelichting","text":"<p>Dit geldt voor AI-systemen die:</p> <ul> <li>gebruikt worden voor directe interactie met natuurlijke personen (zoals chatbots). </li> <li>synthetische afbeeldingen, audio, video of tekst genereert en/of manipuleert (bijvoorbeeld deepfake).</li> <li>doen aan emotieherkenning of biometrische categorisatie.</li> </ul>"},{"location":"vereisten/aia-30-transparantieverplichtingen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 50 Verordening Artifici\u00eble Intelligentie</li> <li>Overweging 132 Verordening Artifici\u00eble Intelligentie</li> <li>Overweging 134 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-30-transparantieverplichtingen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-30-transparantieverplichtingen/#risico","title":"Risico","text":"<p>Bepaalde AI-systemen die bedoeld zijn om met natuurlijke personen te interageren of om content te genereren, kunnen specifieke risico\u2019s op imitatie of misleiding met zich meebrengen, ongeacht of zij als systeem met een hoog risico gelden. </p>"},{"location":"vereisten/aia-30-transparantieverplichtingen/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/aia-31-ai-modellen-algemene-doeleinden/","title":"Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden","text":"<p>aia-31OntwerpOntwikkelenMonitoring en beheerProjectleiderTransparantie</p>"},{"location":"vereisten/aia-31-ai-modellen-algemene-doeleinden/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden moeten (technische) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren.</p>"},{"location":"vereisten/aia-31-ai-modellen-algemene-doeleinden/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden hebben een bijzondere rol en verantwoordelijkheid. Zij leveren modellen die de basis kunnen vormen voor weer andere systemen en algoritmen, die vaak weer door andere partijen worden aangeboden dan de ontwikkelaar van het algemene systeem. Dit vraagt om een goed inzicht in de modellen en hun capaciteiten, zowel qua integratie van de modellen in producten als qua naleving van verplichtingen.</p> <p>Er zijn daarom evenredige transparantiemaatregelen nodig, zoals het opstellen en bijwerken van documentatie en verstrekken van informatie over het AI-model voor algemeen gebruik door de aanbieders van systemen die de algemene modellen gebruiken in hun product. De aanbieder van het AI-model voor algemene doeleinden dient technische documentatie op te stellen en bij te werken om deze op verzoek te kunnen overleggen aan het AI-bureau en de nationale bevoegde autoriteiten. De minimaal in de documentatie op te nemen elementen moeten worden vastgelegd volgens bijlage XII van de AI-Verordening. Hierbij is het ook van belang dat de aanbieder van AI-modellen voor algemene doelstelling beleid opstellen voor naleving van auteursrechten en naburige rechten (artikel 4, lid 3 Richtlijn (EU) 2019/790).</p> <p>In art. 53 lid 2 wordt een uitzondering gemaakt op deze vereisten.</p>"},{"location":"vereisten/aia-31-ai-modellen-algemene-doeleinden/#bronnen","title":"Bronnen","text":"<p>Artikel 53 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-31-ai-modellen-algemene-doeleinden/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-31-ai-modellen-algemene-doeleinden/#risico","title":"Risico","text":"<p>Het niet voldoen aan deze verplichtingen kan leiden tot juridische en ethische complicaties, inclusief schendingen van auteursrechten en gebrek aan transparantie in het gebruik van AI-modellen.</p>"},{"location":"vereisten/aia-31-ai-modellen-algemene-doeleinden/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico/","title":"Aanvullende verplichtingen voor aanbieders van AI-modellen met systeemrisico","text":"<p>aia-32OntwikkelenVerificatie en validatieMonitoring en beheerProjectleiderOntwikkelaarTransparantie</p>"},{"location":"vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model om systeemrisico\u2019s in kaart te brengen en te beperken.</p>"},{"location":"vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico/#toelichting","title":"Toelichting","text":"<p>De aanbieders van AI-modellen voor algemene doeleinden die systeemrisico\u2019s inhouden, moeten, naast de verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden, onderworpen worden aan verplichtingen die gericht zijn op het identificeren en beperken van die risico\u2019s en op waarborging van een passend niveau van cyberbeveiliging, ongeacht of het model een op zichzelf staand model is of ingebed in een AI-systeem of in een product. Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluaties uitvoeren. Dit omvat het testen en documenteren van het model volgens de stand van de techniek, met specifieke aandacht voor het identificeren en beperken van kwetsbaarheden. Deze maatregelen zijn bedoeld om systematische risico's te adresseren en te verminderen. Deze vereiste is een aanvulling op de genoemde verplichtingen in artikel 53 van de AI-verordening.</p> <p>Systeemrisico betekent: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleienden, die aanzienlijke gevolgen hebben voor de markt van de Uniek vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid.</p> <p>Systeemrisico\u2019s nemen logischerwijs toe naargelang de capaciteiten en het bereik van een model groter zijn, kunnen zich voordoen gedurende de gehele levenscyclus van het model en worden be\u00efnvloed door elementen als misbruik van het model, de betrouwbaarheid, billijkheid, beveiliging en mate van autonomie ervan. Ook worden ze be\u00efnvloed door de toegang van het model tot instrumenten, nieuwe of gecombineerde modaliteiten, introductie- en distributiestrategie\u00ebn, en door het potentieel om waarborgen te omzeilen en andere factoren.</p>"},{"location":"vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 55 Verordening Artifici\u00eble Intelligentie</li> <li>[Overweging 110 Verordening Artifici\u00eble Intelligentie]</li> </ul>"},{"location":"vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot negatieve gevolgen voor de gezondheid, veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel.</p>"},{"location":"vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-33-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/","title":"Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico houden relevante informatie over ernstige incidenten bij","text":"<p>aia-33Monitoring en beheerProjectleiderGovernanceTransparantie</p>"},{"location":"vereisten/aia-33-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten.</p>"},{"location":"vereisten/aia-33-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten ernstige incidenten documenteren en rapporteren. Deze informatie moet onmiddellijk worden gemeld aan het AI-bureau en eventueel aan nationale autoriteiten. Dit proces is cruciaal voor het waarborgen van de veiligheid en het nemen van passende corrigerende maatregelen. Dit vereiste is een aanvulling op de in artikel 53 AI-verordening genoemde verplichtingen.</p>"},{"location":"vereisten/aia-33-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#bronnen","title":"Bronnen","text":"<p>Artikel 55(1c) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-33-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-33-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot risico's op veiligheidsincidenten, datalekken en schade aan de betrokken partijen en het publiek.</p>"},{"location":"vereisten/aia-33-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-34-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/","title":"Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor passend niveau van cyberbeveiliging","text":"<p>aia-34OntwikkelenMonitoring en beheerOntwikkelaarGovernanceTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-34-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het model.</p>"},{"location":"vereisten/aia-34-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen met systeemrisico moeten zorgen voor passende cyberbeveiligingsmaatregelen. Dit omvat het beschermen van zowel het AI-model als de fysieke infrastructuur tegen potenti\u00eble cyberdreigingen. Het doel is om de integriteit en veiligheid van het model en de infrastructuur te waarborgen. Dit vereiste is een aanvulling op de in artikel 53 AI-verordening genoemde verplichtingen.</p>"},{"location":"vereisten/aia-34-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#bronnen","title":"Bronnen","text":"<p>Artikel 55(1d) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-34-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-34-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot risico's op veiligheidsincidenten, datalekken en schade aan de betrokken partijen en het publiek.</p>"},{"location":"vereisten/aia-34-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-35-verwerking-in-testomgeving/","title":"Verdere verwerking van persoonsgegevens in AI-testomgevingen","text":"<p>aia-35OrganisatieverantwoordelijkhedenOntwikkelenDataverkenning en datapreparatieJuristOntwikkelaarProjectleiderPrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/aia-35-verwerking-in-testomgeving/#vereiste","title":"Vereiste","text":"<p>Rechtmatig voor andere doeleinden verzamelde persoonsgegevens mogen uitsluitend in de AI-testomgeving voor regelgeving worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen en indien aan alle voorwaarden van art. 57 is voldaan.</p>"},{"location":"vereisten/aia-35-verwerking-in-testomgeving/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens voor AI-testdoeleinden is mogelijk maar het moet voldoen aan strikte voorwaarden die zijn opgenomen in artikel 57 AI-Verordening. Hierbij kan worden gedacht aan voorwaarden als het beschermen van persoonsgevens met passende technische en organisatorische maatregelen,  persoonsgegevens die in de testomgeving worden aangemaakt mogen niet buiten de testomgeving worden gedeeld en logbestanden worden bijgehouden voor de duur van de deelname aan de testomgeving. Voor toepassingen voor het verder verwerken van gegevens kan worden gedacht aan het ontwikkelen van een AI-systeem zodat een overheidsinstantie of een andere natuurlijke of rechtspersoon een aanzienlijk openbaar belang kan waarborgen, bijvoorbeeld op het gebied van kwaliteit van milieu, duurzaamheid, openbare veiligheid en gezondheid.</p>"},{"location":"vereisten/aia-35-verwerking-in-testomgeving/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 57 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/aia-35-verwerking-in-testomgeving/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-35-verwerking-in-testomgeving/#risico","title":"Risico","text":"<p>Verdere verwerking van persoonsgegevens buiten een AI-testomgeving vergroot de kans op bijvoorbeeld het lekken van de persoonsgegevens, wat kan leiden tot een inbreuk op de privacyrechten van betrokken.</p>"},{"location":"vereisten/aia-35-verwerking-in-testomgeving/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-36-monitoring-na-het-in-de-handel-brengen/","title":"Monitoring na het in handel brengen","text":"<p>aia-36Monitoring en beheerProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/aia-36-monitoring-na-het-in-de-handel-brengen/#vereiste","title":"Vereiste","text":"<p>Aanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologie\u00ebn en de risico\u2019s van het AI-systeem met een hoog risico.</p>"},{"location":"vereisten/aia-36-monitoring-na-het-in-de-handel-brengen/#toelichting","title":"Toelichting","text":"<p>Aanbieders moeten een monitoringssysteem opzetten voor het monitoren na het in de handel brengen. Dit systeem moet documenteren op een wijze die passend is bij de aard van de AI-technologie\u00ebn en de risico's van het betreffende AI-systeem met een hoog risico. Dit monitoringssysteem moet proportioneel zijn aan de complexiteit en potenti\u00eble impact van het AI-systeem.</p> <p>Het systeem voor monitoring na het in de handel brengen verzamelt, documenteert en analyseert actief en systematisch relevante data die door gebruiksverantwoordelijken kunnen zijn verstrekt of via andere bronnen kunnen zijn verzameld, over de prestaties van AI-systemen met een hoog risico gedurende hun hele levensduur. Dit stelt de aanbieder in staat na te gaan of AI-systemen blijvend voldoen aan de in hoofdstuk III, afdeling 2, van de AI-verordening vermelde voorschriften. In voorkomend geval omvat de monitoring na het in de handel brengen een analyse van de interactie met andere AI-systemen. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijken die rechtshandhavingsinstanties zijn.</p> <p>Het systeem voor monitoring na het in de handel brengen is gebaseerd op een plan voor monitoring na het in de handel brengen. Het plan voor monitoring na het in de handel brengen maakt deel uit van de in bijlage IV bedoelde technische documentatie.</p>"},{"location":"vereisten/aia-36-monitoring-na-het-in-de-handel-brengen/#bronnen","title":"Bronnen","text":"<p>Artikel 72(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-36-monitoring-na-het-in-de-handel-brengen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-36-monitoring-na-het-in-de-handel-brengen/#risico","title":"Risico","text":"<p>Zonder monitoringssysteem voor na het in handel brengen is er een risico dat verminderde pestaties van een AI-systeem met hoog risico ongedeteceerd blijven. Een aanbieder kan niet nagaan of een AI-systeem blijvend voldoet aan voorschriften.</p>"},{"location":"vereisten/aia-36-monitoring-na-het-in-de-handel-brengen/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-37-melding-ernstige-incidenten/","title":"Melden van ernstige incidenten","text":"<p>aia-37OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderGovernance</p>"},{"location":"vereisten/aia-37-melding-ernstige-incidenten/#vereiste","title":"Vereiste","text":"<p>Aanbieders van in de Europese Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.</p>"},{"location":"vereisten/aia-37-melding-ernstige-incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die binnen de EU worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden. Een 'ernstig incident' wordt in artikel 3 van de AI-verordening gedefinieerd als: een incident of gebrekkig functioneren van een AI-systeem dat direct of indirect leidt tot: </p> <ol> <li>het overlijden van een persoon of ernstige schade voor de gezondheid van een persoon;</li> <li>een ernstige en onomkeerbare verstoring van het beheer of de exploitatie van kritieke infrastructuur;</li> <li>een schending van de uit het recht van de Unie voortvloeiende verplichtingen ter bescherming van de grondrechten;</li> <li>ernstige schade aan eigendommen of het milieu.</li> </ol> <p>Dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze AI-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek. Het doel is om de veiligheid en betrouwbaarheid van AI-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliseren.</p>"},{"location":"vereisten/aia-37-melding-ernstige-incidenten/#bronnen","title":"Bronnen","text":"<p>Artikel 73(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-37-melding-ernstige-incidenten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-37-melding-ernstige-incidenten/#risico","title":"Risico","text":"<p>Het niet melden van ernstige incidenten kan leiden tot vertraagde reactie op potenti\u00eble gevaren voor gebruikers en kan het vertrouwen in AI-systemen ondermijnen.</p>"},{"location":"vereisten/aia-37-melding-ernstige-incidenten/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-38-melding-inbreuk-op-ai-verordening/","title":"Veilig melden van inbreuk op AI verordening","text":"<p>aia-38OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderGovernanceMenselijke controle</p>"},{"location":"vereisten/aia-38-melding-inbreuk-op-ai-verordening/#vereiste","title":"Vereiste","text":"<p>Inbreuken op de AI verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.</p>"},{"location":"vereisten/aia-38-melding-inbreuk-op-ai-verordening/#toelichting","title":"Toelichting","text":"<p>Personen die optreden als klokkenluiders bij inbreuken op de AI-verordening, moeten worden beschermd uit hoofde van het Unierecht. Richtlijn (EU) 2019/1937 (https://eur-lex.europa.eu/legal-content/NL/LSU/?uri=CELEX:32019L1937) van het Europees Parlement en de Raad moet daarom van toepassing zijn. De richtlijn biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders (\"klokkenluiders\") beschermt tegen represailles of vervolging. Deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteit.</p>"},{"location":"vereisten/aia-38-melding-inbreuk-op-ai-verordening/#bronnen","title":"Bronnen","text":"<p>Artikel 87 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-38-melding-inbreuk-op-ai-verordening/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-38-melding-inbreuk-op-ai-verordening/#risico","title":"Risico","text":"<p>Gebrek aan een veilige omgeving kan ertoe leiden dat klokkenluiders geen melding maken van inbreuk op de AI-verordening.  Dit schaadt het rapportagesysteem en heeft negatief effect op het maatschappelijk welzijn.</p>"},{"location":"vereisten/aia-38-melding-inbreuk-op-ai-verordening/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aia-39-recht-klacht-indienen-bij-ai-bureau/","title":"Klachtrecht aanbieders verder in AI-waardeketen","text":"<p>aia-39OrganisatieverantwoordelijkhedenProjectleiderGovernanceFundamentele rechten</p>"},{"location":"vereisten/aia-39-recht-klacht-indienen-bij-ai-bureau/#vereiste","title":"Vereiste","text":"<p>Aanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op de AI verordening bij het AI-bureau.</p>"},{"location":"vereisten/aia-39-recht-klacht-indienen-bij-ai-bureau/#toelichting","title":"Toelichting","text":"<p>Aanbieders verder in de AI-waardeketen hebben het recht om een klacht in te dienen bij het AI-bureau in het geval van een inbreuk op de AI-verordening. Dit biedt hen een mechanisme om actie te ondernemen bij schendingen van de regels met betrekking tot AI-modellen voor algemene doeleinden die zij ge\u00efntrigeerd hebben in AI-systemen. Het AI-bureau kan dan passende maatregelen nemen om de naleving van de verordening te handhaven en eventuele geschillen tussen aanbieders op te lossen.</p>"},{"location":"vereisten/aia-39-recht-klacht-indienen-bij-ai-bureau/#bronnen","title":"Bronnen","text":"<p>Artikel 89(2) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"vereisten/aia-39-recht-klacht-indienen-bij-ai-bureau/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aia-39-recht-klacht-indienen-bij-ai-bureau/#risico","title":"Risico","text":"<p>Gebrek aan klachtrecht verhindert het AI-bureau om tijdig en zorgvuldig te kunnen ingrijpen bij overtreding van de AI-verordening.</p>"},{"location":"vereisten/aia-39-recht-klacht-indienen-bij-ai-bureau/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/arc-01-archiefwet/","title":"De archiefwet is ook van toepassing op algoritmes en AI-systemen","text":"<p>arc-01UitfaserenMonitoring en beheerOntwikkelenProjectleiderOntwikkelaarGovernanceData</p>"},{"location":"vereisten/arc-01-archiefwet/#vereiste","title":"Vereiste","text":"<p>Overheidsorganen zijn verplicht de onder hen berustende archiefbescheiden in goede, geordende en toegankelijke staat te brengen en te bewaren, alsmede zorg te dragen voor de vernietiging van de daarvoor in aanmerking komende archiefbescheiden.</p>"},{"location":"vereisten/arc-01-archiefwet/#toelichting","title":"Toelichting","text":"<p>Volgens de Archiefwet moeten overheden informatie bewaren. Op basis van deze informatie moet  gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes en AI, tot stand zijn gekomen. Informatie over en van algoritmes en AI moet daarom op basis van de selectielijst bewaard en vernietigd worden.</p>"},{"location":"vereisten/arc-01-archiefwet/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 3 Archiefwet 1995 </li> <li>Artikel 15 lid 2 Archiefwet 1995 </li> <li>Archiefbesluit 1995</li> <li>Archiefregeling</li> </ul>"},{"location":"vereisten/arc-01-archiefwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/arc-01-archiefwet/#risico","title":"Risico","text":"<p>Zonder goede toepassing van de Archiefwet is het voor betrokkene(n) of derden niet mogelijk om achteraf te reconstrueren en te controleren hoe besluiten, waar algoritmes en AI aan hebben bijgedragen, tot stand zijn gekomen. Het nalaten om archiefbescheiden na verloop van tijd te verwijderen brengt risico's met zich mee op het gebied van privacy en informatiebeveiliging.</p>"},{"location":"vereisten/arc-01-archiefwet/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-08Bepaal welke documenten voor hoe lang gearchiveerd moeten wordendat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedureBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/aut-01-auteursrechten/","title":"Auteursrechten mogen niet worden geschonden","text":"<p>aut-01Dataverkenning en datapreparatieOntwerpJuristDataGovernance</p>"},{"location":"vereisten/aut-01-auteursrechten/#vereiste","title":"Vereiste","text":"<p>Auteursrechten mogen niet geschonden worden bij het ontwikkelen en gebruiken van algoritmes en AI.</p>"},{"location":"vereisten/aut-01-auteursrechten/#toelichting","title":"Toelichting","text":"<p>Bepaalde vormen van algoritmes en AI worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes en AI. Het gebruiken van deze data mag geen inbreuk maken op Auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes en AI mag geen inbreuk maken op deze rechten.</p>"},{"location":"vereisten/aut-01-auteursrechten/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1 Auteurswet </li> <li>Artikel 4-9 Auteurswet</li> <li>Artikel 10 Auteurswet</li> <li>Artikel 13 Auteurswet</li> <li>Artikel 15n jo. 15o Auteurswet</li> <li>Artikel 3 en 4 van de DSM-richtlijn (EU 2019/790)</li> </ul>"},{"location":"vereisten/aut-01-auteursrechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/aut-01-auteursrechten/#risico","title":"Risico","text":"<p>Het niet voldoen aan het auteursrecht in AI-systemen en algoritmes kan leiden tot onrechtmatig gebruik van auteursrechtelijk beschermde inhoud, wat kan resulteren in mogelijke juridische geschillen, boetes en schadevergoedingen voor inbreuk op het auteursrecht. Bovendien kan het niet naleven van het auteursrecht het vertrouwen van gebruikers en belanghebbenden ondermijnen, wat kan leiden tot reputatieschade en gebrek aan vertrouwen.</p>"},{"location":"vereisten/aut-01-auteursrechten/#maatregelen","title":"Maatregelen","text":"idMaatregelendat-06Controleer de auteursrechten van eigen dataAansprakelijkheidsvoorwaarden worden beoordeeld in de aanbestedingBespreek de vereiste met aanbieder of opdrachtnemerContractuele afspraken over data en artefactenCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Verken maatregelen van aanbieder om schending auteursrechten te voorkomenBewijs laten leveren dat auteursrechten niet worden geschonden met de outputBewijs laten leveren dat auteursrechten niet worden geschonden met de trainingsdataMaak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Restrisico's met betrekking tot schending auteursrechten zijn inzichtelijk gemaaktGarantie in conceptovereenkomst dat aanbieder auteursrechten niet schendt met de outputGarantie in conceptovereenkomst dat auteursrechten niet worden geschonden met de trainingsdataNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/","title":"Verwerking van persoonsgegevens moet rechtmatig plaatsvinden","text":"<p>avg-01ProbleemanalyseOntwerpDataverkenning en datapreparatieProjectleiderJuristPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens moet rechtmatig plaatsvinden.</p>"},{"location":"vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens moet rechtmatig plaatsvinden, wat betekent dat de verwerking gebaseerd moet zijn op \u00e9\u00e9n van de wettelijke grondslagen die zijn geformuleerd in artikel 6 Algemene Verordening Gegevensbescherming. Persoonsgegevens mogen alleen worden verzameld voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden. Het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden.</p> <p>Bij het verwerken van persoonsgegevens ten behoeve van de ontwikkeling en gebruik van algoritmes en AI moet worden onderzocht of dit kan worden gebaseerd op \u00e9\u00e9n van de verwerkingsgrondslagen. Het is van belang dat wordt uitgewerkt welke persoonsgegevens waarvoor worden verwerkt en op basis van welke grondslag. Hierbij kan worden gedacht aan persoonsgegevens ten behoeve van trainingsdata, voor het genereren van output of, indien (juridisch) mogelijk, voor het uitvoeren van een onderzoek naar onbewuste vooringenomenheid.</p>"},{"location":"vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5 lid 1 onder a en b Algemene Verordening Gegevensbescherming</li> <li>Artikel 6 lid 1 onder b Algemene Verordening Gegevensbescherming</li> <li>Artikel 6 Algemene Verordening Gegevensbescherming</li> <li>Overweging 39 en 45 Algemene Verordening Gegevensbescherming</li> </ul>"},{"location":"vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#risico","title":"Risico","text":"<p>Het risico wanneer persoonsgegevens niet op een rechtmatige manier worden verwerkt (verzamelen van gegevens valt hier ook onder), is dat er niet aan de AVG wordt voldaan. Er worden dan onrechtmatig persoonsgegevens verwerkt, waarmee privacy van personen in het geding komt. Ook kan het leiden tot hoge boetes voor organisaties, en kan een datalek plaatsvinden.</p>"},{"location":"vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#maatregelen","title":"Maatregelen","text":"idMaatregelenpba-05Beschrijf de wettelijke grondslag voor de inzet van het algoritmeowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magdat-03Beschrijf welke persoonsgegevens het algoritme gebruikt en waaromBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/","title":"Beperkte bewaartermijn van persoonsgegevens","text":"<p>avg-02OntwerpDataverkenning en datapreparatieOntwikkelenUitfaserenOntwikkelaarBeleid en adviesPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.</p>"},{"location":"vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens dienen toereikend en ter zake dienend te zijn en beperkt te blijven tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt. Dit vereist dat ervoor wordt gezorgd dat de opslagperiode van de persoonsgegevens tot een strikt minimum wordt beperkt. Het beginsel van opslagbeperking betekent dat persoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan voor de realisering van de doeleinden waarvoor de persoonsgegevens worden verwerkt.</p> <p>In de context van algoritmes en AI is het belangrijk dat, wanneer persoonsgegevens worden verwerkt, er onderzocht wordt op welke manieren identificatie van betrokkenen tegen kan worden gegaan. Hierbij kan worden gedacht aan maatregelen als pseudonomisering en anonimisering.</p>"},{"location":"vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 5 lid 1 onder de AVG</p>"},{"location":"vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Het onnodig lang bewaren van persoonsgegevens levert een onrechtmatige situatie op. De privacyrechten van betrokken worden hierdoor aangetast. Er ontstaan aanvullende risico's bij bijvoorbeeld een datalek.</p>"},{"location":"vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#maatregelen","title":"Maatregelen","text":"idMaatregelendat-04Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedureBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/","title":"Persoonsgegevens verzamelen voor specifieke doeleinden","text":"<p>avg-03OntwerpDataverkenning en datapreparatieOntwikkelenJuristOntwikkelaarPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.</p>"},{"location":"vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat \u00e9nkel persoonsgegevens worden verwerkt die noodzakelijk zijn gezien de doeleinden van die vewerking. Er moet een beoordeling worden gemaakt welke persoonsgegevens dit wel en eventueel niet zijn. Voor het ontwikkelen en gebruiken van algoritmes of AI-systemen is het van belang om te beoordelen welke persoonsgegevens noodzakelijk zijn om het beoogde doel te bereiken. Afhankelijk van de toepassing vraagt dit om een intensieve toets. Er moet voor worden gezorgd dat persoonsgegevens die niet als noodzakelijk worden beschouwd, buiten de verwerking blijven. </p>"},{"location":"vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 5 lid 1 onder c Algemene Verordening Gegevensbescherming</p>"},{"location":"vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Het onnodig verwerken van persoonsgegevens kan een inbreuk maken op rechten van betrokkenen, en zou kunnen leiden tot een datalek.</p>"},{"location":"vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#maatregelen","title":"Maatregelen","text":"idMaatregelendat-05Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregerenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-04-proportionaliteit-en-subsidiariteit/","title":"Proportionaliteit en subsidiariteit","text":"<p>avg-04OntwerpDataverkenning en datapreparatieJuristOntwikkelaarFundamentele rechtenPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-04-proportionaliteit-en-subsidiariteit/#vereiste","title":"Vereiste","text":"<p>Gegevensverwerking moet in verhouding staan tot het beoogde doel en persoonsgegevens mogen alleen verwerkt worden als er geen minder ingrijpende manier is om het doel te bereiken. Voor zover het gaat om de verwerking van persoonsgegevens moet dit vereiste aantoonbaar zijn. </p>"},{"location":"vereisten/avg-04-proportionaliteit-en-subsidiariteit/#toelichting","title":"Toelichting","text":"<p>Proportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme of AI en voor het genereren van de benodigde output in balans is met het beoogde doel. Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken.  Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden. Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritmes en AI moet toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.</p>"},{"location":"vereisten/avg-04-proportionaliteit-en-subsidiariteit/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5(1)(c) Algemene Verordening Gegevensbescherming </li> <li>Overweging 170 Algemene Verordening Gegevensbescherming </li> <li>Artikel 5(4) Verdrag betreffende de Europese Unie, Maastricht, 07-02-1992 |</li> <li>Artikel 52 Handvest van de Grondrechten van de Europese Unie </li> <li>Protocol betreffende de toepassing van de beginselen van subsidiariteit en evenredigheid Verdrag betreffende de Europese Unie, Maastricht, 07-02-1992 </li> <li>Artikel 1.10, 1.13 en 1.16 Aanbestedingswet 2012 </li> </ul>"},{"location":"vereisten/avg-04-proportionaliteit-en-subsidiariteit/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-04-proportionaliteit-en-subsidiariteit/#risico","title":"Risico","text":"<p>Zonder toetsing aan het proportinaliteits- en subsidiariteitsbeginsel ontstaat het risico dat er een onnodig zware en daardoor onrechtmatige inbreuk wordt gemaakt op de privacyrechten van betrokkenen.</p>"},{"location":"vereisten/avg-04-proportionaliteit-en-subsidiariteit/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-05Bepaal het soort algoritme en de risicogroep en vereisten die hierbij horenowk-02Maak een noodplan voor het stoppen van het algoritmeBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/","title":"Juistheid en actualiteit van gegevens","text":"<p>avg-05Dataverkenning en datapreparatieOntwikkelaarProjectleiderPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De te verwerken persoonsgegevens zijn juist, nauwkeurig en worden zo nodig geactualiseerd of gewist.</p>"},{"location":"vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>De te verwerken persoonsgegevens moeten nauwkeurig, juist en zo nodig actueel zijn. Dit betekent dat alle maatregelen moeten worden genomen om ervoor te zorgen dat onjuiste persoonsgegevens worden gerectificeerd of gewist. Dat kan betekenen dat persoonsgegevens moeten worden geactualiseerd of verbeterd. In de context van algoritmes en AI is het van belang dat ook daar wordt onderzocht welke maatregelen nodig zijn om die juistheid toe te passen.</p>"},{"location":"vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 5 lid 1 sub d Algemene Verordening Gegevensbescherming</p>"},{"location":"vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Als er geen rekening wordt gehouden met de juistheid, nauwkeurigheid en volledigheid van persoonsgegevens, kunnen kwaliteit en integriteit van data niet voldoende worden gewaarborgd.</p>"},{"location":"vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#maatregelen","title":"Maatregelen","text":"idMaatregelendat-01Controleer de datakwaliteitVeranderingen in de dataBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/","title":"Verantwoordingsplicht voor de rechtmatigheid van de verwerking","text":"<p>avg-06OntwerpDataverkenning en datapreparatieJuristGovernancePrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#vereiste","title":"Vereiste","text":"<p>De verantwoordelijken moeten bij de verwerking van persoonsgegevens door algoritmes en AI-systemen kunnen aantonen dat de verwerkingen rechtmatig plaatsvinden. Dit betekent concreet dat de volgende punten aangetoond kunnen worden:</p> <ul> <li>Rechtmatigheid, behoorlijkheid en transparantie</li> <li>Doelbinding</li> <li>Minimale gegevensverwerking</li> <li>Juistheid</li> <li>Opslagbeperking</li> <li>Integriteit en vertrouwelijkheid</li> </ul> <p>Een aandachtpunt daarbij is dat de rechtmatigheid van de verwerking ten opzichte van andere gerelateerde wetgeving zoals de AI Act en de Algemene wet gelijke behandeling ook moeten kunnen worden aangetoond voor zover de rechtmatigheid van de verwerking onder de AVG daarvan afhankelijk is.</p>"},{"location":"vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#toelichting","title":"Toelichting","text":"<p>Bij het verwerken van persoonsgegevens voor algoritmes en AI-systemen moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn. De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht. Deze maatregelen zijn essentieel om de naleving van regelgeving met betrekking tot gegevensbescherming te waarborgen en het vertrouwen van gebruikers in de verwerking van hun gegevens te vergroten.</p>"},{"location":"vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5 lid 2 Algemene Verordening Gegevensbescherming</li> <li>Artikel 24 Algemene Verordening Gegevensbescherming</li> <li>Artikel 26 Algemene Verordening Gegevensbescherming</li> <li>Artikel 27 Algemene Verordening Gegevensbescherming</li> <li>Artikel 29 Algemene Verordening Gegevensbescherming</li> <li>Verantwoordingsplicht</li> </ul>"},{"location":"vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#risico","title":"Risico","text":"<p>Het niet naleven van deze norm moet worden gekwalificeerd als een onrechtmatigheid, niet als een risico voor de rechten en vrijheden van betrokkenen onder de AVG. Maar het niet voldoen aan artikel 5 betekent in de praktijk vaak wel dat er onvoldoende zicht is op risico's voor de rechten en vrijheden van betrokkenen of dat er te grote risico's worden genomen. Deze gevolgen zijn echter indirect een gevolg van het niet naleven van artikel 5 AVG. Het moeten voldoen aan het aantoonbaarheidsvereiste kan wel risico's hebben voor de organisatie die een algortime inzet. Enkele risico's zijn:</p> <ul> <li>Aantoonbaarheidsvereisten vragen in de praktijk veel documentatie. Deze documentatie kan via de Woo opgevraagd worden. Het ontbreken van documentatie kan door externen vaak relatief makkelijk in verband worden gebracht met een overtreding van deze vereisten.</li> <li>Algoritmen die van nature slecht inzichtelijk en uitlegbaar zijn (zoals deep-learning) hebben een zeer hoge drempel om aan deze vereiste te voldoen. Aantonen van rechtmatigheid is voor een belangrijk deel afhankelijk van inzicht in de werking van het algoritme. De inzet van een algortime kan dus mogelijk tegengehouden worden door deze vereisten.</li> <li>Bij leveranciers die niet of gedeeltelijke transparant zijn over hun product of dienstverlening ontstaat een vergelijkbaar risico. Waar de Woo uitzonderingen heeft voor bedrijfsgeheimen heeft de AVG daar maar beperkte ruimte voor. Het is dus mogelijk dat leveranciers terughoudend zullen zijn met het delen van informatie die onder de AVG ook aan betrokkenen gecommuniceerd moeten worden.</li> <li>Samenwerkingsverbanden en externe leveranciers kunnen niet als argumenten worden gebruikt om de aantoonbaarheidsvereisten op af te schuiven. Onafhankelijk van de onderlinge afspraken daarover hebben alle verwerkingsverantwoordelijken de verplichting om aan deze vereisten te kunnen voldoen. </li> </ul>"},{"location":"vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-01Beschrijf de rollen en verantwoordelijkheden in een RACI-matrixBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/","title":"Transparantie bij verwerking persoonsgegevens","text":"<p>avg-07ImplementatieMonitoring en beheerOntwikkelaarProjectleiderPrivacy en gegevensbeschermingTransparantie</p>"},{"location":"vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens moet transparant zijn.</p>"},{"location":"vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Een betrokkene moet op de hoogte worden gesteld van het feit dat er verwerking plaatsvindt van diens persoonsgegevens en van de doeleinden daarvan (zoals ook is verwoord in het beginsel van transparante verwerking, artikel 5 AVG). Hierbij moeten de specifieke omstandigheden en de context waarin de persoonsgegevens worden verwerkt, worden meegenomen. In artikel 13 en 14 AVG wordt toegelicht welke informatie in welke gevallen moet worden verstrekt door de verwerkersverantwoordelijke. Als persoonsgegevens worden verwerkt ten behoeve van het ontwikkelen of gebruiken van algoritmes en AI-systemen, zal deze informatie moeten worden verstrekt.</p>"},{"location":"vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5 lid 1 Algemene Verordening Gegevensbescherming</li> <li>Artikel 12 Algemene Verordening Gegevensbescherming</li> <li>Artikel 13 Algemene Verordening Gegevensbescherming</li> <li>Artikel 14 Algemene Verordening Gegevensbescherming</li> <li>Overweging 58 Algemene Verordening Gegevensbescherming</li> </ul>"},{"location":"vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#risico","title":"Risico","text":"<p>Rechten van betrokken worden geschonden als er geen sprake is van transparantie over de verwerkingen van de persoonsgegevens.</p>"},{"location":"vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#maatregelen","title":"Maatregelen","text":"idMaatregelenimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het Algoritmeregisterimp-07Vermeld het gebruik van persoonsgegevens in een privacyverklaringimp-08Vermeld het gebruik van persoonsgegevens in het verwerkingsregisterBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/","title":"Wettelijke uitzondering nodig voor verwerken bijzondere categorie\u00ebn persoonsgegevens","text":"<p>avg-08OntwerpDataverkenning en datapreparatieProjectleiderJuristBeleid en adviesPrivacy en gegevensbeschermingBias en non discriminatie</p>"},{"location":"vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#vereiste","title":"Vereiste","text":"<p>Bijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering.</p>"},{"location":"vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens die door hun aard bijzonder gevoelig zijn wat betreft de grondrechten en fundamentele vrijheden, verdienen specifieke bescherming. Dit komt doordat de context van de verwerking ervan significante risico's kan meebrengen voor de grondrechten en de fundamentele vrijheden. Denk hierbij aan persoonsgegevens als ras, ethnische afkomst, politieke opvattingen of religieuze of levenschouwelijke overtuigingen.</p> <p>Bijzondere categorie\u00ebn persoonsgegevens mogen alleen worden verwerkt als er hier een wettelijke uitzondering voor is (artikel 9 AVG en artikel 30 UAVG). Deze vereiste is ook van toepassing bij het ontwikkelen en gebruiken van algoritmes of AI-systemen en stelt daarmee beperkingen aan het mogen verwerken van deze categorie\u00ebn persoonsgegevens, bv. ten behoeve van trainingsdata of het genereren van de beoogde output.</p>"},{"location":"vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 9 AVG</li> <li>Overweging 51 - 54 AVG</li> <li>Artikel 22 - 30 UAVG</li> </ul>"},{"location":"vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#risico","title":"Risico","text":"<p>Het (onrechtmatige) verwerken van bijzondere categorie\u00ebn persoonsgegevens brengt risico's met zich mee op het gebied van respecteren van de persoonlijke levenssfeer en discriminatie.</p>"},{"location":"vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/","title":"Privacyrechten","text":"<p>avg-09OrganisatieverantwoordelijkhedenOntwikkelenOntwikkelaarPrivacy en gegevensbeschermingData</p>"},{"location":"vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Betrokkenen kunnen een beroep doen op hun privacyrechten.</p>"},{"location":"vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Mensen hebben het recht om hun privacyrechten uit te oefenen door een beroep te doen op verschillende wettelijke bepalingen, zoals het recht op inzage, correctie, verwijdering en bezwaar tegen de verwerking van hun persoonsgegevens. Dit betekent dat individuen controle hebben over hoe hun gegevens worden gebruikt en kunnen verzoeken om toegang te krijgen tot hun gegevens of om wijzigingen aan te brengen indien nodig. Het kunnen uitoefenen van privacyrechten is essentieel voor het beschermen van de privacy van individuen, het waarborgen van transparantie en controle uitvoeren over persoonsgegevens. Als persoonsgegevens worden verwerkt voor het ontwikkelen en gebruiken van algoritmes en AI, is het van belang dat maatregelen worden getroffen om deze rechten te eerbiedigen.</p>"},{"location":"vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 15 - 21 Algemene Verordening Gegevensbescherming</p>"},{"location":"vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#risico","title":"Risico","text":"<p>Betrokkenen hebben geen controle over hun persoonsgegevens wanneer ze geen beroep kunnen doen op hun privacyrechten.</p>"},{"location":"vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#maatregelen","title":"Maatregelen","text":"idMaatregelenimp-06Spreek af hoe de organisatie omgaat met privacy-verzoekenimp-09Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces.Bespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/","title":"Recht op niet geautomatiseerde besluitvorming","text":"<p>avg-10OntwerpImplementatieProjectleiderBeleid en adviesPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#vereiste","title":"Vereiste","text":"<p>Betrokkenen hebben het recht om niet onderworpen te worden aan een enkel op geautomatiseerde verwerking, waaronder proflering, gebaseerd besluit, wanneer dit rechtsgevolgen heeft voor hen of het hen anderszins in aanzienlijke mate treft. Dit verbod geldt niet indien de  geautomatiseerde individuele besluitvorming, anders dan op basis van profilering, noodzakelijk is om te voldoen aan een wettelijke verplichting die op de verwerkingsverantwoordelijke rust of noodzakelijk is voor de vervulling van een taak van algemeen belang.</p>"},{"location":"vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#toelichting","title":"Toelichting","text":"<p>Mensen hebben het recht om niet onderworpen te worden aan beslissingen die uitsluitend gebaseerd zijn op geautomatiseerde verwerking, zoals profilering, als dit aanzienlijke gevolgen voor hen heeft of hen op een andere manier aanzienlijk be\u00efnvloedt. Dit recht biedt bescherming tegen mogelijke negatieve effecten van volledig geautomatiseerde besluitvormingssystemen, en waarborgt dat individuen kunnen rekenen op menselijke tussenkomst en beoordeling bij belangrijke beslissingen die hen kunnen treffen. Uitgangspunt is dat voor elk individueel geval een zorgvuldige beoordeling van de kenmerken en omstandigheden plaatsvindt voordat een besluit wordt genomen.</p>"},{"location":"vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 22 Algemene Verordening Gegevensbescherming</li> <li>Artikel 40 Uitvoeringswet AVG </li> <li>Artikel 1:3 Algemene wet bestuursrecht </li> </ul>"},{"location":"vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#risico","title":"Risico","text":"<p>Bij geautomatiseerde besluitvorming kan het risico ontstaan dat kenmerken van een bepaalde groep ten onrechte worden tegengeworpen aan een individu die deze kenmerken niet hoeft te bezitten.</p>"},{"location":"vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#maatregelen","title":"Maatregelen","text":"idMaatregelenimp-03Organiseer menselijke controle van het algoritmeBepaal of de output bepalende invloed heeft in een besluit richting personenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenMenselijke tussenkomst is een vast onderdeel in een projecptlan of een d\u00e9chargedocumentNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/","title":"Privacy door ontwerp","text":"<p>avg-11OntwerpDataverkenning en datapreparatieBeleid en adviesProjectleiderJuristOntwikkelaarPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Privacy en gegevensbescherming door goed ontwerp en door standaardinstellingen</p>"},{"location":"vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Gegevensbescherming door ontwerp en standaardinstellingen houdt in dat privacy- en gegevensbescherming vanaf het begin worden ge\u00efntegreerd in de ontwikkeling van systemen en processen (ook wel privacy-by-design genoemd). Door al bij het ontwerp rekening te houden met privacyaspecten en door standaardinstellingen die privacy bevorderen, wordt de bescherming van persoonsgegevens versterkt. Hierbij kan worden gedacht een het pseudonimiseren van persoonsgegevens of dataminimalisatie. Deze aanpak zorgt ervoor dat privacy-overwegingen een integraal onderdeel zijn van alle aspecten van gegevensverwerking en draagt bij aan het vertrouwen van individuen in de veilige omgang met hun gegevens. Dit is eveneens van toepassing als persoonsgegevens worden verwerkt bij het ontwikkelen en gebruiken van algoritmes en AI.</p>"},{"location":"vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 25 Algemene Verordening Gegevensbescherming</li> </ul>"},{"location":"vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Door privacy en gegevensbescherming door ontwerp en standaardinstellingen niet toe te passen, kan een inbreuk op rechten van betrokkenen ontstaan.</p>"},{"location":"vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-10Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-12-beveiliging-van-verwerking/","title":"Beveiliging van de verwerking","text":"<p>avg-12OrganisatieverantwoordelijkhedenJuristOntwikkelaarPrivacy en gegevensbeschermingTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/avg-12-beveiliging-van-verwerking/#vereiste","title":"Vereiste","text":"<p>Rekening houdend met de stand van de techniek, de uitvoeringskosten, alsook met de aard, de omvang, de context en de verwerkingsdoeleinden en de qua waarschijnlijkheid en ernst uiteenlopende risico's voor de rechten en vrijheden van personen, treffen de verwerkingsverantwoordelijke en de verwerker passende technische en organisatorische maatregelen om een op het risico afgestemd beveiligingsniveau te waarborgen.</p>"},{"location":"vereisten/avg-12-beveiliging-van-verwerking/#toelichting","title":"Toelichting","text":"<p>Voor de ontwikkeling en gebruik van algoritmes en AI is er data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en de algoritmische toepassing of AI-systeem voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.</p>"},{"location":"vereisten/avg-12-beveiliging-van-verwerking/#bronnen","title":"Bronnen","text":"<p>Artikel 32 Algemene Verordening Gegevensbescherming|</p>"},{"location":"vereisten/avg-12-beveiliging-van-verwerking/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-12-beveiliging-van-verwerking/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals potenti\u00eble cyberaanvallen en datalekken. Dit kan leiden bijvoorbeeld tot verlies of diefstal van gevoelige gegevens, verstoring van organisatieprocessen,ongeautoriseerde toegang, vernietiging en onrechtmatige verwerking.</p>"},{"location":"vereisten/avg-12-beveiliging-van-verwerking/#maatregelen","title":"Maatregelen","text":"idMaatregelendat-05Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregerenowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019mon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/avg-13-dpia-verplicht/","title":"Een DPIA is verplicht bij hoog risico voor de rechten en vrijheden van natuurlijke personen","text":"<p>avg-13OntwerpDataverkenning en datapreparatieVerificatie en validatieJuristProjectleiderPrivacy en gegevensbescherming</p>"},{"location":"vereisten/avg-13-dpia-verplicht/#vereiste","title":"Vereiste","text":"<p>Een gegevensbeschermingseffectbeoordeling (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen.</p>"},{"location":"vereisten/avg-13-dpia-verplicht/#toelichting","title":"Toelichting","text":"<p>Een Gegevensbeschermingseffectbeoordeling (GEB) of Data Protection Impact Assessment (DPIA) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen.  Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen.  Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in AI-systemen en algoritmes, waardoor de privacy van individuen wordt gewaarborgd.</p> <p>Let op: de DPIA verplichting is niet gebaseerd op de hoog-risico criteria uit de AI-act. Volgens Besluit lijst verwerkingen persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens moet voor het uitvoeren van een DPIA in ieder geval uitgegaan worden van een hoog risico als er sprake is van \u00e9\u00e9n van de volgende voorwaarden:</p> <ol> <li>Evaluatie of scoretoekenning</li> <li>Geautomatiseerde besluitvorming met rechtsgevolg of vergelijkbaar wezenlijk gevolg</li> <li>Stelselmatige monitoring</li> <li>Gevoelige gegevens of gegevens van zeer persoonlijke aard</li> <li>Op grote schaal verwerkte gegevens</li> <li>Matching of samenvoeging van datasets</li> <li>Gegevens met betrekking tot kwetsbare betrokkenen</li> <li>Innovatief gebruik of innovatieve toepassing van nieuwe technologische of organisatorische oplossingen</li> <li>de situatie waarin als gevolg van de verwerking zelf \"betrokkenen [...] een recht niet kunnen uitoefenen of geen beroep kunnen doen op een dienst of een overeenkomst\";</li> </ol> <p>Het is mogelijk dat algoritmes die niet aan \u00e9\u00e9n of meer van deze eigenschappen voldoen toch voor een potentieel hoog risico zorgen. </p> <p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruiken die informatie op grond van artikel 13 AI Verordening om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren. </p>"},{"location":"vereisten/avg-13-dpia-verplicht/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 35 Algemene Verordening Gegevensbescherming</li> <li>Artikel 26(9) Verordening Artifici\u00eble Intelligentie </li> <li>Besluit lijst verwerkingen persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens</li> <li>Data protection impact assessment (DPIA) Autoriteit Persoonsgegevens</li> </ul>"},{"location":"vereisten/avg-13-dpia-verplicht/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/avg-13-dpia-verplicht/#risico","title":"Risico","text":"<p>Het niet evalueren van de impact van het verwerking van persoonsgegevens in AI-systemen en algoritmes kan resulteren in het niet onderkennen van de bijbehorende risico's  en het niet op tijd te mitigieren van deze risico's. Dit kan leiden tot potenti\u00eble schendingen van de rechten en vrijheden van betrokkenen en een onrechtmatige verwerking.</p>"},{"location":"vereisten/avg-13-dpia-verplicht/#maatregelen","title":"Maatregelen","text":"idMaatregelenowp-09Een model-verwerkersovereenkomst is onderdeel van de aanbesteding als persoonsgegevens worden verwerktowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/awb-01-zorgvuldigheidsbeginsel/","title":"Relevante feiten en belangen zijn bekend","text":"<p>awb-01OntwerpOntwikkelenVerificatie en validatieProjectleiderBeleid en adviesFundamentele rechten</p>"},{"location":"vereisten/awb-01-zorgvuldigheidsbeginsel/#vereiste","title":"Vereiste","text":"<p>De ontwikkeling en het gebruik van algoritmes en AI-systemen komt zorgvuldig tot stand.</p>"},{"location":"vereisten/awb-01-zorgvuldigheidsbeginsel/#toelichting","title":"Toelichting","text":"<p>Dit beginsel vereist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming. Dit betekent dat  algoritmes en AI zodanig moet worden ontwikkeld en gebruikt, dat dit passend is ter ondersteuning van de wettelijke taak en de bijbehorende beslissing of besluitvorming.</p> <p>Het doel en eventuele subdoelen van het algoritme of AI-systeem moet helder zijn gedefinieerd, ook in relatie tot het maatschappelijke resultaat (outcome), en wordt gedeeld door de eigenaar, ontwikkelaar en gebruiker van het algoritme. Een bewuste afweging of het algoritme het juiste middel is om het probleem op doelmatige en doeltreffende wijze op te lossen is gemaakt en vastgelegd. </p>"},{"location":"vereisten/awb-01-zorgvuldigheidsbeginsel/#bronnen","title":"Bronnen","text":"<ul> <li>Afdeling 3.2 Algemene wet bestuursrecht</li> <li>Afdeling 3.4 Algemene wet bestuursrecht</li> </ul>"},{"location":"vereisten/awb-01-zorgvuldigheidsbeginsel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/awb-01-zorgvuldigheidsbeginsel/#risico","title":"Risico","text":"<p>De werking van het algoritmes of AI sluit niet of onvoldoende aan bij de juridische en ethische grenzen van de te ondersteunen wettelijke taak. Hierdoor kunnen ongewenste gevolgen ontstaan zoals een onjuist of onzorgvuldig genomen besluit op een aanvraag.</p>"},{"location":"vereisten/awb-01-zorgvuldigheidsbeginsel/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/awb-02-motiveringsbeginsel/","title":"Een besluit berust op een deugdelijke motivering","text":"<p>awb-02OntwerpImplementatieMonitoring en beheerJuristBeleid en adviesTransparantie</p>"},{"location":"vereisten/awb-02-motiveringsbeginsel/#vereiste","title":"Vereiste","text":"<p>Een besluit berust op een deugdelijke motivering</p>"},{"location":"vereisten/awb-02-motiveringsbeginsel/#toelichting","title":"Toelichting","text":"<p>Een bestuursorgaan moet inzichtelijk maken: </p> <ol> <li>dat een besluit tot stand is gekomen met behulp van een algoritme; </li> <li>van welke feiten het is uitgegaan en welke gegevens van de burger gebruikt c.q. verwerkt zijn;</li> <li>welke relevante belangen tegen elkaar zijn afgewogen en hoe die afweging is verlopen (bijvoorbeeld het gewicht dat wordt toegekend aan elk afgewogen kenmerk; welke analytische technieken gebruikt zijn; welke specifieke voorspellende data; wat de belangrijkste policy-keuzes waren; een uitleg van het voorspellende algoritme); </li> <li>hoe het algoritme werkt (niet de techniek, maar hoe de uitkomsten van het algoritme tot stand komen). </li> </ol> <p>De keuzes en aannames die zijn gemaakt en gedaan moeten worden beschreven en toegelicht.</p>"},{"location":"vereisten/awb-02-motiveringsbeginsel/#bronnen","title":"Bronnen","text":"<ul> <li>Afdeling 3.7 Algemene wet bestuursrecht</li> <li>Jurisprudentie over AERIUS (ABRvS 18 juli 2018, ECLI:NL:RVS:2018:2454), Hof van Justitie C-274/18</li> </ul>"},{"location":"vereisten/awb-02-motiveringsbeginsel/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/awb-02-motiveringsbeginsel/#risico","title":"Risico","text":"<p>Het is onduidelijk op wat voor manier het algoritmes of AI-systeem heeft bijgedragen aan de totstandkoming van een besluit. </p>"},{"location":"vereisten/awb-02-motiveringsbeginsel/#maatregelen","title":"Maatregelen","text":"idMaatregelenver-03Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidimp-01Maak een openbaar besluit over de inzet van het algoritmeBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/","title":"Beveiliging informatie en informatiesystemen","text":"<p>bio-01OrganisatieverantwoordelijkhedenBeleid en adviesOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#vereiste","title":"Vereiste","text":"<p>Informatie en informatiesystemen moeten op de juiste manier worden beveiligd.</p>"},{"location":"vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#toelichting","title":"Toelichting","text":"<p>Informatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen. In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid (BIO) dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn. Algoritmes en AI-systemen en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.</p>"},{"location":"vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid </li> <li>Besluit voorschrift informatiebeveiliging rijksdienst 2007</li> </ul>"},{"location":"vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals ongeautoriseerde toegang, vernietiging, verlies, wijziging of niet-toegestane verwerking van gegevens als de informatie en informatiesystemen onvoldoende zijn beveiligd.</p>"},{"location":"vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#maatregelen","title":"Maatregelen","text":"idMaatregelenorg-02Bepaal het beleid voor het ontwikkelen, inkopen en gebruiken van algoritmesorg-04Maak afspraken over het wijzigen van de codeorg-05Maak afspraken over het beheer van gebruikersorg-06Maak afspraken over het beheer van wachtwoordenowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019owk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de codemon-01Maak back-ups van algoritmesmon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak de vereiste onderdeel van Service Level AgreementMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenVoer een risico-analyse met de leverancier uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/bzk-01-algoritmeregister/","title":"Impactvolle algoritmes worden gepubliceerd in het Nederlandse algoritmeregister","text":"<p>bzk-01ImplementatieMonitoring en beheerProjectleiderTransparantie</p>"},{"location":"vereisten/bzk-01-algoritmeregister/#vereiste","title":"Vereiste","text":"<p>Bestuursorganen publiceren algoritmes met impact en hoog-risico AI-systemen in het Nederlandse Algoritmeregister.</p>"},{"location":"vereisten/bzk-01-algoritmeregister/#toelichting","title":"Toelichting","text":"<p>Het publiceren van impactvolle algoritmes en AI-systemen draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes en AI worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister. Er wordt gewerkt aan wetgeving om het bij wet verplicht te stellen.</p>"},{"location":"vereisten/bzk-01-algoritmeregister/#bronnen-bestaand-beleid","title":"Bronnen (bestaand beleid)","text":"<ul> <li>Handreiking Algoritmeregister</li> <li>Geactualiseerde Werkagenda Waardengedreven Digitaliseren 2024</li> <li>Kamerbrieven</li> </ul>"},{"location":"vereisten/bzk-01-algoritmeregister/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/bzk-01-algoritmeregister/#risico","title":"Risico","text":"<p>Door het niet publiceren van impactvolle of hoog risico AI -systemen in het Algoritmeregister, is het voor betrokkenen of belanghebbenden minder goed mogelijk om de overheid kritisch te volgen, te bevragen en te controleren op de inzet van deze technologie\u00ebn die hen kunnen raken.  Bij het onjuist of onvolledig publiceren in het Algortimeregister ontstaat er een risico dat betrokkenen en belanghebbenden onjuiste inschattingen maken over het gebruik van het algoritme of het AI-systeem en daardoor in hun rechten worden beperkt.</p>"},{"location":"vereisten/bzk-01-algoritmeregister/#maatregelen","title":"Maatregelen","text":"idMaatregelenimp-04Publiceer impactvolle algoritmes en hoog-risico-AI-systemen in het AlgoritmeregisterBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/bzk-01-algoritmeregister/#instrumenten","title":"Instrumenten","text":"idInstrumenten"},{"location":"vereisten/dat-01-databankenwet/","title":"Verbod op schenden databankenrechten","text":"<p>dat-01Dataverkenning en datapreparatieJuristData</p>"},{"location":"vereisten/dat-01-databankenwet/#vereiste","title":"Vereiste","text":"<p>Het is verboden om zonder goedkeuring van de producent een databank op te vragen en/of te hergebruiken.</p>"},{"location":"vereisten/dat-01-databankenwet/#toelichting","title":"Toelichting","text":"<p>De Databankrichtlijn en Databankenwet beschermt de producten/fabrikanten van databanken tegen onrechtmatige toe-eigening van een databank. Degene die een substanti\u00eble financi\u00eble en professionele investering heeft verricht om de inhoud van de databank te verkijgen en te verzamelen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken. Bij verkrijgen gaat het om \"het verzamelen van de werken, gegevens of andere zelfstandige elementen die tezamen de inhoud van de databank vormen\". Dit recht bestaat naast het recht op bescherming van de originele keuze of rangschikking van de inhoud van databanken (auteurswet).</p> <p>Voor het ontwikkelen van algoritme en AI is data nodig. De data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databank.</p>"},{"location":"vereisten/dat-01-databankenwet/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1 en 2 Databankenwet</li> <li>Artikel 5a en 5b Databankenwet</li> <li>Artikel 7 Databankrichtlijn</li> <li>Overwegingen 39 - 41 Databankrichtlijn</li> </ul>"},{"location":"vereisten/dat-01-databankenwet/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/dat-01-databankenwet/#risico","title":"Risico","text":"<p>Als een ontwikkelaar onbevoegd gebruik heeft gemaakt van data uit een databank bij de ontwikkeling van algoritmes en AI, wordt het databankenrecht geschonden van de eigenaar.  De eigenaar van de databank kan bijvoorbeeld ontrekking van de data uit het handelsverkeer, vernietiging en onbruikbaarmaking  eisen, wat vergaande gevolgen kan hebben voor het gebruik kunnen maken van de algoritmische toepassing of AI-systeem.</p>"},{"location":"vereisten/dat-01-databankenwet/#maatregelen","title":"Maatregelen","text":"idMaatregelenBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/grw-01-fundamentele-rechten/","title":"Beschermen van fundamentele rechten en vrijheden","text":"<p>grw-01ProbleemanalyseOntwerpVerificatie en validatieMonitoring en beheerProjectleiderJuristFundamentele rechten</p>"},{"location":"vereisten/grw-01-fundamentele-rechten/#vereiste","title":"Vereiste","text":"<p>Fundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes en AI.</p>"},{"location":"vereisten/grw-01-fundamentele-rechten/#toelichting","title":"Toelichting","text":"<p>Mensenrechten gelden voor alle mensen op de wereld. De mensenrechten in Nederland zijn beschermd door nationale wetten en internationale verdragen. In Nederland staan veel mensenrechten in hoofdstuk 1 van de Grondwet. Deze rechten heten ook wel \u2019grondrechten\u2019. Een bekend voorbeeld is artikel 1 van de Grondwet. Om mensenrechten te beschermen zijn ze op Europees en internationaal niveau in verschillende verklaringen en verdragen vastgelegd.</p> <p>Mensenrechten kunnen soms onder druk komen te staan. De inzet van algoritmes en AI-systemen kan bijvoorbeeld een bedreiging vormen voor de privacy van burgers, voor het  recht op gelijke behandeling en voor het recht op behoorlijk bestuur. Het is daarom belangrijk om tijdig te onderzoeken of er sprake is of kan zijn van een eventuele inbreuk op fundamentele rechten en vrijheden van burgers. Het is van belang dat maatregelen worden getroffen om een eventuele inbreuk te voorkomen.</p>"},{"location":"vereisten/grw-01-fundamentele-rechten/#bronnen","title":"Bronnen","text":"<ul> <li>Grondwet</li> <li>Europees Verdragvoor de Rechten van de Mens (EVRM)</li> <li>Handvest van de grondrechten van de Europese Unie</li> <li>Universele Verklaring van de Rechten van de Mens (UVRM)</li> <li>Internationaal Statuut van de Rechten van de Mens</li> <li>Internationale Verdrag inzake burgerrechten en politieke rechten (IVBPR)</li> <li>Internationale Verdrag inzake economische, sociale en culturele rechten (IVESCR)</li> <li>Internationaal Verdrag inzake de uitbanning van alle vormen van rassendiscriminatie (CERD)</li> <li>Internationaal Verdrag voor de rechten van het kind (CRC)</li> <li>Internationaal Verdrag voor de Rechten van Mensen met een Handicap (VN-verdrag Handicap)</li> <li>Artikel 27 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"vereisten/grw-01-fundamentele-rechten/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/grw-01-fundamentele-rechten/#risico","title":"Risico","text":"<p>Grondrechten kunnen worden geraakt door de inzet van algoritmes met eventuele schadelijke gevolgen voor betrokkenen. </p>"},{"location":"vereisten/grw-01-fundamentele-rechten/#maatregelen","title":"Maatregelen","text":"idMaatregelen"},{"location":"vereisten/grw-01-fundamentele-rechten/#instrumenten","title":"Instrumenten","text":"idInstrumenten"},{"location":"vereisten/grw-02-non-discriminatie/","title":"AI-systemen en algoritmes mogen niet discrimineren","text":"<p>grw-02Dataverkenning en datapreparatieVerificatie en validatieMonitoring en beheerProjectleiderBias en non discriminatie</p>"},{"location":"vereisten/grw-02-non-discriminatie/#vereiste","title":"Vereiste","text":"<p>Allen die zich in Nederland bevinden, worden in gelijke gevallen gelijk behandeld. Directe en indirecte discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, handicap, seksuele gerichtheid of op welke grond dan ook, is niet toegestaan.</p>"},{"location":"vereisten/grw-02-non-discriminatie/#toelichting","title":"Toelichting","text":"<p>Overheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes of AI. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie. Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.</p>"},{"location":"vereisten/grw-02-non-discriminatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1 Grondwet </li> <li>Artikel 14 Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden, Rome, 04-11-1950</li> <li>Artikel 21 Handvest van de Grondrechten van de Europese Unie</li> <li>Artikel 1 Algemene wet gelijke behandeling </li> <li>Artikel 1 Protocol nr. 12 bij het Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden, Rome, 04-11-2000 </li> <li>Artikel 9 Algemene Verordening Gegevensbescherming </li> <li>Artikel 2:4 Algemene wet bestuursrecht </li> </ul>"},{"location":"vereisten/grw-02-non-discriminatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/grw-02-non-discriminatie/#risico","title":"Risico","text":"<p>Het risico bestaat dat het model onwenselijke systematische afwijkingen cre\u00ebert voor specifieke personen, groepen of andere eenheden, wat kan duiden op directe of indirecte discriminerende effecten van het algoritme.</p>"},{"location":"vereisten/grw-02-non-discriminatie/#maatregelen","title":"Maatregelen","text":"idMaatregelenowk-02Maak een noodplan voor het stoppen van het algoritmever-01Toets het algoritme op biasimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenimp-05Spreek af hoe medewerkers omgaan met het algoritme of AI-systeemBespreek de vereiste met aanbieder of opdrachtnemerCre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijvingMaak de vereiste onderdeel van het programma van eisenMaak de vereiste onderdeel van de contractovereenkomstMaak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaardenNeem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst"},{"location":"vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/","title":"Eenieder heeft recht op toegang tot publieke informatie","text":"<p>woo-01OrganisatieverantwoordelijkhedenJuristProjectleiderTransparantie</p>"},{"location":"vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#vereiste","title":"Vereiste","text":"<p>Een bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.</p>"},{"location":"vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#toelichting","title":"Toelichting","text":"<p>Bij het ontwikkelen en gebruiken van algoritmes en AI kunnen documenten en publieke informatie ontstaan die (op verzoek) in aanmerking komen voor openbaarmaking. Het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat. De Wet open overheid gaat uit van een recht op openbaarheid van publieke informatie. Iedereenkan een verzoek tot openbaarmaking van publieke informatie doen bij een bestuursorgaan zonder daarbij een belang te stellen (artikel 4.1 Woo). De aan een verzoeker verstrekte informatie wordt openbaar voor iedereen. De Woo is niet van toepassing op informatie die al openbaar is (uitspraken van de Afdeling bestuursrechtspraak van de Raad van State van 1 december 2010 (ECLI:NL:RVS:2010:BNS6990) en 20 oktober 2010 (ECLI:NL:RVS:2010:BO1165)). Er kunnen uitsluitingsgronden bestaan voor het openbaarmaken van documenten (artikel 5.1 Woo).</p> <p>In de context van het ontwikkelen en gebruiken van algoritmes en AI-systemen is het van belang dat tijdig wordt vastgesteld welke documenten in aanmerking komen voor openbaarmaking. Dit moet worden bekeken in het licht van wat 'actief' moet worden geopenbaard, dus proactief vanuit overheidsinstanties zelf, of wat op 'verzoek' van iemand moet worden geopenbaard.</p>"},{"location":"vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1.1 Wet open overheid</li> <li>Artikel 2.5 Wet open overheid</li> <li>Artikel 4.1 Wet open overheid</li> <li>Artikel 5 Wet open overheid</li> </ul>"},{"location":"vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#wanneer-van-toepassing","title":"Wanneer van toepassing?","text":""},{"location":"vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#risico","title":"Risico","text":"<p>Zonder het openbaren van overheidsinformatie kan de overheid niet effectief worden gecontroleerd bij het uitvoeren van wettelijke taken.</p>"},{"location":"vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#maatregelen","title":"Maatregelen","text":"ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusontwerpontwikkelenOnderwerpenpublieke-inkoopidMaatregelenRollenLevenscyclusOnderwerpenBespreek de vereiste met aanbieder of opdrachtnemer                  projectleider                               ontwerp                               ontwikkelen                               publieke-inkoop              Cre\u00eber ruimte in het contract om opdrachtgever en aanbieder/opdrachtnemer te laten samenwerken om deze vereiste te realiseren.                  projectleider                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak de vereiste onderdeel van het programma van eisen                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak de vereiste onderdeel van de contractovereenkomst                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak de vereiste onderdeel van Service Level Agreement                  ontwerp                               ontwikkelen                               publieke-inkoop              Maak vereisten voor algoritmes en AI-systemen onderdeel van contractvoorwaarden                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop              Neem de vereiste op als een subgunningscriteria bij gunningscriteria beste prijs-kwaliteitverhouding.                  ontwikkelaar                               ontwerp                               ontwikkelen                               publieke-inkoop              Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst                  projectleider                               jurist                               ontwerp                               ontwikkelen                               publieke-inkoop"}]}