{"config":{"lang":["nl"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Algoritmekader","text":"<p>Over het algoritmekader</p> <p>Belangrijkste wetten en regels voor verantwoord gebruik van overheidsalgoritmes, met tips en hulpmiddelen.</p> <p>Meer informatie over het algoritmekader</p> <p>Lees alles over de Europese AI-verordening</p> <ul> <li>\u203a Tijdlijn: alle deadlines op een rij</li> <li>\u203a AI-verordening in het kort</li> <li>\u203a Beslishulp AI-verordening</li> </ul> <p>Ontdek alle informatie</p> <p>Soorten algoritmes en AI</p> <ul> <li>\u203a Wat is een algoritme?</li> <li>\u203a Generatieve AI</li> <li>\u203a Risico van AI-systemen</li> </ul> <p>Bekijk alle algoritmesoorten</p> <p>Voldoen aan wetten en regels</p> <ul> <li>\u203a Vereisten, inclusief AI-verordening</li> <li>\u203a Overzicht aanbevolen maatregelen</li> <li>\u203a Hulpmiddelen</li> </ul> <p>Bekijk alle vereisten</p> <p>Onderwerpen</p> <ul> <li>\u203a Discriminatie</li> <li>\u203a Privacy en persoonsgegevens</li> <li>\u203a Publieke inkoop</li> </ul> <p>Bekijk alle onderwerpen</p> <p></p>"},{"location":"version/","title":"Version","text":""},{"location":"version/#-","title":"---","text":""},{"location":"version/#huidige-versie","title":"Huidige versie","text":"<p>v2.4.3-18-g49db762c3</p>"},{"location":"ai-verordening/","title":"AI-verordening","text":""},{"location":"ai-verordening/#ai-verordening","title":"AI-verordening","text":""},{"location":"ai-verordening/#ai-verordening-in-het-kort","title":"AI-verordening in het kort","text":"<p>De Europese regels voor het verantwoord ontwikkelen en gebruiken van AI.</p>"},{"location":"ai-verordening/#tijdlijn-ai-verordening","title":"Tijdlijn AI-verordening","text":"<p>Belangrijkste deadlines uit de AI-verordening met de vereisten waaraan je moet voldoen.</p>"},{"location":"ai-verordening/#beslishulp-ai-verordening","title":"Beslishulp AI-verordening","text":"<p>Geldt de AI-verordening voor jouw AI-product? En aan welke vereisten moet je dan voldoen?</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/","title":"AI-verordening in het kort","text":""},{"location":"ai-verordening/ai-verordening-in-het-kort/#ai-verordening-in-het-kort","title":"AI-verordening in het kort","text":"<p>In de AI-verordening staan de Europese regels voor het verantwoord ontwikkelen en gebruiken van AI. Sommige AI-systemen zijn verboden vanaf 2 februari 2025. Andere AI-systemen moeten op zijn laatst in 2026 of 2030 voldoen aan bepaalde vereisten.</p> <p>Verordening (EU) 2024/1689 (AI-verordening)</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#europese-regels-voor-het-ontwikkelen-en-gebruiken-van-ai","title":"Europese regels voor het ontwikkelen en gebruiken van AI","text":"<p>De AI-verordening is de eerste uitgebreide wet over artifici\u00eble intelligentie (AI) ter wereld. De regels gelden voor alle Europese lidstaten.</p> <p>De AI-verordening geldt in deze 3 situaties samen:</p> <ul> <li>Je ontwikkelt of gebruikt AI.</li> <li>Dit doe je namens een overheid, bedrijf of andere organisatie.</li> <li>Je organisatie is gevestigd in een EU-land.</li> </ul> <p>Het maakt niet uit waar je AI-producten ontwikkelt. Ontwikkel je buiten de EU, maar is je organisatie gevestigd in een EU-land? Dan geldt de AI-verordening.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#verantwoord-gebruik-van-ai","title":"Verantwoord gebruik van AI","text":"<p>Het doel van de AI-verordening is om verantwoord gebruik van AI te stimuleren in de hele EU. Daarom gelden in alle EU-landen dezelfde regels voor het:</p> <ul> <li>verkleinen van risico\u2019s voor de gezondheid, veiligheid en grondrechten van mensen</li> <li>beschermen van de democratie, de rechtsstaat en het milieu</li> </ul> <p>Het gaat dan om risico\u2019s zoals misleiding en discriminatie door AI-systemen.</p> <p>Bestaande regels zoals de Algemene verordening gegevensbescherming (AVG) en de Algemene wet bestuursrecht (Awb) beschermen maar voor een deel tegen deze risico\u2019s. Zij gelden niet speciaal voor AI. Daarom vult de AI-verordening deze regels aan.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#definitie-ai-systeem","title":"Definitie AI-systeem","text":"<p>De AI-verordening geldt voor AI-systemen.</p> <p>Een rekenregel is op zichzelf geen AI-systeem of AI-model. Rekenregels kunnen hier wel onderdeel van zijn.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#ai-systeem","title":"AI-systeem","text":"<p>Een AI-systeem is volgens de AI-verordening: '(\u2026) een op een machine gebaseerd systeem dat is ontworpen om met verschillende niveaus van autonomie te werken en dat na de uitrol aanpassingsvermogen kan vertonen, en dat, voor expliciete of impliciete doelstellingen, uit de ontvangen input afleidt hoe output te genereren zoals voorspellingen, inhoud, aanbevelingen of beslissingen.'</p> <p>Hieronder vallen systemen die kunstmatig intelligent zijn door zelflerende technieken zoals:</p> <ul> <li>supervised learning</li> <li>unsupervised learning</li> <li>reinforcement learning (bekrachtiginsleren)</li> </ul> <p>In combinatie met deze zelflerende technieken kan ook gebruik gemaakt worden van deep learning.</p> <p>Onder AI-systemen vallen ook systemen die gebruik maken van op logica en kennis gebaseerde benaderingen (knowledge and logic-based approaches) die leren, redeneren of modelleren mogelijk maken.</p> <p>Symbolische AI is meestal ook een AI-systeem. Symbolische AI leert op basis van symbolen en concepten. Een expertsysteem bepaalt bijvoorbeeld op basis van kennis van menselijke experts of iemand een verzekering krijgt of niet. Niet-symbolische AI leert op basis van numerieke data. Dit zijn meetbare data zoals uren, temperatuur en centimeters.</p> <p>Tip</p> <p>De Europese Commissie publiceerde in februari 2025 extra guidance over de definitie van een AI-systeem. De richtlijnen over de definitie van een AI-systeem geven uitleg over de praktische toepassing van het wettelijke concept, zoals verankerd in de AI-verordening.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#ai-model-voor-algemene-doeleinden","title":"AI-model voor algemene doeleinden","text":"<p>Een AI-model voor algemene doeleinden (GPAI):</p> <ul> <li>is onderdeel van AI-systemen zoals ChatGPT of Microsoft Copilot</li> <li>kan allerlei soorten taken uitvoeren</li> <li>traint zichzelf op basis van grote hoeveelheden data</li> <li>kan content maken zoals teksten, audio en video</li> </ul> <p>Een AI-systeem dat is gebaseerd op een AI-model voor algemene doeleinden, noemen we een AI-systeem voor algemene doeleinden.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#risicogroepen","title":"Risicogroepen","text":"<p>De AI-verordening deelt AI-systemen op in 3 risicogroepen. Hoe groter het risico voor de samenleving, hoe strenger de regels uit de AI-verordening. Het hangt ervan af waarvoor je dit AI-systeem gebruikt:</p> <ul> <li>Risico op misleiding</li> <li>Hoog-risico-AI-systemen</li> <li>Verboden AI</li> </ul>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#rollen-uit-de-ai-verordening","title":"Rollen uit de AI-verordening","text":"<p>De AI-verordening geldt zowel voor ontwikkelaars van AI-systemen als voor organisaties en bedrijven die AI-systemen gebruiken. Afhankelijk van jouw rol bij het AI-systeem gelden er verschillende verplichtingen. De meeste verplichtingen gelden voor de ontwikkelaars van AI-systemen.</p> <p>De belangrijkste begrippen die de AI-verordening hiervoor gebruikt zijn: aanbieder en gebruiksverantwoordelijke.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#aanbieder","title":"Aanbieder","text":"<p>Dit is de organisatie die het AI-systeem ontwikkelt.</p> <p>Let op!</p> <p>Je bent ook een aanbieder als je een AI-systeem laat ontwikkelen en het systeem in de handel brengt of in gebruik stelt onder de eigen naam of merk. Of wanneer je een substantiele wijziging aanbrengt in het AI-systeem dat al in gebruik is genomen. Lees meer in Overweging 84 van de AI-verordening.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#gebruiksverantwoordelijke","title":"Gebruiksverantwoordelijke","text":"<p>Dit is de organisatie die het AI-systeem onder eigen verantwoordelijkheid gebruikt.</p> <p>Opmerking</p> <p>Als je het AI-systeem dat je gebruikt ook zelf hebt ontwikkeld, dan ben je zowel aanbieder als gebruiksverantwoordelijke.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#andere-rollen","title":"Andere rollen","text":"<p>De AI-verordening definieert ook andere rollen zoals importeur, distributeur of gemachtigde. Deze zijn voor overheden meestal niet van toepassing.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#tijdlijn","title":"Tijdlijn","text":"<p>De AI-verordening trad in werking op 1 augustus 2024 en gaat stap voor stap gelden:</p> <ul> <li>2 februari 2025: Vereisten over verboden AI en AI-geletterdheid</li> <li>2 augustus 2025: Vereisten voor modellen voor algemene doeleinden (GPAI)</li> <li>2 augustus 2026: Vereisten voor nieuwe hoog-risico-AI-systemen</li> <li>2 augustus 2027: Vereisten voor hoog-risico-AI-systemen in producten</li> <li>2 augustus 2030: Vereisten voor overige hoog-risico-systemen</li> </ul> <p>In de tijdlijn AI-verordening vind je alle vereisten per deadline.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#toezicht-en-implementatie","title":"Toezicht en implementatie","text":"<ul> <li>Nationale toezichthouders: houden toezicht op de meeste bepalingen en kunnen straffen opleggen (nog in oprichting in Nederland)</li> <li>AI-bureau: houdt toezicht op de bepalingen voor modellen voor algemene doeleinden</li> <li>AI-board: Europese raad voor artifici\u00eble intelligentie</li> <li>Wetenschappelijk panel: advies van wetenschappers</li> <li>Adviesforum: advies van belanghebbenden</li> </ul>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#hulp-bij-de-ai-verordening","title":"Hulp bij de AI-verordening","text":""},{"location":"ai-verordening/ai-verordening-in-het-kort/#beslishulp-ai-verordening","title":"Beslishulp AI-verordening","text":"<p>Met de beslishulp AI-verordening bepaal je snel en gemakkelijk of jouw AI-product onder de AI-verordening valt. En wat je dan moet doen.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#gids-ai-verordening","title":"Gids AI-verordening","text":"<p>Wil je de regels uit de AI-verordening overzichtelijk bekijken? Het Ministerie van Economische Zaken schreef de Gids AI-verordening. Dit document zet deze regels helder op een rij en gaat ook dieper in op de mogelijke implicaties van de wet voor het gebruik en de ontwikkeling van AI binnen jouw organisatie.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#hulpmiddelen-implementatie-ai-verordening","title":"Hulpmiddelen implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om bij de implementatie van de AI-verordening te ondersteunen.</p> <p>Hulpmiddelen op gebied van duiding van de AI-verordening:</p> Titel Beschrijving Factsheet AI-verordening voor bestuurders Deze factsheet is bedoelt voor bestuurders om snel inzicht te krijgen in de belangrijkste aspecten van de AI-verordening. Impactanalyse AI-verordening De impactanalyse AI-verordening is een hulpmiddel bij de implementatie van de AI-verordening. Het geeft een overzicht van de vereisten in het licht van mogelijk reeds bestaande governance, maatregelen, etc. Het doel van de impactanalyse is om een betere inschatting te kunnen maken van de benodigde acties bij de implementatie voor alle soorten overheidsorganisaties. Om dit doel te kunnen behalen is gekozen voor generieke termen, de gebruiker moet deze zelf vertalen naar de eigen context. Roadmap inwerkingtreding AI-verordening Dit document geeft een gedetailleerd overzicht van de gefaseerde inwerkingtreding van de AI-verordening. Voor een toegankelijke webpagina-versie (maar minder gedetailleerd), bekijk deze tijdlijn. <p>Hulpmiddelen op gebied van AI-geletterdheid:</p> Titel Beschrijving Wettelijke vereisten AI-geletterdheid Deze factsheet zet uiteen wat de eisen op het gebied van AI-geletterdheid in de AI-verordening inhouden. Blauwdruk AI-geletterdheidsprogramma Deze blauwdruk is opgesteld om als template te fungeren voor een AI-geletterdheidsprogramma waarmee voldaan kan worden aan de vereisten voor AI-geletterdheid uit de AI-verordening. AI-Geletterdheid Self-assessment Met deze self-assessment kan men nagaan welk niveau AI-geletterdheid nodig is, en wat men kan doen om daar te komen. Factsheet AI-geletterdheid voor bestuurders Deze factsheet is bedoelt voor bestuurders om snel inzicht te krijgen in de AI-geletterdheidvereisten die de AI-verordening introduceert. Factsheet AI-geletterdheid voor inkopers Deze factsheet is bedoelt voor inkopers om snel inzicht te krijgen in de AI-geletterdheidvereisten die de AI-verordening introduceert. <p>Al deze hulpmiddelen zijn ook te vinden onder de Hulpmiddelen op het Algoritmekader.</p> <p>Deze hulpmiddelen voor de implementatie van de AI-verordening zijn ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"ai-verordening/ai-verordening-in-het-kort/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/","title":"Tijdlijn AI-verordening","text":""},{"location":"ai-verordening/tijdlijn-ai-verordening/#tijdlijn-ai-verordening","title":"Tijdlijn AI-verordening","text":"<p>De AI-verordening gaat in fasen in. Bekijk wanneer je moet voldoen aan welke vereisten.</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#2-februari-2025-stoppen-met-verboden-ai-starten-met-ai-geletterdheid","title":"2 februari 2025: Stoppen met verboden AI, starten met AI-geletterdheid","text":"<p>Als je aanbieder of gebruiksverantwoordelijke bent van een AI-systeem, moet je v\u00f3\u00f3r 2 februari 2025 voldoen aan de volgende vereisten uit de AI-verordening:</p> <ul> <li>Verboden AI is uitgefaseerd</li> <li>aia-01 Personeel en gebruikers zijn voldoende AI-geletterd</li> </ul> <p>Geldt dit voor jouw organisatie? Gebruik de Beslishulp AI-verordening.</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#2-augustus-2025-ai-modellen-voor-algemene-doeleinden-voldoen-aan-de-vereisten","title":"2 augustus 2025: AI-modellen voor algemene doeleinden voldoen aan de vereisten","text":"<p>Als je aanbieder bent van een AI-model voor algemene doeleinden, moet je v\u00f3\u00f3r 2 augustus 2025 voldoen aan de volgende vereisten uit de AI-verordening:</p> <ul> <li>aia-29 AI-modellen voor algemene doeleinden zijn voorzien van voldoende technische documentatie en informatie</li> <li>aia-30 Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico treffen extra maatregelen</li> <li>aia-31 Als AI-modellen voor algemene doeleinden met systeemrisico\u2019s ernstige incidenten veroorzaken, wordt dit gedocumenteerd en gerapporteerd</li> <li>aia-32 AI-modellen voor algemene doeleinden met systeemrisico\u2019s zijn voldoende beveiligd tegen cyberaanvallen</li> </ul>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#2-augustus-2026-nieuwe-hoog-risico-ai-systemen-voldoen-aan-vereisten","title":"2 augustus 2026: Nieuwe hoog-risico-AI-systemen voldoen aan vereisten","text":"<p>Als je aanbieder en/of gebruiksverantwoordelijke bent van een hoog-risico-AI-systeem dat op de markt komt op of na 2 augustus 2026, moet je v\u00f3\u00f3r 2 augustus 2026 voldoen aan de volgende vereisten uit de AI-verordening:</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#aanbieder","title":"Aanbieder","text":"<ul> <li>aia-02 Beoordeling als \u2018niet-hoog-risico-AI-systeem\u2019 is gedocumenteerd</li> <li>aia-03 Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteem</li> <li>aia-04 Hoog-risico-AI-systemen vormen geen risico voor kwetsbare groepen zoals kinderen</li> <li>aia-05 Datasets voor hoog-risico-AI-systemen voldoen aan kwaliteitscriteria</li> <li>aia-06 Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie</li> <li>aia-07 Hoog-risico-AI-systemen loggen automatisch bepaalde gegevens</li> <li>aia-08 Hoog-risico-AI-systemen zijn op een transparante manier ontwikkeld en ontworpen</li> <li>aia-09 Hoog-risico-AI-systemen staan onder menselijk toezicht</li> <li>aia-10 Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig</li> <li>aia-11 Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteem</li> <li>aia-12 Documentatie over hoog-risico-AI-systemen wordt 10 jaar bewaard door de aanbieder</li> <li>aia-13 Logs van hoog-risico-AI-systemen worden 6 maanden bewaard door de aanbieder</li> <li>aia-14 Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedure</li> <li>aia-15 Hoog-risico-AI-systemen zijn voorzien van een EU-conformiteitsverklaring</li> <li>aia-16 Hoog-risico-AI-systemen zijn voorzien van een CE-markering</li> <li>aia-17 Hoog-risico-AI-systemen zijn geregistreerd in de EU-databank</li> <li>aia-18 Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder in</li> <li>aia-19 Hoog-risico-AI-systemen voldoen aan de toegankelijkheidseisen</li> <li>aia-34 Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem</li> <li>aia-35 Ernstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouder</li> <li>aia-36 Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordening</li> <li>aia-37 Klachtrecht aanbieders verder in waardeketen</li> </ul>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#gebruiksverantwoordelijke","title":"Gebruiksverantwoordelijke","text":"<ul> <li>aia-20 Hoog-risico-AI-systemen worden gebruikt volgens de gebruiksaanwijzing</li> <li>aia-21 Menselijke controle van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkheden</li> <li>aia-22 De werking van hoog-risico-AI-systemen wordt gemonitord</li> <li>aia-23 Logs voor hoog-risico-AI-systemen worden bewaard door de gebruiksverantwoordelijke</li> <li>aia-24 Werknemers weten dat hun organisatie een hoog-risico-AI-systeem gebruikt</li> <li>aia-25 Gebruiksverantwoordelijken controleren de registratie van het hoog-risico-AI-systeem in de EU-databank</li> <li>aia-26 Mensen over wie besluiten worden genomen door hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluiten</li> <li>aia-27 Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechten</li> <li>aia-28 AI-systemen worden zo ontworpen en gebruikt, dat mensen begrijpen wanneer zij met een AI-systeem communiceren en welke content gemaakt is door een AI-systeem</li> </ul> <p>Wat betekent dit voor jouw organisatie? Gebruik de Beslishulp AI-verordening.</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#uitzondering","title":"Uitzondering","text":"<p>Een uitzondering geldt voor hoog-risico-AI-systemen die op 2 augustus 2026 al in gebruik zijn bij overheidsorganisaties. Deze systemen hoeven pas in 2030 te voldoen aan de vereisten uit de AI-verordening. Zie AI-verordening, artikel 26 en artikel 27.</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#2-augustus-2027-hoog-risico-systemen-in-producten-voldoen-aan-vereisten","title":"2 augustus 2027: Hoog-risico-systemen in producten voldoen aan vereisten","text":"<p>Als je aanbieder bent van een product met daarin een hoog-risico-AI-systeem, moet je v\u00f3\u00f3r 2 augustus 2027 voldoen aan de volgende vereisten uit de AI-verordening:</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#aanbieder_1","title":"Aanbieder","text":"<ul> <li>aia-02 Beoordeling als \u2018niet-hoog-risico-AI-systeem\u2019 is gedocumenteerd</li> <li>aia-03 Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteem</li> <li>aia-04 Hoog-risico-AI-systemen vormen geen risico voor kwetsbare groepen zoals kinderen</li> <li>aia-05 Datasets voor hoog-risico-AI-systemen voldoen aan kwaliteitscriteria</li> <li>aia-06 Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie</li> <li>aia-07 Hoog-risico-AI-systemen loggen automatisch bepaalde gegevens</li> <li>aia-08 Hoog-risico-AI-systemen zijn op een transparante manier ontwikkeld en ontworpen</li> <li>aia-09 Hoog-risico-AI-systemen staan onder menselijk toezicht</li> <li>aia-10 Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig</li> <li>aia-11 Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteem</li> <li>aia-12 Documentatie over hoog-risico-AI-systemen wordt 10 jaar bewaard door de aanbieder</li> <li>aia-13 Logs van hoog-risico-AI-systemen worden 6 maanden bewaard door de aanbieder</li> <li>aia-14 Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedure</li> <li>aia-15 Hoog-risico-AI-systemen zijn voorzien van een EU-conformiteitsverklaring</li> <li>aia-16 Hoog-risico-AI-systemen zijn voorzien van een CE-markering</li> <li>aia-17 Hoog-risico-AI-systemen zijn geregistreerd in de EU-databank</li> <li>aia-18 Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder in</li> <li>aia-19 Hoog-risico-AI-systemen voldoen aan de toegankelijkheidseisen</li> <li>aia-34 Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem</li> <li>aia-35 Ernstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouder</li> <li>aia-36 Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordening</li> <li>aia-37 Klachtrecht aanbieders verder in waardeketen</li> </ul>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#gebruiksverantwoordelijke_1","title":"Gebruiksverantwoordelijke","text":"<ul> <li>aia-20 Hoog-risico-AI-systemen worden gebruikt volgens de gebruiksaanwijzing</li> <li>aia-21 Menselijke controle van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkheden</li> <li>aia-22 De werking van hoog-risico-AI-systemen wordt gemonitord</li> <li>aia-23 Logs voor hoog-risico-AI-systemen worden bewaard door de gebruiksverantwoordelijke</li> <li>aia-24 Werknemers weten dat hun organisatie een hoog-risico-AI-systeem gebruikt</li> <li>aia-25 Gebruiksverantwoordelijken controleren de registratie van het hoog-risico-AI-systeem in de EU-databank</li> <li>aia-26 Mensen over wie besluiten worden genomen door hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluiten</li> <li>aia-27 Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechten</li> <li>aia-28 AI-systemen worden zo ontworpen en gebruikt, dat mensen begrijpen wanneer zij met een AI-systeem communiceren en welke content gemaakt is door een AI-systeem</li> </ul> <p>Wat betekent dit voor jouw organisatie? Gebruik de Beslishulp AI-verordening.</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#2-augustus-2030-bestaande-hoog-risico-ai-systemen-voldoen-aan-vereisten","title":"2 augustus 2030: Bestaande hoog-risico-AI-systemen voldoen aan vereisten","text":"<p>Als je aanbieder of gebruiksverantwoordelijke bent van een hoog-risico-AI-systeem dat v\u00f3\u00f3r 2 augustus 2026 in gebruik is genomen, moet je v\u00f3\u00f3r 2 augustus 2030 voldoen aan de volgende vereisten uit de AI-verordening:</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#aanbieder_2","title":"Aanbieder","text":"<ul> <li>aia-02 Beoordeling als \u2018niet-hoog-risico-AI-systeem\u2019 is gedocumenteerd</li> <li>aia-03 Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteem</li> <li>aia-04 Hoog-risico-AI-systemen vormen geen risico voor kwetsbare groepen zoals kinderen</li> <li>aia-05 Datasets voor hoog-risico-AI-systemen voldoen aan kwaliteitscriteria</li> <li>aia-06 Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie</li> <li>aia-07 Hoog-risico-AI-systemen loggen automatisch bepaalde gegevens</li> <li>aia-08 Hoog-risico-AI-systemen zijn op een transparante manier ontwikkeld en ontworpen</li> <li>aia-09 Hoog-risico-AI-systemen staan onder menselijk toezicht</li> <li>aia-10 Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig</li> <li>aia-11 Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteem</li> <li>aia-12 Documentatie over hoog-risico-AI-systemen wordt 10 jaar bewaard door de aanbieder</li> <li>aia-13 Logs van hoog-risico-AI-systemen worden 6 maanden bewaard door de aanbieder</li> <li>aia-14 Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedure</li> <li>aia-15 Hoog-risico-AI-systemen zijn voorzien van een EU-conformiteitsverklaring</li> <li>aia-16 Hoog-risico-AI-systemen zijn voorzien van een CE-markering</li> <li>aia-17 Hoog-risico-AI-systemen zijn geregistreerd in de EU-databank</li> <li>aia-18 Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder in</li> <li>aia-19 Hoog-risico-AI-systemen voldoen aan de toegankelijkheidseisen</li> <li>aia-34 Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem</li> <li>aia-35 Ernstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouder</li> <li>aia-36 Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordening</li> <li>aia-37 Klachtrecht aanbieders verder in waardeketen</li> </ul>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#gebruiksverantwoordelijke_2","title":"Gebruiksverantwoordelijke","text":"<ul> <li>aia-20 Hoog-risico-AI-systemen worden gebruikt volgens de gebruiksaanwijzing</li> <li>aia-21 Menselijke controle van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkheden</li> <li>aia-22 De werking van hoog-risico-AI-systemen wordt gemonitord</li> <li>aia-23 Logs voor hoog-risico-AI-systemen worden bewaard door de gebruiksverantwoordelijke</li> <li>aia-24 Werknemers weten dat hun organisatie een hoog-risico-AI-systeem gebruikt</li> <li>aia-25 Gebruiksverantwoordelijken controleren de registratie van het hoog-risico-AI-systeem in de EU-databank</li> <li>aia-26 Mensen over wie besluiten worden genomen door hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluiten</li> <li>aia-27 Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechten</li> <li>aia-28 AI-systemen worden zo ontworpen en gebruikt, dat mensen begrijpen wanneer zij met een AI-systeem communiceren en welke content gemaakt is door een AI-systeem</li> </ul> <p>Geldt dit voor jouw organisatie? Gebruik de Beslishulp AI-verordening.</p>"},{"location":"ai-verordening/tijdlijn-ai-verordening/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/","title":"Levenscyclus algoritmes en AI","text":""},{"location":"levenscyclus/#levenscyclus-algoritmes-en-ai","title":"Levenscyclus algoritmes en AI","text":""},{"location":"levenscyclus/#over-de-levenscyclus","title":"Over de levenscyclus","text":"<p>De levenscyclus helpt je te bepalen wat je wanneer moet doen. Hoe ziet dit eruit in een plaatje? En waarom 8 fasen?</p>"},{"location":"levenscyclus/#fase-0-organisatieverantwoordelijkheden","title":"Fase 0: Organisatieverantwoordelijkheden","text":"<p>Voordat je start met de ontwikkeling of het gebruik van een algoritme, zul je moeten zorgen dat je organisatie voldoende ingericht is om algoritmes te gebruiken of te ontwikkelen.</p>"},{"location":"levenscyclus/#fase-1-probleemanalyse","title":"Fase 1: Probleemanalyse","text":"<p>In deze fase wordt het probleem en de doelstellingen van een opdrachtgever geanalyseerd en beschreven.</p>"},{"location":"levenscyclus/#fase-2-ontwerp","title":"Fase 2: Ontwerp","text":"<p>In de ontwerpfase wordt het conceptuele ontwerp van het AI-systeem uitgedacht.</p>"},{"location":"levenscyclus/#fase-3-dataverkenning-en-datapreparatie","title":"Fase 3: Dataverkenning en datapreparatie","text":"<p>Dit is de fase waarin het algoritme of AI-systeem wordt ontwikkeld door het ontwikkelteam.</p>"},{"location":"levenscyclus/#fase-4-ontwikkelen","title":"Fase 4: Ontwikkelen","text":"<p>Dit is de fase waarin het algoritme of AI-systeem wordt ontwikkeld door het ontwikkelteam.</p>"},{"location":"levenscyclus/#fase-5-verificatie-en-validatie","title":"Fase 5: Verificatie en validatie","text":"<p>Bij de verificatie en validatie van het algoritme of AI-systeem dient bepaald te worden of het algoritme of AI-systeem gebouwd is volgens de (technische) specificaties en voldoet aan de beoogde doelstellingen.</p>"},{"location":"levenscyclus/#fase-6-implementatie","title":"Fase 6: Implementatie","text":"<p>In deze fase wordt het algoritme of AI-systeem in de praktijk gebracht en duurzaam ge\u00efntegreerd in het bedrijfsproces.</p>"},{"location":"levenscyclus/#fase-7-monitoring-en-beheer","title":"Fase 7: Monitoring en beheer","text":"<p>Het algoritme of AI-systeem wordt in deze fase voortdurend gemonitord om ervoor te zorgen dat het blijft presteren zoals verwacht en kan worden gebruikt door gebruikers.</p>"},{"location":"levenscyclus/#fase-8-uitfaseren","title":"Fase 8: Uitfaseren","text":"<p>Als wordt besloten dat het algoritme of AI-systeem niet langer nodig is of wordt vervangen door een wezenlijk andere versie, wordt het gearchiveerd en uitgefaseerd.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/","title":"Fase 3, dataverkenning en datapreparatie","text":""},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#fase-3-dataverkenning-en-datapreparatie","title":"Fase 3: Dataverkenning en datapreparatie","text":"<p>In deze fase verzamel en analyseer je de data die nodig zijn voor het ontwikkelen van het algoritme of AI-systeem. Je voert een dataverkenning uit, waarin je onderzoekt welke datasets geschikt zijn. Via datapreparatie maak je deze gegevens bruikbaar.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#belangrijke-stappen","title":"Belangrijke stappen","text":"<p>Het proces van data onderzoeken en voorbereiden bestaat in elk geval uit deze stappen:</p> <ol> <li>vaststellen welke data geschikt en beschikbaar zijn</li> <li>onderzoeken hoe je deze data rechtmatig gebruikt</li> <li>verzamelen van de data</li> <li>opschonen van de data</li> <li>analyseren van de datakwaliteit</li> </ol> <p>Ontstaan er risico's door bijvoorbeeld bias in de dataset, missende data of niet-representatieve data, dan onderzoek je het effect op het ontwerp van je algoritme of AI-systeem. Mogelijk moet je het ontwerp aanpassen.</p> <p>Is je data van voldoende kwaliteit en ga je hier rechtmatig mee om, dan kun je het algoritme of AI-systeem (laten) ontwikkelen.</p> <p>Tip</p> <p>Vanaf deze fase blijf je de data analyseren, ook in alle volgende fases.</p>"},{"location":"levenscyclus/dataverkenning-en-datapreparatie/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/implementatie/","title":"Fase 6, implementatie","text":""},{"location":"levenscyclus/implementatie/#fase-6-implementatie","title":"Fase 6: Implementatie","text":"<p>In deze fase implementeer je het algoritme of AI-systeem in de organisatie. Vanaf dan kunnen medewerkers ermee werken. Meestal begin je met een pilot of test, voordat je het echt implementeert.</p>"},{"location":"levenscyclus/implementatie/#pilot-uitvoeren","title":"Pilot uitvoeren","text":"<p>Als je het algoritme of AI-systeem nog test voor implementatie, verwerk je tijdelijk data. Hiervoor moeten je ontwikkelteam en de groep gebruikers die testen goede afspraken maken, over het gebruik van het algoritme of AI-systeem tijdens de pilot.</p> <p>Tijdens de pilot test je de:</p> <ul> <li>prestaties van het algoritme of AI-systeem, door deze opnieuw te valideren</li> <li>output (resultaten): kunnen gebruikers hier bijvoorbeeld mee werken?</li> </ul> <p>Na de pilot concludeer je of het algoritme of AI-systeem presteert volgens de wensen en verwachtingen. En je besluit of het nodig is om terug te gaan naar het ontwikkelen, om te stoppen en uit te faseren of om verder te implementeren.</p>"},{"location":"levenscyclus/implementatie/#implementeren","title":"Implementeren","text":"<p>V\u00f3\u00f3r implementatie regel je in elk geval het volgende:</p> <ul> <li>Gebruikers begrijpen hoe zij de output (resultaten) moeten interpreteren.</li> <li>Gebruikers hebben toegang tot duidelijke werkinstructies.</li> <li>Voor het oplossen van vragen en incidenten heeft de organisatie een goede werkwijze.</li> <li>Het is duidelijk wie waarvoor verantwoordelijk is.</li> <li>De organisatie kent de restrisico\u2019s: risico\u2019s die overblijven nadat je maatregelen neemt.</li> <li>Betrokkenen zijn ge\u00efnformeerd. Dit is verplicht bij het in gebruik nemen van een impactvol algoritme of hoog-risico-AI-systeem.</li> </ul>"},{"location":"levenscyclus/implementatie/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/monitoring-en-beheer/","title":"Fase 7, monitoring en beheer","text":""},{"location":"levenscyclus/monitoring-en-beheer/#fase-7-monitoring-en-beheer","title":"Fase 7: Monitoring en beheer","text":"<p>In deze fase monitor en beheer je het algoritme of AI-systeem. Dit betekent dat je steeds controleert of het nog presteert zoals verwacht. En of gebruikers ermee kunnen werken. Presteert het algoritme of AI-systeem niet of minder goed, dan los je dit probleem op.</p>"},{"location":"levenscyclus/monitoring-en-beheer/#monitoren","title":"Monitoren","text":"<p>Tijdens het monitoren van het algoritme of AI-systeem let je in elk geval op de volgende punten:</p> <ul> <li>Technisch: Doet het nog waarvoor het is ontworpen? Oftewel: is het technisch robuust?</li> <li>Juridisch: Werkt het nog op een rechtmatige manier?</li> <li>Ethisch: Heeft het geen onverwacht nadelig effect op bepaalde mensen of de maatschappij?</li> <li>Zijn de omstandigheden nog hetzelfde waarin de organisatie het gebruikt? Data kan bijvoorbeeld veranderen. Of het werkproces zelf verandert door nieuw beleid of nieuwe wet- en regelgeving.</li> </ul> <p>Als blijkt dat het algoritme of AI-systeem niet meer goed functioneert, neem je passende maatregelen.</p>"},{"location":"levenscyclus/monitoring-en-beheer/#beheren","title":"Beheren","text":"<p>Het is nodig om het algoritme of AI-systeem te beheren om het in de lucht en goed werkend te houden. Het beheerteam zorgt ervoor dat het algoritme of AI-systeem altijd klaar is voor gebruik. Dit team:</p> <ul> <li>voorkomt storingen, zoals het wegvallen van data door wijzigingen in andere systemen</li> <li>lost problemen op, zoals meldingen van gebruikers</li> </ul>"},{"location":"levenscyclus/monitoring-en-beheer/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/ontwerp/","title":"Fase 2, ontwerp","text":""},{"location":"levenscyclus/ontwerp/#fase-2-ontwerp","title":"Fase 2: Ontwerp","text":"<p>In de ontwerpfase schets je ontwerpen voor het algoritme of AI-systeem. Elk ontwerp is een mogelijke oplossing voor het probleem en sluit aan bij de doelen van de opdrachtgever.</p>"},{"location":"levenscyclus/ontwerp/#taken-ontwerpfase","title":"Taken ontwerpfase","text":"<p>In deze fase verzet je meestal veel werk om duidelijk te krijgen wat voor oplossing past bij de doelen van de opdrachtgever. Belangrijke taken zijn:</p> <ul> <li>verwerken van beleid en belangrijke uitgangspunten van de opdrachtgever, zoals doelarchitectuur en datastrategie</li> <li>bestaande applicaties en databronnen op een rij zetten</li> <li>uitvoeren van een businessanalyse en informatieanalyse</li> </ul>"},{"location":"levenscyclus/ontwerp/#toetsen-en-verbeteren","title":"Toetsen en verbeteren","text":"<p>Ontwerpen laat je controleren door een multidisciplinair team. Dit zijn bijvoorbeeld medewerkers in de volgende rollen:</p> <ul> <li>proceseigenaar</li> <li>opdrachtgever</li> <li>gebruiker</li> <li>informatiebeveiligingsadviseur</li> <li>privacy-officer</li> <li>informatiebeheerder</li> <li>architect</li> <li>ethicus</li> </ul> <p>Dit soort experts kunnen vanuit hun vakgebied een eerste toets doen:</p> <ul> <li>Is het ontwerp haalbaar en gewenst?</li> <li>Sluit het ontwerp aan op de behoeftes van gebruikers?</li> <li>Aan welke eisen moet het ontwerp voldoen?</li> <li>Zijn er bepaalde risicoanalyses nodig?</li> <li>Zijn er onafhankelijke commissies nodig?</li> </ul> <p>Op basis van deze informatie verbeter je het ontwerp en werk je vraagstukken uit zoals algoritmegovernance en risicomanagement.</p>"},{"location":"levenscyclus/ontwerp/#maatregelen-bepalen","title":"Maatregelen bepalen","text":"<p>In de ontwerpfase kun je ook starten met het:</p> <ul> <li>vertalen van vereisten naar concrete maatregelen</li> <li>structureren van deze maatregelen</li> <li>aanwijzen van experts die verantwoordelijk zijn voor deze maatregelen</li> </ul> <p>Tip</p> <p>Maatregelen voor het veilig verwerken van persoonsgegevens neem je tijdens de ontwerpfase. Daarna ben je te laat.</p>"},{"location":"levenscyclus/ontwerp/#succesfactoren-bepalen","title":"Succesfactoren bepalen","text":"<p>Besteed aandacht aan de succesfactoren van het algoritme of AI-systeem. Bepaal in elk geval met een multidisciplinair team:</p> <ul> <li>hoe je het algoritme of AI-systeem evalueert</li> <li>met welke methoden je nagaat of het voldoet aan alle vereisten zoals non-discriminatie</li> <li>wat een 'rechtvaardig succes' is</li> </ul>"},{"location":"levenscyclus/ontwerp/#definitief-ontwerp","title":"Definitief ontwerp","text":"<p>Uiteindelijk concludeer je welk type algoritme of AI-systeem passend is. En hoe dit zou moeten werken. Hiervoor vraag je akkoord van de opdrachtgever of (gemandateerd) verantwoordelijke. Heeft het ontwerp nog aanpassingen nodig, dan doorloop je opnieuw de fase van probleemanalyse.</p> <p>Kiest de organisatie een definitief ontwerp, dan ga je verder met dataverkenning en datapreparatie.</p> <p>Tip</p> <p>Denk alvast na over welke versie of versies van het algoritme of AI-systeem je wil archiveren. Door aanpassingen in de data of rekenregels, of door het opnieuw trainen met nieuwe data, kan een algoritme of AI-systeem namelijk veranderen. Als je hier nu al aandacht aan besteed, bespaar je achteraf bij het uitfaseren een hoop uitzoekwerk.</p>"},{"location":"levenscyclus/ontwerp/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/ontwikkelen/","title":"Fase 4, ontwikkelen","text":""},{"location":"levenscyclus/ontwikkelen/#fase-4-ontwikkelen","title":"Fase 4: Ontwikkelen","text":"<p>In de ontwikkelfase bouw je het algoritme of AI-systeem samen met  een multidisciplinair team. Gaat het om rekenregels, dan implementeer je deze in een ontwikkelomgeving of systeem. Gaat het om een AI-systeem, dan train je het model met de juiste datasets.</p>"},{"location":"levenscyclus/ontwikkelen/#taken-ontwikkelfase","title":"Taken ontwikkelfase","text":"<p>De belangrijkste taken in deze fase zijn:</p> <ul> <li>ontwikkelen van het algoritme of AI-systeem, inclusief modellen trainen met goed voorbereide data</li> <li>documenteren van technische informatie en belangrijke keuzes</li> <li>controleren van de uitkomst en werking van het algoritme of AI-systeem</li> <li>beveiligen van het informatiesysteem</li> <li>maatregelen nemen voor bijvoorbeeld het verantwoord ontsluiten van output naar gebruikers, het automatisch genereren van logs en het inrichten van service- en incidentmanagementprocedures</li> </ul>"},{"location":"levenscyclus/ontwikkelen/#rollen-en-verantwoordelijkheden","title":"Rollen en verantwoordelijkheden","text":"<p>Alleen een multidisciplinair team kan algoritmes en AI-systemen technisch correct ontwikkelen en de beperkingen ervan begrijpen. Zo\u2019n team bestaat uit medewerkers in verschillende rollen, zoals een:</p> <ul> <li>proceseigenaar</li> <li>domeinspecialist</li> <li>beleidsmedewerker</li> <li>data-scientist</li> <li>data-engineer</li> <li>privacy-jurist</li> <li>ethicus</li> </ul> <p>Hoe goed een algoritme of AI-systeem werkt, leid je vooral af uit de rekenregels van het algoritme en de inputvariabelen van het machinelearning-model. Goede rekenregels en inputvariabelen zijn:</p> <ul> <li>juridisch toegestaan</li> <li>ethisch wenselijk</li> <li>technisch gezien voldoende significant</li> <li>zinvol voor gebruikers</li> </ul> <p>Het multidisciplinaire team beoordeelt dit en stuurt steeds bij. Zo ontwikkel je samen een verantwoord algoritme of AI-systeem dat past bij het afgesproken doel.</p>"},{"location":"levenscyclus/ontwikkelen/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/organisatieverantwoordelijkheden/","title":"Fase 0, organisatieverantwoordelijkheden","text":""},{"location":"levenscyclus/organisatieverantwoordelijkheden/#fase-0-organisatieverantwoordelijkheden","title":"Fase 0: Organisatieverantwoordelijkheden","text":"<p>In deze fase bereid je de organisatie voor op het verantwoord ontwikkelen en gebruiken van algoritmen en AI. Een deel van deze verantwoordelijkheden regel je liefst voordat je van start gaat.</p>"},{"location":"levenscyclus/organisatieverantwoordelijkheden/#belangrijkste-taken-fase-0","title":"Belangrijkste taken fase 0","text":"<p>Als organisatie die algoritmes ontwikkelt of gebruikt, heb je veel verantwoordelijkheden. Je moet voldoen aan allerlei vereisten. En hiervoor moet je passende maatregelen nemen. Een deel van deze verantwoordelijkheden regel je het beste vooraf. Dit zijn de vereisten en maatregelen die gelden voor alle algoritmes, op elk moment van de levenscyclus:</p> <ul> <li>zaken die je liefst regelt voordat je begint met het gebruik van algoritmes</li> <li>dagelijkse taken die je vooraf in 1 keer organiseert voor alle algoritmes</li> </ul>"},{"location":"levenscyclus/organisatieverantwoordelijkheden/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/over-de-levenscyclus/","title":"Over de levenscyclus","text":""},{"location":"levenscyclus/over-de-levenscyclus/#over-de-levenscyclus","title":"Over de levenscyclus","text":"<p>Om algoritmes op een verantwoorde manier te gebruiken, zul je op de juiste momenten aandacht moeten hebben voor de juiste onderwerpen en risico's. Van het ontwikkelen van een oplossing, tot het in gebruik nemen van die oplossing en er uiteindelijk weer mee stoppen. Door al in een vroeg stadium aandacht besteden aan bijvoorbeeld een eventuele inbreuk op mensenrechten kan je hier gedurende het hele proces al rekening mee houden. De levenscyclus helpt je om te bepalen wat je wanneer moet doen.</p> <pre><code>  flowchart TD\n      subgraph organisatieniveau [organisatieniveau &amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp]\n        0(0. Organisatieverantwoordelijkheden) --&gt; 1(1. Probleemanalyse);\n        subgraph systeemniveau [systeemniveau &amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp&amp;nbsp]\n          7(7. Monitoring en beheer) --&gt; 1(1. Probleemanalyse);\n          1(1. Probleemanalyse) --&gt; 2(2. Ontwerp);\n          2(2. Ontwerp) --&gt; 3(3. Dataverkenning en datapreparatie);\n          3(3. Dataverkenning en datapreparatie) --&gt; 4(4. Ontwikkelen);\n          4(4. Ontwikkelen) --&gt; 5(5. Verificatie en validatie);\n          5(5. Verificatie en validatie) --&gt; 6(6. Implementatie);\n          6(6. Implementatie) --&gt; 7(7. Monitoring en beheer);\n          7(7. Monitoring en beheer) -.-&gt; 8(8. Uitfaseren);\n        end\n      end\n      click 0 href \"../organisatieverantwoordelijkheden\"\n      click 1 href \"../probleemanalyse\"\n      click 2 href \"../ontwerp\"\n      click 3 href \"../dataverkenning-en-datapreparatie\"\n      click 4 href \"../ontwikkelen\"\n      click 5 href \"../verificatie-en-validatie\"\n      click 6 href \"../implementatie\"\n      click 7 href \"../monitoring-en-beheer\"\n      click 8 href \"../uitfaseren\"\n      style 0 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 1 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 2 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 3 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 4 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 5 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 6 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 7 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style 8 color:#fff, fill:#1975d2, stroke:#1975d2, text-decoration:underline;\n      style organisatieniveau fill:transparent</code></pre> <p>Tip</p> <p>In de praktijk herhaal je soms fases of ga je terug naar een eerdere fase. Mislukt bijvoorbeeld het valideren (fase 5), dan moet je terug naar de ontwerpfase (fase 2) omdat het product nog niet voldoet aan de wensen of vereisten.</p>"},{"location":"levenscyclus/over-de-levenscyclus/#fases-van-de-levenscyclus","title":"Fases van de levenscyclus","text":"<ol> <li>Organisatieverantwoordelijkheden</li> <li>Probleemanalyse</li> <li>Ontwerp</li> <li>Dataverkenning en datapreparatie</li> <li>Ontwikkelen</li> <li>Verificatie en validatie</li> <li>Implementeren</li> <li>Monitoring en beheer</li> <li>Uitfaseren</li> </ol>"},{"location":"levenscyclus/over-de-levenscyclus/#systeemniveau-en-organisatieniveau","title":"Systeemniveau en organisatieniveau","text":"<p>De levenscyclus kent 2 verschillende niveau's:</p> <ul> <li>organisatieniveau (proces): Sommige vereisten zijn algemeen en vragen om een organisatiebrede aanpak. Dit gaat bijvoorbeeld om passende processen en risicomanagment in je organisatie. Of het cre\u00ebren van bewustzijn en kennis binnen je organisatie. In het ideale geval besteed je hier al aandacht aan voordat je begint met de ontwikkeling of het gebruik van algoritmes. Bij deze fase horen maatregelen die je niet voor ieder systeem opnieuw zal hoeven te bekijken.</li> <li>systeemniveau (toepassing): Sommige vereisten voor verantwoorde inzet van algoritmes zul je bij ieder algoritme weer opnieuw aandacht moeten geven. Dat geldt bijvoorbeeld voor het beschermen van grondrechten.</li> </ul>"},{"location":"levenscyclus/over-de-levenscyclus/#andere-levenscyclusmodellen","title":"Andere levenscyclusmodellen","text":"<p>De 9 fasen van de levenscyclus zijn gebaseerd op 10 belangrijke levenscyclusmodellen voor het ontwikkelen van AI, zoals:</p> <ul> <li>CRISP-DM (cross-industry standard process for data mining)</li> <li>ASUM-DM (analytics solutions unified method)</li> <li>SEMMA (Sample, Explore, Modify, Model, and Assess)</li> <li>Microsoft TDSP (Team Data Science Process)</li> <li>MDLM (mobile device lifecycle management)</li> <li>NIST (National Institute of Standards and Technology)</li> <li>ISO/IEC 22989</li> </ul> <p>Deze 9 fasen passen zo goed mogelijk bij de manier van werken van overheden. Het is geen verplicht model. Mogelijk past een ander levenscyclusmodel beter bij jouw organisatie.</p>"},{"location":"levenscyclus/over-de-levenscyclus/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/probleemanalyse/","title":"Fase 1, probleemanalyse","text":""},{"location":"levenscyclus/probleemanalyse/#fase-1-probleemanalyse","title":"Fase 1: Probleemanalyse","text":"<p>In deze fase maak je een analyse van het probleem en de doelstellingen van de opdrachtgever. En je onderzoekt of een algoritme of AI-systeem een geschikte oplossing is.</p>"},{"location":"levenscyclus/probleemanalyse/#aanpak-probleemanalyse","title":"Aanpak probleemanalyse","text":"<p>Eerst onderzoek je het doel en het probleem van de opdrachtgever, bijvoorbeeld:</p> <ul> <li>welke publieke taak het algoritme of AI-systeem moet ondersteunen</li> <li>welke publieke waarden je daarbij moet beschermen of bereiken</li> </ul> <p>Daarna onderzoek je of een algoritme of AI-systeem een geschikte manier is om het doel van de opdrachtgever te bereiken en het probleem op te lossen. Dit hangt van af van bijvoorbeeld: * kosten van het verantwoord ontwikkelen van algoritmes en AI * aantal medewerkers dat nodig is voor het verantwoord ontwikkelen van algoritmes en AI * complexiteit van de oplossing * verwachte risico's * soort data dat nodig is * wie welke verantwoordelijkheid krijgt * beleid van de opdrachtgever over het gebruik van algoritmes en AI</p> <p>Uiteindelijk concludeer je of het ontwikkelen of inkopen van een algoritme of AI-systeem wel of niet passend is. Meestal vraag je hiervoor akkoord van de opdrachtgever of de (gemandateerd) verantwoordelijke. Kiest de opdrachtgever voor het ontwikkelen van een algoritme of AI-systeem, dan ga je verder met het ontwerp.</p>"},{"location":"levenscyclus/probleemanalyse/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/uitfaseren/","title":"Fase 8, uitfaseren","text":""},{"location":"levenscyclus/uitfaseren/#fase-8-uitfaseren","title":"Fase 8: Uitfaseren","text":"<p>In deze fase stop je met het algoritme of AI-systeem. Dit proces heet uitfaseren. Je verwijdert het algoritme of AI-systeem en alle trainingsdata. En je archiveert belangrijke informatie.</p>"},{"location":"levenscyclus/uitfaseren/#stoppen-met-algoritmes-of-ai","title":"Stoppen met algoritmes of AI","text":"<p>Je start met uitfaseren wanneer je besluit om te stoppen met een algoritme of AI-systeem. Redenen zijn bijvoorbeeld:</p> <ul> <li>Je bent ontevreden over de werking.</li> <li>Het algoritme of AI-systeem is niet langer nodig.</li> <li>Je vervangt het door een totaal andere of nieuwe versie.</li> </ul> <p>Tijdens de uitfaseerfase zorg je ervoor dat gebruikers het algoritme of AI-systeem niet meer kunnen gebruiken. En je zorgt ervoor dat de organisatie de werking kan reconstrueren. Dit doe je in 4 stappen:</p> <ol> <li>Informeer gebruikers dat het algoritme of AI-systeem wordt uitgefaseerd. Bij sommige gevoelige impactvolle algoritmes en hoog-risico-AI-systemen kan het ook nuttig zijn om andere betrokkenen te informeren.</li> <li>Archiveer belangrijke informatie.</li> <li>Verwijder het algoritme of AI-systeem uit de productieomgeving.</li> <li>Verwijder de trainingsdata uit de ontwikkelomgeving.</li> </ol>"},{"location":"levenscyclus/uitfaseren/#archiveren","title":"Archiveren","text":"<p>Archiveren zorgt ervoor dat je later terug kunt vinden hoe het algoritme werkte en waar het voor werd gebruikt. Je volgt de Archiefwet en bewaart belangrijke stukken voor een bepaalde periode:</p> <ul> <li>informatie \u00f3ver het algoritme of AI-systeem, zoals stukken over de doelstelling en ontwikkeling en het besluit om te gaan uitfaseren</li> <li>gegevens (artefacten) die de werking van het algoritme of AI-systeem beschrijven, zoals logbestanden en parameters</li> </ul> <p>Let erop dat de werking van je algoritme of AI-systeem kan veranderen door aanpassingen in de data of rekenregels, of door het opnieuw trainen met nieuwe data. Geef daarom duidelijk aan welke versie je archiveert. Tijdens de ontwerpfase heb je hier als het goed is al aandacht aan besteed.</p>"},{"location":"levenscyclus/uitfaseren/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"levenscyclus/verificatie-en-validatie/","title":"Fase 5, verificatie en validatie","text":""},{"location":"levenscyclus/verificatie-en-validatie/#fase-5-verificatie-en-validatie","title":"Fase 5: Verificatie en validatie","text":"<p>In deze fase beoordeel en verbeter je het algoritme of AI-systeem. Je start een verificatieproces waarin je alle specificaties controleert. En je start een validatieproces waarin je de afgesproken doelen naloopt. Je neemt maatregelen als dat nodig is.</p>"},{"location":"levenscyclus/verificatie-en-validatie/#taken-verificatie","title":"Taken verificatie","text":"<p>Tijdens het verificatieproces controleer je of het algoritme of AI-systeem voldoet aan alle specificaties. Hiermee stel je vast of alle eigenschappen uit de ontwerpfase daadwerkelijk technisch worden bereikt.</p> <p>Zo\u2019n controle voer je bijvoorbeeld uit via een:</p> <ul> <li>interne audit</li> <li>externe audit</li> <li>conformiteitsbeoordeling voor hoog risico-AI-systemen</li> </ul> <p>Misschien moet je maatregelen nemen op basis van de conclusies.</p>"},{"location":"levenscyclus/verificatie-en-validatie/#taken-validatie","title":"Taken validatie","text":"<p>Tijdens het validatieproces bepaalt een multidisciplinair team of het algoritme of AI-systeem:</p> <ul> <li>goed genoeg presteert</li> <li>geschikt is voor het doel van het systeem</li> </ul> <p>Hiervoor gebruik je nieuwe data, die het systeem nog niet kent.</p> <p>Het multidisciplinaire team evalueert de nauwkeurigheid en prestaties van het algoritme of AI-systeem steeds opnieuw:</p> <ul> <li>Presteert het gelijk voor verschillende groepen? Of maakt het een ongewenst onderscheid?</li> <li>Presteert het ook goed bij uitzonderlijke gevallen en in abnormale situaties?</li> </ul> <p>Bij verificatie kan worden gedacht aan het (laten) controleren of het algoritme voldoet aan de (technische) specificaties, validiteit en betrouwbaarheid, bijvoorbeeld door een interne of externe audit of in de toekomst een conformiteitsbeoordeling voor hoog risico AI-systemen. Hiermee kan (onafhankelijk) worden vastgesteld of het systeem voldoet aan de vereisten die organisaties daaraan stellen. Op basis van bevindingen uit een audit of conformiteitsbeoordeling, is het denkbaar dat het ontwikkelteam nog bepaalde maatregelen moet treffen om te voldoen aan de specificaties.</p> <p>Blijkt het model niet goed of ongeschikt, dan doorloop je opnieuw de ontwikkelfase om de prestaties te verbeteren. Of je stopt ermee en gaat het model uitfaseren.</p> <p>Presteert het model volgens verwachting, dan kun je het gaan implementeren.</p>"},{"location":"levenscyclus/verificatie-en-validatie/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/","title":"Onderwerpen","text":""},{"location":"onderwerpen/#onderwerpen","title":"Onderwerpen","text":""},{"location":"onderwerpen/#discriminerende-effecten-en-ander-ongewenst-onderscheid-door-algoritmes","title":"Discriminerende effecten en ander ongewenst onderscheid door algoritmes","text":"<p>Hulp bij het voorkomen van ongewenst onderscheid, bias en discriminatie bij het gebruik van algoritmes. Met aanbevelingen en hulpmiddelen zoals het toetsingskader van het College voor de Rechten van de Mens.</p>"},{"location":"onderwerpen/#verantwoord-datagebruik","title":"Verantwoord datagebruik","text":"<p>Hulp bij het verantwoord selecteren en verwerken van data voor je algoritmes. Gebruik bijvoorbeeld de toolbox verantwoord datagebruik.</p>"},{"location":"onderwerpen/#duurzaam-werken-met-algoritmes","title":"Duurzaam werken met algoritmes","text":"<p>Hulp bij het maken van duurzame keuzes voor hardware en software. Bijvoorbeeld voor de aanschaf van apparaten of het energieverbruik van trainen en data-opslag.</p>"},{"location":"onderwerpen/#governance-van-algoritmes-binnen-je-organisatie","title":"Governance van algoritmes binnen je organisatie","text":"<p>Hulp bij het verantwoordelijk omgaan met algoritmes. Bijvoorbeeld het vastleggen van rollen en verantwoordelijkheden.</p>"},{"location":"onderwerpen/#grondrechten-beschermen-in-algoritmes","title":"Grondrechten beschermen in algoritmes","text":"<p>Hulp bij het beschermen van grondrechten en mensenrechten in algoritmes. Bijvoorbeeld het beoordelen van de gevolgen per grondrecht.</p>"},{"location":"onderwerpen/#menselijke-controle-over-algoritmes","title":"Menselijke controle over algoritmes","text":"<p>Hulp bij de controle als mens over algoritmes. Bijvoorbeeld kunnen ingrijpen bij onbetrouwbare resultaten.</p>"},{"location":"onderwerpen/#privacy-en-persoonsgegevens-beschermen-in-algoritmes","title":"Privacy en persoonsgegevens beschermen in algoritmes","text":"<p>Hulp bij verantwoord gebruik van gegevens voor algoritmes, zoals persoonsgegevens en privacygevoelige gegevens.</p>"},{"location":"onderwerpen/#publieke-inkoop-van-verantwoorde-algoritmes","title":"Publieke inkoop van verantwoorde algoritmes","text":"<p>Hulp bij het publiek inkopen van software met algoritmen en AI. Met hulpmiddelen zoals modelcontracten en de PIANOo-handreiking Inkoop van algoritmes.</p>"},{"location":"onderwerpen/#technische-robuustheid-en-veiligheid","title":"Technische robuustheid en veiligheid","text":"<p>Hulp bij het bewaken van de prestaties van algoritmes. En beveiliging van de systemen tegen bijvoorbeeld cyberaanvallen.</p>"},{"location":"onderwerpen/#transparant-zijn-over-algoritmes","title":"Transparant zijn over algoritmes","text":"<p>Hulp bij transparant zijn over algoritmes, zoals gebruikers informeren en publiceren in het algoritmeregister.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/","title":"Discriminerende effecten en ander ongewenst onderscheid bij het gebruik van algoritmes","text":""},{"location":"onderwerpen/bias-en-non-discriminatie/#discriminerende-effecten-en-ander-ongewenst-onderscheid-bij-het-gebruik-van-algoritmes","title":"Discriminerende effecten en ander ongewenst onderscheid bij het gebruik van algoritmes","text":"<p>Wie algoritmes ontwikkelt of gebruikt, moet ongewenst onderscheid en eventuele discriminerende effecten hiervan voorkomen. Want met algoritmes kun je makkelijk discrimineren, ook al is dat niet de bedoeling. Let daarom steeds op \u2018bias\u2019. Dit zijn vooroordelen of fouten in je algoritme of aanpak.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#wat-is-ongewenst-onderscheid","title":"Wat is ongewenst onderscheid?","text":"<p>Algoritmes kunnen leiden tot ongewenst onderscheid als je mensen of (andere) groepen ongelijk behandelt in gelijke situaties.</p> <p>Een camera met gezichtsherkenning herkent bijvoorbeeld geen vrouwen van kleur. Of een computerprogramma selecteert vooral mensen met een laag inkomen als risicogroep voor fraude.</p> <p>Dit onderscheid kan op twee manieren ontstaan:</p> <ul> <li>Direct onderscheid: Het algoritme gebruikt een discriminatiegrond als variabele, zoals geloof, politieke voorkeur, ras, nationaliteit, geslacht, handicap, burgerlijke staat, vermogen of leeftijd.</li> <li>Indirect onderscheid: Het algoritme lijkt neutraal of eerlijk. Maar later blijkt dat bepaalde mensen op een andere manier worden behandeld door hun geloof, politieke of seksuele voorkeur, ras, geslacht, of burgerlijke staat.</li> </ul> <p>Direct en indirect onderscheid is in veel gevallen niet toegestaan. Ongewenst onderscheid kan leiden tot discrimerende effecten van een algoritme.</p> <p>Tip</p> <p>Maakt je algoritme een ongewenst onderscheid of is er sprake van discrimerende effecten van je algoritme? Dan moet je zo snel mogelijk stoppen met het algoritme. Gebruik bijvoorbeeld het discriminatieprotocol van het ministerie van Binnenlandse Zaken en Koninkrijksrelaties.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#uitzondering","title":"Uitzondering","text":"<p>Een direct of indirect onderscheid is niet altijd verboden volgens Artikel 2 Algemene wet gelijke behandeling. In bepaalde situaties en onder bepaalde strenge voorwaarden mag je zo\u2019n onderscheid wel maken.</p> <p>Direct onderscheid maken mag bijvoorbeeld als hiervoor een uitzondering staat in de wet. Zo mag je in situaties waar het gaat om moederschap of zwangerschap onderscheid maken op basis van geslacht.</p> <p>Indirect onderscheid maken mag niet, tenzij hiervoor een wettelijke uitzondering geldt. Of je hebt een goede reden (objectieve rechtvaardiging). Selecteert je algoritme bijvoorbeeld alleen vrouwen voor een vacature, dan moet je hier een objectieve rechtvaardiging voor hebben. En het algoritme moet passend en noodzakelijk zijn om een doel te bereiken dat wettelijk is toegestaan. Anders is het discriminatie.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#belang-van-discriminerende-effecten-voorkomen","title":"Belang van discriminerende effecten voorkomen","text":"<p>Discriminatie is verboden volgens Artikel 1 van de Nederlandse Grondwet. En algoritmes kunnen snel een discriminerend effect hebben op grote groepen mensen. Vooral impactvolle algoritmes kunnen veel schade veroorzaken in de maatschappij door discriminatie.</p> <p>Het is erg moeilijk om discriminerende effecten te voorkomen. Discriminatiegronden weglaten als variabele in je algoritme is niet genoeg. Want discriminatie ontstaat ook indirect, door bias.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#profilering","title":"Profilering","text":"<p>Veel organisaties gebruiken risicoprofilering als hulpmiddel om regels te handhaven. Dit gebruik van risicoprofilering kan leiden tot discriminerende effecten. Het gebruik van risicoprofilering vraagt om een zorgvuldige aanpak om nadelige effecten te voorkomen. Om organisaties hier mee te helpen, heeft het College voor de Rechten van de Mens een gedetailleerd toetsingskader voor risicoprofilering ontwikkeld om discriminatie op grond van ras en nationaliteit te voorkomen. Daarnaast kun je gebruik maken van de Publieke standaard profileringsalgoritmes, gepubliceerd door Algorithm Audit.</p> <p>Tip</p> <p>Meer weten over dit onderwerp? Of wil je dat collega's meer weten over dit onderwerp? Volg de e-learning non-discriminatie in algoritmes en data, ontwikkeld door het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#herken-bias","title":"Herken bias","text":"<p>Bias herkennen is een belangrijke stap in het voorkomen van discriminerende effecten van algoritmes.</p> <p>'Bias' is een Engels woord voor vooroordeel of vooringenomenheid. Algoritmes met een bias maken steeds een bepaald soort fout. Volgens de norm ISO/IEC TR 24027 bevat een algoritme bias wanneer het bepaalde mensen, groepen of producten steeds (systematisch) op een verschillende manier behandelt. Dit verhoogt de kans op discriminatie.</p> <p>Alle algoritmes hebben vooroordelen en maken fouten, net als de mens. Wil je dit aanpakken, zoek dan naar bias in het algoritme zelf en in de mensen en processen om het algoritme heen. Een bias-vrij algoritme is niet mogelijk.</p> <p>Bias ontstaat bijvoorbeeld in:</p> <ul> <li>statistiek en berekeningen (statistische bias)</li> <li>systemen en processen in bijvoorbeeld de samenleving of je organisatie (systemische bias)</li> <li>het menselijk denken (menselijke bias)</li> </ul>"},{"location":"onderwerpen/bias-en-non-discriminatie/#bias-in-statistiek-en-berekeningen","title":"Bias in statistiek en berekeningen","text":"<p>Dit zijn fouten in de:</p> <ul> <li>kwaliteit van de data</li> <li>manier waarop algoritmes data verwerken</li> </ul> <p>Voorbeelden:</p> Meet-bias (measurement bias) <p>Je algoritme maakt een verkeerde schatting of benadering van kenmerken of labels. Dit komt doordat het de ene variabele gebruikt om een andere variabele te voorspellen of te benaderen (proxy). En hierbij laat het belangrijke informatie weg, of het voegt onbelangrijke informatie (ruis) toe.</p> <p>Een algoritme maakt bijvoorbeeld een verkeerde schatting van het risico op overlijden aan longontsteking in het ziekenhuis. Het algoritme leert namelijk uit de data dat dit risico lager is voor astmapati\u00ebnten. Maar dit komt niet door hun astma. Het algoritme laat weg dat astmapati\u00ebnten met longontsteking direct naar de intensive care gaan. En mensen zonder astma niet.</p> Versterkingsbias (amplification bias) <p>Je algoritme versterkt een patroon uit de trainingsdata.</p> <p>Een algoritme dat mensen en hun acties herkent, voorspelt bijvoorbeeld 5 keer zo vaak de combinatie \u2018vrouw\u2019 en \u2018koken\u2019. Terwijl deze combinatie in de trainingsdata maar 2 keer zo vaak voorkomt.</p> Evaluatie-bias (evaluation bias) <p>Je algoritme trekt verkeerde conclusies omdat de evaluatiedata niet kloppen, of niet compleet zijn.</p> <p>Een algoritme voor gezichtsherkenning herkent bijvoorbeeld vrouwen van kleur niet goed, omdat deze vrouwen te weinig voorkomen in de dataset voor evaluatie.</p> Representatie-bias (representation bias) <p>Je algoritme doet voorspellingen over een grote groep, op basis van resultaten uit subgroepen met te weinig verschillende proefpersonen.</p> <p>Een algoritme beoordeelt bijvoorbeeld de populariteit van treinstations onder reizigers op basis van hun smartphone-gebruik. Maar deze groep is niet representatief, omdat oudere reizigers vaak minder gebruik maken van smartphones.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#bias-in-systemen-en-processen","title":"Bias in systemen en processen","text":"<p>Dit is vooringenomenheid die vaak in de loop der tijd is ontstaan in de samenleving of je organisatie. Deze vooringenomenheid werkt door in processen of systemen, of wordt soms versterkt door algoritmes. Dit gebeurt vaak niet bewust.</p> <p>Systemische bias heet ook wel: institutionele vooringenomenheid. Dit betekent dat vooroordelen vaak horen bij de cultuur en samenleving. Die vooroordelen zitten daardoor ook in veel datasets, en kunnen zo versterkt worden door je algoritme.</p> <p>Voorbeelden:</p> Historische bias <p>Je algoritme heeft vooroordelen die in de loop der tijd ontstonden in de samenleving.</p> <p>Een algoritme gebruikt bijvoorbeeld data die gebaseerd is op oude belastingregels, terwijl er nieuwe wetten en regels zijn. Dan zit er een historische bias in je data. Of een algoritme voorspelt bijvoorbeeld de koopkracht van mensen, maar gebruikt hiervoor data uit een tijd waarin mannen meer verdienden dan vrouwen.</p> Activiteitenbias (activity bias) <p>Je algoritme geeft een verkeerd beeld over gebruikers van interactieve producten, zoals websites of apps. Dit komt omdat alleen de meest actieve gebruikers trainingsdata aanleveren.</p> <p>Een algoritme onderzoekt bijvoorbeeld wat burgers van een bepaalde brief vinden op basis van kliks in een digitale vragenlijst. Het algoritme kan niet zeggen wat burgers \u00e9cht vinden, omdat de meest actieve internetgebruikers vaker klikken en vaker de vragenlijst invullen.</p> Samenlevingsbias (societal bias) <p>Je algoritme maakt een fout op basis van stereotypes die voorkomen in de samenleving. Dit gebeurt vooral in AI-systemen die taal verwerken via Natural Language Processing (NLP).</p> <p>Een algoritme dat teksten maakt, geeft bijvoorbeeld \u2018verpleegster\u2019 als vrouwelijke vorm van \u2018dokter\u2019. Dit komt omdat het stereotype dokter in die samenleving een man is.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#bias-in-menselijk-denken","title":"Bias in menselijk denken","text":"<p>Dit zijn vooroordelen in het menselijk denken die steeds (systematisch) invloed hebben op de manier waarop iemand iets ziet, hoort, ruikt, proeft of voelt.</p> <p>Menselijke bias kan invloed hebben op de:</p> <ul> <li>verzamelde data</li> <li>manier waarop je het algoritme optimaliseert</li> <li>besluiten die je neemt op basis van het algoritme</li> </ul> <p>Voorbeelden:</p> Automatiseringsbias <p>Mensen maken een denkfout omdat zij de voorkeur geven aan adviezen van automatische besluitvormingssystemen. Zelfs als uit andere informatie blijkt dat deze adviezen niet kloppen.</p> <p>Wanneer behandelaren handmatig controleren of een uitkering van een burger klopt, hebben zij vaak de neiging om de beslissing te volgen van het algoritme.</p> Cognitieve bias <p>Mensen maken een denkfout omdat zij volgens een vast patroon afwijken van logisch nadenken. Vaak gebeurt dit om complexe denktaken te versimpelen of versnellen.</p> <p>Administratief medewerkers weigeren bijvoorbeeld een AI-systeem te gebruiken, omdat ze slechte ervaringen hebben met een ander AI-systeem. Zij willen het nieuwe AI-systeem dus niet gebruiken, terwijl ze dit nooit gebruikt hebben.</p> Bevestigingsbias <p>Mensen maken een denkfout omdat zij de voorkeur geven aan voorspellingen van algoritmes die hun eigen overtuigingen of gedachtes bevestigen.</p> <p>Rechercheurs zoeken bijvoorbeeld direct naar bewijs om verdachte X te veroordelen, nadat een algoritme X voorspelt als dader. Terwijl de rechercheurs ook ander bewijs moeten zoeken.</p> Implementatie-bias <p>Een algoritme wordt op een andere manier gebruikt dan hoe het bedoeld is en waarvoor het ontwikkeld is. Dit komt vaak voor wanneer een algoritme wordt gebruikt als beslishulp voor mensen. Deze vorm van bias is een menselijke denkfout in de vorm dat gebruikers niet op dezelfde of goede manier omgaan met adviezen.</p> <p>Een wet over bijvoorbeeld immigratie wordt ingevoerd en er wordt een algoritme ontwikkeld om te onderzoeken wat de gevolgen hiervan zijn. Dit algoritme is dan ook bedoeld om voor bepaalde groepen mensen te kijken wat de gevolgen zijn. Het algoritme wordt ook gebruikt bij het toekennen van staatsburgerschap aan de hand van de gevolgen. Dit is niet zoals het systeem bedoeld is en dus kunnen er incomplete antwoorden of resultaten uitkomen.</p> Overlevingsbias (survivorship bias) <p>Mensen hebben de neiging om voorkeur te geven aan dingen, mensen of observaties die door een bepaalde selectie zijn gekomen. Naar de gevallen die buiten de selecties vallen wordt vaak niet of minder gekeken. Dit kan leiden tot een zichzelf versterkend proces.  Zo worden bijvoorbeeld modellen die werken verbeterd, maar wordt niet gekeken waarom de andere modellen niet werken.</p> <p>Om fraudeherkenning te vergemakkelijken wordt bijvoorbeeld een model getraind op data van personen/huishoudens die eerder zijn gecontroleerd op mogelijke fraude. Hiermee wordt een groot gedeelte personen/huishoudens niet meegenomen in de trainingsdata, omdat deze groep niet eerder gecontroleerd is.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#let-altijd-op-discriminerende-effecten","title":"Let altijd op discriminerende effecten","text":"<p>Het risico op bias en discriminatie blijft altijd bestaan. Je kunt dit niet in 1 keer wegnemen.</p> <p>Houd daarom rekening met bias tijdens het ontwikkelen, inkopen en gebruiken van algoritmes. En controleer voortdurend of je algoritmes en je aanpak nog eerlijk en rechtvaardig zijn. Let hierop in alle fasen van de levenscyclus van het algoritme.</p>"},{"location":"onderwerpen/bias-en-non-discriminatie/#aanbevolen-hulpmiddelen","title":"Aanbevolen hulpmiddelen","text":"HulpmiddelenThe Fairness HandbookHandreiking non-discriminatie by designStandaardenToetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit"},{"location":"onderwerpen/bias-en-non-discriminatie/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/data/","title":"Verantwoord datagebruik","text":""},{"location":"onderwerpen/data/#verantwoord-datagebruik","title":"Verantwoord datagebruik","text":"<p>Overheden moeten verantwoord omgaan met de data die hun algoritmes gebruiken. De data moet voldoen aan regels voor bijvoorbeeld privacy. De kwaliteit van de data moet goed zijn. En overheden moeten deze gegevens goed beheren. Zo wordt het algoritme:</p> <ul> <li>Betrouwbaar (zijn de resultaten die het algoritme geeft onder dezelfde omstandigheden hetzelfde?)</li> <li>Valide (doet het algoritme wat het beoogt te doen?)</li> </ul>"},{"location":"onderwerpen/data/#wat-is-verantwoord-datagebruik","title":"Wat is verantwoord datagebruik?","text":"<p>Verantwoord datagebruik betekent:</p> <ul> <li>Rechtmatig gebruik van gegevens</li> <li>Goede datakwaliteit</li> <li>Goed databeheer</li> </ul>"},{"location":"onderwerpen/data/#rechtmatig-gebruik-van-data","title":"Rechtmatig gebruik van data","text":"<p>Net als organisaties mogen algoritmes niet zomaar gegevens verzamelen en gebruiken. Dit moet rechtmatig gebeuren: volgens de wettelijke regels. Zo moet je rekening houden met auteursrechten. Ook v\u00f3\u00f3rdat het algoritme in gebruik is, moet je rechtmatig omgaan met data. Dus tijdens het trainen, valideren en testen.</p> <p>Andere belangrijke regels gaan over privacy. Zo mag je algoritme alleen de minimale persoonsgegevens gebruiken die nodig zijn om het doel te bereiken. Technieken om dit te doen zijn:</p> <ul> <li>Anonimiseren: data zoveel mogelijk anoniem maken</li> <li>Pseudonimiseren: data moeilijker herleidbaar maken (meestal in geval van persoonsgegevens)</li> <li>Aggregeren: data zoveel mogelijk combineren of samenvoegen tot 1 waarde, zoals een totaal of gemiddelde</li> </ul>"},{"location":"onderwerpen/data/#goede-datakwaliteit","title":"Goede datakwaliteit","text":"<p>Goede datakwaliteit is in het geval van het trainen of ontwikkelen van een algoritme belangrijk zodat het algoritme een zo hoog mogelijke validiteit krijgt. Bij het gebruik van een zelflerend algoritme kan slechte datakwaliteit de validiteit van het algoritme verlagen. Met rekenregels met een hoge validiteit kan slechte datakwaliteit juist aangetoond worden en heeft de datakwaliteit geen invloed op de algoritme zelf.</p> <p>Je bepaalt en controleert zelf de kwaliteit van je dataset. Check bijvoorbeeld of alle gegevens juist, compleet en actueel zijn. En herken bias in je data.</p>"},{"location":"onderwerpen/data/#goed-databeheer-datagovernance-en-datamanagement","title":"Goed databeheer: datagovernance en datamanagement","text":"<p>Goed databeheer betekent dat je organisatie duidelijke afspraken maakt over het:</p> <ul> <li>opslaan en verwerken van data</li> <li>gebruik van data: welke data mag je waarvoor gebruiken?</li> <li>beveiligen van data</li> <li>bewaken van de datakwaliteit, zoals het actueel houden van de gegevens</li> <li>eigenaarschap van data, bijvoorbeeld de partij die het algoritme ontwikkelt</li> <li>documenteren en labelen van data (metadata)</li> </ul> <p>Leg de processen en afspraken hierover vast in de datagovernance van je organisatie. In een datamanagementstrategie beschrijf je hoe je organisatie data verzamelt, ordent en gebruikt. Zo kan je organisatie optimaal gebruikmaken van data.</p> <p>Hoe goed je organisatie data beheert, check je met datavolwassenheidsmodellen uit de Toolbox verantwoord datagebruik van de Interbestuurlijke Datastrategie (IBDS). Of gebruik de beslishulp datavolwassenheid.</p>"},{"location":"onderwerpen/data/#belang-van-verantwoord-datagebruik","title":"Belang van verantwoord datagebruik","text":"<p>Algoritmes kunnen veel schade veroorzaken in de maatschappij als ze de verkeerde gegevens gebruiken.</p> <p>Met verantwoord datagebruik verklein je de kans op:</p> <ul> <li>verkeerde beslissingen doordat je algoritme resultaten baseert op data van slechte kwaliteit</li> <li>discriminerende effecten van algoritmes doordat je data bias bevat</li> <li>lekken van privacygevoelige informatie, zoals persoonsgegevens</li> <li>gebruik van data die niet rechtenvrij zijn, zoals teksten met auteursrechten</li> <li>dat resultaten niet te reproduceren zijn, doordat de data niet goed is opgeslagen</li> </ul> <p>Voor een zo hoog mogelijke kwaliteit van een algoritme gaan hoge datakwaliteit en het kwalitatief juist programmeren van het algoritme hand in hand.</p>"},{"location":"onderwerpen/data/#bescherming-van-cruciale-infrastructuurdata","title":"Bescherming van cruciale infrastructuurdata","text":"<p>Niet alleen persoonsgegevens, maar ook gegevens over de Nederlandse infrastructuur vragen om verantwoord datagebruik. Dit omvat zowel fysieke infrastructuur, zoals wegen, bruggen, tunnels en energievoorzieningen, als digitale infrastructuur, zoals datakabels en datacentra.</p> <p>Het ongecontroleerd delen of gebruiken van deze gegevens, bijvoorbeeld voor het trainen van buitenlandse AI-toepassingen, kan risico\u2019s opleveren voor de nationale veiligheid en de continu\u00efteit van vitale systemen. Overheden en organisaties moeten deze data goed beveiligen en duidelijke kaders opstellen om verantwoord gebruik te waarborgen.</p>"},{"location":"onderwerpen/data/#hulpmiddelen","title":"Hulpmiddelen","text":"<ul> <li>Toolbox verantwoord datagebruik, Interbestuurlijke Datastrategie (IBDS)</li> <li>Richtlijnen voor \u2018FAIR\u2019 data, GO FAIR Foundation</li> </ul>"},{"location":"onderwerpen/duurzaamheid/","title":"Duurzaam werken met algoritmes","text":""},{"location":"onderwerpen/duurzaamheid/#duurzaam-werken-met-algoritmes","title":"Duurzaam werken met algoritmes","text":"<p>Overheden moeten duurzaam werken met hun ICT, zoals algoritmes. Dit betekent dat je algoritmes inkoopt, ontwikkelt en gebruikt op een manier die vriendelijk is voor mens en milieu.</p>"},{"location":"onderwerpen/duurzaamheid/#wat-is-duurzaam-werken-met-algoritmes","title":"Wat is duurzaam werken met algoritmes?","text":"<p>Je werkt duurzaam met algoritmes als je tijdens de hele levenscyclus keuzes maakt die passen bij de duurzame en sociale doelen van de overheid:</p> <ul> <li>klimaatneutraal werken in 2030</li> <li>50% minder gebruik van grondstoffen direct uit de natuur (zoals olie, gas en lithium) in 2030</li> <li>circulair werken in 2050: zonder afval, met alleen hergebruikte grondstoffen</li> <li>meer banen voor mensen met een arbeidsbeperking</li> <li>geen sociale misstanden in internationale productieketens, zoals slechte arbeidsomstandigheden of schending van mensenrechten</li> </ul> <p>Om bij te dragen aan deze doelen, kies je bijvoorbeeld voor:</p> <ul> <li>energiezuinig programmeren</li> <li>energiezuinig trainen van AI-systemen</li> <li>dataopslag in een duurzaam of \u2018groen\u2019 datacenter</li> </ul>"},{"location":"onderwerpen/duurzaamheid/#belang-van-duurzaam-werken","title":"Belang van duurzaam werken","text":"<p>Algoritmes kunnen veel impact hebben op het milieu. De rekenkracht die algoritmes nodig hebben op computers kost elektriciteit. En de datacenters die nodig zijn voor het opslaan van data, verbruiken veel energie, water en grondstoffen. Vooral complexe AI-systemen zoals Large Language Models (LLM\u2019s) verbruiken veel energie door training en gebruik en door opslag van grote datasets in datacenters.</p>"},{"location":"onderwerpen/duurzaamheid/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/fundamentele-rechten/","title":"Grondrechten beschermen in algoritmes","text":""},{"location":"onderwerpen/fundamentele-rechten/#grondrechten-beschermen-in-algoritmes","title":"Grondrechten beschermen in algoritmes","text":"<p>Als overheid moet je de grondrechten van burgers beschermen. Dit geldt ook als je algoritmes gebruikt voor publieke taken.</p>"},{"location":"onderwerpen/fundamentele-rechten/#wat-is-het-beschermen-van-grondrechten-in-algoritmes","title":"Wat is het beschermen van grondrechten in algoritmes?","text":"<p>Dit betekent dat je tijdens het ontwikkelen en gebruiken van algoritmes rekening houdt met de fundamentele rechten van de mens:</p> <ul> <li>grondrechten uit de Grondwet</li> <li>mensenrechtenverdragen zoals het Europees Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden (EVRM).</li> </ul>"},{"location":"onderwerpen/fundamentele-rechten/#belang-van-grondrechten-beschermen","title":"Belang van grondrechten beschermen","text":"<p>Algoritmes kunnen grondrechten schenden. Een bekend probleem is bias in algoritmes. Hierdoor worden resultaten onbetrouwbaar en kun je mensen ongelijk behandelen.</p> <p>Belangrijke grondrechten die vaak worden geraakt door algoritmen zijn bijvoorbeeld:</p> <ul> <li>recht op persoonsgegevensbescherming</li> <li>verbod op ongelijke behandeling</li> <li>recht op eerbiediging van de persoonlijke levenssfeer</li> </ul> <p>Als overheid moet je hier goed op letten. Doe dit zo vroeg mogelijk in de levenscyclus. De maatregelen die we adviseren, beginnen al bij het ontwerpen en trainen van algoritmes.</p>"},{"location":"onderwerpen/fundamentele-rechten/#aanbevolen-maatregelen","title":"Aanbevolen maatregelen","text":"MaatregelenOverleg regelmatig met belanghebbendenLeg vast wat de impact van het algoritme is als het niet werkt zoals beoogdInventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingMaak een lijst van de meest kwetsbare groepen en bescherm hen extra"},{"location":"onderwerpen/fundamentele-rechten/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenAI Impact Assessment (AIIA)Assessment List for Trustworthy Artificial Intelligence (ALTAI)De Ethische Data AssistentImpact Assessment Mensenrechten en AlgoritmesThe Fairness HandbookFramework for Meaningful EngagementHandreiking non-discriminatie by designToetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit"},{"location":"onderwerpen/fundamentele-rechten/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/governance/","title":"Governance van algoritmes binnen je organisatie","text":""},{"location":"onderwerpen/governance/#governance-van-algoritmes-binnen-je-organisatie","title":"Governance van algoritmes binnen je organisatie","text":"<p>Zorg voor effectieve governance van je algoritmes. Dit is het beleid van je organisatie voor het verantwoordelijk omgaan met algoritmes en AI-systemen. Leg bijvoorbeeld vast wie waarvoor verantwoordelijk is.</p>"},{"location":"onderwerpen/governance/#wat-is-governance-van-algoritmes-binnen-je-organisatie","title":"Wat is governance van algoritmes binnen je organisatie?","text":"<p>Algoritme-governance is de manier waarop je organisatie omgaat met algoritmes en AI-systemen. Algoritme-governance beschrijft een systeem van regels, werkwijzen, processen en technologische hulpmiddelen die worden gebruikt om ervoor te zorgen dat het gebruik van algoritmes door een organisatie in overeenstemming is met de strategie\u00ebn, doelstellingen en waarden van de organisatie<sup>1</sup>. En dat je voldoet aan wettelijke vereisten en ethische principes.</p> <p>Belangrijke aandachtspunten zijn:</p> <ul> <li>algoritme-governance is geen doel op zich, maar gebruik je om andere doelen te bereiken.</li> <li>algoritme-governance sluit aan bij de strategie, doelstellingen en publieke waarden van de organisatie.</li> </ul> <p>Deze afspraken maak je op 2 niveaus:</p>"},{"location":"onderwerpen/governance/#organisatieniveau","title":"Organisatieniveau","text":"<p>Hoe de organisatie met algoritmes in het algemeen omgaat, bijvoorbeeld:</p> <ul> <li>richtlijnen en gedragscode voor medewerkers</li> <li>strategie en visie</li> <li>werkwijze</li> <li>teamleden en hun verantwoordelijkheden, zoals chief data officers en algoritmefunctionarissen</li> </ul>"},{"location":"onderwerpen/governance/#toepassingsniveau","title":"Toepassingsniveau","text":"<p>Dit zijn afspraken over het beheer en de totstandkoming van de algoritmes zelf, bijvoorbeeld:</p> <ul> <li>multidisciplinair ontwikkelen</li> <li>verantwoordelijkheden per toepassing</li> <li>procedures voor klachten of vragen</li> </ul>"},{"location":"onderwerpen/governance/#belang-van-algoritme-governance","title":"Belang van algoritme-governance","text":"<p>Zonder governance verlies je grip op het inkopen, ontwikkelen, gebruiken en uitfaseren van algoritmes en AI. Dit vergroot het risico op overtredingen van wetten en regels zoals de AI-verordening, Grondwet, Algemene Verordening Gegevensbescherming (AVG) en Auteurswet.</p> <p>Goede governance van algoritmes helpt bij het:</p> <ul> <li>correct uitvoeren van wetten en regels</li> <li>toepassen van je eigen strategie, doelstellingen en publieke waarden</li> <li>ontwikkelen en implementeren van algoritmetoepassingen</li> </ul>"},{"location":"onderwerpen/governance/#aanpak-algoritme-governance","title":"Aanpak algoritme-governance","text":"<p>Algoritme-governance bepaal je zelf als organisatie.</p> <p>Houd in elk geval rekening met:</p> <ul> <li>organisatieverantwoordelijkheden: de minimale voorwaarden om te starten met algoritmes</li> <li>levenscyclus van algoritmes: waar je per fase op moet letten</li> <li>zoek aansluiting met bestaande governancestructuren</li> </ul> <p>Tip</p> <p>Zorg dat iemand verantwoordelijk is voor algoritme-governance. En betrek stakeholders.</p> <p>Governancekader VNG</p> <p>Werk je bij een gemeente? Je kunt het VNG-Governancekader alvast raadplegen. Hierop vind je diverse hulpmiddelen die te maken hebben met AI-governance. Dit Governancekader is nog in ontwikkeling.</p>"},{"location":"onderwerpen/governance/#vereisten","title":"Vereisten","text":"WetgevingAI-verordeningAVGVereistenWetgevingVerboden AI mag niet worden gebruiktAI-verordeningPersoneel en gebruikers zijn voldoende AI-geletterdAI-verordeningBeoordeling als niet 'hoog-risico-AI-systeem' is gedocumenteerdAI-verordeningHoog-risico-AI-systemen zijn voorzien van een risicobeheersysteemAI-verordeningHoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteemAI-verordeningHoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedureAI-verordeningHoog-risico-AI-systemen zijn voorzien van een EU-conformiteitsverklaringAI-verordeningHoog-risico-AI-systemen worden gebruikt volgens de gebruiksaanwijzingAI-verordeningMenselijk toezicht van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkhedenAI-verordeningGebruiksverantwoordelijken controleren de registratie van het hoog-risico AI-systeem in de EU-databankAI-verordeningMensen over wie besluiten worden genomen door een hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluitenAI-verordeningAls AI-modellen voor algemene doeleinden met systeemrisico\u2019s ernstige incidenten veroorzaken, wordt dit gedocumenteerd en gerapporteerdAI-verordeningErnstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouderAI-verordeningKlokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordeningAI-verordeningOrganisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerkenAVG"},{"location":"onderwerpen/governance/#aanbevolen-maatregelen","title":"Aanbevolen maatregelen","text":"MaatregelenInventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueelBepaal of er genoeg experts beschikbaar zijnStel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieMaak een plan voor het omgaan met risico\u2019sZorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheidSluit algoritmegovernance aan op bestaande governancestructuren binnen de organisatieGebruik een algoritme volwassenheidsmodel om te weten waar de organisatie staatRicht een algoritmegovernance in op basis van het Three Lines-modelRicht vaste beslismomenten en controlepunten in in de algoritmelevenscyclusRicht algoritmegovernance in op basis van de risicoclassificatie van algoritmesTaken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernanceMaak afspraken over het beheer van gebruikersControleer en verbeter regelmatig de kwaliteit van het algoritmeMaak afspraken over het beheer van wachtwoordenMaak afspraken over het wijzigen van de codeZorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AIBeschrijf het probleem dat het algoritme moet oplossenBeschrijf het doel van het algoritmeBeschrijf waarom een algoritme het probleem moet oplossenOverleg regelmatig met belanghebbendenBeschrijf de wettelijke grondslag voor de inzet van het algoritmeBeschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmesStel vast in welke risicogroep het algoritme valt en bepaal vervolgens welke vereisten van toepassing zijn.Pas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmesMaak een noodplan voor het stoppen van het algoritmeControleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidStel een werkinstructie op voor gebruikersRicht bij besluitvorming betekenisvolle menselijke tussenkomst inRicht een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit procesMaak een openbaar besluit over de inzet van het algoritmeSpreek af hoe de organisatie omgaat met privacy-verzoekenMaak een noodplan voor beveiligingsincidenten"},{"location":"onderwerpen/governance/#aanbevolen-hulpmiddelen","title":"Aanbevolen hulpmiddelen","text":"HulpmiddelenAI-Geletterdheid Self-assessmentImpactanalyse AI-verordeningBlauwdruk AI-geletterdheidsprogrammaFactsheet AI-geletterdheid voor bestuurdersFactsheet AI-geletterdheid voor inkopersFactsheet AI-verordening voor bestuurdersGovernancekader AI en algoritmen voor en door gemeentenHandreiking inventarisatie, identificatie en classificatie AI-systemenOnderzoekskader algoritmes Auditdienst Rijk 2023Roadmap inwerkingtreding AI-verordeningStandaardenToetsingskader Algoritmes Algemene RekenkamerWettelijke vereisten AI-geletterdheid <ol> <li> <p>Vrij vertaald van de definitie van AI-governance gedefinieerd door M\u00e4ntym\u00e4ki, M., Minkkinen, M., Birkstedt, T. et al. Defining organizational AI governance. AI Ethics 2, 603\u2013609 (2022). \u21a9</p> </li> </ol>"},{"location":"onderwerpen/menselijke-controle/","title":"Menselijke controle over algoritmes","text":""},{"location":"onderwerpen/menselijke-controle/#menselijke-controle-over-algoritmes","title":"Menselijke controle over algoritmes","text":"<p>Algoritmes van de overheid moeten onder controle blijven van mensen. In alle gevallen moet een mens in staat zijn om het algoritme aan te passen, te stoppen of de output kritisch te evalueren en, zo nodig, naast zich neer te leggen.</p>"},{"location":"onderwerpen/menselijke-controle/#wat-is-menselijke-controle","title":"Wat is menselijke controle?","text":"<p>Menselijke controle kan gezien worden als alle wijzen waarop mensen invloed hebben op de werking en uitkomsten van een algoritme en hoe zij kritisch daarmee omgaan. Zo zijn mensen steeds in staat om in te grijpen als op \u00e9\u00e9n van deze vlakken een probleem optreedt.</p> <p>In bestaande wet- en regelgeving worden twee vormen van menselijke controle specifiek benoemd. De Algemene Verordening Gegevensbescherming (AVG) spreekt in artikel 22 over het recht op menselijke tussenkomst bij besluitvorming gebaseerd op geautomatiseerde verwerking en profilering dat voor betrokkene rechtsgevolgen heeft of die de betrokkene in aanmerkelijke mate treft. Volledig geautomatiseerde besluitvorming is in principe verboden. De AI-verordening spreekt in artikel 14 over menselijk toezicht. Dit artikel bevat een breed palet aan toezichtmaatregelen die verplicht zijn bij hoog-risico AI-systemen in de zin van de AI-verordening.</p>"},{"location":"onderwerpen/menselijke-controle/#belang-van-menselijke-controle","title":"Belang van menselijke controle","text":"<p>Algoritmegebruik kan op grote schaal de levens en rechten van burgers be\u00efnvloeden. Het is daarom belangrijk dat mensen die de algoritmes gebruiken controle houden op de werking daarvan en of deze daadwerkelijk binnen de gestelde kaders functioneren. Het is van belang dat dit door mensen gedaan wordt, omdat mensen over eigenschappen en kennis beschikken die algoritmes niet hebben.</p> <p>De Europese wetgever heeft specifiek voor de geautomatiseerde verwerking van persoonsgegevens voor besluitvorming en voor algoritmes die als hoog-risico AI-systeem gekwalificeerd kunnen worden een expliciete vorm van menselijke controle willen regelen.</p> <p>De bescherming van persoonsgegevens is een grondrecht in de Europese Unie. De verwerking van persoonsgegevens zou steeds ten dienste van de mens moeten staan. De snelle technologische en globaliserende ontwikkelingen hebben samen met de economische en sociale integratie van de interne Europese markt een grote toename van verzameling en deling van persoonsgegevens veroorzaakt. Het is in dat licht dat de AVG ertoe verplicht dat bij besluiten die gebaseerd zijn op geautomatiseerde verwerking van persoonsgegevens, met inbegrip van profilering, in principe altijd een mens kritisch dient te kijken naar de output van een algoritme en het op basis daarvan te nemen besluit. Uitzonderingen hierop zijn alleen mogelijk als waarborgen worden ingericht.</p> <p>Hetzelfde geldt voor de AI-systemen die in de AI-verordening als hoog risico gekwalificeerd worden. Dit zijn systemen die aanzienlijke schadelijke gevolgen kunnen hebben voor de gezondheid, veiligheid en grondrechten van personen binnen de Europese Unie. Om schade te beperken verplicht de AI-verordening de aanbieders van deze systemen ertoe ze zo in te richten dat er door mensen op doeltreffende wijze toezicht op kan worden uitgeoefend.</p> <p>Menselijke controle is voornamelijk noodzakelijk in de gevallen dat een algoritme onverhoopt niet goed functioneert en incorrecte output levert. Het zou grote negatieve gevolgen voor betrokkenen kunnen hebben als er geen persoon is die dan kan tegenhouden dat op basis daarvan besluiten worden genomen. In het verlengde daarvan kan op basis van deze controle dan ook het systeem zelf weer worden aangepast of verbeterd. Een zekere vorm van controle is dus ook op zijn plek bij het ontwikkelen van algoritmes en het trainen daarvan. Zo ontstaat er een cyclus van ontwikkeling, training, gebruik en verbetering, waarbij controle bij iedere fase wenselijk en bij enkele fasen verplicht is.</p> <p>Het is hierbij belangrijk om steeds in het oog te houden dat menselijke controle enkel door mensen gedaan kan worden. De controle kan dus niet zelf weer geautomatiseerd worden. Je kan mensen wel ondersteunen met technologische hulpmiddelen.</p>"},{"location":"onderwerpen/menselijke-controle/#aanpak-menselijke-controle","title":"Aanpak menselijke controle","text":"<p>Er bestaan dus specifieke normen voor menselijke tussenkomst en menselijk toezicht. De AP heeft handvatten opgesteld voor de inrichting van betekenisvolle menselijke tussenkomst in de zin van de AVG. Richtlijnen voor de inrichting van menselijk toezicht op hoog-risico AI-systemen volgen nog.</p> <p>Om in meer algemene termen na te denken over hoe menselijke controle kan worden ingericht volgt hieronder algemene informatie. Ten eerste is het goed om in elk geval twee vormen van controle te onderscheiden:</p> <ul> <li>Technische controle: Controle uitoefenen op het algoritme zelf en de technische kenmerken daarvan. Je bepaalt bijvoorbeeld dat een AI-systeem alleen mag 'bijleren\u2019 wanneer de data voldoet aan bepaalde voorwaarden voor sociale representativiteit.</li> <li>Gebruikerscontrole: Controle op het gebruik van algoritmes. Je houdt een vorm van toezicht op de werking van het algoritme bij gebruik en kan het algoritme stilleggen of wijzigen.</li> </ul> <p>Wanneer en hoe je controle uitoefent, hangt af van het soort algoritme en risico, de levenscyclusfase van je project en je expertise. Bepaal in elk geval zo vroeg mogelijk wie in welke levenscyclusfase verantwoordelijk is voor menselijke controle en beschrijf dit in een RACI-matrix of VERI-matrix. Menselijke controle is nodig in verschillende fases, door verschillende mensen. Er is nooit \u00e9\u00e9n persoon verantwoordelijk voor de totale controle. Het beste is dus om uit te gaan van meerdere 'humans in the loop' oftewel een 'team in the loop'.</p> <p>Tijdens de ontwikkeling en het gebruik kun je menselijke controle op de volgende manieren uitoefenen:</p> <ol> <li>Human in the loop</li> </ol> <p>Bij dit model speelt de mens een actieve rol in elke fase van het algoritme. Deze variant geeft de meeste controle en invloed, maar kan leiden tot vertraagde of minder effici\u00ebnte besluitvorming, vooral bij real-time of zeer complexe taken waarbij snelheid cruciaal is. Een voorbeeld van toepassen van human-in-the-loop is het nakijken en beoordelen van de output van een algoritme door een mens, telkens voordat een beslissing wordt genomen. Het verwerken van data gebeurt alleen in opdracht van de mens en het algoritme of AI-model neemt geen autonome beslissingen.</p> <ol> <li>Human on the loop</li> </ol> <p>Hier behoudt de mens toezicht en kan ingrijpen wanneer dat nodig is om te garanderen dat een model veilig en ethisch opereert. Dit model biedt daardoor een balans tussen autonome besluitvorming en menselijke controle. Het is vooral nuttig in situaties waarin afwijkende keuzes of acties van het algoritme grote gevolgen kunnen hebben. De menselijke operator houdt de werking van het algoritme in de gaten en staat klaar om in te grijpen of beslissingen terug te draaien wanneer nodig.</p> <ol> <li>Human above the loop</li> </ol> <p>In dit model houdt de mens toezicht op een hoger niveau, met een focus op strategische en ethische keuzes, in plaats van dat de menselijke operator zich bezighoudt met directe operationele beslissingen. Dit stelt de mens in staat in te grijpen wanneer kritieke morele, juridische of sociale zorgen ontstaan om het model op de langere termijn bij te sturen. De menselijke tussenkomst is gericht op het bepalen van beleid en de richtlijnen voor algoritmes. Het gaat daarbij niet alleen over het defini\u00ebren van operationele procedures maar ook het maken van bepaalde ethische overwegingen, het zorgen voor naleving van regelgeving en het overwegen van de implicaties van de inzet van algoritmes op de lange termijn.</p> <ol> <li>Human before the loop</li> </ol> <p>Hier maakt de mens vooraf ethische en morele afwegingen die in het algoritme zelf worden ingebouwd. Hoewel het model in productie autonoom opereert, zal de menselijke input gedurende de ontwikkeling ervoor zorgen dat het model ook in complexe situaties volgens de juiste (ethische)afwegingen keuzes en acties onderneemt.</p> <p>Dit model is essentieel in situaties waar menselijk ingrijpen tijdens de uitvoering niet mogelijk is(wanneer er bijvoorbeeld weinig of helemaal geen tijd is om als mens te interveni\u00ebren), maar waar ethische keuzes cruciaal blijven. Denk aan bestrijding van zeemijnen of situaties met zelf rijdende auto\u2019s in onvoorspelbare verkeerssituaties (bron: Towards Digital Life: Een toekomstvisie op AI anno2032, TNO). Deze variant kan ook worden ingezet voor situaties waarin wel nog menselijk ingrijpen mogelijk is.</p>"},{"location":"onderwerpen/menselijke-controle/#meer-informatie","title":"Meer informatie?","text":"<p>Raadpleeg de publicatie van de Autoriteit Persoonsgegevens over handvatten voor betekenisvolle menselijke tussenkomst.</p>"},{"location":"onderwerpen/menselijke-controle/#aanbevolen-maatregelen","title":"Aanbevolen maatregelen","text":"MaatregelenControleer en verbeter regelmatig de kwaliteit van het algoritmeBeschrijf waarom een algoritme het probleem moet oplossenMaak een noodplan voor het stoppen van het algoritmeStel een werkinstructie op voor gebruikersRicht bij besluitvorming betekenisvolle menselijke tussenkomst inNeem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomen"},{"location":"onderwerpen/menselijke-controle/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenAI Impact Assessment (AIIA)Assessment List for Trustworthy Artificial Intelligence (ALTAI)Framework for Meaningful EngagementStandaarden"},{"location":"onderwerpen/menselijke-controle/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/privacy-en-gegevensbescherming/","title":"Privacy en persoonsgegevens beschermen in algoritmes","text":""},{"location":"onderwerpen/privacy-en-gegevensbescherming/#privacy-en-persoonsgegevens-beschermen-in-algoritmes","title":"Privacy en persoonsgegevens beschermen in algoritmes","text":"<p>Overheden die algoritmes gebruiken, moeten de persoonsgegevens van burgers beschermen. Hiervan gebruik je niet meer dan nodig is. En je beveiligt deze gegevens goed.</p>"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#wat-is-het-beschermen-van-privacy-en-persoonsgegevens-in-algoritmes","title":"Wat is het beschermen van privacy en persoonsgegevens in algoritmes?","text":"<p>Overheidsalgoritmes mogen persoonsgegevens gebruiken als hier een grondslag voor is, bijvoorbeeld omdat de verwerking wordt voorgeschreven in specifieke wetgeving of wanneer de verwerking noodzakelijk is voor een specifieke wettelijke taak. En wanneer je netjes omgaat met hun persoonsgegevens. Dit betekent:</p> <ul> <li>Verantwoord gebruik van data, zoals rechtmatig persoonsgegevens gebruiken</li> <li>Beveiligen van persoonsgegevens</li> <li>Transparant zijn over het gebruik van persoonsgegevens</li> </ul> <p>Als overheid moet je hier goed op letten. Doe dit zo vroeg mogelijk in de levenscyclus van het algoritme.</p>"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#rechtmatig-persoonsgegevens-gebruiken","title":"Rechtmatig persoonsgegevens gebruiken","text":"<p>Als je persoonsgegevens gebruikt voor algoritmes, moet je rekening houden met wetgeving, zoals de Algemene Verordening Gegevensbescherming (AVG) en de Auteurswet. De belangrijkste regels zijn:</p> <ul> <li>Gebruik alleen persoonsgegevens die je mag gebruiken voor het doel van je algoritme: je hebt toestemming van de eigenaar, of het mag volgens de wet.</li> <li>Gebruik zo min mogelijk persoonsgegevens om dit doel bereiken.</li> </ul> <p>Je organisatie moet aantoonbaar de verwerking beperken tot de persoonsgegevens die noodzakelijk zijn voor een duidelijk bepaald doel. Dit kan lastig zijn. Want welke gegevens zijn bijvoorbeeld nodig als je vooraf niet weet welke verbanden het algoritme legt?</p> <p>De persoonsgegevens die overblijven, gebruik je zo minimaal mogelijk. Hoe minimaal dat is, bepaalt je organisatie zelf. Technieken om privacy zoveel mogelijk te beschermen zijn:</p> <ul> <li>Anonimiseren: data zoveel mogelijk anoniem maken</li> <li>Pseudonimiseren: data moeilijker herleidbaar maken naar personen</li> <li>Aggregeren: data zoveel mogelijk combineren of samenvoegen tot 1 waarde, zoals een totaal of gemiddelde</li> </ul> <p>Tip</p> <p>Leg de keuzes die je maakt duidelijk uit. Zo voorkom je fouten op de werkvloer. Persoonsgegevens die zijn verzameld voor doel A mogen bijvoorbeeld alleen onder specifieke voorwaarden voor doel B gebruiken.</p>"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#belang-van-privacy-en-persoonsgegevens-beschermen","title":"Belang van privacy en persoonsgegevens beschermen","text":"<p>Algoritmes die persoonsgegevens verwerken, kunnen snel de privacy schenden van grote groepen mensen. Vooral impactvolle algoritmes kunnen veel schade veroorzaken in de maatschappij.</p> <p>Wanneer je de privacy en persoonsgegevens van mensen goed beschermt, verlaag je de kans op:</p> <ul> <li>Gebruik van persoonsgegevens voor het verkeerde doel, zoals het per ongeluk publiceren van iemands paspoortfoto op de website van een gemeente.</li> <li>Discriminatie, bijvoorbeeld door onnodig gebruik van leeftijd in een algoritme.</li> <li>Lekken van persoonsgegevens.</li> </ul> <p>Persoonsgegevens helemaal niet gebruiken, is onmogelijk. Voor sommige taken kunnen overheden niet meer zonder algoritmes, bijvoorbeeld voor het beoordelen van grote aantallen aanvragen voor subsidies of vergunningen. Hiervoor zijn persoonsgegevens nodig zoals iemands naam, adres of bepaalde kenmerken.</p>"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#aanbevolen-hulpmiddelen","title":"Aanbevolen hulpmiddelen","text":"HulpmiddelenAI Impact Assessment (AIIA)Assessment List for Trustworthy Artificial Intelligence (ALTAI)Data Protection Impact AssessmentStandaarden"},{"location":"onderwerpen/privacy-en-gegevensbescherming/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/publieke-inkoop/","title":"Inkoop van verantwoorde algoritmes","text":""},{"location":"onderwerpen/publieke-inkoop/#inkoop-van-verantwoorde-algoritmes","title":"Inkoop van verantwoorde algoritmes","text":"<p>Algoritmes die de overheid inkoopt bij leveranciers, moeten voldoen aan strenge eisen. Het inkoopproces speelt een belangrijke rol bij het in goede banen leiden van alle belangen. Begin met een uitgebreide behoeftestelling. En werk goed samen met de leverancier.</p>"},{"location":"onderwerpen/publieke-inkoop/#wat-is-inkoop-van-verantwoorde-algoritmes","title":"Wat is inkoop van verantwoorde algoritmes?","text":"<p>Overheidsorganisaties kunnen een behoefte hebben om hun taken beter uit te gaan voeren en om daar algoritmes voor in te zetten. Het ontwikkelen van algoritmes wordt soms door de overheid zelf gedaan waar dat nodig is. In veel gevallen wordt ervoor gekozen om algoritmes te gaan gebruiken die worden ontwikkelt door leveranciers die hierin gespecialiseerd zijn.</p> <p>Het inkoopproces moet eraan bijdragen dat uiteindelijk een contract wordt gesloten met een leverancier die het best in staat is om invulling te geven aan deze \u2018overheidsopdracht\u2019. Het is van belang dat in het inkoopproces duidelijk wordt gemaakt aan welke voorwaarden moet worden voldaan door leveranciers. Net als voor privacy en informatiebeveiliging, zullen de vereisten specifiek voor algoritmes ook een plek moeten krijgen in het inkoopproces.</p>"},{"location":"onderwerpen/publieke-inkoop/#belang-van-het-inkoopproces","title":"Belang van het inkoopproces","text":"<p>Het inkoopproces neemt een bijzondere positie in om tot een verantwoorde inzet van algoritmes te komen door overheidsorganisaties. Met een gedegen inkoopproces kunnen mogelijke negatieve effecten van algoritmes voor een belangrijk deel al op voorhand worden voorkomen. Dit wordt gedaan door een leverancier te selecteren die voldoet aan de wensen en bijzondere vereisten die aan deze algoritmes moeten worden gesteld en door hier nadere afspraken mee te maken.</p> <p>Het is daarom van belang dat de wensen en vereisten goed in beeld worden gebracht. En dat bijvoorbeeld een inkoopadviseur deze wensen en vereisten een plek geeft in een aanbesteding, zodat je bij de meest geschikte leverancier uitkomt. Dit geldt ook voor onderhandse gunningen.</p> <p>Het publiek inkopen van algoritmes biedt naast het voldoen aan vereisten, een waardevolle kans om nadere invulling te geven aan publieke waarden die worden nagestreefd door overheidsorganisaties.</p>"},{"location":"onderwerpen/publieke-inkoop/#maak-een-uitgebreide-behoeftestelling","title":"Maak een uitgebreide behoeftestelling","text":"<p>Afhankelijk van de behoeftestelling, moet worden beoordeeld aan welke vereiste de benodigde algoritmes van leveranciers moet voldoen en hoe deze betekenisvol kunnen worden geadresseerd. Omdat algoritmes bijzondere kenmerken en effecten kunnen hebben, zoals een niet-transparante of onbedoelde discriminerende werking, moet hier aandacht voor zijn. Het is raadzaam om deze beoordeling met een multidisciplinair team te doen.</p> <p>Beantwoord in elk geval de volgende vragen:</p> <ul> <li>Wat is het op te lossen probleem, de bijbehorende doelstelling en waarom de inzet van een algoritme een geschikte oplossing?</li> <li>Welke beleid rondom AI voert een overheidsorganisatie? Worden er bijvoorbeeld standaard inkoopvoorwaarden gehanteerd?</li> <li>Om wat voor type algoritme gaat het?</li> <li>Hoe risicovol is de inzet van het beoogde type algoritme?</li> <li>Welke verantwoordelijkheden zijn er wie is hiervoor verantwoordelijk? Een leverancier of een de opdrachtgever zelf?</li> <li>Welke publieke waarden worden geraakt met de inzet van het algoritme?</li> <li>Welke expertise moet de opdrachtgever zelf organiseren om algoritmes verantwoord te kunnen gebruiken? De levenscyclus kan hier waardevolle inzichten voor geven.</li> <li>Zijn er specifieke standaarden voor algoritmes die moeten worden gehanteerd? Denk hierbij aan de ISO27001.</li> </ul> <p>Een inkoper heeft een belangrijke rol om antwoorden op deze vragen te verzamelen en om dit te vertalen naar sleutelmomenten binnen het inkoopproces.</p>"},{"location":"onderwerpen/publieke-inkoop/#verken-de-markt-en-specificeer-de-inkoopbehoefte","title":"Verken de markt en specificeer de inkoopbehoefte","text":"<p>Nadat de behoefstelling is beeld is gebracht, is het van belang om te verkennen welke oplossingen in de markt beschikbaar zijn. Dat kan worden gedaan met bijvoorbeeld een marktconsultatie en door met leveranciers in gesprek te gaan. Dit kan waardevolle inzichten opleveren om het inkoopproces verder mee vorm te gaan geven.</p> <p>Het multidisciplinaire inkoopteam zal vervolgens de behoeftestelling moeten gaan specificeren. Daar kan op verschillende manieren. Hier kan worden gedacht aan:</p> <ul> <li>Als voldoende specifiek is waar een algoritme aan moet voldoen, bv. welke output het moet kunnen genereren, kan dit worden ondergebracht in een Programma van Eisen;</li> <li>Bepaalde vereisten gebruiken als gunningscriteria;</li> <li>Ruimte cre\u00ebren voor samenwerking met een leverancier na het sluiten van een contract.</li> <li>Bewijsstukken uitvragen waaruit blijkt dat wordt voldaan aan bepaalde vereisten, zoals het niet schenden van auteursrechten.</li> <li>Zaken die specifiek gelden voor algoritmes opnemen in een SLA.</li> </ul>"},{"location":"onderwerpen/publieke-inkoop/#beoordeel-de-inschrijvingen-en-stel-het-contract-op","title":"Beoordeel de inschrijvingen en stel het contract op","text":"<p>Als leveranciers, bijvoorbeeld bij een aanbesteding, hun inschrijving hebben ingediend, moet worden beoordeeld welke leverancier het best aansluit bij de opdracht.</p> <p>Stel een beoordelingsteam samen waarin voldoende kennis over algoritmes aanwezig is.</p> <p>Er wordt vervolgens een leverancier geselecteerd waarmee een contract wordt opgesteld. Het is van belang dat goed wordt nagedacht hoe het contractbeheer wordt vormgegeven en welke verantwoordelijkheden er blijven bestaan voor de opdrachtgever.</p>"},{"location":"onderwerpen/publieke-inkoop/#aanbevolen-hulpmiddelen","title":"Aanbevolen hulpmiddelen","text":"HulpmiddelenFactsheet AI-geletterdheid voor inkopersInkoopvoorwaardenStandaarden"},{"location":"onderwerpen/publieke-inkoop/#bronnen","title":"Bronnen","text":"<ul> <li>Inkoopproces PIANOo, expertisecentrum aanbesteden van het ministerie van Economische Zaken</li> <li>Community of Practice Digitale Innovaties, PIANOo</li> <li>Leidraad voor het kopen of laten ontwikkelen van algoritmes en AI, Community of Practice Digitale Innovaties, PIANOo</li> </ul>"},{"location":"onderwerpen/publieke-inkoop/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/","title":"Technische robuustheid en veiligheid","text":""},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#technische-robuustheid-en-veiligheid","title":"Technische robuustheid en veiligheid","text":"<p>Algoritmes van de overheid moeten robuust en veilig zijn. Dit betekent dat je algoritmes in elke situatie goed presteren, ook als er iets onverwachts gebeurt. Gaat er toch iets mis, dan is er een noodplan.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#wat-is-technisch-robuust-en-veilig","title":"Wat is technisch robuust en veilig?","text":"<p>Een technisch robuust en veilig algoritme presteert onder elke omstandigheid zoals het bedoeld is.</p> <p>Een robuust algoritme is:</p> <ul> <li>Nauwkeurig: Het algoritme geeft de juiste uitkomst voor het gewenste doel, of meldt dat de uitkomst onzeker is.</li> <li>Betrouwbaar: Ook in nieuwe of onverwachte situaties geeft het algoritme de juiste uitkomst.</li> <li>Reproduceerbaar: In dezelfde situaties vertoont het algoritme hetzelfde gedrag.</li> </ul> <p>Een algoritme is veilig onder deze omstandigheden:</p> <ul> <li>Geautoriseerde toegang: Alleen personen en systemen met toestemming kunnen het algoritme gebruiken of beheren.</li> <li>Confidentieel: Het algoritme kan geen vertrouwelijke of gevoelige informatie lekken door aanvallen.</li> <li>Integer: Kwaadwillenden kunnen nergens in de levenscyclus van het algoritme onbedoeld de controle van het model overnemen.</li> <li>Beschikbaar: Je kunt op elk moment het algoritme gebruiken waarvoor het bedoeld is. Gaat dit toch fout, dan ontstaat er geen grote schade.</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#belang-van-robuuste-veilige-algoritmes","title":"Belang van robuuste, veilige algoritmes","text":"<p>Algoritmes kunnen grote schade veroorzaken aan de maatschappij. Met een technisch robuust en goed beveiligd algoritme voorkom je:</p> <ul> <li>onverwachte schadelijke uitkomsten, zoals verkeerde beslissingen of discriminatie door onvoldoende nauwkeurigheid</li> <li>uitval van het systeem</li> <li>lekken van informatie, zoals persoonsgegevens</li> <li>gebruik van het algoritme voor verkeerde doelen</li> <li>schade door misbruik of aanvallen van buitenaf</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#gebruik-algoritmes-op-de-juiste-manier","title":"Gebruik algoritmes op de juiste manier","text":"<p>Gebruik een algoritme alleen voor het juiste doel en op de juiste manier. Dit is de manier die is getest en gecontroleerd. Wanneer je het algoritme gebruikt voor een ander doel of in een verkeerde context, zijn de resultaten niet meer betrouwbaar.</p> <p>Voorkom dat medewerkers op de verkeerde manier werken met het algoritme. Zij moeten weten wat het algoritme wel en niet kan. En wat ze moeten doen als het algoritme fouten maakt of niet goed werkt. Denk aan technische en organisatorische ondersteuning:</p> <ul> <li>Leid medewerkers op.</li> <li>Maak duidelijke afspraken over werkprocessen (governance).</li> <li>Stuur gebruikers in het juiste gebruik via interactie en technische verbeteringen in het ontwerp.</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#controleer-regelmatig","title":"Controleer regelmatig","text":"<p>Begin zo vroeg mogelijk met regelmatige controles van de uitkomst en werking van het algoritme. In de praktijk verandert de omgeving en de situatie waarin het algoritme wordt gebruikt. Controleer daarom regelmatig of het algoritme nog werkt zoals het is bedoeld.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#voorbeeld","title":"Voorbeeld","text":"<p>Een algoritme leest kentekens tijdens parkeercontroles. Het herkent de juiste letters en cijfers op elk kenteken. Ook als het bord een andere kleur heeft, op een andere plek zit of vies is. Het algoritme is nauwkeurig en dus robuust.</p> <p>Een algoritme berekent het risico op fraude door mensen. Maar bij personen uit dezelfde groep geeft het algoritme de ene keer als uitkomst \u2018hoog risico\u2019 en de andere keer \u2018geen risico\u2019. De uitkomst is niet reproduceerbaar. Hierdoor is het algoritme niet robuust.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#controles-voorbereiden","title":"Controles voorbereiden","text":"<p>Bereid de controles voor tijdens de levenscyclusfases probleemanalyse, ontwerp en dataverkenning en datapreparatie. Onderzoek de situatie waarin je organisatie het algoritme gaat gebruiken: Wat zijn de risico\u2019s? Welke onderdelen van het algoritme moet je evalueren? Analyseer de kwaliteit en variatie van de data. Bedenk maatregelen waarmee je de risico\u2019s zoveel mogelijk voorkomt. En bedenk met welke methode je de controles gaat evalueren.</p> <p>Ontwikkel je het algoritme zelf, controleer dan tijdens de ontwikkeling al wat er gebeurt in de verschillende situaties die je verwacht. Experimenteer met nieuwe combinaties van de inputdata en gebruik verschillende representatieve test-sets.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#controles-uitvoeren","title":"Controles uitvoeren","text":"<p>Voer de controles uit tijdens de ontwikkelfase en de verificatie- en validatiefase. Test het algoritme goed. Evalueer hoe robuust en veilig het algoritme is. Verbeter het algoritme waar nodig. En monitor goed welke data het algoritme gebruikt, zodat je veranderingen in die data snel signaleert. Maak een noodplan voor als blijkt dat het algoritme niet meer werkt zoals het bedoeld was.</p> <p>Blijf regelmatig controleren tijdens de fases implementatie en monitoring en beheer. Dit zijn de fases waarin je het algoritme gebruikt. Presteert het algoritme niet goed, los het probleem dan op of stop het gebruik.</p> <p>Tip</p> <p>Houd rekening met concept drift. Dit betekent dat de eigenschappen van je data in de loop van de tijd kunnen veranderen. Hierdoor trekt je algoritme mogelijk verkeerde conclusies. Zo was er v\u00f3\u00f3r 2020 een verband tussen thuiswerken en ziek zijn. Maar sinds de coronacrisis in 2020 is dit verband minder sterk, omdat gezonde mensen vaker thuiswerken.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#bescherm-algoritmes-tegen-aanvallen-en-bedreigingen","title":"Bescherm algoritmes tegen aanvallen en bedreigingen","text":"<p>Beveilig het ICT-systeem waarin het algoritme wordt gebruikt. Dit zijn bijvoorbeeld maatregelen uit de Baseline Informatiebeveiliging Overheid (BIO) die je standaard neemt voor beveiliging van ICT-systemen tegen cyberaanvallen.</p> <p>Beveilig de algoritmes zelf tegen cybercriminelen. Belangrijke bedreigingen voor algoritmes zijn:</p> <ul> <li>Trainingsdata van een AI-model aanpassen, waardoor het later fouten gaat maken tijdens het gebruik.</li> <li>Input van een algoritme aanpassen om het normale gedrag te omzeilen, of om het algoritme specifieke, ongewenste output te laten geven.</li> <li>Een \u2018achterdeurtje\u2019 inbouwen met toegang tot het algoritme, waardoor aanvallers het algoritme kunnen misbruiken.</li> <li>Intellectueel eigendom of kwetsbaarheden afleiden uit de details van een AI-model.</li> <li>Gevoelige informatie afleiden uit de eigenschappen van trainingsdata.</li> </ul> <p>Lees meer in het TNO-rapport Verkenning van het raakvlak cybersecurity en AI.</p> <p>Aandachtspunten voor het beschermen van algoritmes tegen specifieke dreigingen:</p> <ul> <li>Controleer of de trainingsdata geschikt, correct en betrouwbaar is.</li> <li>Controleer of de inputdata geschikt, correct en betrouwbaar is.</li> <li>Houd bij complexe algoritmes rekening met verborgen en onwenselijke functionaliteiten.</li> <li>Train je algoritme om bestand te zijn tegen aanvallen.</li> <li>Stimuleer veilig gebruik van het algoritme door gebruikers.</li> <li>Maak afspraken met leveranciers en controleer de geleverde algoritmes voor gebruik.</li> <li>Test periodiek of het algoritme weerbaar is tegen bekende aanvallen.</li> </ul> <p>Hiermee voorkom je:</p> <ul> <li>misleiding, doordat het algoritme niet werkt op de bedoelde manier</li> <li>verkeerde implementatie en daardoor een verkeerde werking</li> </ul> <p>Begin zo vroeg mogelijk met beveiligen. Beveilig in elk geval in de fases ontwikkelen, verificatie en validatie, implementatie, monitoring en beheer en uitfaseren.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#verklein-de-kans-op-schade","title":"Verklein de kans op schade","text":"<p>Veroorzaak zo min mogelijk schade als het toch fout gaat. En maak een noodplan voor incidenten. Het doel van dit plan is ervoor zorgen dat de fout zo min mogelijk gevolgen heeft voor de organisatie en de maatschappij. In het plan staat bijvoorbeeld wie wat moet doen als het systeem uitvalt.</p>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#aanbevolen-maatregelen","title":"Aanbevolen maatregelen","text":"MaatregelenMaak afspraken over het beheer van gebruikersMaak afspraken over het beheer van wachtwoordenMaak afspraken over het wijzigen van de codeBeschrijf welke techniek gebruikt wordt voor de beoogde toepassingLeg vast wat de impact van het algoritme is als het niet werkt zoals beoogdMaak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmesVoer een risico-analyse met de aanbieder uit op het gebied van informatiebeveiliging bij een uitbestedingstrajectIdentificeer en implementeer technische interventies die robuustheid vergrotenVoorkom kwetsbaarheden die ge\u00efntroduceerd worden in de supply-chain van het algoritmeGeef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedureGebruik bij machine learning technieken gescheiden train-, test- en validatiedata en houd rekening met underfitting en overfittingControleer de data op manipulatie en ongewenste afhankelijkhedenControleer de input van gebruikers op misleidingOntwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019Maak een noodplan voor het stoppen van het algoritmeMaak logbestanden waarin staat wie wanneer toegang had tot de data en de codeZorg voor reproduceerbaarheid van de uitkomstenBepaal welke feedbackloops van invloed zijn op het algoritmeOntwerp en train het algoritme om bestand te zijn tegen (cyber)aanvallenZorg dat (gevoelige) informatie niet kan lekken op basis van de output van het algoritmeDocumenteer en beargumenteer de keuze voor gebruikte modellen en parametersControleer regelmatig of het algoritme werkt zoals het bedoeld isEvalueer de nauwkeurigheid van het algoritmeZorg voor een representatieve testomgevingEvalueer de betrouwbaarheid van het algoritmeDoe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controlerenNeem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomenMaak back-ups van algoritmesBeveilig de softwareMaak een noodplan voor beveiligingsincidentenMaak een evaluatieplan voor tijdens het gebruik van het algoritmeMonitor regelmatig op veranderingen in de data. Bij veranderingen evalueer je de prestaties en output van het algoritme.Stel een plan op voor continue monitoringControleer regelmatig of een algoritme voldoende weerbaar is tegen bekende aanvallenBij uitfaseren en doorontwikkeling wordt correct omgegaan met data en modelinformatie"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenAI Impact Assessment (AIIA)Assessment List for Trustworthy Artificial Intelligence (ALTAI)Baseline Informatiebeveiliging Overheid (BIO)Standaarden"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#bronnen","title":"Bronnen","text":"<ul> <li>Natalia D\u00edaz-Rodr\u00edguez et al, 2023, Connecting the dots in trustworthy Artificial Intelligence: From AI principles, ethics, and key requirements to responsible AI systems and regulation, Information Fusion 99.</li> <li>Andrea Tocchetti, Lorenzo Corti, Agathe Balayn, Mireia Yurrita, Philip Lippmann, Marco Brambilla, and Jie Yang. 2022. A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities. In ACM, New York, NY, USA</li> <li>Ronan Hamon, Henrik Junklewitz, Ignacio Sanchez, 2020, Robustness and Explainability of Artificial Intelligence: from technical to policy solutions, JRC Technical Report, EUR 30040 EN</li> <li>Bhanu Chander, Chinju John, Lekha Warrier, Gopalakrishnan Kumaravelan, 2024, Toward Trustworthy AI in the Context of Explainability and Robustness, ACM Computing Surveys</li> <li>Niels Brink, Yori Kamphuis, Yuri Maas, Gwen Jansen-Ferdinandus, Jip van Stijn, Bram Poppink, Puck de Haan, Irina Chiscop, 2023, Adversarial AI in de cyber domain, TNO-2023-R10292-EN</li> </ul>"},{"location":"onderwerpen/technische-robuustheid-en-veiligheid/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"onderwerpen/transparantie/","title":"Transparant zijn over algoritmes","text":""},{"location":"onderwerpen/transparantie/#transparant-zijn-over-algoritmes","title":"Transparant zijn over algoritmes","text":"<p>Overheden moeten transparant zijn over hun algoritmes. Dit betekent dat je duidelijke informatie geeft over de algoritmes die je ontwikkelt of gebruikt.</p>"},{"location":"onderwerpen/transparantie/#wanneer-ben-je-transparant","title":"Wanneer ben je transparant?","text":"<p>Je draagt bij aan transparantie over algoritmes als je duidelijk uitlegt:</p> <ul> <li>dat je algoritmes ontwikkelt of gebruikt</li> <li>voor welk doel je deze algoritmes ontwikkelt of gebruikt</li> <li>wat voor soort algoritmes dit zijn</li> <li>welke code of programmeertaal je hiervoor gebruikt</li> <li>welke data je hiervoor gebruikt</li> <li>hoe uitkomsten tot stand komen</li> <li>hoe belanghebbenden bezwaar kunnen maken tegen gevolgen van het algoritme</li> </ul>"},{"location":"onderwerpen/transparantie/#belang-van-transparantie","title":"Belang van transparantie","text":"<p>Als je open bent over de algoritmes die je ontwikkelt of gebruikt, kunnen burgers en bedrijven zich beter verdedigen tegen mogelijke nadelige gevolgen. Verkeerd gebruik van algoritmes kan iemands leven namelijk ernstig be\u00efnvloeden. Bijvoorbeeld door discriminatie of een besluit dat niet klopt.</p> <p>Door uit te leggen hoe het algoritme werkt, kun je de beslissingen van het algoritme makkelijker controleren. Je leert sneller waarom het bepaalde keuzes maakt en waar de zwakke plekken zitten.</p> <p>Ook je organisatie is makkelijker te controleren. Omdat je transparant bent over algoritmes, kunnen burgers feedback geven. Journalisten zien wat je doet. En andere overheden kunnen hiervan leren.</p>"},{"location":"onderwerpen/transparantie/#aanpak-transparant-werken","title":"Aanpak transparant werken","text":"<p>Hoe je transparantie organiseert, hangt af van:</p> <ul> <li>het doel van je algoritme</li> <li>het soort algoritme waarmee je werkt</li> <li>wie de gebruikers zijn van het algoritme, bijvoorbeeld medewerkers of burgers</li> <li>de vereisten waar je aan moet voldoen</li> <li>de maatregelen die je neemt</li> <li>de doelgroep die je wil bereiken</li> <li>de levenscyclus-fase van je algoritme</li> </ul> <p>Onderzoek goed welk soort algoritme je gebruikt of wil gebruiken. Hoe groter de impact en het risico, hoe strenger de vereisten.</p> <p>De keuze voor het soort algoritme bepaalt ook hoe transparant je kunt zijn. Van rekenregels kun je namelijk precies uitleggen hoe deze tot een beslissing komen.</p> <p>Complexe AI-systemen, vaak met generatieve AI, zijn echter al snel een black box: niemand weet precies hoe deze systemen beslissingen maken. Volledige transparantie is dan niet mogelijk. In dat geval moet je de werking zo goed mogelijk onderzoeken. Probeer in elk geval ernstige gevolgen zoals discriminatie te voorkomen. Wees ook zo transparant mogelijk over de datasets die worden gebruikt om het model te trainen en bied een duidelijke documentatie van het systeem aan.</p> <p>Tip</p> <p>Rekenregels zijn makkelijker uit te leggen dan AI-systemen. Als een rekenregel voldoende is voor het bereiken van je doel, dan is het ook makkelijker om transparant te zijn.</p>"},{"location":"onderwerpen/transparantie/#betrokken-partijen","title":"Betrokken partijen","text":"<p>Stem je informatie af op de betrokken partij. Zo moeten gebruikers de uitkomst van het algoritme voldoende begrijpen voor het nemen van onderbouwde beslissingen. En belanghebbenden zoals burgers moeten weten dat zij te maken hebben met een algoritme. Zij moeten snel en makkelijk kunnen vinden wat hun rechten zijn en hoe zij in beroep kunnen gaan.</p> Doelgroep Informeer bijvoorbeeld over Geef de informatie bijvoorbeeld via: Ontwikkelaar de werking, keuzes van het ontwikkelteam technische documentatie Gebruiker hoe uitkomsten tot stand komen, gebruikte data, wat het algoritme wel en niet kan gebruiksinstructies,  trainingen Medewerker contactpersonen, algoritmegebruik binnen de organisatie, afspraken over algoritmemanagement (ook wel: algoritmegovernance) intern algoritmeregister, trainingen Belanghebbende (iemand voor wie het algoritme gevolgen heeft) hoe een besluit tot stand kwam, mogelijkheden om bezwaar te maken, contactmogelijkheden brief over het besluit, webpagina over het algoritme Ge\u00efnteresseerde burger algoritmegebruik binnen de organisatie webpagina over het algoritme, algoritmeregister Auditor werking, ontwikkelproces, keuzes van het ontwikkelteam, hoe uitkomsten tot stand komen algoritmeregister, technische documentatie, programmeercode Onderzoeker of journalist algoritmegebruik binnen de organisatie algoritmeregister, technische documentatie, code"},{"location":"onderwerpen/transparantie/#aanbevolen-maatregelen","title":"Aanbevolen maatregelen","text":"MaatregelenInventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueelStel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieZorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheidBeschrijf het probleem dat het algoritme moet oplossenBeschrijf het doel van het algoritmeBeschrijf de wettelijke grondslag voor de inzet van het algoritmeBepaal welke documenten voor hoe lang gearchiveerd moeten wordenMaak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomstVul technische documentatie van aanbieder aan met relevante informatie vanuit de gebruiksverantwoordelijkeBepaal in een aanbesteding of algoritmes van een aanbieder bepalende invloed hebben in een besluit richting personenStel vast welke betrokkenen ge\u00efnformeerd moeten worden en welke informatie zij nodig hebbenPas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmesPas uitlegbaarheidstechnieken toe en evalueer en valideer dezeMaak gebruik van een algoritme dat bronvermelding kan genereren bij de outputZorg voor reproduceerbaarheid van de uitkomstenControleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidStel een werkinstructie op voor gebruikersPubliceer impactvolle algoritmes en hoog-risico AI-systemen in het AlgoritmeregisterVermeld het gebruik van persoonsgegevens in een privacyverklaringVermeld het gebruik van persoonsgegevens in het verwerkingsregisterMaak een openbaar besluit over de inzet van het algoritmeBij uitfaseren en doorontwikkeling wordt correct omgegaan met data en modelinformatie"},{"location":"onderwerpen/transparantie/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenAI Impact Assessment (AIIA)Assessment List for Trustworthy Artificial Intelligence (ALTAI)Impact Assessment Mensenrechten en AlgoritmesAlgoritmeregisterFramework for Meaningful EngagementHandreiking inventarisatie, identificatie en classificatie AI-systemenStandaarden"},{"location":"onderwerpen/transparantie/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/","title":"Contact en meedoen","text":""},{"location":"over-het-algoritmekader/CONTRIBUTING/#contact-en-meedoen","title":"Contact en meedoen","text":"<p>We moedigen iedereen aan om ons te helpen met het verbeteren van het Algoritmekader. Deze website komt open source tot stand. Dat betekent dat iedereen kan meekijken en meedenken.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#vragen-en-suggesties","title":"Vragen en suggesties","text":"<p>E-mail het team Algoritmekader: algoritmes@minbzk.nl.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#werkgroepen","title":"Werkgroepen","text":"<p>Sluit je aan bij een van de werkgroepen over algoritmes en AI. En denk mee over het Algoritmekader, het Algoritmeregister of andere onderwerpen.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#evenementen","title":"Evenementen","text":"<p>Doe mee aan online en offline evenementen over algoritmes en AI.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#nieuws","title":"Nieuws","text":"<p>Volg het nieuws over overheidsalgoritmes. Of abonneer je op de nieuwsbrief.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#meedoen-via-github","title":"Meedoen via GitHub","text":"<p>Wie handig is met computercode of contentmanagementsystemen kan meewerken aan de website via GitHub. Dit is een online platform voor softwareontwikkelaars. Iedereen kan meekijken en meedenken op dit platform.</p> <p>Als je inhoud (\u2018content\u2019) aanbiedt of plaatst, ga je akkoord met het volgende: - Je hebt 100% van de inhoud zelf geschreven. - Je beschikt zelf over de auteursrechten op de inhoud. - Je houdt je aan de gedragscode: de Contributor Covenant Code of Conduct.</p> <p>Je hebt een GitHub-account nodig om te reageren en aanpassingen te doen.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#issue-aanmaken-in-github","title":"Issue aanmaken in GitHub","text":"<p>Op deze manier kun je een vraag of probleem doorgeven aan het team Algoritmekader. Bijvoorbeeld een foutje, een suggestie of een zwakke plek in de software. 1. Bekijk eerst de bestaande issues. Misschien werkt het team al aan een oplossing! 2. Via de knop New issue kies je het type issue. 3. Vul een duidelijke titel en beschrijving in en klik op \u2018Create\u2019. 4. Anderen kunnen jouw issue nu lezen en hierop reageren. 5. Het team neemt je issue zo snel mogelijk in behandeling.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#algoritmekader-aanpassen","title":"Algoritmekader aanpassen","text":"<p>Een andere manier om je idee te delen is door het bijbehorende bestand te wijzigen in GitHub. Zo kun je zelf het Algoritmekader aanpassen.</p> <p>Zo\u2019n wijziging kun je niet zelf live zetten. Het team Algoritmekader beoordeelt je suggestie en past dit eventueel aan. Bij akkoord gaat je wijziging mee in een volgende release.</p> <p>Houd er rekening mee dat een nieuwe functionaliteit nuttig moet zijn voor de meerderheid van de gebruikers. Dus niet slechts voor een kleine groep. Het is aan jou om het team en de community hiervan te overtuigen.</p>"},{"location":"over-het-algoritmekader/CONTRIBUTING/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie, opmerking of voorbeeld via GitHub. Of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"over-het-algoritmekader/cookies/","title":"Cookies","text":""},{"location":"over-het-algoritmekader/cookies/#cookies","title":"Cookies","text":"<p>Onze website gebruikt geen cookies. Je kunt onze website bezoeken zonder dat er informatie op je computer, tablet of telefoon wordt opgeslagen.</p>"},{"location":"over-het-algoritmekader/cookies/#waarom-gebruiken-wij-geen-cookies","title":"Waarom gebruiken wij geen cookies?","text":"<p>Wij hebben ervoor gekozen om geen cookies te gebruiken om je privacy zo goed mogelijk te beschermen. Dit betekent dat:</p> <ul> <li>Wij niet bijhouden hoe je onze website gebruikt.</li> <li>Er geen gegevens over je bezoek worden opgeslagen.</li> <li>Je de website volledig anoniem kunt gebruiken.</li> </ul>"},{"location":"over-het-algoritmekader/cookies/#externe-diensten","title":"Externe diensten","text":"<p>Onze website maakt ook geen gebruik van externe diensten (zoals Google Analytics of social media widgets) die cookies zouden kunnen plaatsen.</p>"},{"location":"over-het-algoritmekader/cookies/#uw-privacy","title":"Uw privacy","text":"<p>Omdat wij geen cookies gebruiken, worden er geen gegevens over jouw bezoek aan onze website verzameld of opgeslagen.</p>"},{"location":"over-het-algoritmekader/cookies/#meer-weten","title":"Meer weten?","text":"<p>Wil je meer weten over cookies in het algemeen of hoe je deze kunt beheren op andere websites? Kijk dan op de website Veiliginternetten.nl of het Nationaal Cyber Security Centrum.</p>"},{"location":"over-het-algoritmekader/cookies/#heb-je-vragen","title":"Heb je vragen?","text":"<p>Neem contact met ons op via algoritmes@minbzk.nl.</p>"},{"location":"over-het-algoritmekader/copyright/","title":"Copyright","text":""},{"location":"over-het-algoritmekader/copyright/#copyright","title":"Copyright","text":""},{"location":"over-het-algoritmekader/copyright/#herbruik-van-inhoud-en-auteursrechten","title":"Herbruik van inhoud en auteursrechten","text":"<p>De inhoud van deze website mag worden hergebruikt. Dit geldt voor alle teksten, tenzij bij een onderdeel (zoals een document) staat dat er auteursrechtelijke beperkingen zijn. In dat geval is hergebruik niet toegestaan.</p>"},{"location":"over-het-algoritmekader/copyright/#beelden-fotos-videos-en-infographics","title":"Beelden (foto's, video's en infographics)","text":"<p>De regels voor beelden zijn anders:</p> <ul> <li>Op beelden rusten vaak auteursrechten van anderen.</li> <li>Beelden mogen niet worden hergebruikt, tenzij erbij staat dat dit is toegestaan.</li> <li>Als u een beeld hergebruikt, moet u \u2013 als vermeld \u2013 de naam van de maker overnemen.</li> </ul>"},{"location":"over-het-algoritmekader/copyright/#let-op-bij-citeren","title":"Let op bij citeren","text":"<p>Bij citeren van inhoud mag niet de indruk worden gewekt dat de Rijksoverheid de inhoud van uw werk automatisch ondersteunt.</p>"},{"location":"over-het-algoritmekader/copyright/#vragen-over-auteursrechten","title":"Vragen over auteursrechten","text":"<p>Denkt u dat dit bij een beeld niet goed is gegaan? Neem dan contact met ons op via algoritmes@minbzk.nl.</p>"},{"location":"over-het-algoritmekader/copyright/#licentie","title":"Licentie","text":"<p>Het Algoritmekader is beschikbaar onder de European Union Public Licence (EUPL) v. 1.2.</p> <p>De volledige licentietekst is beschikbaar in de LICENSE.md file in de repository.</p> <p>U kunt de licentie ook raadplegen op de offici\u00eble EUPL website.</p>"},{"location":"over-het-algoritmekader/kwetsbaarheid-melden/","title":"Kwetsbaarheid melden","text":""},{"location":"over-het-algoritmekader/kwetsbaarheid-melden/#kwetsbaarheid-melden","title":"Kwetsbaarheid melden","text":"<p>Ontdekt u een zwakke plek of kwetsbaarheid op deze website, meld dit dan aan het Nationaal Cyber Security Centrum (NCSC). Het maken van zo'n melding heet Coordinated Vulnerability Disclosure (CVD). Wij bekijken samen met het NCSC het probleem en lossen dit zo snel mogelijk op.</p> <p>Melden van kwetsbaarheden</p>"},{"location":"over-het-algoritmekader/over-het-algoritmekader/","title":"Over het Algoritmekader","text":""},{"location":"over-het-algoritmekader/over-het-algoritmekader/#over-het-algoritmekader","title":"Over het Algoritmekader","text":"<p>Het Algoritmekader is een hulpmiddel voor overheden die algoritmes, waaronder AI (artifici\u00eble intelligentie), gebruiken. Hierin vind je de wetten en regels, hulpmiddelen en adviezen per situatie.</p>"},{"location":"over-het-algoritmekader/over-het-algoritmekader/#verantwoord-gebruik-van-algoritmes","title":"Verantwoord gebruik van algoritmes","text":"<p>In het Algoritmekader vind je informatie over verantwoord gebruik van algoritmes. Bijvoorbeeld:</p> <ul> <li>Wie is waarvoor verantwoordelijk?</li> <li>Hoe voorkom je discriminatie (bias) in een algoritme?</li> <li>Hoe verwerk je gegevens op een veilige manier?</li> <li>Hoe voorkom je mensenrechtenschendingen?</li> <li>Welke inkoopvoorwaarden spreek je af voor algoritmes van een externe partij?</li> </ul> <p>De informatie is bedoeld voor medewerkers van de rijksoverheid, provincies, gemeentes en waterschappen.</p>"},{"location":"over-het-algoritmekader/over-het-algoritmekader/#informatie-van-de-overheid","title":"Informatie van de overheid","text":"<p>Het Algoritmekader is een website van het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties. Het team Data, AI en Algoritmes stelt de informatie samen, op basis van:</p> <ul> <li> <p>alle wetten en regels, zoals de AI-verordening en de Algemene wet bestuursrecht</p> </li> <li> <p>belangrijke hulpmiddelen, zoals de IAMA (Impact Assessment Mensenrechten en Algoritmes)</p> </li> <li>adviezen en ervaringen van experts, zoals wetenschappers</li> </ul>"},{"location":"over-het-algoritmekader/over-het-algoritmekader/#versie-24","title":"Versie 2.4","text":"<p>Versie 2.4 is de nieuwste, betrouwbare versie van het Algoritmekader. Deze versie verscheen op 15 september 2025 en bevat de laatste updates en aanpassingen.</p> <p>Tot 19 december 2024 was deze website een b\u00e8taversie. De eerste versie van het Algoritmekader was een rapport: Implementatiekader 'Verantwoorde inzet van algoritmen'. Door het verder ontwikkelen van dit rapport ontstond de website Algoritmekader.</p>"},{"location":"over-het-algoritmekader/over-het-algoritmekader/#iedereen-mag-meedenken","title":"Iedereen mag meedenken","text":"<p>De informatie in het Algoritmekader komt open source tot stand. Dat betekent dat iedereen kan meekijken en zijn mening mag geven, of een voorstel mag doen:</p> <ul> <li>Geef je vraag of wijziging door.</li> <li>Sluit je aan bij een werkgroep.</li> <li>Doe mee aan een (online) vergadering zoals onze demo na een nieuwe release van het Algoritmekader.</li> </ul>"},{"location":"over-het-algoritmekader/over-het-algoritmekader/#nieuwsbrief","title":"Nieuwsbrief","text":"<p>Via onze maandelijkse Nieuwsbrief Algoritmes blijf je op de hoogte over de ontwikkelingen van het Algoritmekader.</p>"},{"location":"over-het-algoritmekader/privacy/","title":"Privacy","text":""},{"location":"over-het-algoritmekader/privacy/#privacy","title":"Privacy","text":"<p>Je privacy is belangrijk voor ons. Hier leggen we uit welke gegevens we verzamelen, waarom we dat doen en hoe we goed met je gegevens omgaan. Deze verklaring geldt voor de verwerking van gegevens door het ministerie van Binnenlandse Zaken en Koninkrijksrelaties op deze website.</p>"},{"location":"over-het-algoritmekader/privacy/#welke-gegevens-verzamelen-wij","title":"Welke gegevens verzamelen wij?","text":"<p>Wij verzamelen of bewaren geen gegevens van jouw bezoek aan deze website. De enige gegevens die wij kunnen verwerken zijn gegevens die je zelf actief aan ons geeft, zoals:</p> <ul> <li>Als je een e-mail stuurt naar algoritmes@minbzk.nl.</li> </ul>"},{"location":"over-het-algoritmekader/privacy/#lokale-opslag-in-je-browser-beslishulp-ai-verordening","title":"Lokale opslag in je browser (beslishulp AI-verordening)","text":"<p>Als je gebruik maakt van de beslishulp AI-verordening, wordt de informatie die je invult alleen lokaal op je eigen apparaat opgeslagen (in de local storage van je browser). Dit betekent dat:</p> <ul> <li>De gegevens nooit naar onze servers worden gestuurd.</li> <li>Alleen jij toegang hebt tot deze gegevens.</li> <li>Je de gegevens op elk moment kunt verwijderen door je browsercache te wissen.</li> <li>Wij deze gegevens niet kunnen inzien of bewaren.</li> </ul>"},{"location":"over-het-algoritmekader/privacy/#waarom-verzamelen-wij-je-gegevens","title":"Waarom verzamelen wij je gegevens?","text":"<p>Als je ons een e-mail stuurt, gebruiken we je gegevens om:</p> <ul> <li>Je vragen te beantwoorden.</li> <li>Je feedback te verwerken.</li> <li>Te voldoen aan de wet.</li> </ul>"},{"location":"over-het-algoritmekader/privacy/#hoe-beschermen-wij-je-gegevens","title":"Hoe beschermen wij je gegevens?","text":"<p>Als je ons e-mailt, zorgen wij ervoor dat je gegevens veilig zijn. Alleen medewerkers die de gegevens nodig hebben, kunnen erbij.</p>"},{"location":"over-het-algoritmekader/privacy/#hoe-lang-bewaren-wij-je-gegevens","title":"Hoe lang bewaren wij je gegevens?","text":"<p>We bewaren je gegevens (zoals e-mails) alleen zolang het nodig is. Als we je gegevens niet meer nodig hebben, verwijderen we ze.</p>"},{"location":"over-het-algoritmekader/privacy/#je-rechten","title":"Je rechten","text":"<p>Als je ons gegevens hebt gestuurd (bijvoorbeeld via e-mail), heb je het recht om:</p> <ul> <li>Je gegevens in te zien, aan te passen of te laten verwijderen.</li> <li>Een klacht in te dienen als je vindt dat wij niet goed omgaan met je gegevens.</li> </ul>"},{"location":"over-het-algoritmekader/privacy/#vragen","title":"Vragen?","text":"<p>Heb je vragen over deze verklaring? Neem contact met ons op via algoritmes@minbzk.nl.</p>"},{"location":"over-het-algoritmekader/sitemap/","title":"Sitemap","text":""},{"location":"over-het-algoritmekader/sitemap/#sitemap","title":"Sitemap","text":""},{"location":"over-het-algoritmekader/sitemap/#home","title":"Home","text":"<ul> <li>Home</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#soorten-algoritmes-en-ai","title":"Soorten algoritmes en AI","text":"<ul> <li>Soorten algoritmes en AI</li> <li>Wat is een algoritme</li> <li>Risico van AI-systemen</li> <li>Impact van algoritmes</li> <li>Generatieve AI</li> <li>Geautomatiseerde risicoselectie</li> <li>Definities</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#onderwerpen","title":"Onderwerpen","text":"<ul> <li>Onderwerpen</li> <li>Bias en non-discriminatie</li> <li>Data</li> <li>Duurzaamheid</li> <li>Fundamentele rechten</li> <li>Governance</li> <li>Menselijke controle</li> <li>Privacy en gegevensbescherming</li> <li>Publieke inkoop</li> <li>Technische robuustheid en veiligheid</li> <li>Transparantie</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#levenscyclus","title":"Levenscyclus","text":"<ul> <li>Levenscyclus</li> <li>Over de levenscyclus</li> <li>Organisatieverantwoordelijkheden</li> <li>Probleemanalyse</li> <li>Ontwerp</li> <li>Dataverkenning en datapreparatie</li> <li>Ontwikkelen</li> <li>Verificatie en validatie</li> <li>Implementatie</li> <li>Monitoring en beheer</li> <li>Uitfaseren</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#rollen","title":"Rollen","text":"<ul> <li>Rollen</li> <li>Beleid en advies</li> <li>Ontwikkelaar</li> <li>Projectleider</li> <li>Jurist</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#voldoen-aan-wetten-en-regels","title":"Voldoen aan wetten en regels","text":"<ul> <li>Overzicht</li> <li>Vereisten</li> <li>Maatregelen</li> <li>Hulpmiddelen</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#ai-verordening","title":"AI-verordening","text":"<ul> <li>Overzicht</li> <li>AI-verordening in het kort</li> <li>Tijdlijn AI-verordening</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#over-het-algoritmekader","title":"Over het Algoritmekader","text":"<ul> <li>Over het Algoritmekader</li> <li>Meedoen</li> <li>Contact</li> <li>Veelgestelde vragen</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#beleid","title":"Beleid","text":"<ul> <li>Cookies</li> <li>Copyright</li> <li>Kwetsbaarheid melden</li> <li>Privacy</li> <li>Releasenotes</li> <li>Toegankelijkheid</li> </ul>"},{"location":"over-het-algoritmekader/sitemap/#externe-links","title":"Externe links","text":"<ul> <li>Overheid.nl</li> <li>Rijksoverheid.nl</li> <li>Digitale Overheid</li> <li>Data.overheid.nl</li> <li>AI en algoritmes (Pleio)</li> <li>GitHub repository</li> </ul>"},{"location":"over-het-algoritmekader/toegankelijkheid/","title":"Toegankelijkheid","text":""},{"location":"over-het-algoritmekader/toegankelijkheid/#toegankelijkheid","title":"Toegankelijkheid","text":""},{"location":"over-het-algoritmekader/veelgestelde-vragen/","title":"Veelgestelde vragen","text":""},{"location":"over-het-algoritmekader/veelgestelde-vragen/#veelgestelde-vragen","title":"Veelgestelde vragen","text":""},{"location":"over-het-algoritmekader/veelgestelde-vragen/#a-algemene-informatie","title":"A - Algemene informatie","text":"Wat is het Algoritmekader? <p>Het Algoritmekader is een hulpmiddel met standaarden en richtlijnen voor het verantwoord inzetten van algoritmes en AI-systemen in de openbare sector. Het helpt overheidsorganisaties om algoritmes op een verantwoorde manier te ontwerpen, in te voeren en te gebruiken. Het Algoritmekader draagt bij aan vertrouwen in algoritmes en zorgt dat zij eerlijk, transparant en veilig worden ingezet.</p> Voor wie is het Algoritmekader bedoeld? <p>Het Algoritmekader is bedoeld voor medewerkers van de rijksoverheid, provincies, gemeentes en waterschappen die algoritmes inzetten. De informatie is geschikt voor verschillende rollen:</p> <ul> <li>Beleid en advies - Beleidsmedewerkers, ethici, CIO-adviseurs en architecten</li> <li>Jurist - Privacy-juristen, compliance-officers en functionarissen gegevensbescherming</li> <li>Ontwikkelaar - Data-scientists, developers en informatieanalisten</li> <li>Projectleider - Product-owners, proceseigenaren en IT-projectmanagers</li> </ul> <p>Ook externe leveranciers die algoritmes ontwikkelen voor overheidsorganisaties kunnen het Algoritmekader gebruiken.</p> Wat zijn de doelen van het Algoritmekader? <p>Het Algoritmekader heeft als doelen:</p> <ul> <li>Het verantwoord en transparant inzetten van algoritmes bevorderen.</li> <li>De maatschappelijke impact van algoritmes minimaliseren.</li> <li>Vertrouwen in algoritmegebruik door de overheid vergroten.</li> <li>Aansluiting met geldende wetgeving waarborgen, zoals de AVG, de Awb en de Europese AI-verordening.</li> <li>Overheidsorganisaties ondersteunen bij het omgaan met risico's van algoritmes.</li> </ul> Wat is het verschil tussen het Algoritmekader en het Algoritmeregister? <p>Het Algoritmekader is een hulpmiddel met standaarden en richtlijnen voor het verantwoord inzetten van algoritmes.</p> <p>Het Algoritmeregister is een openbaar register waarin overheidsorganisaties informatie over hun algoritmes publiceren.</p> <p>De twee werken samen: het Algoritmekader helpt overheden om algoritmes verantwoord in te zetten, en het Algoritmeregister zorgt voor transparantie over welke algoritmes de overheid gebruikt.</p> Hoe is het Algoritmekader opgebouwd? <p>De rode draad door het Algoritmekader zijn de wettelijke vereisten. Dit is met name de AI-verordening, maar ook wetten als de Algemene wet bestuursrecht (Awb), de Algemene Verordening Gegevensbescherming (AVG) en de Wet open overheid (Woo) raken aan AI en algoritmes.</p> <p>Om aan die wettelijke vereisten te voldoen worden maatregelen voorgesteld.</p> <p>En om die maatregelen in de praktijk te brengen worden ook hulpmiddelen gegeven.</p> <p>Daarnaast is het Algoritmekader opgebouwd rond drie pijlers:</p> <ul> <li>Rollen - Vier verschillende rollen met elk hun verantwoordelijkheden</li> <li>Levenscyclus - Negen fasen waarin algoritmes worden ontwikkeld en beheerd</li> <li>Onderwerpen - Tien onderwerpen met standaarden en richtlijnen</li> </ul> <p>Bij elke fase van de levenscyclus vind je maatregelen en hulpmiddelen om je algoritmes verantwoord in te zetten. De rollen bepalen wie wat doet, en de onderwerpen geven richtlijnen per vakgebied.</p> Wie beheert het Algoritmekader? <p>Het Algoritmekader wordt beheerd door het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties.</p> Wordt het kader bijgewerkt bij nieuwe ontwikkelingen? <p>Ja! Het team achter het Algoritmekader houdt het veld in de gaten. Nieuwe ontwikkelingen worden regelmatig in het Algoritmekader verwerkt. Denk aan nieuw beleid vanuit de Rijksoverheid of andere overheden, ontwikkelingen vanuit de Europese Unie of nieuwe instrumenten die worden ontwikkeld. In de praktijk leidt dit tot vier \u00e0 vijf nieuwe inhoudelijke [i]releases[/i] per jaar. Technische fouten worden daarnaast ook opgelost als deze gesignaleerd worden.</p> <p>Heb je zelf een aanvulling op of opmerking over het kader? Je kunt altijd contact met ons opnemen.</p>"},{"location":"over-het-algoritmekader/veelgestelde-vragen/#b-gebruik-van-het-algoritmekader","title":"B - Gebruik van het Algoritmekader","text":"Hoe pas je het Algoritmekader toe? <p>Het Algoritmekader biedt richtlijnen en best practices die je toepast bij elke fase van de levenscyclus. Voor elk fase vind je:</p> <ul> <li>Relevante maatregelen en activiteiten</li> <li>Hulpmiddelen en checklists</li> <li>Verwijzingen naar wetten en regelgeving</li> <li>Aandachtspunten per rol</li> </ul> <p>Je hoeft niet alles letterlijk toe te passen. Het Algoritmekader is flexibel en je past het aan op basis van je situatie en het risicoprofiel van je algoritme.</p> Wie is verantwoordelijk voor algoritmes binnen een organisatie? <p>De verantwoordelijkheid voor algoritmes is verdeeld over verschillende rollen. Elke rol heeft specifieke verantwoordelijkheden:</p> <ul> <li>Beleid en advies - Zorgen voor beleid en governance</li> <li>Jurist - Zorgen voor wettelijke naleving</li> <li>Ontwikkelaar - Zorgen voor technische kwaliteit</li> <li>Projectleider - Co\u00f6rdinatie en voortgang</li> </ul> <p>Het is belangrijk dat de verantwoordelijkheden duidelijk zijn vastgesteld en dat er goede afstemming tussen deze rollen plaatsvindt.</p> Wat is de levenscyclus van algoritmes? <p>De levenscyclus beschrijft de verschillende fasen van een algoritme of AI-systeem van begin tot einde:</p> <ul> <li>Fase 0: Organisatieverantwoordelijkheden - Je organisatie inrichten voor het verantwoord gebruik van algoritmes</li> <li>Fase 1: Probleemanalyse - Het probleem en de doelstellingen analyseren</li> <li>Fase 2: Ontwerp - Het conceptuele ontwerp uitdenken</li> <li>Fase 3: Dataverkenning en datapreparatie - De data voorbereiden</li> <li>Fase 4: Ontwikkelen - Het algoritme of AI-systeem bouwen</li> <li>Fase 5: Verificatie en validatie - Testen of het goed werkt</li> <li>Fase 6: Implementatie - Het in de praktijk brengen</li> <li>Fase 7: Monitoring en beheer - Voortdurend controleren en beheren</li> <li>Fase 8: Uitfaseren - Archiveren en stopzetten</li> </ul> Wat zijn minimale vereisten volgens het Algoritmekader? <p>De minimale vereisten hangen af van het risiconiveau van het algoritme. Voor alle algoritmes geldt dat je:</p> <ul> <li>Weet onder welke risicocategorie het algoritme valt</li> <li>Weet wat het algoritme doet</li> <li>Risico's identificeert</li> <li>Menselijk toezicht waarborgt</li> <li>Transparant communiceert over het gebruik</li> </ul> <p>Voor algoritmes met hogere risico's gelden aanvullende vereisten, zoals regelmatige controles en impact assessments. Doorloop de beslishulp om erachter te komen of je algoritme onder een hoog risico valt.</p>"},{"location":"over-het-algoritmekader/veelgestelde-vragen/#c-informatie-en-ondersteuning","title":"C - Informatie en ondersteuning","text":"Waar vind ik meer informatie over het Algoritmekader? <p>Meer informatie vind je via:</p> <ul> <li>De website van het Algoritmekader (deze site)</li> <li>De richtlijnen en documentatie per onderwerp</li> <li>De maatregelen per levenscyclus fase</li> <li>Het Algoritmeregister: https://algoritmes.overheid.nl</li> <li>Webinars en trainingen (zie de website voor het aanbod)</li> </ul> Kan ik ondersteuning krijgen bij de toepassing van het Algoritmekader? <p>Ondersteuning is beschikbaar via:</p> <ul> <li>De documentatie en handleidingen op deze website</li> <li>Contact met het team Algoritmekader: algoritmes@minbzk.nl</li> <li>Deelname aan werkgroepen van organisaties die het Algoritmekader gebruiken</li> <li>Webinars en trainingen (zie de website voor het aanbod)</li> </ul> Hoe blijf ik ge\u00efnformeerd over updates van het Algoritmekader? <p>Om ge\u00efnformeerd te blijven over updates kun je:</p> <ul> <li>De website van het Algoritmekader regelmatig bezoeken</li> <li>Je inschrijven voor meldingen (zie de website voor opties)</li> <li>Lid worden van het netwerk van gebruikers</li> <li>Je inschrijven voor de maandelijkse nieuwsbrief over algoritmes</li> <li>De releasenotes op GitHub bekijken voor technische updates</li> </ul>"},{"location":"over-het-algoritmekader/veelgestelde-vragen/#d-wetgeving-en-regelgeving","title":"D - Wetgeving en regelgeving","text":"Welke wetten zijn relevant voor het Algoritmekader? <p>Verschillende wetten en regelgeving zijn relevant voor algoritmes:</p> <ul> <li>AVG (Algemene Verordening Gegevensbescherming) - Voor gegevensbescherming</li> <li>Awb (Algemene wet bestuursrecht) - Voor besluitvormingsprocessen</li> <li>Europese AI-verordening - Voor AI-systemen (in implementatiefase)</li> <li>WOO (Wet open overheid) - Voor transparantie en openbaarheid</li> </ul> <p>Het Algoritmekader helpt je om aan deze wetten te voldoen.</p> Hoe verhoudt het Algoritmekader zich tot de Europese AI-verordening? <p>Het Algoritmekader is een Nederlands hulpmiddel dat aansluit op internationale regelgeving, waaronder de Europese AI-verordening. Het Algoritmekader voorziet in sommige opzichten in aanvullende richtlijnen ten opzichte van de minimale vereisten van de AI-verordening.</p>"},{"location":"over-het-algoritmekader/veelgestelde-vragen/#e-overige-vragen","title":"E - Overige vragen","text":"Staat je vraag er niet bij? <p>Heb je een vraag die hier niet beantwoord is? Neem dan contact op met het team Algoritmekader via algoritmes@minbzk.nl. We helpen je graag verder.</p>"},{"location":"rollen/","title":"Rollen","text":""},{"location":"rollen/#rollen","title":"Rollen","text":""},{"location":"rollen/#beleid-en-advies","title":"Beleid en advies","text":"<p>Dit zijn professionals die ervoor zorgen dat de organisatie algoritmes verantwoord en volgens de beleidsdoelen ontwikkelt en inzet. Bijvoorbeeld een beleidsmedewerker, ethicus, CIO-adviseur of architect.</p>"},{"location":"rollen/#jurist","title":"Jurist","text":"<p>Juristen zorgen ervoor dat de organisatie bij het ontwikkelen en gebruiken van algoritmes voldoet aan de wettelijke verplichtingen en beginselen van behoorlijk bestuur. Bijvoorbeeld een privacy-jurist, compliance-officer of functionaris gegevensbescherming (FG).</p>"},{"location":"rollen/#ontwikkelaar","title":"Ontwikkelaar","text":"<p>Ontwikkelaars zijn technische experts die ervoor zorgen dat algoritmes voldoen aan technische en ethische standaarden. Bijvoorbeeld een data-scientist, developer of informatieanalist.</p>"},{"location":"rollen/#projectleider","title":"Projectleider","text":"<p>Projectleider verbinden de benodigde expertises en waarborgen alle stappen van het ontwikkelproces. Bijvoorbeeld een product-owner, proceseigenaar of IT-projectmanager.</p>"},{"location":"rollen/beleid-en-advies/","title":"Beleids- en adviesprofessional","text":""},{"location":"rollen/beleid-en-advies/#beleids-en-adviesprofessional","title":"Beleids- en adviesprofessional","text":"<p>Professionals op het gebied van beleid en advies zorgen ervoor dat de organisatie algoritmes verantwoord en in lijn met beleidsdoelen ontwikkelt en inzet.</p> <p>Zij dragen bij aan impact-assessments, risicobeoordelingen en beleidsplannen over algoritmes. En zij helpen bij het signaleren en mitigeren van potenti\u00eble risico\u2019s, zoals onbedoelde bias of risico's op het gebied van privacy.</p> <p>Door hun brede blik en specialistische kennis ondersteunen zij adviseurs bij het opstellen en vertalen van beleidskaders naar concrete maatregelen en adviezen. Zij vormen zo een verbindende factor tussen de technische, organisatorische en bestuurlijke aspecten van algoritmeontwikkeling.</p>"},{"location":"rollen/beleid-en-advies/#belangrijke-taken-van-een-beleidsprofessional-of-adviseur","title":"Belangrijke taken van een beleidsprofessional of adviseur:","text":"<ul> <li>zorgt ervoor dat de organisatie beleidskaders en richtlijnen correct interpreteert en effectief toepast</li> <li>schakelt met ontwikkelaars, projectleiders en eindverantwoordelijken</li> <li>ontsluit de juiste expertise op het juiste moment</li> <li>adviseert bij belangrijke beslissingen</li> </ul>"},{"location":"rollen/beleid-en-advies/#beleids-en-adviesprofessionals-zijn-bijvoorbeeld","title":"Beleids- en adviesprofessionals zijn bijvoorbeeld:","text":"<ul> <li>CIO-adviseur</li> <li>Beleidsmedewerker</li> <li>Ethicus</li> <li>Architect of enterprise-architect</li> <li>Security-officer</li> <li>Inkoopadviseur</li> <li>Domeinspecialist</li> </ul>"},{"location":"rollen/beleid-en-advies/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"rollen/jurist/","title":"Jurist","text":""},{"location":"rollen/jurist/#jurist","title":"Jurist","text":"<p>Juristen verantwoorden algoritmes vanuit een juridisch perspectief. Zij zorgen ervoor dat de ontwikkeling en het gebruik van algoritmes voldoet aan wettelijke verplichtingen, zoals de Algemene Verordening Gegevensbescherming (AVG) en de beginselen van behoorlijk bestuur.</p> <p>Zij signaleren en mitigeren mogelijke juridische risico\u2019s op het gebied van bijvoorbeeld bias, transparantieverplichtingen of aansprakelijkheid.</p> <p>Juristen kunnen vroeg in het proces helpen om juridische problemen te voorkomen en zorgen voor een rechtmatige implementatie van algoritmes.</p>"},{"location":"rollen/jurist/#belangrijke-taken-van-een-jurist","title":"Belangrijke taken van een jurist:","text":"<ul> <li>waarborgt de geldende wetten, regels en ethische principes</li> <li>adviseert over juridische risico's</li> <li>stelt kaders op voor het waarborgen van bijvoorbeeld privacy en gegevensbescherming, transparantie en non-discriminatie</li> <li>vertaalt complexe juridische normen naar toepasbare richtlijnen voor de ontwikkeling en toepassing van algoritmes</li> </ul>"},{"location":"rollen/jurist/#juristen-zijn-bijvoorbeeld","title":"Juristen zijn bijvoorbeeld","text":"<ul> <li>Juridisch adviseur</li> <li>Privacy-officer</li> <li>Privacy-jurist</li> <li>Compliance-officer</li> <li>Functionaris gegevensbescherming (FG)</li> <li>Contractbeheerder</li> </ul>"},{"location":"rollen/jurist/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"rollen/ontwikkelaar/","title":"Ontwikkelaar","text":""},{"location":"rollen/ontwikkelaar/#ontwikkelaar","title":"Ontwikkelaar","text":"<p>Ontwikkelaars zijn de technische experts die ervoor zorgen dat algoritmes voldoen aan technische en ethische standaarden. Zij passen methodes toe om te waarborgen dat AI-modellen duurzaam, eerlijk en transparant zijn. Vaak zijn zij verantwoordelijk voor het testen en optimaliseren van algoritmes en voor het implementeren van maatregelen om privacy en persoonsgegevens te beschermen.</p>"},{"location":"rollen/ontwikkelaar/#belangrijke-taken-van-een-ontwikkelaar","title":"Belangrijke taken van een ontwikkelaar","text":"<ul> <li>analyseert, ontwikkelt en implementeert algoritmes en AI-modellen</li> <li>verzorgt de technische kant van de algoritmeontwikkeling, inclusief programmeren, opschonen van data, data-analyse en het ontwerpen van informatieprocessen</li> </ul>"},{"location":"rollen/ontwikkelaar/#ontwikkelaars-zijn-bijvoorbeeld","title":"Ontwikkelaars zijn bijvoorbeeld","text":"<ul> <li>Data-analist</li> <li>Data-scientist</li> <li>Data-engineer</li> <li>Developer</li> <li>Informatieanalist</li> <li>Softwareontwikkelaar</li> </ul>"},{"location":"rollen/ontwikkelaar/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"rollen/projectleider/","title":"Projectleider","text":""},{"location":"rollen/projectleider/#projectleider","title":"Projectleider","text":"<p>Projectleiders spelen de hoofdrol in het realiseren van een verantwoorde en effectieve inzet van algoritmes binnen de organisatie. Zij verbinden de benodigde expertises en waarborgen alle stappen van het ontwikkelproces. Zo zorgen zij ervoor dat de organisatie het ontwikkelproces verantwoord en volgens de gestelde kaders uitvoert.</p> <p>Projectmanagers maken afspraken over de vereisten waar de organisatie aan moet voldoen. En zij prioriteren maatregelen die hiervoor nodig zijn. Zij houden contact met opdrachtgevers en verantwoordelijken over de projectdoelen en risico\u2019s.</p>"},{"location":"rollen/projectleider/#belangrijke-taken-van-een-projectleider","title":"Belangrijke taken van een projectleider","text":"<ul> <li>co\u00f6rdineert processen en stuurt alle betrokken partijen aan bij de ontwikkeling van algoritmes</li> <li>leidt projecten door de verschillende fasen van de levenscyclus van algoritmes, van probleemanalyse tot monitoring en beheer, of uitfaseren.</li> </ul>"},{"location":"rollen/projectleider/#projectleiders-zijn-bijvoorbeeld","title":"Projectleiders zijn bijvoorbeeld","text":"<ul> <li>Projectleider</li> <li>Product-owner</li> <li>Proceseigenaar</li> <li>IT-projectmanager</li> </ul>"},{"location":"rollen/projectleider/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"soorten-algoritmes-en-ai/","title":"Soorten algoritmes en AI","text":""},{"location":"soorten-algoritmes-en-ai/#wat-is-een-algoritme","title":"Wat is een algoritme?","text":"<p>Het soort algoritme bepaalt aan welke vereisten je moet voldoen. Werk je met simpele rekenregels of een AI-systeem?</p>"},{"location":"soorten-algoritmes-en-ai/#risico-van-ai-systemen","title":"Risico van AI-systemen","text":"<p>Je AI-systeem valt mogelijk onder een risicogroep uit de AI-verordening.</p>"},{"location":"soorten-algoritmes-en-ai/#impact-van-algoritmes","title":"Impact van algoritmes","text":"<p>Impactvolle algoritmes registreer je in het Algoritmeregister.</p>"},{"location":"soorten-algoritmes-en-ai/#generatieve-ai","title":"Generatieve AI","text":"<p>Overheden mogen werken met generatieve AI, zolang zij deze op een verantwoorde manier ontwikkelen, inkopen en gebruiken.</p>"},{"location":"soorten-algoritmes-en-ai/#geautomatiseerde-risicoselectie","title":"Geautomatiseerde risicoselectie","text":"<p>Algoritmen met geautomatiseerde risicoselectie zijn gevoelig en vereisen speciale aandacht.</p>"},{"location":"soorten-algoritmes-en-ai/#woordenlijst","title":"Woordenlijst","text":"<p>Uitleg van begrippen die je vaak tegenkomt op deze website.</p>"},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/","title":"Geautomatiseerde risicoselectie","text":""},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/#wat-is-geautomatiseerde-risicoselectie","title":"Wat is geautomatiseerde risicoselectie?","text":"<p>Geautomatiseerde risicoselectie helpt overheden om gerichter dossiers in beeld te brengen die extra aandacht nodig hebben, bijvoorbeeld voor het aanbieden van ondersteuning aan burgers bij aanvragen, het vroegtijdig corrigeren van fouten of het detecteren van misbruik of fraude met voorzieningen. Bij risicoselectie staat centraal dat algemene aannames worden toegepast op concrete gevallen. Op basis van criteria of \u2018profielen\u2019 worden dossiers ingedeeld in categorie\u00ebn, waaraan vervolgens bepaalde handelingen worden gekoppeld, bijvoorbeeld de beslissing om een dossier wel of niet nader te bekijken. Risicoselectie kan gebaseerd zijn op een enkel criterium of op een set van criteria.</p> <p>Het gehanteerde algoritme kan een eenvoudige geprogrammeerde beslisboom zijn, een geavanceerd statistisch model of een AI-systeem. Geautomatiseerde risicoselectie kan ook deels handmatig plaatsvinden, bijvoorbeeld in het geval dat na de geautomatiseerde risicoselectie een medewerker op basis van bepaalde criteria nader bekijkt welke dossiers in aanmerking komen voor behandeling.</p>"},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/#kaders-begrippen-en-definities","title":"Kaders, begrippen en definities","text":"<p>Risicoselectie wordt ook wel risicoprofilering genoemd. Er bestaan verschillende relevante kaders. Overheden moeten er in alle gevallen voor zorgen dat de inzet van risicoselectie in lijn is met het recht op non-discriminatie. Het College voor de Rechten van de Mens heeft het \u2018Toetsingskader risicoprofilering\u2019 opgesteld ter voorkoming van discriminatie op grond van ras en nationaliteit. Wanneer persoonsgegevens worden verwerkt is (ook) de AVG van toepassing. De Autoriteit Persoonsgegevens (AP) heeft in een advies geduid hoe geautomatiseerde risicoselectie zich verhoudt tot de AVG, met name het verbod op volledig geautomatiseerde besluitvorming.</p> <p>De AP beschrijft geautomatiseerde risicoselectie als een specifieke toepassing van profilering in de zin van de AVG in de context van publieke dienstverlening. De AVG definieert profilering als een geautomatiseerde verwerking waarbij aan de hand van persoonsgegevens bepaalde persoonlijke aspecten van een natuurlijke persoon worden ge\u00ebvalueerd, met name met de bedoeling om te analyseren of voorspellen.</p> <p>De AP licht toe dat een indeling van dossiers op basis van bepaalde kenmerken op zichzelf nog niet kwalificeert als profilering maar dat dit afhangt van het doel: er moet bij de selectie of categorisering sprake zijn van een zekere beoordeling van een persoon of dossier. Het College hanteert iets andere definities van profilering en risicoprofilering dan de AVG en de AP, omdat zijn toetsingskader zich toespitst op risicoselectie in de context van opsporings- of controlebevoegdheden.</p>"},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/#verantwoord-gebruik-door-de-overheid","title":"Verantwoord gebruik door de overheid","text":"<p>Risicoselectie helpt overheden om de beschikbare capaciteit voor publieke dienstverlening gerichter in te zetten, maar het kent ook risico\u2019s. Doordat risicoselectie altijd onderscheid maakt, is er een risico op het schenden van het recht op non-discriminatie. Wanneer de risicoselectie is gebaseerd op persoonsgegevens moeten overheden aandacht hebben voor het recht op privacy en het recht op bescherming van persoonsgegevens.</p> <p>Het is op grond van de AVG niet toegestaan om op basis van profilering volledig geautomatiseerd besluiten te nemen die rechtsgevolgen of aanmerkelijke effecten hebben voor natuurlijke personen. Daar is een specifieke wettelijke grondslag voor nodig. Wanneer deze ontbreekt kan geautomatiseerde risicoselectie enkel gebruikt worden om te beoordelen of acties jegens betrokkene nodig zijn, zoals navraag doen of informatie verzamelen. Eventuele rechtsgevolgen of aanmerkelijke effecten voor betrokkenen mogen pas tot stand komen na betekenisvolle menselijke tussenkomst. Het delen of bewaren van risicoselecties voor andere doeleinden zal al snel aanmerkelijke effecten tot gevolg hebben.</p> <p>Het spreekt voor zich dat geautomatiseerde risicoselectie alleen kan worden ingezet indien dit in lijn is met wettelijke vereisten en de grondrechten gerespecteerd worden. De hierboven genoemde kaders van de Autoriteit Persoonsgegevens en het College voor de Rechten van de Mens helpen om hieraan te voldoen. Daarnaast hebben de Eerste Kamer en Tweede Kamer verzocht om een aantal aanvullende waarborgen. Deze pagina geeft een overzicht van de belangrijkste plichten en aanvullende richtlijnen voor verantwoord gebruik van geautomatiseerde risicoselectie door overheden.</p>"},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/#belangrijkste-plichten-voor-overheden-die-geautomatiseerde-risicoselectie-gebruiken","title":"Belangrijkste plichten voor overheden die geautomatiseerde risicoselectie gebruiken","text":"<ul> <li>Voldoe aan bestaande wetgeving (zoals de Grondwet, anti-discriminatiewetgeving, de AVG en de AI-verordening).</li> <li>Wanneer voor geautomatiseerde risicoselectie persoonsgegevens worden verwerkt, is sprake van een hoog-risicoverwerking (evaluatie of scoretoekenning). Het uitvoeren van een DPIA is verplicht.</li> <li>De verwerking van persoonsgegevens moet transparant zijn: vermeld dit in de privacyverklaring en het verwerkingsregister van je organisatie.</li> </ul> <p>Tip</p> <p>De AVG verplicht organisaties om personen te informeren over de verwerking van persoonsgegevens. De AP adviseert om dit te doen in een online privacyverklaring. Op de website van de AP staat welke informatie in de privacyverklaring moet staan. Informatie over verwerkingen voor geautomatiseerde risicoselectie kunnen bijvoorbeeld op de volgende wijze worden vermeld:</p> <p>[Organisatie] verwerkt persoonsgegevens voor geautomatiseerde risicoselectie. Het doel van de geautomatiseerde risicoselectie is [invullen]. De wettelijke grondslag om hiervoor persoonsgegevens te verwerken is [invullen]. Geautomatiseerde risicoselectie wordt alleen gebruikt om dossiers of aanvragen te selecteren die extra aandacht nodig hebben van een medewerker. Eventuele besluiten worden altijd genomen door een medewerker.</p> <ul> <li>Het risico op discriminatie moet voorafgaand aan de inzet worden onderzocht en ondervangen en na ingebruikname periodiek worden onderzocht. Het gebruik van \u2018ras\u2019 (huidskleur, etniciteit en nationale of etnische herkomst) als selectiecriterium is altijd verboden bij risicoselectie ten behoeve van gerichte controle op normovertreding.</li> <li>Eventuele rechtsgevolgen of andere aanmerkelijke effecten mogen pas intreden na betekenisvolle menselijke tussenkomst tussen de selectie van een dossier als risico en een eventueel besluit. Raadpleeg de handvatten die de AP heeft opgesteld.</li> <li>Indien geautomatiseerde risicoselectie een rol speelde voorafgaand aan of in de voorbereidende fase van een Awb-besluit, moet dit uiterlijk in het besluit aan betrokkene kenbaar worden gemaakt.</li> <li>Wanneer een AI-systeem wordt ingezet voor geautomatiseerde risicoselectie, kan sprake zijn van een hoog-risico AI-systeem onder de AI-verordening. In dat geval gelden extra vereisten, zoals het uitvoeren van een mensenrechtenimpactassessment. Gebruik de beslishulp AI-verordening om te bepalen wat er in jouw situatie van toepassing is.</li> </ul>"},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/#aanvullende-richtlijnen-voor-overheden-die-geautomatiseerde-risicoselectie-gebruiken","title":"Aanvullende richtlijnen voor overheden die geautomatiseerde risicoselectie gebruiken","text":"<ul> <li>Ook indien geen sprake is van een hoog-risico AI-systeem, is het sterk aanbevolen om een mensenrechtenimpactassessment (bijvoorbeeld het IAMA uit te voeren en deze periodiek te herhalen en publiceren. Neem indien nodig preventieve en mitigerende maatregelen.</li> <li>Het uitgangspunt is dat geautomatiseerde risicoselectie-algoritmen worden gepubliceerd in het Algoritmeregister. Als deze algoritmen niet in categorie A (hoog-risico AI) vallen, vallen ze in categorie B (impactvolle algoritmen). Er kunnen redenen zijn om het algoritme of de gehanteerde criteria niet of slechts gedeeltelijk te publiceren; raadpleeg de handreiking. Licht in het register toe hoe wordt voldaan aan de wettelijke vereisten en de waarborgen voor geautomatiseerde risicoselectie zoals geadviseerd door de AP.</li> </ul> <p>Tip</p> <p>Geef in het Algoritmeregister bij de volgende velden aan hoe de inzet van geautomatiseerde risicoselectie voldoet aan de wettelijke vereisten en de waarborgen:</p> <ul> <li>Wettelijke basis: noem de wettelijke grondslag voor het doel waarvoor de geautomatiseerde risicoselectie wordt gebruikt en voor verwerking van de (persoons)gegevens.</li> <li>Risicobeheer: beschrijf in elk geval hoe de risico\u2019s op discriminatie zijn onderzocht en ondervangen.</li> <li>Menselijke tussenkomst: beschrijf hoe de uitkomsten door een mens gebruikt worden en hoe betekenisvolle menselijke tussenkomst tussen de risicoselectie en eventuele besluitvorming met rechtsgevolgen of aanmerkelijke effecten is gewaarborgd.</li> <li>Impacttoetsen: geef aan dat een IAMA en, indien van toepassing, een DPIA zijn uitgevoerd en voeg een link toe naar de documenten.</li> </ul> <ul> <li>Documenteer bij de inzet van geautomatiseerde risicoselectie de onderliggende besluitvorming over en verantwoording van het doel en de ontwikkeling van het model, de verantwoording van de gebruikte data en selectiecriteria, en de wijze waarop de waarborgen worden getroffen.</li> <li>Gebruik naast geautomatiseerde risicoselectie ook aselecte steekproeven om dossiers te selecteren. Dit helpt om tunnelvisie en een zelfversterkende feedbackloop tegen te gaan.</li> </ul> <p>Voorbeeld: RDI - Metrologie KDW</p> <p>Door mogelijke statistische patronen in historische inspecties kan het algoritme bias vertonen in risico-inschattingen, omdat een groot deel van de gegevens gebruikt voor training afkomstig zijn van deze historische inspecties. Om dit risico te mitigeren zijn een aantal maatregelen ge\u00efmplementeerd, waaronder: 50% van alle inspecties worden uitgevoerd op basis van willekeur, dus niet op basis van het algoritme.</p> <p>Bron: Algoritmeregister - Metrologie KDW</p> <p>Voorbeeld: Inspectie Onderwijs - Prestatiemonitor</p> <p>Omdat instellingen met hogere risicoscores vaker onderzocht worden, kan verkeerde risicoschatting ook blijven doorwerken (tunnelvisie). Daarom zijn we sinds september 2023 gestart met onderzoeken op locatie bij willekeurig geselecteerde onderwijsinstellingen. Hiermee kunnen we de kwaliteit van risicoschatting nog beter evalueren. Willekeurige selectie helpt namelijk bij het voorkomen van tunnelvisie.</p> <p>Bron: Algoritmeregister - Prestatiemonitor</p> <ul> <li>Zorg ervoor dat de risicoselectie geen invloed heeft op de inhoudelijke beoordeling van een dossier. De risicoselectie is een aanleiding voor verdere behandeling, maar zegt op zichzelf niets over een individuele casus. Neem maatregelen om bias, vooringenomenheid en tunnelvisie tegen te gaan.</li> </ul> <p>Tip</p> <p>Een algoritme kan de menselijke beoordelaar be\u00efnvloeden, onder meer wanneer mensen te veel vertrouwen op de output van een algoritme (automation bias). De AP heeft handvatten opgesteld voor betekenisvolle menselijke tussenkomst, onder meer om automation bias tegen te gaan, zoals: * Zorg ervoor dat dossiers via verschillende routes aan medewerkers worden voorgelegd, zowel op basis van risicoselectie als op basis van een aselecte steekproef. * Een mogelijkheid is om medewerkers dossiers \u2018blind\u2019 te laten beoordelen, waarbij de medewerker geen kennis heeft van de wijze waarop een dossier is geselecteerd voor behandeling (risicoselectie of willekeurig). Een nadeel hiervan is dat de medewerker de risicoselectie zelf niet kan controleren. In hoeverre dit een optie is hangt af van het proces waarvoor de risicoselectie wordt ingezet. * Indien \u2018blinde\u2019 beoordeling niet mogelijk of onwenselijk is, dan is het zaak om goed na te denken over de manier waarop de risicoselectie aan de medewerker wordt gepresenteerd. Zorg voor een neutrale interface, bedenk of het noodzakelijk is om een score of risicocategorie te presenteren en stimuleer eigen onderzoek van de medewerker. Test wat het effect is van de verschillende manieren waarop de informatie aan medewerkers wordt voorgelegd en overweeg wat de beste optie is. Blijf mogelijke automation bias na invoering van de risicoselectie monitoren.</p> <p>Bron: AP handvatten, hoofdstuk 2 'Technologie en ontwerp'</p> <p>Voorbeeld van blind beoordelen: UWV - risicoscan verwijtbare werkeloosheid</p> <p>Uit de risicoscan komt een selectie van signalen die medewerkers verder onderzoeken. Aan deze selectie wordt altijd een aantal (30%) willekeurig gekozen WW-aanvragen toegevoegd. De medewerker weet dus niet of een signaal uit de risicoscan komt of uit de aanvragen die willekeurig zijn toegevoegd. Zo zorgen we ervoor dat medewerkers niet worden be\u00efnvloed en kritisch blijven op situaties die zij moeten onderzoeken.</p> <p>Bron: Algoritmeregister - Risicoscan verwijtbare werkeloosheid</p> <p>Voorbeeld van blind beoordelen: CIBG - selectiemodel BIG herregistratie</p> <p>Een zorgverlener die de BIG herregistratie aanvraagt, hoeft deze aanvraag niet altijd met bewijsstukken te onderbouwen. Er wordt een willekeurige en gerichte steekproef uitgevoerd. Bij de gerichte steekproef zet het BIG-register een algoritme in. Het is voor de medewerkers die de bewijsstukken beoordelen niet inzichtelijk of de betreffende aanvraag in de willekeurige of gerichte selectie is gevallen. Dit om te voorkomen dat zij onbewust worden be\u00efnvloed door deze informatie.</p> <p>Bron: Algoritmeregister - Selectiemodel BIG herregistratie</p> <ul> <li>Stel een discriminatieprotocol vast voor de situatie dat er (een vermoeden van) discriminatie door een algoritme is geconstateerd en pas dit wanneer nodig toe.</li> </ul>"},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens</li> <li>Autoriteit Persoonsgegevens, advies artikel 22 AVG en geautomatiseerde selectietechnieken, 2024</li> <li>Autoriteit Persoonsgegevens, Rapportage AI- en algoritmerisico\u2019s Nederland (RAN), zomer 2024, hoofdstuk 4</li> <li>Autoriteit Persoonsgegevens, 2025, Handvatten betekenisvolle menselijke tussenkomst</li> <li>Kabinetsreactie AP-advies over artikel 22 AVG en geautomatiseerde selectie-instrumenten</li> <li>Impact Assessment Mensenrechten en Algoritmes</li> <li>Handreiking non-discriminatie by design</li> </ul>"},{"location":"soorten-algoritmes-en-ai/geautomatiseerde-risicoselectie/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"soorten-algoritmes-en-ai/generatieve-ai/","title":"Generatieve AI","text":""},{"location":"soorten-algoritmes-en-ai/generatieve-ai/#generatieve-ai","title":"Generatieve AI","text":"<p>Generatieve AI biedt veel kansen, maar ook valkuilen. Overheden mogen werken met generatieve AI, zolang zij deze op een verantwoorde manier ontwikkelen, inkopen en gebruiken. Om dit te doen, zijn er een aantal dingen om rekening mee te houden.</p>"},{"location":"soorten-algoritmes-en-ai/generatieve-ai/#wat-is-generatieve-ai","title":"Wat is generatieve AI?","text":"<p>Generatieve AI is een vorm van kunstmatige intelligentie. Je gebruikt prompts, opdrachten in natuurlijke taal aan de applicatie, om content te genereren. De output hiervan is dan bijvoorbeeld tekst, beeld of computercode. Generatieve AI valt onder de AI-modellen voor algemene doeleinden (general purpose AI, oftewel GPAI). Dat wil zeggen dat ze voor meerdere toepassingen gebruikt kunnen worden.</p> <p>Meestal draaien generatieve AI-toepassingen op large language models (LLMs). Dit houdt in dat de applicatie getraind is op grote hoeveelheden data, waaruit het heeft 'geleerd' om patronen en structuren te herkennen. Op basis van die patronen voorspelt het getrainde model het meest logische volgende element in bijvoorbeeld een zin. AI-chatbots, zoals ChatGPT, Gemini en Microsoft CoPilot, genereren hierdoor lopende zinnen en alinea's. Deze antwoorden zijn niet altijd betrouwbaar. Geeft een chatbot onjuiste informatie, dan heet dit 'hallucineren.'</p>"},{"location":"soorten-algoritmes-en-ai/generatieve-ai/#verantwoord-gebruik-door-de-overheid","title":"Verantwoord gebruik door de overheid","text":"<p>De overheid heeft \u00e9\u00e9n standpunt voor het gebruik van generatieve AI opgesteld. Dit standpunt geldt voor alle overheidsorganisaties.</p> <p>Generatieve AI biedt veel kansen. De overheid stimuleert overheidsorganisaties om deze technologie te gebruiken bij het zoeken naar nieuwe oplossingen voor problemen. Bijvoorbeeld als hulpmiddel voor brainstormen, softwareontwikkeling en tekstbewerking.</p> <p>Het is van belang dat generatieve AI op een juiste en verantwoorde manier wordt ingezet. De burger moet betrouwbare informatie krijgen en mag niet onrechtmatig worden behandeld wanneer de overheid generatieve AI inzet. Wees je bewust van de beperkingen en valkuilen van generatieve AI. Anders kan het vertrouwen van de burger worden geschaad.</p>"},{"location":"soorten-algoritmes-en-ai/generatieve-ai/#belangrijkste-plichten-voor-overheden-die-generatieve-ai-gebruiken","title":"Belangrijkste plichten voor overheden die generatieve AI gebruiken","text":"<ul> <li>Bestaande wetgeving wordt gevolgd (zoals de AI-verordening, de AVG en de Grondwet).</li> <li>Het doel om generatieve AI in te zetten is duidelijk geformuleerd.</li> <li>De generatieve AI-toepassing is verantwoord en veilig bevonden door middel van een risico-analyse (bijvoorbeeld een DPIA of IAMA). Dit geldt in het bijzonder wanneer er persoonsgegevens verwerkt worden.</li> <li>De inzet van generatieve AI is ingebed in het beleid.</li> <li>De juiste rollen zijn betrokken bij de besluitvorming over generatieve AI-inzet.</li> <li>De data die wordt gebruikt in de generatieve AI-toepassing is volledig, recent en kwalitatief goed.</li> <li>Er zijn specifieke afspraken gemaakt bij het inkopen van generatieve AI-modellen en/of -toepassingen over onder andere datadeling, dataretentie en het hertrainen van modellen.</li> <li>Er is altijd een menselijke tussenkomst bij de inzet van generatieve AI ('human-in-the-loop'). Besluiten worden niet puur en alleen op basis van de output van generatieve AI genomen.</li> <li>In het kader van AI-geletterdheid zijn medewerkers voldoende ge\u00efnformeerd over en opgeleid in het verantwoord gebruiken van generatieve AI.</li> <li>Er worden g\u00e9\u00e9n generatieve AI-toepassingen gebruikt die online voor iedereen toegankelijk zijn, zoals ChatGPT.</li> <li>Wanneer externe partijen diensten leveren aan de overheid en daarbij overheidsgegevens verwerken in generatieve AI, gelden deze vereisten en richtlijnen ook voor hen. Voorbeeld: adviesbureau Bereschot neemt interviews af met overheidsmedewerkers en gebruikt generatieve AI om deze te transcriberen en samen te vatten.</li> </ul>"},{"location":"soorten-algoritmes-en-ai/generatieve-ai/#verdere-tips","title":"Verdere tips","text":"<ul> <li>Het inkopen van generatieve AI-toepassingen heeft wat meer haken en ogen dan 'gewone' AI. Stel hiervoor goede inkoopvoorwaarden op.</li> <li>Werk bij voorkeur met een open toepassing of model, waar mogelijk ook met een open source-toepassing of model. Meer informatie hierover vind je op de website van het Open Source Initiative.</li> <li>Gebruik bij voorkeur een generatieve AI-toepassing die binnen Europa is ontwikkeld en wordt beheerd. Deze zijn vaak beter ingesteld op de Nederlandse taal en maken ons minder afhankelijk van niet-EU-landen.</li> <li>Onderzoek van tevoren welk model de beste resultaten oplevert. Voor specialistische of complexe onderwerpen kan dat bijvoorbeeld een kleiner model zijn.</li> <li>Gebruik generatieve AI niet om foto's, video's en voice-overs te genereren, zeker niet wanneer deze publiekelijk gedeeld worden.</li> <li>Houd er rekening mee dat je organisatie, wanneer je een AI-model voor algemene doeleinden gebruikt, te maken krijgt met vereisten uit de AI-verordening. Bekijk de tijdlijn met vereisten.</li> <li>Als je bij een Rijkskennisinstituut werkt, kun je ook gebruik maken van het RKI-kader voor generatieve AI (PDF) om je wat meer praktische handvatten te geven.</li> </ul>"},{"location":"soorten-algoritmes-en-ai/generatieve-ai/#bronnen","title":"Bronnen","text":"<ul> <li>Overheidsbreed standpunt voor de inzet van generatieve AI</li> <li>Overheidsbrede handreiking generatieve AI</li> <li>Open Source Initiative</li> <li>RKI-kader voor generatieve AI (PDF)</li> </ul>"},{"location":"soorten-algoritmes-en-ai/generatieve-ai/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"soorten-algoritmes-en-ai/impact-van-algoritmes/","title":"Impact van algoritmes","text":""},{"location":"soorten-algoritmes-en-ai/impact-van-algoritmes/#impact-van-algoritmes","title":"Impact van algoritmes","text":"<p>Als je algoritme impactvol is, kan het schade veroorzaken aan de maatschappij. Daarom zijn de regels strenger voor impactvolle dan voor niet-impactvolle algoritmes. Zo moet je impactvolle algoritmes publiceren in het Algoritmeregister.</p> <p>Naar het Algoritmeregister</p>"},{"location":"soorten-algoritmes-en-ai/impact-van-algoritmes/#impactvol","title":"Impactvol","text":"<p>Je algoritme is in elk geval impactvol in deze situaties:</p> <ul> <li>Je algoritme voldoet aan de definitie van een hoog-risico-AI-systeem, zoals vastgelegd in de AI-verordening.</li> <li>Je algoritme heeft invloed op een proces met rechtsgevolgen voor burgers of organisaties. Bijvoorbeeld het wel of niet krijgen van boetes of subsidies.</li> <li>Je algoritme heeft invloed op de manier waarop de overheid burgers of organisaties indeelt, of contact met hen zoekt. Bijvoorbeeld bij het inschatten van risico\u2019s of het signaleren van fraude.</li> <li>Je overheidsorganisatie vindt zelf dat het algoritme impact heeft op de maatschappij. Bijvoorbeeld omdat het algoritme ingewikkeld is, veel data gebruikt, vaak in de media komt of onderzocht wordt door een toezichthouder.</li> </ul> <p>Meer uitleg en voorbeelden vind je in de Handreiking Algoritmeregister.</p> <p>Tip</p> <p>Twijfel je of je algoritme impactvol is of niet? Beschouw het algoritme dan als impactvol.</p>"},{"location":"soorten-algoritmes-en-ai/impact-van-algoritmes/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/","title":"Risico van AI-systemen","text":""},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-van-ai-systemen","title":"Risico van AI-systemen","text":"<p>Valt je AI-systeem onder een risicogroep uit de Europese AI-verordening, dan gelden speciale regels. Hoe groter het risico voor de samenleving, hoe strenger de regels. Het hangt ervan af waarvoor je het AI-systeem gebruikt.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#risico-op-misleiding","title":"Risico op misleiding","text":"<p>In deze risicogroep vallen AI-systemen die je gebruikt voor:</p> <ul> <li>interactie met mensen, zoals AI-chatbots</li> <li>genereren van content, zoals afbeeldingen laten maken door Dall-E</li> </ul> <p>Hiervoor gelden verplichtingen op het gebied van transparantie. Gebruikers mogen niet denken dat zij te maken hebben met echte mensen of originele content.</p> <p>Zie AI-verordening, hoofdstuk IV.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#hoog-risico-ai-systeem","title":"Hoog-risico-AI-systeem","text":"<p>In deze risicogroep vallen AI-systemen die je gebruikt als veiligheidsonderdeel van bepaalde producten, of voor bepaalde diensten of processen.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#gebruik-als-veiligheidsonderdeel","title":"Gebruik als veiligheidsonderdeel","text":"<p>'Gebruiken als veiligheidsonderdeel' betekent dat je AI-systeem een belangrijke rol speelt in de veiligheid van een product. En dit product valt onder de harmonisatiewetgeving van de EU, zoals:</p> <ul> <li>machines</li> <li>speelgoed</li> <li>liften</li> <li>uitrusting en beveiligingssystemen voor plaatsen met ontploffingsgevaar</li> <li>radioapparatuur</li> <li>drukapparatuur</li> <li>pleziervaartuigen</li> <li>kabelbaaninstallaties</li> <li>gastoestellen</li> <li>medische hulpmiddelen</li> <li>hulpmiddelen voor het testen van menselijk materiaal (in-vitrodiagnostiek)</li> <li>auto-industrie</li> <li>luchtvaartindustrie</li> </ul> <p>Zie AI-verordening, bijlage I.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#gebruik-voor-bepaalde-diensten-of-processen","title":"Gebruik voor bepaalde diensten of processen","text":"<p>Dit zijn AI-systemen die je gebruikt voor:</p> <ul> <li>Biometrie, zoals het herkennen of indelen van mensen op basis van hun vingerafdruk, gezicht of andere lichamelijke kenmerken.</li> <li>Kritieke infrastructuur, zoals het veilig houden van digitale netwerken en verkeersnetwerken en het leveren van elektriciteit, water, gas en warmte.</li> <li>Onderwijs en beroepsopleiding, zoals het bepalen welke studenten je toelaat en het beoordelen van hun prestaties of gedrag.</li> <li>Werkgelegenheid, personeelsbeheer en toegang tot zelfstandige arbeid, zoals het werven en selecteren van mensen, besluiten nemen die invloed hebben op hun contract en het beoordelen van hun prestaties of gedrag.</li> <li>Essenti\u00eble particuliere en openbare diensten, zoals bepalen wie recht heeft op uitkeringen, gezondheidszorg en andere belangrijke diensten en wie noodhulp krijgt van politie, brandweer en ambulance, het beoordelen van iemands financi\u00eble situatie, fraude opsporen en het bepalen van risico\u2019s en prijzen voor levensverzekeringen en ziektekostenverzekeringen.</li> <li>Rechtshandhaving, zoals iemands kans inschatten om slachtoffer of dader te worden, het gebruik van een leugendetector, het beoordelen van bewijsmateriaal en het opsporen van verdachten.</li> <li>Migratie, asiel en grenzen, zoals inschatten wat de kans is dat iemand gevaarlijk of illegaal is, het behandelen van aanvragen en klachten en het herkennen of opsporen van mensen.</li> <li>Rechtsbedeling en democratische processen, zoals het uitleggen van de wet aan een rechtbank, gerechtshof of de Hoge Raad, advies geven bij een geschil of het be\u00efnvloeden van de uitslag van een verkiezing.</li> </ul> <p>Zie AI-verordening, bijlage III.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#verboden-ai","title":"Verboden AI","text":"<p>Deze risicogroep bestaat uit soorten AI-praktijken die volgens de AI-verordening verboden zijn.</p> <p>Dit zijn AI-systemen die:</p> <ul> <li>misleiden</li> <li>misbruik maken van kwetsbaarheden of gevoelige situaties, zoals het overhalen van mensen met schulden om iets te kopen</li> <li>sociale scores bijhouden voor gedrag van mensen en hen hiervoor straffen</li> <li>beoordelen hoe groot het risico is dat iemand een strafbaar feit pleegt</li> <li>afbeeldingen van gezichten \u2018scrapen\u2019 (verzamelen) via internet of bewakingscamera\u2019s en deze opslaan in een databank</li> <li>emoties herkennen van mensen op hun werkplek of op school</li> <li>biometrisch categoriseren: mensen indelen in gevoelige categorie\u00ebn zoals ras en geloof, op basis van lichamelijke kenmerken zoals huidskleur</li> <li>biometrisch identificeren op afstand voor rechtshandhaving, zoals gezichten herkennen via camera\u2019s op een openbaar plein (hiervoor gelden uitzonderingen in ernstige situaties zoals ontvoeringen en terrorisme)</li> </ul> <p>Zie AI-verordening, artikel 5.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#voldoen-aan-de-ai-verordening","title":"Voldoen aan de AI-verordening","text":"<p>Als je AI-systeem onder een risicogroep valt, moet je voldoen aan vereisten uit de AI-verordening. Bekijk de tijdlijn met vereisten of gebruik de beslishulp AI-verordening.</p>"},{"location":"soorten-algoritmes-en-ai/risico-van-ai-systemen/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"soorten-algoritmes-en-ai/wat-is-een-algoritme/","title":"Wat is een algoritme?","text":""},{"location":"soorten-algoritmes-en-ai/wat-is-een-algoritme/#wat-is-een-algoritme","title":"Wat is een algoritme?","text":"<p>Met een algoritme bedoelen we een set regels en instructies die een computer uitvoert, met als doel: problemen oplossen, vragen beantwoorden, taken of processen uitvoeren en/of besluiten nemen. Dit kunnen simpele rekenregels zijn. Of zelflerende algoritmes en AI-systemen.</p>"},{"location":"soorten-algoritmes-en-ai/wat-is-een-algoritme/#rekenregels","title":"Rekenregels","text":"<p>Rekenregels (ook wel: regelgebaseerde algoritmes) zijn de meest eenvoudige algoritmes. Dit zijn door mensen bedachte regels die het computersysteem precies moet opvolgen: als x gebeurt, dan doe je y.</p> <p>Rekenregels:</p> <ul> <li>zijn expliciet geprogrammeerd en bedacht door mensen</li> <li>bestaan uit vaste stappen om een taak uit te voeren</li> </ul> <p>Het bevatten van rekenregels maakt van een systeem geen AI. Rekenregels kunnen wel onderdeel zijn van een AI-systeem.</p>"},{"location":"soorten-algoritmes-en-ai/wat-is-een-algoritme/#voorbeelden","title":"Voorbeelden","text":"<ul> <li>Eenvoudige chatbots die burgers advies geven op basis van door mensen bedachte beslisbomen.</li> <li>Ondersteuning berekening uitkering dat adviseert over uitkeringen, op basis van door mensen bedachte beslisbomen.</li> <li>Prestatiemonitor dat risicoscores berekent van scholen, op basis van door mensen bedachte regels.</li> </ul>"},{"location":"soorten-algoritmes-en-ai/wat-is-een-algoritme/#zelflerende-algoritmes","title":"Zelflerende algoritmes","text":"<p>Zelflerende algoritmes zijn algoritmes die zichzelf trainen. Dit proces heet machinelearning. Hierdoor leren computers van data, zonder dat mensen dit precies zo programmeren. Ze zoeken bijvoorbeeld naar patronen of doen voorspellingen. Dit is een veel voorkomende vorm van AI.</p> <p>Zelflerende technieken zijn in elk geval:</p> <ul> <li>Supervised learning (gecontroleerd leren): Je algoritme leert van gegevens die je labelt met informatie. Je biedt bijvoorbeeld foto\u2019s aan met de labels: dit is wel een kat, dit is geen kat. Voorbeeld: Virtuele assistent Gem.</li> <li>Unsupervised learning (ongecontroleerd leren): Je laat het algoritme zelf patronen en structuren ontdekken in ongestructureerde gegevens zonder labels. Je biedt bijvoorbeeld foto\u2019s aan van dieren die het algoritme zelf moet groeperen. Voorbeeld: Polis voor participatieplatformen.</li> <li>Reinforcement learning (bekrachtiginsleren): Het algoritme leert door straf en beloning. Het doel is zo hoog mogelijk scoren in zo min mogelijk tijd. Je geeft bijvoorbeeld punten als het algoritme foto\u2019s sorteert die op katten lijken. Dit proces is vergelijkbaar met hoe mensen leren door ervaring. Bij reinforcement learning leert het AI-model autonoom bij. Bij online reinforcement learning kan het model in productie ook nog continu zichzelf bijstellen. Je kunt er ook voor kiezen dit alleen in trainingsfase te doen, en het model 'bevroren' in te zetten. Voorbeeld van reinforcement learning: I-VRI voor verkeerslichten.</li> <li>Deep learning: Supervised, unsupervised of reinforcement learning gecombineerd met diepe neurale netwerken. Dit zijn kunstmatige neurale netwerken met veel verschillende lagen. Hierdoor kun je nog ingewikkeldere problemen oplossen. Voorbeeld: Geautomatiseerde gezichtsvergelijking bij het RNI-inschrijfproces.</li> </ul>"},{"location":"soorten-algoritmes-en-ai/wat-is-een-algoritme/#ai-systeem","title":"AI-systeem","text":"<p>Met een AI-systeem bedoelen we een systeem dat kunstmatig intelligent is volgens de Europese AI-verordening. Een belangrijk kenmerk van AI-systemen is hun inferentievermogen. Dat betekent dat een AI-systeem dat op een bepaalde manier is getraind een voorspelling, aanbeveling of ander resultaat kan genereren op basis van nieuwe data die geen onderdeel uitmaakten van de trainingsdata.</p> <p>Je systeem zal in de meeste gevallen onder de definitie van AI-systeem vallen als gebruik wordt gemaakt van:</p> <ul> <li>supervised learning</li> <li>unsupervised learning</li> <li>reinforcement learning</li> </ul> <p>Als je systeem alleen nauwkeurige regels volgt ('als dit, dan dat') die rechtstreeks terug te herleiden zijn op bestaande wet- en regelgeving en die zonder machine learning tot stand zijn gekomen, dan is er geen sprake van een AI-systeem.</p> <p>Tip</p> <p>Twijfel je of je algoritme onderdeel is van een AI-systeem? Volg de handreiking Identificatie AI-systemen AI-verordening. Kom je er niet uit? Raadpleeg een expert. Of beschouw het systeem voor de zekerheid als een AI-systeem.</p>"},{"location":"soorten-algoritmes-en-ai/wat-is-een-algoritme/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/","title":"Voldoen aan wetten en regels","text":""},{"location":"voldoen-aan-wetten-en-regels/#voldoen-aan-wetten-en-regels","title":"Voldoen aan wetten en regels","text":""},{"location":"voldoen-aan-wetten-en-regels/#vereisten-voor-de-overheid","title":"Vereisten voor de overheid","text":"<p>Overzicht van de belangrijkste vereisten voor overheden die algoritmes of AI-systemen ontwikkelen of gebruiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/#aanbevolen-maatregelen","title":"Aanbevolen maatregelen","text":"<p>Maatregelen waarmee je kunt voldoen aan de vereisten voor overheden. Deze maatregelen zijn niet verplicht.</p>"},{"location":"voldoen-aan-wetten-en-regels/#hulpmiddelen","title":"Hulpmiddelen","text":"<p>Hulpmiddelen waarmee je kunt voldoen aan de vereisten voor overheden. Deze hulpmiddelen zijn niet verplicht.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/","title":"Hulpmiddelen","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/#hulpmiddelen","title":"Hulpmiddelen","text":"<p>Overzicht van aanbevolen hulpmiddelen voor het verantwoord ontwikkelen, gebruiken, beoordelen en monitoren van algoritmes en AI-systemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/#overzicht-hulpmiddelen","title":"Overzicht hulpmiddelen","text":"ZoekenOnderwerpenbias-en-non-discriminatiedataduurzaamheidfundamentele-rechtengovernancegrondrechtenmenselijke-controleprivacy-en-gegevensbeschermingpublieke-inkooptechnische-robuustheid-en-veiligheidtransparantieHulpmiddelenOnderwerpenAI-Geletterdheid Self-assessment                  governance              AI Impact Assessment (AIIA)                  privacy-en-gegevensbescherming                               duurzaamheid                               fundamentele-rechten                               technische-robuustheid-en-veiligheid                               transparantie                               menselijke-controle                               data              Assessment List for Trustworthy Artificial Intelligence (ALTAI)                  privacy-en-gegevensbescherming                               duurzaamheid                               fundamentele-rechten                               technische-robuustheid-en-veiligheid                               transparantie                               menselijke-controle                               data              Baseline Informatiebeveiliging Overheid (BIO)                  technische-robuustheid-en-veiligheid              De Ethische Data Assistent                  data                               fundamentele-rechten              Data Protection Impact Assessment                  privacy-en-gegevensbescherming              Impact Assessment Mensenrechten en Algoritmes                  fundamentele-rechten                               transparantie              Impactanalyse AI-verordening                  governance              Algoritmeregister                  transparantie              Blauwdruk AI-geletterdheidsprogramma                  governance              Factsheet AI-geletterdheid voor bestuurders                  governance              Factsheet AI-geletterdheid voor inkopers                  governance                               publieke-inkoop              Factsheet AI-verordening voor bestuurders                  governance              The Fairness Handbook                  bias-en-non-discriminatie                               fundamentele-rechten              Framework for Meaningful Engagement                  menselijke-controle                               transparantie                               fundamentele-rechten              Governancekader AI en algoritmen voor en door gemeenten                  governance              Handreiking inventarisatie, identificatie en classificatie AI-systemen                  transparantie                               governance              Handreiking non-discriminatie by design                  bias-en-non-discriminatie                               fundamentele-rechten              Inkoopvoorwaarden                  publieke-inkoop              Onderzoekskader algoritmes Auditdienst Rijk 2023                  governance              Roadmap inwerkingtreding AI-verordening                  governance              Standaarden                  data                               bias-en-non-discriminatie                               duurzaamheid                               governance                               menselijke-controle                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid                               transparantie                               publieke-inkoop                               grondrechten              Toetsingskader Algoritmes Algemene Rekenkamer                  governance              Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit                  bias-en-non-discriminatie                               fundamentele-rechten              Wettelijke vereisten AI-geletterdheid                  governance"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/#richtlijnen-en-andere-hulpmiddelen","title":"Richtlijnen en andere hulpmiddelen","text":"<p>Met hulpmiddelen bedoelen we hulpmiddelen voor verantwoord en effectief gebruik van algoritmes en AI-systemen, zoals:</p> <ul> <li>richtlijnen</li> <li>standaarden</li> <li>leidraden</li> <li>handboeken</li> </ul> <p>Deze hulpmiddelen helpen je bij het op een rij zetten, beoordelen en verbeteren van de kenmerken, prestaties, effecten en risico\u2019s van algoritmes en AI.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/#hoe-we-hulpmiddelen-selecteren","title":"Hoe we hulpmiddelen selecteren","text":"<p>Hulpmiddelen die we aanbevelen, zijn:</p> <ul> <li>relatief bekend onder ambtenaren</li> <li>in gebruik door overheid, wetenschap of industrie</li> <li>positief beoordeeld door gebruikers</li> <li>geschikt voor algoritmes of AI-systemen van overheden</li> </ul> <p>Staat een instrument niet in onze selectie, dan kan het nog steeds een goed instrument zijn voor jouw organisatie. Er zijn dus meer hulpmiddelen mogelijk. We maken een selectie om 2 redenen:</p> <ul> <li>Een selectie is duidelijker. Als we alle hulpmiddelen aanbieden, is het voor gebruikers moeilijker te bepalen welk instrument of welke combinatie het meest geschikt is. Daarvoor lijken de hulpmiddelen te veel op elkaar.</li> <li>Een selectie kunnen we controleren op kwaliteit. We kunnen niet alle hulpmiddelen controleren.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/#sommige-hulpmiddelen-zijn-verplicht","title":"Sommige hulpmiddelen zijn verplicht","text":"<p>Als een instrument verplicht is, staat dit er duidelijk bij. Een verplicht hulpmiddel is bijvoorbeeld de Data protection impact assessment (DPIA).</p> <p>De meeste hulpmiddelen zijn niet verplicht. Bepaal zelf of je er gebruik van maakt.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/","title":"AI-Geletterdheid Self-assessment","text":"<p>OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesJuristOntwikkelaarGovernance</p> <p>Download hier de AI-Geletterdheid Self-assessment (.xlsx)</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#hulpmiddel","title":"Hulpmiddel","text":"<p>Om op een verantwoorde manier om te gaan met Artificial Intelligence (AI)-systemen, is een bepaald niveau van AI-geletterdheid belangrijk. Zo stelt Artikel 4 van de AI-Verordening dat binnen een organisatie waar gewerkt wordt met AI-systemen, iedereen een bepaalde mate van AI-geletterd is, afhankelijk van de context.</p> <p>Verschillende mensen hebben verschillende niveaus van AI kennis nodig om binnen hun rol onderbouwde beslissingen te kunnen maken met betrekking tot AI-systemen. Binnen de Rijksoverheid zijn kerncompetenties vastgesteld die sturing bieden in wat deze nodige kennis op verschillende niveaus inhoudt. Deze self-assessment is ontwikkeld om na te gaan of je al op het voor jou benodigde niveau zit, en wat je kunt doen om daar te komen. Denk in dat geval aan opleidingen of e-learning modules, maar dit is uit te breiden met generiekere adviezen of verwijzingen naar relevante wetteksten of documenten.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#werking","title":"Werking","text":"<p>1. Op het eerste tabblad kan men een rol binnen de organisatie selecteren via het drop-downmenu. Daarnaast verschijnt automatisch het AI-geletterdheidsniveau dat bij deze rol past.</p> <ol> <li> <p>Door een rol te selecteren wordt in het volgende blad automatisch een vragenlijst gegenereerd. Afhankelijk van het passende niveau kunnen dit meer of minder vragen zijn.\u00a0</p> </li> <li> <p>Na het invullen worden de antwoorden in het blad \u00b4Uitslag\u00b4 verwerkt tot een overzicht van de kennis per competentie, en krijg je een overzicht te zien van welke cursussen of e-learnings voor jou relevant kunnen zijn om je kennis te vergroten.</p> </li> </ol> <p>Deze self-assessment is modulair. De gekoppelde cursussen die worden aanbevolen, kunnen worden uitgebreid met organisatie-specifiek leeraanbod, waardoor bij de uiteindelijke uitslag medewerkers specifiek kunnen worden geholpen binnen de eigen organisatie-context.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#ai-geletterdheid","title":"AI-geletterdheid","text":"<p>Al-geletterdheid moet betrokkenen in staat stellen om onderbouwde beslissingen te kunnen maken met betrekking tot Al-systemen. Afhankelijk van iemands rol en het toepassingsgebied van het Al-systeem, bestaat een toereikend niveau van Al-geletterdheid uit inzicht in:</p> <ul> <li>De correcte toepassing van technische elementen tijdens de ontwikkeling van Al-systemen.</li> <li>De maatregelen die genomen moeten worden tijdens het gebruik van een Al-systeem.</li> <li>De juiste interpretatie van de output van Al-systemen.</li> <li>De impact van Al-besluiten op natuurlijke personen.</li> <li>De kennis die nodig is om naleving en handhaving van de Al-verordening mogelijk te maken.</li> </ul> <p>Bekijk de wettelijke vereisten voor AI-gelleterdheid hier. Bekijk ook de factsheets voor bestuurders of inkopers, met meer informatie over AI-geletterdheid specifiek voor deze rollen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-04Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheidorg-16Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AIorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AI-Geletterdheid-self-assessment/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AIIA/","title":"AI Impact Assessment (AIIA)","text":"<p>ProbleemanalyseOntwerpVerificatie en validatieMonitoring en beheerOntwikkelenJuristOntwikkelaarProjectleiderBeleid en adviesPrivacy en gegevensbeschermingDuurzaamheidFundamentele rechtenTechnische robuustheid en veiligheidTransparantieMenselijke controleData</p> <p>Direct naar het AIIA</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AIIA/#hulpmiddel","title":"Hulpmiddel","text":"<p>Het AIIA is een praktisch hulpmiddel en begeleidt het denkproces achter AI-ontwikkeling en -inzet, met als doel de verantwoording, kwaliteit en reproduceerbaarheid van AI-inzet te vergroten. Het AIIA kijkt naar risico's met betrekking tot dataverzameling, het AI-model, de algoritmiek en houdt rekening met geldende wet- en regelgeving. Een ingevuld AIIA maakt de gemaakte afwegingen om een AI-systeem wel of niet te gebruiken inzichtelijk. Het AIIA wordt ingevuld door een multi-disciplinair team.</p> <p>Het AIIA bestaat uit twee delen. Deel A gaat in op de afwegingen voor het gebruik van een AI-systeem: wat is het doel en de verwachte effecten? Met deze informatie wordt een afweging gemaakt voor de toepassing van het AI-systeem en eventuele maatregelen. Op deze manier is de ethische discussie rondom de wenselijkheid van de toepassing aantoonbaar. Deel B gaat over de inrichting, implementatie en het gebruik van het AI-systeem.</p> <p>Het AIIA kan toegepast worden in elke fase van ontwikkeling en inkoop van een AI-systeem, maar heeft de meeste toegevoegde waarde indien het vanaf de start van een AI-project wordt gebruikt. De gedachte is dat de diepgang en detailniveau van invullen past bij het stadium van ontwikkeling en risico\u2019s van de applicatie. Bij een AI-idee hoeft bijvoorbeeld nog niet alles duidelijk te zijn, maar wel inzicht in waar mogelijke knelpunten liggen.</p> <p>Het AIIA bestaat uit:</p> <ul> <li>AI Impact Assessment (Nederlandse en Engelse versie)</li> <li>Invultemplate Nederlands (docx, 46 KB) of Invultemplate Engels (docx, 45 KB)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AIIA/#relevantie","title":"Relevantie","text":"<p>Het AIIA is praktisch ingestoken en is ontwikkeld samen met de organisatie. Hierdoor is de AIIA goed toepasbaar in verschillende trajecten. Daarnaast is de AIIA in 2024 vernieuwd (een eerste versie verscheen in 2022) waarbij de laatste versie van de AI Act en geldige wet en regelgeving ge\u00efntegreerd is, waardoor het een compleet document is geworden dat verschillende aspecten van een AI systeem behandelt. Het AIIA kan in elke fase van een project worden ingezet. Zoek hierbij de diepgang en het detailniveau dat past bij het stadium van ontwikkeling en de risico\u2019s van de applicatie. Het AIIA zet je bijvoorbeeld in als quick-scan om te onderzoeken of een AI-idee toegevoegde waarde heeft. Ook kan het gebruikt worden bij het maken van een projectplan zodat alle relevante aspecten, zoals bijvoorbeeld technische robuustheid, impact en communicatie meegenomen worden.</p> <p>Het AIIA heeft enige overlap met het IAMA. Het AIIA is echter specifiek voor AI ontwikkeld, waar het IAMA toepasbaar is op alle soorten algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AIIA/#auteur","title":"Auteur","text":"<p>Het AIIA is ontwikkeld door het Ministerie van Infratsructuur en Waterstaat (IenW). Het is opgesteld in nauwe samenwerking met de datalabs van de Inspectie Leefomgeving en transport en Rijkswaterstaat. Het is een verplicht instrument binnen het Ministerie van IenW, maar wordt inmiddels ook breder gebruikt.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/AIIA/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelpba-03Beschrijf waarom een algoritme het probleem moet oplossenowp-11Beschrijf welke data gebruikt wordt voor de beoogde toepassingowp-07Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingimp-03Richt bij besluitvorming betekenisvolle menselijke tussenkomst inimp-10Spreek af hoe de organisatie omgaat met privacy-verzoekenmon-02Beveilig de softwarepba-05Beschrijf de wettelijke grondslag voor de inzet van het algoritmeowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magdat-03Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedureowp-08Maak een lijst van de meest kwetsbare groepen en bescherm hen extraimp-04Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregisterver-03Toets het algoritme op bias en voer een rechtvaardigingstoets uitver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/ALTAI/","title":"Assessment List for Trustworthy Artificial Intelligence (ALTAI)","text":"<p>OntwerpOntwikkelenJuristOntwikkelaarProjectleiderBeleid en adviesPrivacy en gegevensbeschermingDuurzaamheidFundamentele rechtenTechnische robuustheid en veiligheidTransparantieMenselijke controleData</p> <p>Direct naar de ALTAI</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/ALTAI/#hulpmiddel","title":"Hulpmiddel","text":"<p>In 2019 publiceerde de High-Level Expert Group on Artificial Intelligence (AI HLEG), opgericht door de Europese Commissie, de Ethics Guidelines for Trustworthy Artificial Intelligence. De ALTAI is een hulpmiddel dat ontwikkelaars en organisaties helpt hun AI-systemen te beoordelen, gebaseerd op deze Ethics Guidelines for Trustworthy Artificial Intelligence. Het helpt te bepalen of het AI-systeem dat wordt ontwikkeld, ingezet, aangeschaft of gebruikt, voldoet aan zeven vereisten van betrouwbare AI:</p> <ul> <li>Menselijke tussenkomst en toezicht;</li> <li>Technische robuustheid en veiligheid;</li> <li>Privacy en gegevensbeheer;</li> <li>Transparantie;</li> <li>Diversiteit, non-discriminatie en eerlijkheid;</li> <li>Maatschappelijk en ecologisch welzijn;</li> <li>Verantwoordelijkheid</li> </ul> <p>De ALTAI is bedoeld voor zelfevaluatie. Het hulpmiddel is verankerd in de bescherming van de fundamentele rechten van mensen, de term die in de Europese Unie wordt gebruikt om te verwijzen naar de mensenrechten die zijn vastgelegd in de EU-verdragen, het Handvest van de Grondrechten, en het internationale mensenrechtenrecht.</p> <p>De ALTAI is bedoeld voor flexibele inzet: organisaties kunnen gebruikmaken van de relevante onderdelen van dit hulpmiddel voor een specifiek AI-systeem of er elementen aan toevoegen die zij passend achten, rekening houdend met de sector waarin zij opereren. Het helpt organisaties te begrijpen wat betrouwbare AI inhoudt, in het bijzonder welke risico's een AI-systeem zou kunnen meebrengen en hoe deze risico's kunnen worden geminimaliseerd terwijl de kansen van AI worden gemaximaliseerd. Organisaties halen het meeste waarde uit de ALTAI door de gestelde vragen uitgebreid te beantwoorden, die zijn bedoeld om zorgvuldige reflectie te stimuleren en passende vervolgacties aan te formuleren, en een organisatiecultuur te bevorderen die zich inzet voor de ontwikkeling van betrouwbare AI-systemen. Het vergroot het bewustzijn van de mogelijke impact van AI op de samenleving, het milieu, consumenten, werknemers en burgers (in het bijzonder kinderen en mensen die tot gemarginaliseerde groepen behoren).</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/ALTAI/#relevantie","title":"Relevantie","text":"<p>De ALTAI biedt houvast bij het evalueren van in hoeverre een betreffend AI-systeem voldoet aan de zeven vereisten van betrouwbare AI, zoals geformuleerd door de EU. Deze zeven vereisten en de ALTAI hebben samen de basis gevormd voor de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/ALTAI/#auteur","title":"Auteur","text":"<p>De ALTAI is ontwikkeld door de High-Level Expert Group on Artificial Intelligence van de Europese Commissie.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/ALTAI/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelpba-03Beschrijf waarom een algoritme het probleem moet oplossenowp-07Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingimp-03Richt bij besluitvorming betekenisvolle menselijke tussenkomst inimp-10Spreek af hoe de organisatie omgaat met privacy-verzoekenmon-02Beveilig de softwarepba-05Beschrijf de wettelijke grondslag voor de inzet van het algoritmeowp-03Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit magdat-03Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedureowp-08Maak een lijst van de meest kwetsbare groepen en bescherm hen extraimp-04Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregisterver-03Toets het algoritme op bias en voer een rechtvaardigingstoets uitver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houdenowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/BIO/","title":"Baseline Informatiebeveiliging Overheid (BIO)","text":"<p>OntwerpImplementatieMonitoring en beheerJuristOntwikkelaarProjectleiderTechnische robuustheid en veiligheid</p> <p>Direct naar de BIO</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/BIO/#hulpmiddel","title":"Hulpmiddel","text":"<p>De BIO is het basisnormenkader voor informatiebeveiliging voor alle overheidslagen, waardoor een gezamenlijke norm voor informatiebeveiliging is ontstaan. Het gebruik van 1 normenkader voor de gehele overheid biedt een aantal voordelen:</p> <ul> <li>Het versterken van de informatieveiligheid door betere afstemming binnen ketens van overheden en andere partijen;</li> <li>Administratieve lastenverlichting bij overheid en bedrijven, zowel afnemers als leveranciers, door uniforme beveiligingsnormen bij de overheid;</li> <li>Aansluiting bij internationale regelgeving en standaarden;</li> <li>Vermindering van onderhoudskosten.</li> </ul> <p>Op dit moment wordt er gewerkt aan de BIO2.0. Omdat de BIO2.0 pas eind 2024 van kracht zal worden, is op 1 juni 2023 de handreiking BIO2.0-opmaat opgeleverd. In deze handreiking is de indeling van de controls, doelstellingen en overheidsmaatregelen in deel 2 van de BIO in lijn gebracht met de 2022-versie van de ISO-27002. Naast tekstuele wijzigingen, zijn ook een aantal overheidsmaatregelen geactualiseerd, vanwege nieuwe dreigingen, zoals ransomware. Naast de verhoging van de feitelijke veiligheid, wordt ook geanticipeerd op aanpassingen die in de BIO2.0 zullen worden doorgevoerd. Overheidsorganisaties doen er goed aan deze actualisatie in hun beveiliging door te voeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/BIO/#relevantie","title":"Relevantie","text":"<p>Iedere overheidsorganisatie is verplicht de BIO in te voeren. De BIO is in december 2018 vastgesteld door de ministerraad voor de Rijksoverheid. Daarvoor was door de gemeenten, waterschappen en provincie reeds besloten tot invoering van de BIO. De overheidslagen zijn per 1 januari 2019 gestart met de implementatie van de BIO. Iedere overheidslaag heeft daarvoor zelf een implementatiepad opgesteld. De minister van BZK heeft bepaald dat in het digitale verkeer met het Rijk de BIO wordt gehanteerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/BIO/#auteur","title":"Auteur","text":"<p>De interbestuurlijke werkgroep-BIO draagt zorg voor het onderhoud op de BIO. Onder het voorzitterschap van BZK zijn in de werkgroep de 4 overheidskoepels vertegenwoordigd: CIO Rijk, Vereniging Nederlandse Gemeenten, InterProvinciaal Overleg en Unie van Waterschappen. Verder bestaat de werkgroep uit een aantal grote uitvoeringsorganisaties, het Forum Standaardisatie, het Nationaal Cybersecurity Centrum en het Centrum voor Informatiebeveiliging &amp; Privacybescherming. Besluitvorming over de BIO vindt plaats in het kern-IBO, waarin onder voorzitterschap van BZK vertegenwoordigers van de 4 overheidskoepels zitting hebben.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/BIO/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-11Maak afspraken over het beheer van gebruikersorg-13Maak afspraken over het beheer van wachtwoordenorg-14Maak afspraken over het wijzigen van de codeowp-34Voorkom kwetsbaarheden die ge\u00efntroduceerd worden in de supply-chain van het algoritmeowk-01Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019owk-04Maak logbestanden waarin staat wie wanneer toegang had tot de data en de codeowk-09Ontwerp en train het algoritme om bestand te zijn tegen (cyber)aanvallenowk-10Zorg dat (gevoelige) informatie niet kan lekken op basis van de output van het algoritmemon-01Maak back-ups van algoritmesmon-02Beveilig de softwaremon-03Maak een noodplan voor beveiligingsincidentenmon-08Controleer regelmatig of een algoritme voldoende weerbaar is tegen bekende aanvallen"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DEDA/","title":"De Ethische Data Assistent","text":"<p>ProbleemanalyseOntwerpBeleid en adviesJuristOntwikkelaarProjectleiderDataFundamentele rechten</p> <p>Direct naar DEDA</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DEDA/#hulpmiddel","title":"Hulpmiddel","text":"<p>DEDA is ontwikkeld door de Data School van de Universiteit Utrecht en bestaat uit een toolkit die helpt bij het in kaart brengen van ethische kwesties bij dataprojecten, bij het documenteren van het beraadslagingsproces en bij de bevordering van de verantwoording aan de diverse stakeholders en het publiek.</p> <p>DEDA bestaat uit een poster voor brainstormsessies, een interactieve vragenlijst en een handleiding. Alle tools zijn gepubliceerd door de Data School van de Universiteit Utrecht.</p> <p>DEDA bevordert verantwoordingsplicht, onderwijst gebruikers, communiceert problemen en ondersteunt projectmanagement.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DEDA/#relevantie","title":"Relevantie","text":"<p>DEDA is een belangrijk hulpmiddel omdat het helpt bij de vroege identificatie en bespreking van ethische kwesties in dataprojecten. Net als de IAMA, biedt DEDA een gestructureerde aanpak om de implicaties van datagebruik en algoritmische besluitvorming te beoordelen. Het ondersteunt overheden bij het naleven van het zorgvuldigheidsbeginsel en maakt ethische afwegingen inzichtelijk als onderdeel van de besluitvorming. Door een interactieve vragenlijst en documentatie bevordert DEDA verantwoordingsplicht en transparantie.</p> <p>DEDA stimuleert interdisciplinaire samenwerking en helpt beleidsmakers, juristen en ontwikkelaars de ethische dimensies van data-analyse beter te begrijpen. Dit draagt bij aan zorgvuldige en rechtvaardige datagedreven oplossingen binnen de publieke sector. DEDA draagt bij aan transparantie en uitlegbaarheid van datagebruik, essentieel voor publiek vertrouwen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DEDA/#auteur","title":"Auteur","text":"<p>DEDA is ontwikkeld door de Data School van de Universiteit Utrecht. DEDA is in nauwe samenwerking met data-analisten ontwikkeld. Inmiddels is DEDA een wijdverspreid instrument, waar de Utrecht Data School ook trainingen en begeleiding bij geeft. Via deze link is meer informatie te vinden.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DEDA/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelpba-03Beschrijf waarom een algoritme het probleem moet oplossenowp-11Beschrijf welke data gebruikt wordt voor de beoogde toepassing"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DPIA/","title":"Data Protection Impact Assessment","text":"<p>ProbleemanalyseOntwerpDataverkenning en datapreparatieBeleid en adviesJuristProjectleiderPrivacy en gegevensbescherming</p> <p>Direct naar de DPIA</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DPIA/#hulpmiddel","title":"Hulpmiddel","text":"<p>Is je organisatie van plan persoonsgegevens te verwerken, maar levert dat waarschijnlijk een hoog privacyrisico op? Dan is je organisatie verplicht eerst een 'data protection impact assessment' (DPIA) uit te voeren. Als organisatie moet je zelf bepalen of de gegevensverwerking een hoog privacyrisico oplevert. En je dus een DPIA moet uitvoeren. De volgende criteria kunnen hierbij helpen:</p> <ul> <li>Wat er in de Algemene verordening gegevensbescherming (AVG) staat over wanneer je een DPIA moet uitvoeren.</li> <li>De lijst van de Autoriteit Persoonsgegevens (AP) met soorten verwerkingen waarvoor je een DPIA moet uitvoeren.</li> <li>De 9 criteria voor een DPIA van de Europese privacytoezichthouders.</li> </ul> <p>De AVG geeft aan dat je in ieder geval een DPIA moet uitvoeren als je als organisatie:</p> <ul> <li>Systematisch en uitgebreid persoonlijke aspecten van mensen beoordeelt en dit gebeurt op basis van geautomatiseerde verwerking van persoonsgegevens, waaronder profiling. En hierop besluiten baseert die gevolgen hebben voor mensen. Bijvoorbeeld dat zij geen lening kunnen afsluiten. Een voorbeeld hiervan is creditscoring.</li> <li>Op grote schaal bijzondere persoonsgegevens verwerkt.</li> <li>Strafrechtelijke gegevens verwerkt.</li> <li>Op grote schaal en systematisch mensen volgt in een publiek toegankelijk gebied. Bijvoorbeeld met cameratoezicht.</li> </ul> <p>Een DPIA moet in een vroeg stadium van de beleids- of projectontwikkeling worden uitgevoerd. Op dat moment kan namelijk nog zonder vooroordelen worden nagedacht over de gevolgen en kan het voorstel nog makkelijker worden herzien. Dit voorkomt ook latere, kostbare aanpassingen in processen, herontwerp van systemen of zelfs stopzetten van een project. Behalve aan het begin van een project kan een DPIA ook op andere momenten en meermaals worden uitgevoerd en geactualiseerd. Als het voorstel wijzigt, wordt een DPIA opnieuw uitgevoerd. Als de gegevensverwerkingen of de gevolgen ervan veranderen, moet de DPIA worden geactualiseerd. Volgens de European Data Protection Board (EDPB) moet een DPIA iedere drie jaar worden ge\u00ebvalueerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DPIA/#relevantie","title":"Relevantie","text":"<p>Een organisatie is bij wet verplicht een DPIA uit te voeren wanneer de verwerking van persoonsgegevens een hoog privacyrisico oplevert. Wanneer hier sprake van is binnen jouw organisatie, dan is de DPIA per definitie relevant voor jou.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DPIA/#auteur","title":"Auteur","text":"<p>De DPIA is ontwikkeld door de Europese Unie in het kader van de AVG.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/DPIA/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelowk-03Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houden"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/IAMA/","title":"Impact Assessment Mensenrechten en Algoritmes","text":"<p>ProbleemanalyseOntwerpVerificatie en validatieMonitoring en beheerProjectleiderOntwikkelaarJuristBeleid en adviesFundamentele rechtenTransparantie</p> <p>Direct naar het IAMA</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/IAMA/#hulpmiddel","title":"Hulpmiddel","text":"<p>Het Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA) is een instrument voor overheidsorganen om een interdisciplinaire dialoog en besluitvorming te faciliteren bij de ontwikkeling en inzet van algoritmische systemen. Het IAMA stelt een reeks vragen die moeten worden besproken en beantwoord om een zorgvuldige afweging van de inzet van algoritmen te waarborgen. Dit proces is onderverdeeld in drie fasen: voorbereiding, input en throughput, en output en toezicht, waarbij steeds aandacht wordt besteed aan het vierde onderdeel van het IAMA: de impact op mensenrechten. Het IAMA fungeert als naslagwerk voor de besluitvorming en is gekoppeld aan andere relevante richtlijnen en instrumenten, zoals de gegevensbeschermingseffectbeoordeling (ook wel DPIA). Hierdoor biedt het een overkoepelend kader dat helpt om algoritmen verantwoord te implementeren en mogelijke risico\u2019s, zoals inbreuken op grondrechten, te identificeren en te mitigeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/IAMA/#relevantie","title":"Relevantie","text":"<p>Het IAMA kan op dit moment op veel politieke en internationale belangstelling rekenen. In zowel de Eerste als Tweede Kamer zijn hierover moties ingediend en vragen gesteld. Daarbij is het IAMA een van de weinige instrumenten in de EU die een interdisciplinaire discussie rondom (de ontwikkeling, inzet en monitoring van) algoritmes, AI en grondrechten initieert en bevordert.</p> <p>Het IAMA heeft enige overlap met de AIIA. Het AIIA is echter specifiek voor AI ontwikkeld, waar het IAMA toepasbaar is op alle soorten algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/IAMA/#auteur","title":"Auteur","text":"<p>Het IAMA is ontwikkeld door de Utrecht Data School. De auteurs van het IAMA zijn prof. mr. Janneke Gerards, dr. Mirko Tobias Sch\u00e4fer, Arthur Vankan en Iris Muis, allen werkzaam aan de Universiteit Utrecht. Opdrachtgever voor de ontwikkeling is het Ministerie van Binnenlandse Zaken.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/IAMA/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelowp-07Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafweging"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/IAMA/#bronnen","title":"Bronnen","text":"<p>Impact Assessment Mensenrechten en Algoritmes</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/IAMA/#voorbeeld","title":"Voorbeeld","text":"<p>Benieuwd naar ervaringen in de praktijk? Bekijk het rapport IAMA in Actie voor de lessons learned van 15 IAMA-trajecten bij Nederlandse overheidsorganisaties.</p> <p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/","title":"Impactanalyse AI-verordening","text":"<p>OrganisatieverantwoordelijkhedenProbleemanalyseProjectleiderBeleid en adviesGovernance</p> <p>Download hier de Impactanalyse AI-verordening (.xlsx)</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/#hulpmiddel","title":"Hulpmiddel","text":"<p>De impactanalyse AI-verordening is een hulpmiddel bij de implementatie van de AI-verordening. Het geeft een overzicht van de vereisten in het licht van mogelijk reeds bestaande governance, maatregelen, etc. Het doel van de impactanalyse is om een betere inschatting te kunnen maken van de benodigde acties bij de implementatie voor alle soorten overheidsorganisaties. Om dit doel te kunnen behalen is gekozen voor generieke termen, de gebruiker moet deze zelf vertalen naar de eigen context.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-00Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueelorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-03Maak een plan voor het omgaan met risico\u2019sorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernancever-05Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/Impactanalyse-AI-verordening/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/algoritmeregister/","title":"Algoritmeregister","text":"<p>Monitoring en beheerProjectleiderOntwikkelaarTransparantie</p> <p>Direct naar het Algoritmeregister</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/algoritmeregister/#hulpmiddel","title":"Hulpmiddel","text":"<p>De regering wil dat de overheid algoritmes verantwoord gebruikt. Mensen moeten erop kunnen vertrouwen dat algoritmes voldoen aan de waarden en normen van de samenleving. En er moet uitleg zijn over hoe algoritmes werken. Het Algoritmeregister helpt hierbij. Wanneer overheidsorganisaties open zijn over algoritmes en hun toepassing, kunnen burgers, organisaties en media de overheid kritisch volgen.</p> <p>Je kunt hier meer lezen over de doelen van het Algoritmeregister.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/algoritmeregister/#relevantie","title":"Relevantie","text":"<p>In de Handreiking Algoritmeregister staan bruikbare handvatten voor overheidsorganisaties om met publicatie van hun algoritmes aan de slag te gaan. Hierin wordt bijvoorbeeld duidelijkheid gegeven over welke doelen we ermee bereiken, welke algoritmes erin thuishoren en welke organisaties erin kunnen publiceren.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/algoritmeregister/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelimp-04Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregister"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/algoritmeregister/#bronnen","title":"Bronnen","text":"<p>Algoritmeregister</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/algoritmeregister/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/","title":"Blauwdruk AI-geletterdheidsprogramma","text":"<p>OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesJuristGovernance</p> <p>Download hier de Blauwdruk AI-geletterdheidsprogramma</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#hulpmiddel","title":"Hulpmiddel","text":"<p>Deze blauwdruk is opgesteld om als template te fungeren voor een AI-geletterdheidsprogramma waarmee voldaan kan worden aan de vereisten voor AI-geletterdheid uit de AI-verordening.</p> <p>Omdat de opgave om aan AI-geletterdheid te voldoen sterk afhankelijk is van de omvang en het soort organisatie, en de mate waarin AI-systemen worden gebruikt is bij het opstellen van deze blauwdruk gekozen voor zo algemeen mogelijke beschrijvingen.</p> <p>Deze blauwdruk is daarom bedoeld om vertaald te worden naar een plan van aanpak door en voor uw eigen organisatie. Hierbij zijn niet alleen de omvang van de organisatie en AI-systemen die in gebruik zijn relevant. Ook bestaande governance in het digitale domein, trainings- en opleidingsinitiatieven, en ander beleid, strategie\u00ebn, en initiatieven die gerelateerd zijn aan AI en awareness/training zijn relevant om te betrekken bij het opstellen van een AI-geletterdheidsprogramma voor uw organisatie.</p> <p>De Autoriteit Persoonsgegevens heeft ook een document dat helpt bij de stappen die men kan zetten op het gebied van AI-geletterdheid, getiteld 'Aan de slag met AI-geletterdheid .</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#ai-geletterdheid","title":"AI-geletterdheid","text":"<p>Al-geletterdheid moet betrokkenen in staat stellen om onderbouwde beslissingen te kunnen maken met betrekking tot Al-systemen. Afhankelijk van iemands rol en het toepassingsgebied van het Al-systeem, bestaat een toereikend niveau van Al-geletterdheid uit inzicht in:</p> <ul> <li>De correcte toepassing van technische elementen tijdens de ontwikkeling van Al-systemen.</li> <li>De maatregelen die genomen moeten worden tijdens het gebruik van een Al-systeem.</li> <li>De juiste interpretatie van de output van Al-systemen.</li> <li>De impact van Al-besluiten op natuurlijke personen.</li> <li>De kennis die nodig is om naleving en handhaving van de Al-verordening mogelijk te maken.</li> </ul> <p>Bekijk de wettelijke vereisten voor AI-gelleterdheid hier. Bekijk ook de factsheets voor bestuurders of inkopers, met meer informatie over AI-geletterdheid specifiek voor deze rollen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-04Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheidorg-16Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AIorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/blauwdruk-template-AI-geletterdheidsprogramma/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/","title":"Factsheet AI-geletterdheid voor bestuurders","text":"<p>OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p> <p>Download hier de Factsheet AI-geletterdheid voor bestuurders</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#hulpmiddel","title":"Hulpmiddel","text":"<p>Deze factsheet is bedoelt voor bestuurders om snel inzicht te krijgen in de AI-geletterdheidvereisten die de AI-verordening introduceert.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#ai-geletterdheid","title":"AI-geletterdheid","text":"<p>Al-geletterdheid moet betrokkenen in staat stellen om onderbouwde beslissingen te kunnen maken met betrekking tot Al-systemen. Afhankelijk van iemands rol en het toepassingsgebied van het Al-systeem, bestaat een toereikend niveau van Al-geletterdheid uit inzicht in:</p> <ul> <li>De correcte toepassing van technische elementen tijdens de ontwikkeling van Al-systemen.</li> <li>De maatregelen die genomen moeten worden tijdens het gebruik van een Al-systeem.</li> <li>De juiste interpretatie van de output van Al-systemen.</li> <li>De impact van Al-besluiten op natuurlijke personen.</li> <li>De kennis die nodig is om naleving en handhaving van de Al-verordening mogelijk te maken.</li> </ul> <p>Bekijk ook de factsheet voor inkopers, met meer informatie over AI-geletterdheid specifiek voor deze rol. Bovendien is er de factsheet met de Wettelijke vereisten AI-geletterdheid waarin de eisen op geletterdheid volgens de AI-verordening verder worden verduidelijkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-04Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheidorg-16Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AIorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-bestuurders/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/","title":"Factsheet AI-geletterdheid voor inkopers","text":"<p>OrganisatieverantwoordelijkhedenOntwerpProjectleiderBeleid en adviesJuristGovernancePublieke inkoop</p> <p>Download hier de Factsheet AI-geletterdheid voor inkopers</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#hulpmiddel","title":"Hulpmiddel","text":"<p>Deze factsheet is bedoelt voor inkopers om snel inzicht te krijgen in de AI-geletterdheidvereisten die de AI-verordening introduceert.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#ai-geletterdheid","title":"AI-geletterdheid","text":"<p>Al-geletterdheid moet betrokkenen in staat stellen om onderbouwde beslissingen te kunnen maken met betrekking tot Al-systemen. Afhankelijk van iemands rol en het toepassingsgebied van het Al-systeem, bestaat een toereikend niveau van Al-geletterdheid uit inzicht in:</p> <ul> <li>De correcte toepassing van technische elementen tijdens de ontwikkeling van Al-systemen.</li> <li>De maatregelen die genomen moeten worden tijdens het gebruik van een Al-systeem.</li> <li>De juiste interpretatie van de output van Al-systemen.</li> <li>De impact van Al-besluiten op natuurlijke personen.</li> <li>De kennis die nodig is om naleving en handhaving van de Al-verordening mogelijk te maken.</li> </ul> <p>Bekijk ook de factsheet voor bestuurders, met meer informatie over AI-geletterdheid specifiek voor deze rol. Bovendien is er de factsheet met de Wettelijke vereisten AI-geletterdheid waarin de eisen op geletterdheid volgens de AI-verordening verder worden verduidelijkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-16Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AIorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernancepba-06Stel een multidisciplinair team samen bij het ontwikkelen of inkopen van algoritmesowp-12Koop duurzaam algoritmes inowp-16Maak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomstowp-17Maak het leveren van bewijs voor het voldoen aan de vereisten voor algoritmes onderdeel van de beoordeling van een inschrijvingowp-18Laat aanbieder(s) bewijs leveren dat de door hen ontwikkelde algoritmes geen inbreuk maken op de auteursrechten van derden met de trainingsdata en de outputowp-24Bepaal in een aanbesteding of algoritmes van een aanbieder bepalende invloed hebben in een besluit richting personenowp-25Laat de aanbieder aangeven welke mate van opleiding en ondersteuning bij de implementatie nodig is om de beoogde algoritmes verantwoord te gebruikenowp-27Maak vereisten onderdeel van het programma van eisen bij een aanbestedingowp-29Maak (contractuele) afspraken over data en artefacten met een aanbiederowp-34Voorkom kwetsbaarheden die ge\u00efntroduceerd worden in de supply-chain van het algoritmeowp-36Bepaal of een algoritme moet worden ontwikkeld of ingekochtdat-08Zorg dat je controle of eigenaarschap hebt over de data"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-geletterdheid-inkopers/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/","title":"Factsheet AI-verordening voor bestuurders","text":"<p>OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p> <p>Download hier de Factsheet AI-verordening voor bestuurders</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/#hulpmiddel","title":"Hulpmiddel","text":"<p>Deze factsheet is bedoelt voor bestuurders om snel inzicht te krijgen in de belangrijkste aspecten van de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-04Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheidorg-16Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AIorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/factsheet-AI-verordening-bestuurders/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/fairness-handbook/","title":"The Fairness Handbook","text":"<p>ProbleemanalyseOntwerpProjectleiderBias en non discriminatieFundamentele rechten</p> <p>Direct naar het Fairness Handbook</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/fairness-handbook/#hulpmiddel","title":"Hulpmiddel","text":"<p>Het Fairness Handbook biedt overheidsorganisaties een gedetailleerde richtlijn om eerlijkheid in algoritmen te waarborgen en schadelijke vooroordelen binnen AI-systemen te verminderen. Het handboek, dat origineel is ontwikkeld voor de Gemeente Amsterdam, richt zich op het voorkomen en mitigeren van vooroordelen en oneerlijke uitkomsten (bias) door middel van een gestructureerde Fairness Pipeline. Deze pipeline behandelt alle fasen van het ontwikkelproces, van het formuleren van het probleem tot de uiteindelijke implementatie en monitoring. Dit hulpmiddel biedt inzicht in de soorten schadelijke effecten van AI (zoals representatiebias en denigratieschade) en introduceert specifieke technieken, zoals het uitvoeren van een bias-analyse en het gebruik van contra-feitelijke scenario's (counterfactual fairness), om te controleren of de algoritmen rechtvaardige resultaten opleveren.</p> <p>Naast praktische technieken voor het meten en mitigeren van vooroordelen, definieert het Fairness Handbook verschillende eerlijkheidsprincipes en bijbehorende statistische metrics. Deze metrics helpen ontwikkelaars en beleidsmakers om de prestaties van modellen te analyseren en verschillen in modelprestaties tussen verschillende groepen te detecteren. Door de nadruk te leggen op transparantie, zowel in de keuze van datasets als in de manier waarop het model beslissingen neemt, helpt het handboek om het vertrouwen in AI-systemen te vergroten en discriminerend gedrag in algoritmen te verminderen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/fairness-handbook/#relevantie","title":"Relevantie","text":"<p>Het Fairness Handbook biedt ondersteuning voor overheden die streven naar verantwoorde, niet-discriminerende algoritmische besluitvorming. Het handboek ondersteunt overheidsinstanties bij het identificeren en corrigeren van vooroordelen in datasets en algoritmes, waardoor het risico op schadelijke effecten, zoals ongelijke verdeling van kansen of kwaliteit van dienstverlening, wordt geminimaliseerd. Het hulpmiddel sluit nauw aan bij andere hulpmiddelen, zoals de IAMA, door richtlijnen te geven voor het beoordelen van specifieke eerlijkheidsaspecten in de context van datagebruik en algoritmeontwikkeling.</p> <p>Door de combinatie van technische en niet-technische benaderingen bevordert het Fairness Handbook een holistische benadering van algoritmische eerlijkheid. Er wordt rekening gehouden met zowel de technische als de sociale en ethische dimensies. Dit maakt het een bruikbaar hulpmiddel voor diverse overheidsprojecten, waaronder de ontwikkeling van AI-toepassingen in het sociaal domein en besluitvormingsprocessen waarbij kansengelijkheid van groot belang is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/fairness-handbook/#auteurs-en-ontwikkeling","title":"Auteurs en Ontwikkeling","text":"<p>Het Fairness Handbook is ontwikkeld in 2022 door de Gemeente Amsterdam, met als doel de eerlijkheid en transparantie van haar AI-systemen te verbeteren. Het project is tot stand gekomen in samenwerking met diverse stakeholders, waaronder datawetenschappers, ethici en beleidsmakers, om ervoor te zorgen dat het handboek aansluit bij de bredere maatschappelijke behoeften en regelgeving. Door deze samenwerking biedt het Fairness Handbook een gebalanceerd perspectief, met aandacht voor zowel technische oplossingen als ethische en juridische overwegingen die nodig zijn voor verantwoorde AI-toepassingen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/fairness-handbook/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregeldat-01Controleer de datakwaliteitver-03Toets het algoritme op bias en voer een rechtvaardigingstoets uitimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controleren"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/fairness-handbook/#bronnen","title":"Bronnen","text":"<p>The Fairness Handbook</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/fairness-handbook/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van het Fairness Handbook op het gebied van algoritmen? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/framework-meaningful-engagement/","title":"Framework for Meaningful Engagement","text":"<p>ProbleemanalyseOntwerpProjectleiderBeleid en adviesMenselijke controleTransparantieFundamentele rechten</p> <p>Direct naar het Framework for Meaningful Engagement</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/framework-meaningful-engagement/#hulpmiddel","title":"Hulpmiddel","text":"<p>Het Framework for Meaningful Engagement biedt organisaties een praktische aanpak om verschillende stakeholders effectief te betrekken in processen rondom AI en algoritmes. Het beschrijft stapsgewijs hoe men betrokkenheid kan ontwerpen en uitvoeren, met de nadruk op drie pijlers:</p> <ol> <li>een gedeelde doelstelling</li> <li>een betrouwbaar proces</li> <li>een zichtbare impact</li> </ol> <p>Het framework helpt organisaties om input van belanghebbenden daadwerkelijk te integreren, wat leidt tot duurzamere, inclusievere besluitvorming.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/framework-meaningful-engagement/#relevantie-voor-het-algoritmekader","title":"Relevantie voor het Algoritmekader","text":"<p>Betekenisvolle betrokkenheid van stakeholders is cruciaal voor verantwoord algoritmegebruik. Voor overheden biedt dit framework handvatten om transparanter te zijn over de ontwikkeling en impact van algoritmes en om een goed proces in te richten bij het gebruik van een algoritme. Dit sluit aan bij eisen rond menselijke controle.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/framework-meaningful-engagement/#auteurs-en-ontwikkeling","title":"Auteurs en ontwikkeling","text":"<p>Het framework is ontwikkeld door de European Center for Not-for-Profit Law Stichting (ECNL) en SocietyInside, als onderdeel van de Deense Tech for Democracy Initiative. De totstandkoming vond plaats via een consultatieproces met bijdragen van meer dan 150 individuen en organisaties wereldwijd, waaronder belanghebbenden uit het maatschappelijk middenveld, bedrijfsleven en overheden. Het framework bouwt voort op de VN-richtlijnen voor bedrijfs- en mensenrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/framework-meaningful-engagement/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelimp-03Richt bij besluitvorming betekenisvolle menselijke tussenkomst inver-05Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleidver-01Controleer regelmatig of het algoritme werkt zoals het bedoeld isowp-07Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-08Maak een lijst van de meest kwetsbare groepen en bescherm hen extrapba-01Beschrijf het probleem dat het algoritme moet oplossenpba-02Beschrijf het doel van het algoritmepba-03Beschrijf waarom een algoritme het probleem moet oplossenpba-04Overleg regelmatig met belanghebbendenorg-01Bepaal of er genoeg experts beschikbaar zijn"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/framework-meaningful-engagement/#bronnen","title":"Bronnen","text":"<ul> <li>ECNL - Framework for Meaningful Engagement</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/governancekader-VNG/","title":"Governancekader AI en algoritmen voor en door gemeenten","text":"<p>OrganisatieverantwoordelijkhedenProbleemanalyseOntwerpOntwikkelenVerificatie en validatieImplementatieMonitoring en beheerUitfaserenProjectleiderJuristOntwikkelaarBeleid en adviesGovernance</p> <p>Direct naar het Governancekader AI en algoritmen voor en door gemeenten</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/governancekader-VNG/#hulpmiddel","title":"Hulpmiddel","text":"<p>Het governancekader AI en algoritmen is een interactieve website, ontwikkeld voor en door gemeenten. Het governancekader geeft inzicht in welke rollen er nodig zijn en welke processtappen doorlopen worden om AI en algoritmen op een bewuste en verantwoorde manier in de organisatie in te zetten; zowel voor gemeenten die net beginnen met AI en algoritmen, als voor gemeenten die al ervaren zijn met de inzet ervan.\u202fOok andere overheidsorganisaties kunnen het kader gebruiken als houvast of ter inspiratie. Veel van de instrumenten, definities en kaders zijn landelijk of overheidsbreed. Het governancekader bevat verschillende onderdelen, waaronder:</p> <ul> <li>De kennisbank: Hier vind je informatie over instrumenten en kaders die gebruikt worden door gemeenten bij de verantwoorde inzet van AI &amp; algoritmen.</li> <li>Rollen: Hier krijg je inzicht in welke rollen, taken en verantwoordelijkheden een aandeel hebben in de verantwoorde inzet van AI in de gemeentelijke organisatie.</li> <li>Processtappen: Hier vind je de processtappen die doorlopen kunnen worden wanneer je gebruik wil gaan maken van AI of algoritmen in jouw gemeente of wilt (laten) ontwikkelen intern of door een leverancier.</li> </ul> <p>De filterfunctie geeft relevante kenniskaarten per rol of combinatie van rollen weer, zodat de hoeveelheid informatie relevant en behapbaar is voor de gebruiker.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/governancekader-VNG/#relevantie","title":"Relevantie","text":"<p>Het governancekader AI en algoritmen biedt houvast, structuur en inspiratie voor de verantwoorde inzet van AI en algoritmen door gemeenten. Het kader is een levend, lerend product, ontwikkeld en getoetst in samenwerking met diverse gemeenten. Ook andere overheidsorganisaties kunnen het kader gebruiken als houvast of ter inspiratie.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/governancekader-VNG/#auteur","title":"Auteur","text":"<p>Het governancekader AI en algoritmen is ontwikkeld door de Vereniging van Nederlandse Gemeenten (VNG) in samenwerking met de gemeenten Utrecht, Veenendaal, Amersfoort en Arnhem, de Gemeenschappelijke regeling Holland Rijnland en de werkgroep van de VNG-community AI en algoritmen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/governancekader-VNG/#bronnen","title":"Bronnen","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/governancekader-VNG/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-03Maak een plan voor het omgaan met risico\u2019sorg-05Sluit algoritmegovernance aan op bestaande governancestructuren binnen de organisatieorg-09Richt algoritmegovernance in op basis van de risicoclassificatie van algoritmespba-01Beschrijf het probleem dat het algoritme moet oplossenpba-03Beschrijf waarom een algoritme het probleem moet oplossenowp-01Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmesowp-07Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafwegingowp-16Maak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomstowp-36Bepaal of een algoritme moet worden ontwikkeld of ingekochtimp-03Richt bij besluitvorming betekenisvolle menselijke tussenkomst in"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/","title":"Handreiking inventarisatie, identificatie en classificatie AI-systemen","text":"<p>OrganisatieverantwoordelijkhedenProbleemanalyseMonitoring en beheerProjectleiderBeleid en adviesJuristTransparantieGovernance</p> <p>Download hier de handreiking</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/#hulpmiddel","title":"Hulpmiddel","text":"<p>Deze handreiking ondersteunt de impactanalyse voor de AI-verordening. Dit document bevat concrete handvatten voor het inventariseren, identificeren en classificeren van AI-systemen. Deze handvatten helpen de gebruiker bij het invullen van de impactanalyse en het bepalen van de toepasselijke vereisten.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelimp-04Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregisterorg-09Richt algoritmegovernance in op basis van de risicoclassificatie van algoritmesorg-00Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueelowp-05Stel vast in welke risicogroep het algoritme valt en bepaal vervolgens welke vereisten van toepassing zijn.ver-05Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-identificatie-classificatie-AI-systemen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/","title":"Handreiking non-discriminatie by design","text":"<p>OntwikkelenImplementatieProjectleiderOntwikkelaarBias en non discriminatieFundamentele rechten</p> <p>Direct naar de Handreiking non-discriminatie by design</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#hulpmiddel","title":"Hulpmiddel","text":"<p>Deze handreiking legt uit welke vragen en principes leidend zijn bij het ontwikkelen en implementeren van een AI-systeem met het oog op het discriminatieverbod, vanuit zowel juridisch, technisch, als organisatorisch perspectief. De handreiking is een praktisch toepasbaar ontwerpkader dat ontwikkelaars helpt om al in de ontwikkelfase van een AI-systeem discriminerende patronen zoveel mogelijk te identificeren, te voorkomen en te bestrijden.</p> <p>Er zijn 4 uitgangspunten die leidend zijn in de handreiking:</p> <ol> <li>Diversiteit</li> <li>Context</li> <li>Controleerbaarheid</li> <li>Evaluatie.</li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#relevantie","title":"Relevantie","text":"<p>Stuk over relevantie voor het AK volgt nog. Net als bij het IAMA, is dit document een manier om een multidisciplinaire discussie te faciliteren en stimuleren. Hierbij kunnen verschillende rollen betrokken worden door de projectleider: data-scientists, juristen, de functionaris gegevensbescherming (FG), aangevuld met domeinspecialisten.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#wanneer-toepassen","title":"Wanneer toepassen?","text":"<p>De handreiking is primair geschreven voor teams die zelf AI-systemen bouwen. Het gaat in op verschillende fases van ontwikkeling: probleemanalyse, dataverkenning en datapreparatie, ontwikkeling, implementatie en evaluatie. Daarnaast kan deze handreiking dienen voor opdrachtgevers van AI-systemen, ofwel om vooraf offrerende partijen te vragen aan te geven hoe zij rekening zullen houden met de diverse punten uit de handreiking, ofwel om tijdens het proces mee te kijken en op relevante punten aanwijzingen te geven, ofwel om achteraf te controleren of een opgeleverd product aan alle relevante voorwaarden voldoet.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#relatie-tot-iama","title":"Relatie tot IAMA","text":"<p>Gebruikers van zowel de Handreiking non-discriminatie by design als het IAMA geven enkele verschillen tussen de twee instrumenten. Deze bevindingen zijn te vinden in het rapport Bekendheid, toepasbaarheid en toegevoegde waarde handreiking 'non-discriminatie by design' van de Auditdienst Rijk.</p> <p>Zij geven aan dat het IAMA wordt gezien als instrument voor het nagaan van de impact van grondrechten in algemenere zin, waar de Handreiking zich specifiek richt op discriminatie. De handreiking bevat dan weer meer praktische voorbeelden die kunnen helpen bij begrip en afwegingen, waar de IAMA wat abstracter is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#relatie-tot-het-fairness-handbook","title":"Relatie tot het Fairness Handbook","text":"<p>Over het Fairness Handbook werd in het rapport aangegeven dat het een technischere uitwerking bevat dan de Handreiking. Het Handbook biedt wellicht meer houvast voor iemand die analyses maakt om inzicht te geven in de prestaties van het algoritme met het oog op \u2018fairness\u2019 en \u2018bias\u2019. Dit komt doordat het Handbook meer details geeft over de technische stappen die nodig zijn om te komen tot bepaalde analyses.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#relatie-tot-toetsingskader-risicoprofilering-van-het-college-voor-de-rechten-van-de-mens","title":"Relatie tot Toetsingskader Risicoprofilering van het College voor de Rechten van de Mens","text":"<p>Ook het toetsingskader Risicoprofilering College voor de Rechten van de Mens kan worden gebruikt om te bepalen of er discriminatie plaatsvindt. De verschillende stappen die daarin gebruikt worden om te bepalen of een risicoprofiel leidt tot onderscheid op grond van ras of nationaliteit, zijn zeer relevant.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregeldat-01Controleer de datakwaliteitver-03Toets het algoritme op bias en voer een rechtvaardigingstoets uitimp-02Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controleren"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking non-discriminatie by design</li> <li>Onderzoeksrapport Bekendheid, toepasbaarheid en toegevoegde waarde handreiking 'non-discriminatie by design'</li> <li>Toetsingskader Risicoprofilering, College voor de Rechten van de Mens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/handreiking-non-discriminatie/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van de Handreiking non-discriminatie by design op het gebied van algoritmen? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/","title":"Inkoopvoorwaarden","text":"<p>ProbleemanalyseOntwerpJuristProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#hulpmiddel","title":"Hulpmiddel","text":"<p>Voorbeelden of templates van inkoopvoorwaarden (ook wel modelcontractbepalingen genoemd) helpen om een contract op te stellen dat een organisatie in staat stelt veilige en verantwoorde algoritmen of AI-systemen in te kopen. Organisaties kunnen deze voorwaarden of bepalingen opnemen wanneer zij een contract afsluiten met een leverancier van een algoritme of algoritmisch systeem. Zij kunnen dan bijvoorbeeld beperkingen opnemen om onaanvaardbare risico's van AI te vermijden, of bepaalde voorwaarden waaraan een algoritme juist moet voldoen. Ook kunnen zij bepaalde voorwaarden op basis van de vereisten in het Algoritmekader opnemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#europese-commissie","title":"Europese Commissie","text":"<p>De Europese Commissie biedt Europese modelcontractbepalingen voor laag- en hoog-risico-AI. Hiermee kunnen aanbestedende organisaties specifieke clausules opnemen in hun overeenkomst. Op deze manier maken zij afspraken die in lijn zijn met de Europese AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#gemeente-amsterdam","title":"Gemeente Amsterdam","text":"<p>De Europese modelcontractbepalingen voor AI zijn gebaseerd op onder andere de modelbepalingen die de Gemeente Amsterdam eerder opstelde. Deze dienen als voorbeeld voor andere gemeenten die algoritmische toepassingen willen inkopen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#ai-module-bij-arbit-2022","title":"AI-module bij ARBIT-2022","text":"<p>De AI-module bij de ARBIT (Algemene Rijksinkoopvoorwaarden bij IT\u2011overeenkomsten) is gebaseerd op de Europese modelcontractbepalingen voor AI. Via een verwijzing in de gebruikte modelovereenkomst kan de AI-module onderdeel uitmaken van een onder de ARBIT te sluiten overeenkomst. In de Leidraad voor inkopen en ontwikkelen algoritmes in IT-toepassingen vanuit PIANOo vind je handvatten om je op weg te helpen.</p> <p>De ARBIT zijn bedoeld voor kleine en middelgrote IT-inkopen door de overheid.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#relevantie","title":"Relevantie","text":"<p>Steeds meer organisaties kopen algoritmische toepassingen in die veel impact hebben op gebruikers of beslissingen. Het is daarom van belang dat aanbestedende overheidsorganisaties afspraken maken met leveranciers, zodat zij transparant zijn over de werking van de algoritmische toepassing en dit op een veilige en verantwoorde manier gebruiken. Verschillende organisaties stellen daarom (voorbeeld)contractvoorwaarden voor het inkopen van AI-systemen beschikbaar. Denk aan de Europese Commissie en de Gemeente Amsterdam.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#generatieve-ai","title":"Generatieve AI","text":"<p>Let bij het inkopen van generatieve AI specifiek op de volgende zaken.</p> <ul> <li>Verken mogelijkheden van lokale of Europese dienstverleners van generatieve AI. Deze voldoen vaak eerder aan onze (Europese) veiligheidsstandaarden dan niet-Europese dienstverleners. Dit voorkomt ook vendor lock-in, i.e. dat je vastzit aan een aanbieder omdat de kosten van wisselen te hoog zijn.</li> <li>Niet alle taalmodellen kunnen even goed omgaan met de Nederlandse taal. Europese initiatieven, zoals EuroLLM en OpenGPT-X Teuken-modellen, besteden extra aandacht aan Europese talen.</li> <li>Maak afspraken over de toegang tot en het gebruik, de opslag en logging van gegevens. Doe dit vanuit de datastrategie van je organisatie. Zorg ervoor dat de leverancier de dienst actief monitort op dit gebied en zorg voor controle over eigen data.</li> <li>Maak waar mogelijk gebruik van een open-sourceapplicatie of -model. Let wel op dat deze transparantie niet ten koste mag gaan van de veiligheid van deze modellen.</li> <li>Verken de mogelijkheden van offline en on-premise generatieve AI-modellen. Deze zijn in principe niet met het internet verbonden. Hierdoor blijft de inzet en data binnen de organisatie. Let wel op dat hiervoor aanzienlijke investeringen nodig zijn, onder meer vanwege de benodigde hardware.</li> <li>Zet datadeling voor externe optimalisatie van het model uit. Hiermee voorkom je onder andere dat persoonsgegevens worden gedeeld om het model te trainen.</li> <li>Houd rekening met de capaciteiten van verschillende Foundation Models. De Holistic Foundation of Language Models van het Stanford Center for Research on Foundation and Media (CRFM) biedt een goede vergelijking van modellen op verschillende criteria.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregeldat-08Zorg dat je controle of eigenaarschap hebt over de dataowp-16Maak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomstowp-17Maak het leveren van bewijs voor het voldoen aan de vereisten voor algoritmes onderdeel van de beoordeling van een inschrijvingowp-18Laat aanbieder(s) bewijs leveren dat de door hen ontwikkelde algoritmes geen inbreuk maken op de auteursrechten van derden met de trainingsdata en de outputowp-25Laat de aanbieder aangeven welke mate van opleiding en ondersteuning bij de implementatie nodig is om de beoogde algoritmes verantwoord te gebruikenowp-02Voer voorafgaand aan een project een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#bronnen","title":"Bronnen","text":"<ul> <li>Modelbepalingen voor gemeenten voor verantwoord gebruik van Algoritmische toepassingen</li> <li>Contractvoorwaarden voor het inkopen van artifici\u00eble intelligentie (AI)</li> <li>AI-module bij de modelovereenkomst ARBIT-2022</li> <li>Leidraad voor inkopen en ontwikkelen algoritmes in IT-toepassingen</li> <li>EuroLLM</li> <li>OpenGPT-X Teuken-modellen</li> <li>Holistic Foundation of Language Models</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/inkoopvoorwaarden/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van modelbepalingen of contractvoorwaarden op het gebied van algoritmen? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/onderzoekskader-adr/","title":"Onderzoekskader algoritmes Auditdienst Rijk 2023","text":"<p>OntwerpImplementatieMonitoring en beheerProjectleiderBeleid en adviesGovernance</p> <p>Direct naar Onderzoekskader algoritmes</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/onderzoekskader-adr/#hulpmiddel","title":"Hulpmiddel","text":"<p>Dit onderzoekskader is een instrument om de beheersing van algoritmes in kaart te brengen. Het geeft inzicht in de risico\u2019s die algoritmes met zich meebrengen en met welke maatregelen deze risico\u2019s beheerst (kunnen) worden.</p> <p>Het onderzoekskader is in eerste instantie bedoeld als instrument voor auditors om de beheersing en werking van algoritmes binnen overheidsorganisaties te onderzoeken, maar is ook bruikbaar voor andere partijen om inzicht te krijgen in de huidige en/of gewenste beheersing van algoritme(s).</p> <p>Het kader richt zich op algoritmes die binnen overheidsorganisaties gebruikt worden. Het is ingericht op algoritmes die zelf van voorbeelden leren, zoals machine learning, maar is ook toepasbaar op regelgebaseerde algoritmes. Het kader is ook bruikbaar voor andere organisaties en kan bij verschillende fases van de levenscyclus van een algoritme worden ingezet. Mogelijk zijn niet alle thema\u2019s relevant gezien de context van het algoritme. De opdrachtgever en auditor(s) dienen daarom voorafgaand aan een onderzoek te analyseren en te bepalen welke thema\u2019s en onderwerpen worden onderzocht. Het onderzoekskader is ingedeeld in 4 thema\u2019s:</p> <ul> <li>Sturing en Verantwoording</li> <li>Privacy</li> <li>Data en Model</li> <li>Informatiebeveiliging</li> </ul> <p>Ethiek raakt alle thema\u2019s en komt daarom bij elk thema in het kader terug. Elk thema bevat deelgebieden en de risico\u2019s en beheersmaatregelen die daarbij horen (inclusief de bron). Ook deze kunnen weer gerelateerd zijn aan een ander thema. Een apart werkbestand voor auditors is opgesteld wat kan worden gebruikt bij het uitvoeren van een onderzoek. Dit bestand heeft dezelfde opbouw, maar bevat ook invulvelden om als auditor het risico (kans x impact) in te schatten en de bevindingen op te nemen. Daarnaast zijn toelichtingen en voorbeelden van checks en evidence opgenomen per beheersmaatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/onderzoekskader-adr/#relevantie","title":"Relevantie","text":"<p>Het onderzoekskader is ontwikkeld met behulp van nationale en internationale richtlijnen en kaders, rapporten en instrumenten, zoals de Ethics guidelines for trustworthy AI van de Europese Commissie (EC), Impact Assessment voor Mensenrechten bij de inzet van Algoritmes (IAMA), de 'Richtlijnen voor het toepassen van algoritmen door overheden en publieksvoorlichting over data-analyses' van het ministerie van JenV, het DPIA model Rijksoverheid (gebaseerd op o.a. AVG) en de Guiding Principles Trustworthy AI Investigations van NOREA (beroepsvereniging IT-auditors Nederland). De bron van de betreffende risico\u2019s en beheersmaatregelen is tevens opgenomen.</p> <p>Dit onderzoekskader is erg overkoepelend (net als het toetsingskader van de Algemene Rekenkamer). Er zijn dan ook veel maatregelen in het Algoritmekader gebaseerd op maatregelen die in het kader van de ADR staan. Bekijk alle maatregelen van het Algoritmekader hier.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/onderzoekskader-adr/#auteur","title":"Auteur","text":"<p>Het Onderzoekskader Algoritmes is ontwikkeld door de Auditdienst Rijk</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/onderzoekskader-adr/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"<p>Geen maatregelen beschikbaar voor dit hulpmiddel.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/","title":"Roadmap inwerkingtreding AI-verordening","text":"<p>OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p> <p>Download hier de Roadmap inwerkingtreding AI-verordening (.xlsx)</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/#hulpmiddel","title":"Hulpmiddel","text":"<p>Dit document geeft een gedetailleerd overzicht van de gefaseerde inwerkingtreding van de AI-verordening. Voor een toegankelijke webpagina-versie (maar minder gedetailleerd), bekijk deze tijdlijn op het Algoritmekader.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-00Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueelorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-03Maak een plan voor het omgaan met risico\u2019sorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernancever-05Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/roadmap-inwerkingtreding-AI-verordening/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/","title":"Standaarden","text":"<p>OntwerpOntwikkelenVerificatie en validatieMonitoring en beheerProjectleiderOntwikkelaarJuristBeleid en adviesDataBias en non discriminatieDuurzaamheidGovernanceMenselijke controlePrivacy en gegevensbeschermingTechnische robuustheid en veiligheidTransparantiePublieke inkoopGrondrechten</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#wat-zijn-standaarden","title":"Wat zijn standaarden?","text":"<p>Standaarden zijn afspraken die worden vastgelegd om ervoor te zorgen dat producten, processen of diensten voldoen aan specifieke eisen op het gebied van kwaliteit, veiligheid en prestaties. Sommige standaarden worden ontwikkeld door standaardisatieorganisaties, meestal op initiatief van belanghebbenden die een behoefte aan een bepaalde standaard zien bij of na het ontwikkelen van Europese regelgeving, zoals de Europese Commissie. Normen zijn standaarden die door standaardisatieorganisaties worden gemaakt, zoals ISO of CEN/CENELEC, of NEN.</p> <p>Standaarden zijn er op allerlei gebieden. Momenteel speelt de ontwikkeling van standaarden voor de Europese AI-verordening een belangrijke rol voor de betrouwbare ontwikkeling en gebruik van AI. Vandaar dat deze pagina focust op standaarden voor AI.</p> <p>Europese geharmoniseerde standaarden zijn essentieel voor de AI-Verordening, omdat ze juridische zekerheid verschaffen. Geharmoniseerde standaarden zijn er bijvoorbeeld al voor speelgoed, elektrische apparaten, medische hulpmiddelen, en straks dus ook voor hoog risico AI-systemen. Als het over standaarden voor de AI-verordening gaat, gaat het dus om geharmoniseerde standaarden.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#waarom-zijn-standaarden-belangrijk-voor-de-ai-verordening","title":"Waarom zijn standaarden belangrijk voor de AI-verordening?","text":"<p>Wanneer AI-systemen worden ontworpen of gebruikt, bieden standaarden praktische richtlijnen en technische kaders (praktische meerwaarde) waarmee compliance aantoonbaar kan worden gemaakt (juridische meerwaarde).</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#juridische-waarde-van-standaarden","title":"Juridische waarde van standaarden","text":"<p>Als een organisatie zich houdt aan de bij de wet behorende geharmoniseerde Europese normen, wordt aangenomen dat er wordt voldaan aan de essenti\u00eble eisen voor hoog-risico AI-systemen in de AI-verordening (Presumption of Conformity), ofwel, een vermoeden van conformiteit. Dit betekent dat het AI-systeem wordt beschouwd als conform de wettelijke vereisten voor hoog-risico AI-systemen, wat zorgt voor juridische zekerheid en eenvoudiger toezicht\u200b. Let wel: dit geldt voor de vereisten voor hoog-risico systemen waar een standardisation-request (SR) voor uitstaat; Artikel 4 (AI-geletterdheid) valt bijvoorbeeld buiten deze scope omdat daar geen SR voor ligt.</p> <p>De geharmoniseerde normen zijn niet wettelijk verplicht, maar dankzij de presumption of conformity bieden ze organisaties wel juridische duidelijkheid. Organisaties mogen er voor kiezen om de geharmoniseerde norm n\u00edet te implementeren in de eigen organisatie, maar moeten dan onderbouwen dat hun eigen werkwijze op adequate wijze invulling geeft aan de essenti\u00eble eisen. Dit kost tijd en geld, en er is schaarse expertise voor nodig. Het geeft bovendien juridische onzekerheid. De verwachting is dat verreweg de meeste organisaties daarom de geharmoniseerde normen zullen volgen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#praktische-waarde-van-standaarden","title":"Praktische waarde van standaarden","text":"<p>Geharmoniseerde normen hebben daarnaast een duidelijke praktische waarde. Ze vertalen abstracte wettelijke verplichtingen uit de AI-verordening naar concrete technische en organisatorische eisen, bijvoorbeeld op het gebied van risicomanagement en kwaliteitsmanagement, maar ook voor duurzaamheid en transparantie\u200b. Er zullen standaarden ontwikkeld worden voor de AI-verordening op het gebied van verschillende fases in de algoritme-levenscyclus. Zo helpen standaarden organisaties dus bij het ontwikkelen, inkopen en implementeren van betrouwbare AI-systemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#een-overzicht-van-belangrijke-standaarden","title":"Een overzicht van belangrijke standaarden","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#normen-die-worden-ontwikkeld-voor-de-ai-verordening","title":"Normen die worden ontwikkeld voor de AI-verordening","text":"<p>Er is een standaardisatieverzoek gedaan door de Europese Commissie op 10 specifieke wettelijke vereisten in de AI-Verordening die gaan over belangrijke aspecten van AI. Deze aspecten vind je ook terug in de verschillende onderwerpen, vereisten en maatregelen die in het Algoritmekader terugkomen.</p> <ol> <li>Risicomanagement</li> <li>Gegevensbeheer en -kwaliteit</li> <li>Logging (\"Record Keeping\" in de Engelse teksten)</li> <li>Transparantie</li> <li>Menselijke controle (soms ook wel Menselijk toezicht genoemd)</li> <li>Accuraatheid</li> <li>Robuustheid</li> <li>Cybersecurity</li> <li>Kwaliteitsmanagement</li> <li>Conformiteitsbeoordeling</li> </ol> <p>Enkele van de belangrijkste normen die worden ontwikkeld voor het voldoen aan de vereisten voor hoog-risico AI systemen, zullen zijn: - AI trustworthiness framework - AI risk management (AI risicomanagement) - Quality management for EU AI regulatory purposes (AI kwaliteitsmanagement) - Conformity assessment (conformiteitsbeoordeling)</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#duurzaamheid","title":"Duurzaamheid","text":"<p>Wat in deze 10 standaardisatieverzoeken nog niet terugkomt, maar wel in het Algoritmekader, is duurzaamheid. Momenteel worden er wel enkele TR's en TS's ontwikkeld. Zodra die bekend zijn, zullen deze worden aangevuld met meer informatie of links.</p> <ul> <li>TR 20226 'Environmental sustainability aspects of AI systems' is een technisch rapport (TS), geen standaard. Dit TS bevindt zich in de 'committee draft' fase, wat wil zeggen dat er een concept is waar nog overeenstemming over moet worden gevonden.</li> <li>TR 18145 'Environmentally sustainable Artificial Intelligence' is een technisch rapport (TR). Het is nu \"under approval\".</li> <li>Werkgroep JTC 21 heeft een \"preliminary work item\" genaamd 'Guidelines and metrics for the Environmental Impact of Artificial Intelligence Systems and Services' wat nog aan werk onderhevig is.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#welke-standaarden-rapporten-en-specificaties-zijn-er-al","title":"Welke standaarden, rapporten en specificaties zijn er al?","text":"<p>Op dit moment zijn er verschillende Technische Rapporten, Technische Specificaties en Normen (onder de tabel kun je meer informatie vinden over deze termen) die al van belang zijn voor AI. In onderstaande tabel worden er enkele uitgelicht. Ben je opzoek naar meer, kijk dan eens op de AI Standards Hub van het Verenigd Koninkrijk, of op NEN Connect.</p> Norm Titel Status ISO/IEC 42001 Information technology - Artificial intelligence - Management system ISO Norm ISO/IEC TS 25058 Systems and software engineering - Systems and software Quality Requirements and Evaluation (SQuaRE) - Guidance for quality evaluation of artificial intelligence (AI) systems Technische Specificatie NEN-EN-ISO/IEC 23894 Information technology - Artificial intelligence - Guidance on risk management Europese Norm NEN-EN-ISO/IEC 25059 Software engineering - Systems and software Quality Requirements and Evaluation (SQuaRE) - Quality model for AI systems Europese Norm NEN-ISO/IEC 38507 Information technology - Governance of IT - Governance implications of the use of artificial intelligence by organizations Nederlandse Norm NPR-CEN/CLC ISO/IEC TR 24027 Information technology - Artificial intelligence (AI) - Bias in AI systems and AI aided decision making Nederlandse Praktijk Richtlijn NPR-ISO/IEC TR 27563 Security and privacy in artificial intelligence use cases - Best practices Nederlandse Praktijk Richtlijn NVN-ISO/IEC TS 8200 Information technology - Artificial intelligence - Controllability of automated artificial intelligence systems Nederlandse Voornorm Uitleg over gebruikte termen <p>Er zijn verschillende soorten standaarden, zoals normen, Technische Rapporten (TR) en Technische Specificaties (TS).</p> <ul> <li>Normen zijn standaarden die door standaardisatieorganisaties worden gemaakt, zoals ISO of CEN/CENELEC, of NEN.</li> <li>Geharmoniseerde normen zijn standaarden gemaakt door Europese standaardisatieorganisaties in opdracht van de Europese Commissie om de implementatie van Europese richtlijnen of verordeningen eenvoudiger te maken. De meeste normen zijn geen geharmoniseerde normen en worden n\u00edet in opdracht van de Europese Commissie gemaakt.</li> <li>Technische Rapporten (TR) hebben een meer informatief karakter. Een TR wordt gebruikt om informatie te delen die niet geschikt is voor een norm, bijvoorbeeld gegevens uit onderzoeken of enqu\u00eates. Een TR is vaak de opmaat voor het opstellen van een norm.</li> <li>Technische Specificaties (TS) zijn normatief, en bieden voorlopige specificaties, vooral voor technologie\u00ebn in ontwikkeling. Een TS kan in een later stadium worden omgezet in een volledige norm als er voldoende consensus voor is.</li> </ul> <p>Zowel een Technisch Rapport als een Technische Specificatie bieden dus ondersteuning in situaties waar nog geen norm bestaat of waar consensus nog niet is bereikt. Dus een TS of TR kan ook zeker interessante informatie bevatten voor organisaties, maar ze hebben niet de status of juridische binding van een norm.</p> <p>Er is een onderscheid tussen internationale normen (ISO), Europese normen (EN) en Nederlandse normen (NEN). De NEN onderscheidt ook verschillende typen afspraken, zoals Nederlandse praktijkrichtlijn (NPR) of Nederlandse voornorm (NVN).</p> <p>Voor een compleet overzicht van internationaal gepubliceerde standaarden die relateren aan AI, kijk op de website van de ISO, of gebruik NEN Connect.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#wat-moeten-nederlandse-overheidsorganisaties-doen","title":"Wat moeten Nederlandse overheidsorganisaties doen?","text":"<p>Nederlandse overheidsorganisaties kunnen standaarden gebruiken als praktische hulpmiddelen om te voldoen aan de eisen van de AI-verordening.</p> <p>Hoe gebruik je standaarden?</p> <ol> <li>Kies de juiste standaarden: Begin met het identificeren van relevante standaarden en het begrijpen hoe deze toegepast kunnen worden. Focus op geharmoniseerde Europese normen die aansluiten bij de AI-verordening, en wanneer die er nog niet zijn, kies standaarden die aansluiten bij de onderwerpen uit de AI-verordening, door te kijken naar de lijst van 10 onderwerpen waarvoor een standaardisatieverzoek ligt (zie hierboven).</li> <li>Pas standaarden toe in de praktijk: Gebruik standaarden als richtlijnen om technische processen en organisatorische maatregelen in te richten, zoals het waarborgen van datakwaliteit, transparantie en betrouwbaarheid van AI-systemen\u200b. Stel de afdeling inkoop op de hoogte van de ontwikkeling, zodat zij hierop kunnen anticiperen als hoog-risico-AI-systemen moet worden ingekocht.</li> <li>Blijf op de hoogte: Volg de ontwikkelingen binnen JTC 21 en houd bij welke internationale standaarden worden opgenomen in het Europese normalisatieproces. Door standaarden actief te gebruiken, kunnen overheidsorganisaties hun AI-systemen veiliger en betrouwbaarder maken en tegelijkertijd voldoen aan de wettelijke vereisten van de AI-verordening.</li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#verwachte-ontwikkelingen-en-tijdlijn","title":"Verwachte ontwikkelingen en tijdlijn","text":"<p>De komende jaren zullen nieuwe AI-standaarden worden ontwikkeld en gepubliceerd om te voldoen aan de eisen van de AI-verordening. Deze standaarden zullen geharmoniseerd worden en juridisch relevant zijn, met name voor hoog-risico AI-systemen. Dit proces is complex en vereist samenwerking tussen vele stakeholders, inclusief industrie, overheid en maatschappelijke organisaties.</p> <p>Een overzicht van lopende en verwachte ontwikkelingen rondom standaarden voor de AI-verordening:</p> <ul> <li>2024 \u2013 2025: Europese standaardisatieorganisaties (CEN/CENELEC) werken aan de afronding van geharmoniseerde standaarden. Conceptversies van belangrijke horizontale standaarden verschijnen ter beoordeling door leden van de NEN normcommissie. (Meer info via AI@nen.nl)</li> <li>Begin 2025: Publicatie van een update van het standaardisatieverzoek van de Europese Commissie.</li> <li>Eind 2025: Publicatie van eerste geharmoniseerde Europese normen in het Official Journal of the EU. Deze normen cre\u00ebren juridische zekerheid (Presumption of Conformity) voor organisaties die AI-systemen ontwikkelen.</li> <li>Augustus 2026: De verplichtingen voor hoog-risico AI-systemen treden in werking. Vanaf dit moment moeten systemen voldoen aan de eisen van de AI-verordening, ondersteund door geharmoniseerde standaarden\u200b.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#de-rol-van-jtc21","title":"De rol van JTC21","text":"<p>De JTC 21 (CEN-CENELEC Joint Technical Committee on Artificial Intelligence) speelt een centrale rol in het ontwikkelen van Europese AI-standaarden. Deze commissie volgt de strategie van adopt, adapt en develop: eerst wordt gekeken naar bestaande internationale standaarden (zoals ISO-normen), waarna deze indien nodig worden aangepast aan de Europese context. Als er geen geschikte standaarden beschikbaar zijn, ontwikkelt JTC 21 zelf nieuwe Europese standaarden\u200b.</p> <p>Omdat de door JTC 21 ontwikkelde geharmoniseerde Europese normen straks juridische zekerheid bieden voor organisaties, betekent dit dat organisaties de ontwikkelingen binnen JTC 21 goed moeten volgen. Door inzicht te krijgen in lopende projecten, kunnen organisaties zich tijdig voorbereiden op toekomstige standaarden en compliance-eisen\u200b.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#bronnen","title":"Bronnen","text":"<p>Lijst van gebruikte bronnen, standaarden, en aanvullende documentatie</p> <ul> <li>Harmonised Standards for the European AI Act - Science for Policy brief, Joint Research Centre (Europese Commissie)</li> <li>Standards in Europe</li> <li>Artificial Intelligence en Big Data, NEN</li> <li>'AI Act Compact: Compliance, Management &amp; Use Cases in Corporate Practice', Peter Hense, Tea Mustac, 2024</li> <li>'AI Act and the future standards - webinar' (11 december 2024). Het webinar kan hier worden teruggekeken. Hier zijn ook de presentaties en Q&amp;A's over standaarden te vinden.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#beslishulp-ai-verordening","title":"Beslishulp AI-verordening","text":"<p>Met de beslishulp AI-verordening bepaal je snel en gemakkelijk of jouw AI-product onder de AI-verordening valt. En wat je dan moet doen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/standaarden/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-algemene-rekenkamer/","title":"Toetsingskader Algoritmes Algemene Rekenkamer","text":"<p>Monitoring en beheerVerificatie en validatieProjectleiderBeleid en adviesJuristGovernance</p> <p>Direct naar het Toetsingskader</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-algemene-rekenkamer/#hulpmiddel","title":"Hulpmiddel","text":"<p>Het toetsingskader omvat 5 perspectieven op algoritmes, elk met hun belangrijkste risico's geformuleerd. Het gaat om Sturing en Verantwoordelijkheid, Model en Data, Privacy, IT-beheer en Ethiek. Voor elk risico is er een specifieke onderzoeksvraag opgesteld. Door deze vragen te beantwoorden en een score toe te kennen, krijgt de gebruiker inzicht in hoe goed het gekozen algoritme de risico's beheerst.</p> <p>De mate van risico voor een specifiek algoritme wordt bepaald door twee factoren: de gebruikte geavanceerde technieken en de impact van het algoritme op de burger.</p> <p>Het toetsingskader is in eerste instantie bedoeld als toetsinstrument voor auditors (controleurs en toezichthouders). Zij kunnen dit kader gebruiken om de risico's van het beoordeelde algoritme in beeld te krijgen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-algemene-rekenkamer/#relevantie","title":"Relevantie","text":"<p>Het digitale toetsingskader 'Aandacht voor algoritmes' is ontwikkeld vanwege de toenemende maatschappelijke aandacht voor algoritmes en de behoefte aan een integraal instrument voor toetsing en analyse. Het is gebaseerd op bestaande informatie en raamwerken, zowel binnen het Rijk als door externe partijen zoals NOREA en grote accountantskantoren.</p> <p>Dit onderzoekskader is erg overkoepelend (net als het onderzoekskader van de ADR). Er zijn dan ook veel maatregelen in het Algoritmekader gebaseerd op maatregelen die in het kader van de Algemene Rekenkamer staan. Bekijk alle maatregelen van het Algoritmekader hier.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-algemene-rekenkamer/#auteur","title":"Auteur","text":"<p>Het Toetsingskader Algoritmes is ontwikkeld door de Algemene Rekenkamer</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-algemene-rekenkamer/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"<p>Geen maatregelen beschikbaar voor dit hulpmiddel.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-risicoprofilering/","title":"Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit","text":"<p>OntwerpVerificatie en validatieBeleid en adviesJuristBias en non discriminatieFundamentele rechten</p> <p>Direct naar het Toetsingskader risicoprofilering</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-risicoprofilering/#hulpmiddel","title":"Hulpmiddel","text":"<p>Dit toetsingskader is bedoeld voor alle instanties die verantwoordelijk zijn voor de handhaving van wetten, regels en voorwaarden. Dat gaat vaak om overheidsinstanties, zoals uitvoeringsinstanties, de marechaussee, de politie en gemeenten. Dit hulpmiddel geeft de meest belangrijke handvatten en richtlijnen weer waarmee discriminatie bij risicoprofilering voorkomen kan worden. Het toetsingskader past de wetgeving en jurisprudentie op het terrein van gelijke behandeling toe op de praktijk van risicoprofilering. Dit toetsingskader is gebaseerd op nationale en internationale geldende verdragen, wetten en jurisprudentie tot aan november 2024. De normen en jurisprudentie op dit terrein zijn echter continu in ontwikkeling. Het is belangrijk om te benadrukken dat het hierbij gaat om de juridische ondergrens van het discriminatieverbod, zoals geformuleerd door internationale en nationale rechters. Aan de regels uit dit toetsingskader moet de overheid zich dus ten minste houden. Dit laat onverlet dat de overheid kan beslissen om strengere regels te hanteren.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-risicoprofilering/#vervanging-van-het-toetsingskader-uit-2021","title":"Vervanging van het toetsingskader uit 2021","text":"<p>Het College voor de Rechten van de Mens publiceerde in 2021 het 'toetsingskader Discriminatie door Risicoprofielen'. Het nieuwe toetsingskader moet gezien worden als een doorontwikkelde, geheel herziene versie die de versie uit 2021 vervangt. Omdat het non-discriminatierecht bij beide toetsingskader het uitgangspunt is, zullen ook onderdelen uit het toetsingskader 2021 terugkomen in deze nieuwe versie.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-risicoprofilering/#relevantie","title":"Relevantie","text":"<p>Het spreekt voor zich dat overheidsinstanties zich bij het uitvoeren van hun taken moeten onthouden van discriminatie. De voorbeelden van discriminerende risicoprofilering, zoals de Kinderopvangtoeslagaffaire of de Controle Uitwonendenbeurs bij DUO, van de laatste jaren laten zien dat handhavende instanties in de praktijk nog onvoldoende in staat zijn om discriminatie bij risicoprofilering te voorkomen. In dit toetsingskader wil het College verhelderen welke normen uit het verbod op discriminatie voortvloeien, specifiek op grond van \u2018ras\u2019 en nationaliteit. Het schetst de verplichtingen die instanties hebben bij gebruik van risicoprofilering, en welke stappen zij minimaal moeten zetten om discriminatie te voorkomen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-risicoprofilering/#auteur","title":"Auteur","text":"<p>Het Toetsingskader risicoprofilering is ontwikkeld door het College voor de Rechten van de Mens.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/toetsingskader-risicoprofilering/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelver-03Toets het algoritme op bias en voer een rechtvaardigingstoets uitdat-02Toets en analyseer of de inputvariabelen of risicoindicatoren geschikt zijn voor het beoogde algoritme"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/","title":"Wettelijke vereisten AI-geletterdheid","text":"<p>OrganisatieverantwoordelijkhedenProbleemanalyseProjectleiderBeleid en adviesJuristGovernance</p> <p>Download hier de Factsheet Wettelijke vereisten AI-geletterdheid</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#hulpmiddel","title":"Hulpmiddel","text":"<p>Deze factsheet zet uiteen wat de eisen op het gebied van AI-geletterdheid in de AI-verordening inhouden.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#ai-geletterdheid","title":"AI-geletterdheid","text":"<p>Al-geletterdheid moet betrokkenen in staat stellen om onderbouwde beslissingen te kunnen maken met betrekking tot Al-systemen. Afhankelijk van iemands rol en het toepassingsgebied van het Al-systeem, bestaat een toereikend niveau van Al-geletterdheid uit inzicht in:</p> <ul> <li>De correcte toepassing van technische elementen tijdens de ontwikkeling van Al-systemen.</li> <li>De maatregelen die genomen moeten worden tijdens het gebruik van een Al-systeem.</li> <li>De juiste interpretatie van de output van Al-systemen.</li> <li>De impact van Al-besluiten op natuurlijke personen.</li> <li>De kennis die nodig is om naleving en handhaving van de Al-verordening mogelijk te maken.</li> </ul> <p>Bekijk ook de factsheets voor bestuurders of inkopers, met meer informatie over AI-geletterdheid specifiek voor deze rollen.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#kan-ik-100-op-dit-document-vertrouwen","title":"Kan ik 100% op dit document vertrouwen?","text":"<p>Hoewel deze informatie zorgvuldig is opgesteld kunnen er bepaalde nuances zijn verloren, gebruik deze handreiking daarom altijd samen met de offici\u00eble tekst van de AI-verordening. De interpretatie van definities en bepalingen in de AI-verordening is nog in ontwikkeling, het is daarom mogelijk dat een deel van de in dit document gegeven informatie in de loop van de tijd niet meer volledig of actueel is.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#hulpmiddelen-bij-de-ai-verordening","title":"Hulpmiddelen bij de AI-verordening","text":""},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#auteur","title":"Auteur","text":"<p>Dit document is ontwikkeld door de directie CIO Rijk (Ministerie van Binnenlandse Zaken en Koninkrijksrelaties) met adviseurs van het Rijks ICT Gilde en de interdepartementale werkgroep \u2018Rijksbrede implementatie AI-verordening\u2019 in opdracht van de CDO-raad.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#implementatie-ai-verordening","title":"Implementatie AI-verordening","text":"<p>De Rijksoverheid ontwikkelt voortdurend instrumenten en hulpmiddelen om de implementatie van de AI-verordening te ondersteunen. Onder Hulpmiddelen zijn meer van deze instrumenten te vinden, en hier kun je meer lezen over de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#bijbehorende-maatregelen","title":"Bijbehorende maatregelen","text":"IDMaatregelorg-04Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheidorg-16Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AIorg-02Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatieorg-10Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance"},{"location":"voldoen-aan-wetten-en-regels/hulpmiddelen/wettelijke-vereisten-AI-geletterdheid/#voorbeeld","title":"Voorbeeld","text":"<p>Heb jij een goed voorbeeld van het gebruik van dit hulpmiddel? Laat het ons weten!</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/","title":"Aanbevolen maatregelen","text":""},{"location":"voldoen-aan-wetten-en-regels/maatregelen/#aanbevolen-maatregelen","title":"Aanbevolen maatregelen","text":"<p>Overzicht van maatregelen waarmee je kunt voldoen aan de vereisten voor de overheid. Deze maatregelen zijn niet verplicht. Andere maatregelen zijn ook mogelijk.</p> ZoekenRollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedataduurzaamheidfundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingpublieke-inkooptechnische-robuustheid-en-veiligheidtransparantieEr zijn 108 resultaten gevonden Exporteer maatregelenExcel (XLSX)OpenDocument Spreadsheet (ODS)MaatregelenRollenLevenscyclusOnderwerpenInventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueel                  beleid-en-advies                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               transparantie              Bepaal of er genoeg experts beschikbaar zijn                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatie                  beleid-en-advies                               organisatieverantwoordelijkheden                               governance                               transparantie              Maak een plan voor het omgaan met risico\u2019s                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheid                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance                               transparantie              Sluit algoritmegovernance aan op bestaande governancestructuren binnen de organisatie                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Gebruik een algoritme volwassenheidsmodel om te weten waar de organisatie staat                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Richt een algoritmegovernance in op basis van het Three Lines-model                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Richt vaste beslismomenten en controlepunten in in de algoritmelevenscyclus                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Richt algoritmegovernance in op basis van de risicoclassificatie van algoritmes                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Maak afspraken over het beheer van gebruikers                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid                               governance              Controleer en verbeter regelmatig de kwaliteit van het algoritme                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              Maak afspraken over het beheer van wachtwoorden                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid                               governance              Maak afspraken over het wijzigen van de code                  projectleider                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid                               governance              Stel een protocol vast voor de situatie dat er (een vermoeden van) discriminatie door een algoritme is geconstateerd en pas dit wanneer nodig toe                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               implementatie                               bias-en-non-discriminatie              Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AI                  beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Beschrijf het probleem dat het algoritme moet oplossen                  projectleider                               probleemanalyse                               governance                               transparantie              Beschrijf het doel van het algoritme                  projectleider                               probleemanalyse                               governance                               transparantie              Beschrijf waarom een algoritme het probleem moet oplossen                  projectleider                               probleemanalyse                               governance                               menselijke-controle              Overleg regelmatig met belanghebbenden                  projectleider                               probleemanalyse                               ontwerp                               implementatie                               governance                               fundamentele-rechten              Beschrijf de wettelijke grondslag voor de inzet van het algoritme                  jurist                               probleemanalyse                               governance                               transparantie              Stel een multidisciplinair team samen bij het ontwikkelen of inkopen van algoritmes                  projectleider                               beleid-en-advies                               ontwerp                               publieke-inkoop              Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmes                  projectleider                               ontwerp                               implementatie                               monitoring-en-beheer                               governance              Voer voorafgaand aan een project een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit                  projectleider                               beleid-en-advies                               ontwerp                               publieke-inkoop                               data              Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit mag                  projectleider                               jurist                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               implementatie                               privacy-en-gegevensbescherming              Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing                  ontwikkelaar                               ontwerp                               technische-robuustheid-en-veiligheid              Stel vast in welke risicogroep het algoritme valt en bepaal vervolgens welke vereisten van toepassing zijn.                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               publieke-inkoop                               governance              Leg vast wat de impact van het algoritme is als het niet werkt zoals beoogd                  projectleider                               ontwikkelaar                               probleemanalyse                               ontwerp                               technische-robuustheid-en-veiligheid                               fundamentele-rechten              Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafweging                  projectleider                               beleid-en-advies                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              Maak een lijst van de meest kwetsbare groepen en bescherm hen extra                  beleid-en-advies                               ontwerp                               fundamentele-rechten              Bepaal welke documenten voor hoe lang gearchiveerd moeten worden                  ontwikkelaar                               projectleider                               jurist                               ontwerp                               ontwikkelen                               transparantie              Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmes                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               implementatie                               technische-robuustheid-en-veiligheid              Beschrijf welke data gebruikt wordt voor de beoogde toepassing                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               data              Koop duurzaam algoritmes in                  projectleider                               beleid-en-advies                               ontwerp                               publieke-inkoop                               duurzaamheid              Ontwerp algoritmes zo eenvoudig mogelijk                  ontwikkelaar                               ontwerp                               ontwikkelen                               duurzaamheid              Maak het opstellen van een verwerkersovereenkomst onderdeel van de aanbesteding als persoonsgegevens worden verwerkt                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               publieke-inkoop                               privacy-en-gegevensbescherming              Bespreek de vereisten die gelden voor een verantwoorde inzet van algoritmes met aanbieders                  projectleider                               ontwerp                               ontwikkelen                               publieke-inkoop              Maak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomst                  projectleider                               beleid-en-advies                               ontwerp                               publieke-inkoop                               transparantie              Maak het leveren van bewijs voor het voldoen aan de vereisten voor algoritmes onderdeel van de beoordeling van een inschrijving                  projectleider                               beleid-en-advies                               ontwerp                               publieke-inkoop              Laat aanbieder(s) bewijs leveren dat de door hen ontwikkelde algoritmes geen inbreuk maken op de auteursrechten van derden met de trainingsdata en de output                  projectleider                               beleid-en-advies                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               publieke-inkoop                               data              Aansprakelijkheidsvoorwaarden van een aanbieder worden beoordeeld in de aanbesteding                  jurist                               beleid-en-advies                               ontwerp                               implementatie                               publieke-inkoop              Maak vereisten onderdeel van (sub)gunningscriteria bij een aanbesteding                  ontwikkelaar                               ontwerp                               publieke-inkoop              Cre\u00eber ruimte om met een aanbieder samen te gaan werken om specifieke vereisten te realiseren                  projectleider                               ontwerp                               ontwikkelen                               publieke-inkoop              Vul technische documentatie van aanbieder aan met relevante informatie vanuit de gebruiksverantwoordelijke                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               publieke-inkoop                               transparantie              Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst                  projectleider                               beleid-en-advies                               ontwerp                               publieke-inkoop              Bepaal in een aanbesteding of algoritmes van een aanbieder bepalende invloed hebben in een besluit richting personen                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               publieke-inkoop                               transparantie              Laat de aanbieder aangeven welke mate van opleiding en ondersteuning bij de implementatie nodig is om de beoogde algoritmes verantwoord te gebruiken                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               publieke-inkoop              Voer een risico-analyse met de aanbieder uit op het gebied van informatiebeveiliging bij een uitbestedingstraject                  projectleider                               beleid-en-advies                               ontwerp                               technische-robuustheid-en-veiligheid                               publieke-inkoop              Maak vereisten onderdeel van het programma van eisen bij een aanbesteding                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               publieke-inkoop              Maak vereisten voor algoritmes onderdeel van de Service Level Agreement                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               publieke-inkoop              Maak (contractuele) afspraken over data en artefacten met een aanbieder                  jurist                               ontwerp                               implementatie                               publieke-inkoop              Stel vast welke betrokkenen ge\u00efnformeerd moeten worden en welke informatie zij nodig hebben                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               transparantie              Pas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmes                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance                               transparantie              Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               transparantie              Identificeer en implementeer technische interventies die robuustheid vergroten                  ontwikkelaar                               ontwerp                               ontwikkelen                               technische-robuustheid-en-veiligheid              Voorkom kwetsbaarheden die ge\u00efntroduceerd worden in de supply-chain van het algoritme                  ontwikkelaar                               beleid-en-advies                               jurist                               ontwerp                               publieke-inkoop                               data                               technische-robuustheid-en-veiligheid              Maak gebruik van een algoritme dat bronvermelding kan genereren bij de output                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               transparantie                               publieke-inkoop              Bepaal of een algoritme moet worden ontwikkeld of ingekocht                  projectleider                               ontwerp                               publieke-inkoop              Controleer de datakwaliteit                  ontwikkelaar                               dataverkenning-en-datapreparatie                               data              Toets en analyseer of de inputvariabelen of risicoindicatoren geschikt zijn voor het beoogde algoritme                  ontwikkelaar                               beleid-en-advies                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data                               bias-en-non-discriminatie                               privacy-en-gegevensbescherming              Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedure                  jurist                               projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               privacy-en-gegevensbescherming              Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregeren                  ontwikkelaar                               jurist                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              Controleer de auteursrechten van eigen data                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               data              Gebruik duurzame datacenters                  ontwikkelaar                               projectleider                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               implementatie                               monitoring-en-beheer                               duurzaamheid              Gebruik bij machine learning technieken gescheiden train-, test- en validatiedata en houd rekening met underfitting en overfitting                  ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               data                               technische-robuustheid-en-veiligheid                               bias-en-non-discriminatie              Zorg dat je controle of eigenaarschap hebt over de data                  projectleider                               dataverkenning-en-datapreparatie                               data                               publieke-inkoop              Beperk de omvang van datasets voor energie-effici\u00ebntie                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               ontwikkelen                               data                               duurzaamheid              Controleer de data op manipulatie en ongewenste afhankelijkheden                  ontwikkelaar                               beleid-en-advies                               dataverkenning-en-datapreparatie                               monitoring-en-beheer                               data                               technische-robuustheid-en-veiligheid              Controleer de input van gebruikers op misleiding                  ontwikkelaar                               dataverkenning-en-datapreparatie                               monitoring-en-beheer                               data                               technische-robuustheid-en-veiligheid              Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie                  ontwikkelaar                               dataverkenning-en-datapreparatie                               data              Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019                  projectleider                               ontwikkelaar                               ontwikkelen                               technische-robuustheid-en-veiligheid              Maak een noodplan voor het stoppen van het algoritme                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               governance                               menselijke-controle                               technische-robuustheid-en-veiligheid              Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houden                  projectleider                               jurist                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               privacy-en-gegevensbescherming              Maak logbestanden waarin staat wie wanneer toegang had tot de data en de code                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Kies energiezuinige programmeermethoden                  ontwikkelaar                               ontwikkelen                               duurzaamheid              Optimaliseer AI-trainingsprocessen voor energie-effici\u00ebntie                  ontwikkelaar                               ontwikkelen                               duurzaamheid              Zorg voor reproduceerbaarheid van de uitkomsten                  ontwikkelaar                               ontwikkelen                               technische-robuustheid-en-veiligheid                               transparantie              Bepaal welke feedbackloops van invloed zijn op het algoritme                  projectleider                               ontwikkelaar                               ontwerp                               ontwikkelen                               technische-robuustheid-en-veiligheid                               bias-en-non-discriminatie              Ontwerp en train het algoritme om bestand te zijn tegen (cyber)aanvallen                  beleid-en-advies                               ontwikkelaar                               ontwikkelen                               technische-robuustheid-en-veiligheid              Zorg dat (gevoelige) informatie niet kan lekken op basis van de output van het algoritme                  ontwikkelaar                               ontwikkelen                               implementatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Documenteer en beargumenteer de keuze voor gebruikte modellen en parameters                  ontwikkelaar                               ontwikkelen                               implementatie                               technische-robuustheid-en-veiligheid              Gebruik een passende licentie bij publicatie of gebruik van (open) data                  ontwikkelaar                               jurist                               ontwikkelen                               dataverkenning-en-datapreparatie                               monitoring-en-beheer                               data              Controleer regelmatig of het algoritme werkt zoals het bedoeld is                  projectleider                               ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               bias-en-non-discriminatie              Evalueer de nauwkeurigheid van het algoritme                  ontwikkelaar                               projectleider                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               bias-en-non-discriminatie              Toets het algoritme op bias en voer een rechtvaardigingstoets uit                  projectleider                               beleid-en-advies                               ontwikkelaar                               jurist                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              Zorg voor een representatieve testomgeving                  ontwikkelaar                               projectleider                               verificatie-en-validatie                               technische-robuustheid-en-veiligheid              Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid                  jurist                               verificatie-en-validatie                               monitoring-en-beheer                               governance                               transparantie              Evalueer de betrouwbaarheid van het algoritme                  ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Stel een werkinstructie op voor gebruikers                  projectleider                               beleid-en-advies                               implementatie                               menselijke-controle                               transparantie                               governance              Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controleren                  ontwikkelaar                               dataverkenning-en-datapreparatie                               implementatie                               monitoring-en-beheer                               bias-en-non-discriminatie                               technische-robuustheid-en-veiligheid              Richt bij besluitvorming betekenisvolle menselijke tussenkomst in                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               monitoring-en-beheer                               menselijke-controle                               governance              Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregister                  projectleider                               beleid-en-advies                               implementatie                               monitoring-en-beheer                               transparantie              Vermeld het gebruik van persoonsgegevens in een privacyverklaring                  projectleider                               jurist                               implementatie                               privacy-en-gegevensbescherming                               transparantie              Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces                  projectleider                               ontwikkelaar                               implementatie                               monitoring-en-beheer                               governance              Vermeld het gebruik van persoonsgegevens in het verwerkingsregister                  projectleider                               jurist                               implementatie                               transparantie                               privacy-en-gegevensbescherming              Maak een openbaar besluit over de inzet van het algoritme                  projectleider                               organisatieverantwoordelijkheden                               implementatie                               governance                               transparantie              Neem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomen                  ontwikkelaar                               projectleider                               beleid-en-advies                               implementatie                               ontwikkelen                               technische-robuustheid-en-veiligheid                               menselijke-controle              Spreek af hoe de organisatie omgaat met privacy-verzoeken                  projectleider                               beleid-en-advies                               jurist                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               governance                               data              Maak back-ups van algoritmes                  ontwikkelaar                               beleid-en-advies                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Beveilig de software                  projectleider                               beleid-en-advies                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Maak een noodplan voor beveiligingsincidenten                  projectleider                               beleid-en-advies                               jurist                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid                               governance              Maak een evaluatieplan voor tijdens het gebruik van het algoritme                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Monitor regelmatig op veranderingen in de data. Bij veranderingen evalueer je de prestaties en output van het algoritme.                  ontwikkelaar                               monitoring-en-beheer                               data                               technische-robuustheid-en-veiligheid              Meten, monitoren en rapporteren van milieu-impact van algoritmes                  ontwikkelaar                               beleid-en-advies                               projectleider                               ontwerp                               monitoring-en-beheer                               duurzaamheid              Stel een plan op voor continue monitoring                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Controleer regelmatig of een algoritme voldoende weerbaar is tegen bekende aanvallen                  ontwikkelaar                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Bij uitfaseren en doorontwikkeling wordt correct omgegaan met data en modelinformatie                  ontwikkelaar                               uitfaseren                               ontwerp                               technische-robuustheid-en-veiligheid                               privacy-en-gegevensbescherming                               transparantie"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/#alle-maatregelen-zijn-adviezen","title":"Alle maatregelen zijn adviezen","text":"<p>De maatregelen zijn niet verplicht. Het zijn adviezen uit:</p> <ul> <li>Toetsingskader Algoritmes, Algemene Rekenkamer</li> <li>Onderzoekskader algoritmes, Auditdienst Rijk</li> <li>nationale en internationale standaarden (NEN, JTC21 en ISO)</li> <li>andere relevante bronnen</li> <li>onze werkgroepen</li> </ul> <p>Benieuwd hoe de maatregelen samenhangen met het Onderzoekskader van de Auditdienst Rijk en het Toetsingskader van de Algemene Rekenkamer?</p> <p>Bekijk de zogenaamde 'mapping' tussen de maatregelen uit het Algoritmekader, het Toetsingskader Algoritmes en het Onderzoekskader algoritmes. Hierin zie je waar elke maatregel uit deze kaders terugkomt in het Algoritmekader. Dit staat ook altijd aangegeven in de bronvermelding van de betreffende maatregel.</p> <p>Download mapping</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/#voorbeeld","title":"Voorbeeld","text":"<p>Onderzoek het ontwikkelde algoritme op onbewuste vooringenomenheid (discriminatie) door middel van een bias-analyse.</p> <p>Deze maatregel helpt om te voldoen aan de vereiste om niet te discrimineren. Maar deze maatregel is niet verplicht. Je organisatie mag ook eigen maatregelen nemen. Zolang je uiteindelijk maar voldoet aan de vereiste.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/#aantal-maatregelen-verschilt-per-situatie","title":"Aantal maatregelen verschilt per situatie","text":"<p>Welke maatregelen handig zijn in jouw situatie, hangt af van:</p> <ul> <li>de fase in de levenscyclus van je project</li> <li>de vereisten waar jouw organisatie aan moet voldoen</li> <li>jouw rol in de organisatie</li> </ul> <p>Tip</p> <p>Met \u00e9\u00e9n maatregel voldoe je soms aan meerdere vereisten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/","title":"Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueel","text":"<p>org-00OrganisatieverantwoordelijkhedenMonitoring en beheerBeleid en adviesGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/#maatregel","title":"Maatregel","text":"<p>Inventariseer de algoritmes die binnen jouw organisatie worden gebruikt en houd dit overzicht actueel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/#toelichting","title":"Toelichting","text":"<p>Om grip te krijgen op het gebruik van algoritmes binnen jouw organisatie, heb je allereest overzicht nodig van de algoritmes die in jouw organisatie gebruikt worden. Zorg dat je dit overzicht regelmatig actualiseert. Bepaal voor ieder algoritme de risicogroep en vervolgens welke vereisten daarop van toepassing zijn. Hiervoor kan je gebruik maken van de beslishulp AI-verordening.</p> <p>Bepaal ook of er sprake is van geautomatiseerde besluitvorming of geautomatiseerde risicoselectie.</p> <p>Inventariseren van de algoritmes die gebruikt worden, helpt bij:</p> <ul> <li>Inzicht in de risico's en kansen van het gebruik van algoritmes.</li> <li>Het correct registreren van de algoritmes in het Algoritmeregister</li> <li>Het opzetten van een goede algoritmegovernance.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking identificatie verboden AI-systemen (.pptx, 9MB)</li> <li>Handreiking Algoritmeregister</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-00-inventariseren-algoritmes/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-01-benodigde-expertise-en-capaciteit/","title":"Bepaal of er genoeg experts beschikbaar zijn","text":"<p>org-01OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#maatregel","title":"Maatregel","text":"<p>Bepaal welke expertise en capaciteit noodzakelijk is voor het ontwikkelen, inkopen en gebruiken van algoritmes en stel vast of er voldoende expertise en capaciteit beschikbaar is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#toelichting","title":"Toelichting","text":"<ul> <li>Bepaal welke expertise en capaciteit binnen de organisatie noodzakelijk is voor het ontwikkelen, inkopen en gebruiken van algoritmes.</li> <li>Dit is sterk afhankelijk van de specifieke toepassing en de inzichten die voortkomen uit risicoanalyses. Hoe complexer en risicovoller de toepassing, des te meer expertise en capaciteit noodzakelijk is.</li> <li>Indien is vastgesteld dat er onvoldoende expertise aanwezig is, investeer dan in bewustwording en voldoende opleidingen over de kansen en risico's van algoritmes en AI.</li> <li>Interne en externe actoren die betrokken zijn bij het ontwikkelen, inkopen en gebruik moeten over voldoende expertise en capaciteit beschikken om hun taken naar behoren uit te voeren.</li> <li>Stel vast of er afhankelijkheden van externe aanbieders ontstaan.</li> <li>Bepaal voorafgaand aan het (laten) ontwikkelen of inkopen van algoritmes of voldoende expertise en capaciteit beschikbaar is om tot een verantwoorde inzet ervan te komen.</li> <li>Leg vast of er voldoende expertise en capaciteit beschikbaar is en onderbouw dit in projectdocumentatie.</li> <li>Om menselijke controle te kunnen uitoefenen in verschillende fases van de ontwikkeling (of inkoop) van algortimes moet de mens bepaalde kennis, tijd en vaardigheden hebben. Alleen met de juiste kennis, tijd en vaardigheden kunnen risico\u2019s op tijd ge\u00efdentificeerd en afgedekt worden. Deze kennis en expertise kan ook buiten de organisatie liggen, maar dan is het belangrijk om verantwoordelijkheden goed vast te leggen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#risico","title":"Risico","text":"<p>Zonder voldoende expertise en capaciteit kan het zijn dat het ontwikkelen, inkopen, en gebruiken van algoritmes niet goed verloopt binnen de organisatie doordat de middelen hiervoor ontbreken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.12</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.04</li> <li>Competencies and governance practices for AI in the public sector. Zie hoofdstuk 4</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-01-benodigde-expertise-en-capaciteit/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-02-beleid-opstellen-inzet-algoritmes/","title":"Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatie","text":"<p>org-02OrganisatieverantwoordelijkhedenBeleid en adviesGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-02-beleid-opstellen-inzet-algoritmes/#maatregel","title":"Maatregel","text":"<p>Stel beleid op voor een verantwoorde inzet van algoritmes binnen de organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-02-beleid-opstellen-inzet-algoritmes/#toelichting","title":"Toelichting","text":"<p>Een duidelijk beleid over de inzet van algoritmes helpt organisaties te voldoen aan de vereisten voor het verantwoord gebruik ervan. Hierin worden zaken beschreven als:</p> <ul> <li>Hoe de inzet van algoritmes gaat bijdragen aan het realiseren van de organisatiedoelstellingen.</li> <li>Het beschrijven van de stappen die moeten worden gezet om algoritmes op een verantwoorde wijze in te gaan zetten. Dit is afhankelijk en verschilt per type algoritme en de bijbehorende risicoclassificatie.</li> <li> <p>Het beschrijven van welke hulpmiddelen in welke gevallen moeten worden ingezet om te voldoen aan de vereisten die gelden voor algoritmes. Hierbij kan worden gedacht aan:</p> <ul> <li>Een Impact Assessment Mensenrechten en Algoritmes.</li> <li>Een Data Protection Impact Assessment.</li> <li>Het hanteren van inkoopvoorwaarden.</li> <li>Het uitvoeren van een biasanalyse.</li> </ul> </li> <li> <p>Hoe burgers worden ge\u00efnformeerd over de inzet van algoritmes door de organisatie (communicatiestrategie) en welke kanalen hiervoor kunnen worden gebruikt. Hierbij kan worden gedacht aan:</p> <ul> <li>Het Algoritmeregister voor het publiceren van hoog risico AI-systemen of impactvolle algoritmes.</li> <li>Een algemene pagina op de website met informatie over de inzet van algoritmes.</li> <li>Het verwerkingsregister.</li> <li>Een intern registratiesysteem, bijvoorbeeld voor het registreren van laag risico of niet-impactvolle algoritmes zodat deze informatie voor medewerkers beschikbaar is.</li> <li>In welke gevallen een (openbaar) besluit wordt genomen door het bestuur over de inzet van een algoritme.</li> </ul> </li> <li> <p>Of algoritmes zelf worden ontwikkeld, of dat algoritmes of systemen worden ingekocht. Dit vraagt om een andere governancestructuur en aanpak.</p> </li> <li> <p>Er is beschreven welke informatie over welke typen algoritmes wordt gecommuniceerd met betrokkenen bij de ontwikkeling of gebruik ervan door de organisatie.</p> </li> <li> <p>Stel dit beleid op voor zowel:</p> <ul> <li>nieuw te ontwikkelen algoritmes</li> <li>gedurende de ontwikkeling van algoritmes</li> <li>bestaande algoritmes</li> </ul> </li> <li> <p>Bepaal in welke gevallen het nodig is om een externe audit of validatie uit te voeren op het algoritme.</p> </li> <li>Bepaal of het wenselijk is om gebruik te maken van een (externe) ethische commissie en hoe dit onderdeel kan zijn van je processen.</li> <li>Er is beschreven welke stappen worden gezetten in het geval dat er incidenten ontstaan rondom de inzet van algoritmes, denk hierbij aan een discriminatieprotocol.</li> <li>Betrek een brede groep met verschillende disciplines bij de ontwikkeling van governance.</li> <li>Dit beleidsdocument is beschikbaar en toegankelijk voor ge\u00efnteresseerden.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-02-beleid-opstellen-inzet-algoritmes/#risico","title":"Risico","text":"<p>Zonder duidelijk beleid over de inzet van algoritmes kan het gebeuren dat algoritmes worden ontwikkeld of gebruikt die niet passend zijn binnen de organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-02-beleid-opstellen-inzet-algoritmes/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, SV.8</li> <li>IPO Whitepaper ChatGPT, overwegingen voor verantwoord gebruik</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-02-beleid-opstellen-inzet-algoritmes/#voorbeelden","title":"Voorbeelden","text":"<p>Handreiking Algoritmen - Gemeente Amsterdam</p> <p>Gemeente Amsterdam heeft een Handreiking Algoritmen ontwikkeld waarin de aanpak van en instrumenten voor verantwoord algoritme\u00ad\u00adgebruik in Amsterdam worden toegelicht. Denk aan governance voor verantwoorde toepassing van algoritmes, en contractvoorwaarden voor algoritmische toepassingen.</p> <p>Bron: Handreiking Algoritmen (Er zijn hier ook handreikingen te vinden over Dataverzameling en Digitale ongelijkheid.)</p> <p>Ethische commissie Gemeente Groningen</p> <p>Gemeente Groningen maakt gebruik van een ethische commissie Data en Technologie. De commissie adviseert het college gevraagd en ongevraagd over het gebruiken van (nieuwe) digitale technologie\u00ebn in de gemeente Groningen. Denk aan kunstmatige intelligentie (AI), algoritmen en sensoren.</p> <p>Ervaring uit de praktijk</p> <p>Werk samen. Betrek iedereen die je nodig hebt. De directie moet willen. En die moet het begrijpen. Laat juristen niet pas achteraf stukken lezen. Neem iedereen mee. Dan wordt iedereen verantwoordelijk. En ontstaat wederzijds vertrouwen.\"</p> <p>Ervaring uit de praktijk</p> <p>\"Je moet een hele duidelijke visie hebben. Wat zijn dan de dingen die we op ons af zien komen? Wat betekent dit voor ons? Wat willen we daarmee? En hoe gaan we dat wegzetten in de tijd dat we daarmee omgaan? Want we kunnen niet alles tegelijk gaan doen. Je moet daar een soort volgordelijkheid in gaan bouwen van wat gaan we dan eerst doen? En waar gaan we dan mee aan de slag?\"</p> <p>Ervaring uit de praktijk</p> <p>\"Als je wilt starten, start klein aan de hand van een casus. Langs die casus kan je ontdekken welke stappen je moet zetten om ervoor te zorgen dat je de ethische waarde goed inricht, dat je vanuit privacy en security goed hebt ingericht en dat je ook daadwerkelijk die toegevoegde waarde voor de organisatie realiseert.\"</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/","title":"Maak een plan voor het omgaan met risico\u2019s","text":"<p>org-03OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/#maatregel","title":"Maatregel","text":"<p>Pas risicobeheer gestructureerd toe voorafgaand en gedurende de ontwikkeling en gebruik van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/#toelichting","title":"Toelichting","text":"<ul> <li>Bepaal tijdig, bijvoorbeeld in de ontwerpfase om wat voor toepassing het gaat (algoritme of AI-systeem) en bepaal welke risicoclassificatie hierbij hoort.</li> <li>Bepaal op basis van de toepassing en de risicoclassificatie, welke aspecten van risicobeheer moeten worden toegepast.</li> <li>Inventariseer tijdig, bijvoorbeeld in de probleemanalayse- of ontwerpfase, bij betrokken experts welke beleidskaders en hulpmiddelen binnen de organisatie moeten worden ingezet om risicobeheer toe te passen.</li> <li>Bepaal op basis van de levenscyclus van een algoritme of AI-systeem wanneer welke aspecten van risicobeheer moeten worden toegepast.</li> <li>Maak inzichtelijk op welke niveaus risicobeheer kan en moet worden belegd bij het ontwikkelen en gebruiken van algoritmes.</li> <li>Daarbij gaat het om het identificeren, analyseren, evalueren (afhankelijk van de risicobereidheid), behandelen (risicoreactie, o.a. maatregelen), monitoren &amp; beoordelen en communiceren &amp; rapporteren van risico's.</li> <li>Gedurende de levenscyclus van een algoritme of AI-systemen kunnen nieuwe risico's ontstaan waar mogelijk nieuwe maatregelen voor moeten worden getroffen. Het is van belang dat iteratief wordt gewerkt aan mitigerende maatregelen en dat risicobeheer periodiek wordt toegepast.</li> </ul> <p>Let op! Sommige maatregelen in het Algoritmekader gaan dieper in op het uitvoeren van risicoanalyses.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/#generatieve-ai","title":"Generatieve AI","text":"<p>Bij het gebruik van generatieve AI is het van extra belang dat risico's gedekt worden.</p> <ul> <li>Breng de veiligheidsrisico's van generatieve AI-toepassingen systematisch in kaart, bijvoorbeeld door middel van de OWASP Risk Rating Methodology.</li> <li>Verzeker je ervan dat je door ontwikkeling of gebruik van generatieve AI niet discrimineert. Stel een protocol op voor situaties waar discriminatie toch optreedt.</li> <li>Zorg ervoor dat je een eindverantwoordelijke aanstelt op het kruisingsgebied tussen cybersecurity en generatieve AI, en een eindverantwoordelijke voor privacy en generatieve AI. Stel ook een ondersteunende rol aan, bij wie medewerkers terecht kunnen voor vragen over generatieve AI.</li> <li>Maak het mogelijk om incidenten te rapporteren.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/#risico","title":"Risico","text":"<p>Risico's worden niet (tijdig) vastgesteld en adequaat geadresseerd en behandeld.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.13 </li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.03</li> <li>OWASP Risk Rating Methodology</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-03-toepassen-risicobeheer/#voorbeelden","title":"Voorbeelden","text":"<p>Nationaal Cyber Security Centrum: Richtlijnen veilig software ontwikkelen</p> <p>Het Nationaal Cyber Security Centrum van het Ministerie van Justitie en Veiligheid heeft een publicatie over het ontwikkelen van veilige software. Hierin staat beschreven hoe op beleidsmatig niveau beveiligingsrichtlijnen toegepast kunnen worden. Er wordt in Hoofdstuk B.03 'Risicomanagement' een duidelijk beeld geschetst van wat noodzakelijke maatregelen hiervoor zijn.</p> <p>Hier worden ook verschillende methodes voorgesteld voor de risicoanalyse. Omdat deze publicatie uit 2021 komt is bijvoorbeeld de NEN-ISO/IEC 27005:2011 niet maar van toepassing maar is deze vervangen door de versie uit 2024 (NEN-ISO/IEC 27005:2024).</p> <p>Bron: Beleids- en beheersingsrichtlijnen voor de ontwikkeling van veilige software</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-04-politiek-bestuurlijke-verantwoordelijkheid/","title":"Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid, en verantwoordelijkheid","text":"<p>org-04OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-04-politiek-bestuurlijke-verantwoordelijkheid/#maatregel","title":"Maatregel","text":"<p>Zorg voor politiek-bestuurlijk bewustzijn, betrokkenheid en verantwoordelijkheid.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-04-politiek-bestuurlijke-verantwoordelijkheid/#toelichting","title":"Toelichting","text":"<p>Voor een passende algoritmegovernance is politiek-bestuurlijk bewustzijn, betrokkenheid en verantwoordelijkheid essentieel. Het maken van verantwoorde keuzes rond de inzet van specifieke algoritmen en AI en het vinden van balans tussen voordelen en risico's, juridische vereisten en ethische principes vraagt om een bestuurlijke afweging. Daarmee is ook het opstellen van een goede governancestructuur een bestuurlijke verantwoordelijkheid. Zorg ervoor dat bestuurders bewust zijn van de voor- en nadelen van de inzet van algoritmes en daarnaar kunnen handelen. Het opstellen van een juiste governancestructuur helpt teams bij het maken van de juiste overwegingen bij de ontwikkeling en gebruik van algoritmes. Het geeft ook inzicht wanneer de politiek of bestuurlijk verantwoordelijke(n) moeten worden betrokken bij het project om beslissingen te nemen, bijvoorbeeld of de mate van onbewuste vooringenomenheid (bias) binnen acceptabele grenzen ligt.</p> <p>De kernvraag voor publieke organisaties bij de inzet van algoritmen is altijd: Hoe wegen we (als publieke organisatie of samenleving) de voordelen en nadelen van de inzet van algoritmen? Dit gaat niet alleen over direct opbrengsten maar ook over lange termijn en indirecte effecten, de mate waarin de inzet van technologie bijdraagt aan de legitimiteit van publieke organisatie en hoe burgers met deze technologie worden bejegend.</p> <p>Om te zorgen voor politiek-bestuurlijke betrokkenheid kan het helpen om een meerjarige visie/strategie rondom verantwoorde inzet te formuleren waar een communicatiestrategie richting burgers onderdeel van is. Het doorlopen van een concrete casus voor de ontwikkeling en gebruik van een algoritme, inclusief het uitvoeren van een IAMA, kan waardevolle informatiegeven om een meerjarige visie of strategie op te stellen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-04-politiek-bestuurlijke-verantwoordelijkheid/#risico","title":"Risico","text":"<p>Het verwaarlozen van politiek-bestuurlijk bewustzijn, betrokkenheid en verantwoordelijkheid kan leiden tot een het ontwikkelen van algoritmegovernance dat op de lange termijn niet effectief inzetbaar is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-04-politiek-bestuurlijke-verantwoordelijkheid/#bronnen","title":"Bronnen","text":"<p>Kleur bekennen, Rekenkamer Rotterdam</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-04-politiek-bestuurlijke-verantwoordelijkheid/#voorbeelden","title":"Voorbeelden","text":"<p>Voorbeeld gemeente Rotterdam</p> <p>\u00c9\u00e9n van de belangrijkste hoofdconclusies uit het rapport Kleur bekennen onderstreept het belang van actief bestuur binnen algoritme- en AI-governance:</p> <p>\"Het ontbreekt aan een politiek-bestuurlijk kader dat duidelijk maakt welke normen en principes leidend zijn bij de ontwikkeling en het gebruik van algoritmes. Dit heeft als effect dat belangrijke besluit over bijvoorbeeld wenselijkheid, haalbaarheid, transparantie en bias bij de ambtelijke organisatie komen te liggen. Deze besluiten vragen om een politieke afweging\".</p> <p>De algoritmegovernance van de Gemeente Rotterdam bestaat uit een:</p> <ul> <li>visie op de inzet van algoritmes</li> <li>instrumentarium voor risicobeheersing dat onder andere bestaat uit een risico-assessment en een mensenrechtenassessment</li> <li>uiteenzetting van rollen en verantwoordelijkheden</li> <li>omschrijving van de verantwoordelijkheden voor controle en advies</li> </ul> <p>Deze stappen volgen kan helpen bij het inrichten van een algoritmegovernance.</p> <p>Visie op algoritmische systemen Dienst Toeslagen</p> <p>De Dienst Toeslagen heeft een Visie op algoritmische systemen opgesteld. Deze visie beschrijft hoe Dienst Toeslagen algoritmische systemen wil inzetten, hoe dat te bereiken en welke kansen en welke randvoorwaarden nodig zijn voor een verantwoorde inzet. De visie bevat een vertaling van de missie, visie en kernwaarden van Dienst Toeslagen naar de context van algoritmische systemen.</p> <p>Amsterdamse Visie op AI</p> <p>De gemeente Amsterdam heeft samen met bewoners, de Amsterdamse Visie op AI gemaakt: een visie die ons helpt AI op een verantwoorde, betrouwbare en mensgerichte manier te gebruiken.</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/","title":"Sluit algoritmegovernance aan op bestaande governancestructuren binnen de organisatie","text":"<p>org-05OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#maatregel","title":"Maatregel","text":"<p>Sluit algoritmegovernance aan op bestaande governancestructuren binnen de organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#toelichting","title":"Toelichting","text":"<p>Zoek bij het opstellen van een algoritmegovernance van een organisatie aansluiting en samenwerking met huidige governancestructuren. Dit kan op drie manieren: aansluiting bij bestaande governance binnen je organisatie, governance van andere sectoren en governance van andere overheidsorganisaties.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#aansluiting-met-bestaande-governancestructuren-binnen-je-eigen-organisatie","title":"Aansluiting met bestaande governancestructuren binnen je eigen organisatie","text":"<p>Zoek aansluiting met bestaande governance binnen je organsatie, zoals:</p> <ul> <li>IT governance</li> <li>datagovernance</li> <li>informatiebeveiliging zoals governance rondom de NIS2 richtlijn</li> <li>privacygovernance</li> </ul> <p>Deze governancestructuren kunnen waardevolle aanknopingspunten bieden voor algoritmegovernance, omdat hierin vaak al duidelijke afspraken zijn gemaakt en processen zijn geschreven om bijvoorbeeld risico's zo goed mogelijk te managen. In veel organisaties werken bijvoorbeeld privacy- en informatiebeveiliging en informatiebeheerders nauw samen van strategisch organisatieniveau tot operationeel, omdat deze onderwerpen raken aan beide domeinen. Voor een verantwoorde inzet van algoritmes zullen deze expertise moeten gaan samengewerkt met andere expertise, zoals die van data science en ethiek. Het is van belang dat deze expertises tijdig en voldoende ruimte krijgen om samen te werken, zodat de functionele en niet functionele requirements kunnen worden gedefinieerd voor een verantwoorde inzet van algoritmes. Stel vast waar deze expertises elkaar nodig hebben en waar deze zelfstandige taken en verantwoordelijkheden hebben. Voorgaande geeft inzichten om te bepalen in hoeverre algoritmegovernance, naast de bestaande governancestructuren, moet worden ingericht.</p> <p>De volgende vragen kunnen bedragen om bovenstaande inzichtelijk te krijgen:</p> <ul> <li>Welke lessen zijn geleerd met de implementatie van de AVG of de toepassing van de BIO?</li> <li>Is er iemand intern verantwoordelijk gemaakt voor (toezicht op) algoritmes?</li> <li>Hoe werken experts vanuit verschillende onderwerpen zoals privacy, informatiebeheer, informatiebeveiliging en data op dit moment samen als het gaat om de inzet van algoritmes?</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#governance-van-andere-sectoren","title":"Governance van andere sectoren","text":"<p>Andere sectoren hebben in veel gevallen al governancestructuren met vergelijkbare elementen. Denk aan governancestructuren uit de verzekeringssector of de bankensector.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#aansluiting-met-andere-overheidsorganisaties","title":"Aansluiting met andere overheidsorganisaties","text":"<p>Probeer aansluiting te zoeken met vergelijkbare overheidsorganisaties.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#risico","title":"Risico","text":"<p>Als er bij de bestaande governancestructuren geen rekening wordt gehouden met het invoeren van algoritmegovernance is er een risico dat verantwoord gebruik van algoritmes niet genoeg wordt overwogen binnen de organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-05-bestaande-governance/#voorbeelden","title":"Voorbeelden","text":"<p>Ervaring uit de praktijk</p> <p>\"Misschien is het grootste succes wel dat we het vooral niet helemaal zelf bedacht hebben. En dat we het gewoon grotendeels gekopieerd hebben van andere partijen die dit hebben gemaakt. En vooral hebben gekeken naar wat we als organisatie nodig hebben.\"</p> <p>Voorbeeld: Ervaringen Kadaster</p> <p>Enkele ervaringen van het Kadaster bij het aansluiten van nieuwe onderwerpen op de bestaande governance-structuren:</p> <ol> <li>Bij de inwerkingtreding van de AVG ging men bij veel organisaties, waaronder het Kadaster, voortvarend aan de slag met DPIA\u2019s en andere instrumenten. Volgens het Kadaster is het echter belangrijk te waken voor een schijndossier: begrijp goed wat daadwerkelijk toegepast moet worden voordat je begint; voer geen acties uit alleen om maar aan te tonen dat je eraan voldoet.</li> <li>Het Kadaster benadrukt daarnaast het belang van een doordachte governance. Hoewel de rol van de Functionaris Gegevensbescherming (FG) wettelijk is vastgelegd, is dit niet voldoende. Er moet worden nagedacht over de benodigde profielen ter ondersteuning van de uitvoering, zoals (centrale) privacy officers, en of hiervoor voldoende capaciteit beschikbaar is.</li> <li>Verder is het volgens het Kadaster essentieel dat interpretaties van wet- en regelgeving consistent zijn binnen de organisatie en tussen collega\u2019s die binnen de governance-structuur samenwerken.</li> <li>Uit ervaring blijkt bovendien dat er vaak beleid wordt opgesteld, maar dat in de praktijk de capaciteit ontbreekt om dit uit te voeren. Daarom pleit het Kadaster voor een realistisch beleidsplan waarmee de gestelde doelen daadwerkelijk kunnen worden gerealiseerd.</li> </ol> <p>Handreiking gezamenlijk gebruik IAMA en DPIA - Ministerie van BZK</p> <p>Binnen het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties (BZK) is een handreiking opgesteld voor het gezamenlijk gebruik van twee impact assessments: de Data Protection Impact Assessment (DPIA) en Impact Assessment Mensenrechten en Algoritmes (IAMA).</p> <p>In deze handreiking wordt toegelicht wat de overeenkomsten en verschillen tussen het IAMA en DPIA zijn. Daarnaast wordt aangegeven hoe deze instrumenten gecombineerd kunnen worden. Het doel is om zo deze instrumenten op een effici\u00ebnte en gebruikersvriendelijke manier samen te kunnen gebruiken.</p> <p>Bron: Handreiking gezamenlijk gebruik IAMA en Model DPIA Rijksdienst</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-06-volwassenheidsmodel/","title":"Gebruik een algoritme volwassenheidsmodel om te weten waar de organisatie staat","text":"<p>org-06OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-06-volwassenheidsmodel/#maatregel","title":"Maatregel","text":"<p>Breng de volwassenheid van je organisatie op het gebied van algoritmes in kaart.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-06-volwassenheidsmodel/#toelichting","title":"Toelichting","text":"<ul> <li>Om tot een passende algoritmegovernance voor een organisatie te komen, moet eerst worden vastgesteld wat op dit moment al is ingericht binnen een organisatie op het gebied van algoritmes.</li> <li>Hiervoor kan een volwassenheidsmodel worden toegepast.</li> <li>Op basis hiervan kunnen vervolgstappen worden gedefinieerd, zodat je een handelingsperspectief hebt om je organisatie te organiseren. Ook kunnen deze uitkomsten helpen bewustzijn over de uitdagingen te vergroten.</li> <li>Het is denkbaar dat het realiseren van algoritmegovernance vraagt om een organisatieverandering. De noodzaak voor implementatie van de AI-Verordening kan hier een katalysator voor zijn. Pas daarom verandermanagementtechnieken toe.</li> <li>Deel deze informatie met het bestuur en zorg dat hier bewustzijn ontstaat. Bepaal vervolgens hoe algoritmegovernance moet worden ingericht.</li> <li>Het is aan te raden om verantwoordelijkheden te beleggen voor het realiseren van algoritmegovernance.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-06-volwassenheidsmodel/#risico","title":"Risico","text":"<p>Als je niet een goed beeld hebt van waar de organisatie staat, is het moeilijk te peilen welke richting gekozen moet worden en kan dit leiden tot het doen van dubbel werk.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-06-volwassenheidsmodel/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-06-volwassenheidsmodel/#voorbeelden","title":"Voorbeelden","text":"<p>Voorbeeld: Interbestuurlijke Datastrategie - Datavolwassenheidsmodel</p> <p>Het datavolwassenheidmodel van de Interbestuurlijke Datastrategie (IBDS) kijkt naar hoe goed organisaties omgaan met data. Dit model is ook belangrijk voor algoritmes, omdat data daar een grote rol speelt. Het model heeft een beslishulp datavolwassenheid waarmee bepaald kan worden hoe volwassen een organisatie is met data. IBDS biedt ook een gids aan met verschillende manieren om de datavolwassenheid in kaart te brengen.</p> <p>Bron: Beslishulp datavolwassenheid</p> <p>Voorbeeld: Krijger, Thuis, de Ruiter, Ligthart &amp; Broekman - AI ethics maturity model</p> <p>Het in 2023 gepubliceerde \u2018AI ethics maturity model' door Krijger, Thuis, de Ruiter, Ligthart &amp; Broekman gebruikt zes categorie\u00ebn om volwassenheid op verschillende niveaus in kaart te brengen. Dit model focust zich met name op het ethische aspect van volwassenheid met als categorie\u00ebn: awareness &amp; culture, policy, governance, communication &amp; training, development process en tooling. Er zijn vijf verschillende niveaus waar iedere categorie onder kan vallen om zo volwassenheid aan te geven.</p> <p>Bron: The AI ethics maturity model</p> <p>Voorbeeld: MITRE - AI Maturity Model en Organizational Assessment Tool</p> <p>MITRE is een Amerikaanse non-profitorganisatie en enigzins vergelijkbaar met het Nederlandse TNO. Zij hebben een AI Maturity Model en de bijbehorende Organizational Assessment Tool ontwikkeld. Dit volwassenheidsmodel onderscheidt een zestal pijlers in de AI volwassenheid van een organisatie en daarbij een vijftal volwassenheidsniveaus.  In dit document wordt ook toegelicht hoe een organisatie van een niveau naar het volgende kan ontwikkelen. Daarnaast wordt dit ook op individuele pijlers uitgelegd.</p> <p></p> <p>Bron: MITRE AI Maturity Model</p> <p>Voorbeeld: Rijksorganisatie voor Ontwikkeling, Digitalisering en Innovatie - Innovatie Maturity Scan</p> <p>De Rijksorganisatie voor Ontwikkeling, Digitalisering en Innovatie (ODI) heeft een Innovatie Maturity Scan gemaakt om de innovatievolwassenheid van een organisatie te meten. Omdat het gebruik van algoritmes vaak gezien wordt als vorm van innovatie is dit ook een interessant model om naar te kijken.</p> <p>De scan bestaat uit vijf niveaus (level 1 t/m 5) en vijf segmenten (leiderschap, cultuur, sociaal, uitvoering en sturing). Aan de hand van stellingen in de scan kan op deze manier het niveau per segment bepaald worden.</p> <p>Bron: Innovatie Maturity Scan</p> <p>Practice: Provincie Overijsel - Implementatiestrategie Digitale-Ethiek</p> <p>Provincie Overijsel heeft in hun implementiestrategie Digitale Ethiek verschillende zaken opgenomen, waaronder een volwassenheidsmodel. Hierin focussen zij zich op het toekomstbestendig maken van de provincie met de notie dat het hoogste niveau voor hen op dit moment te hoog gegrepen is. Zij geven zo dus duidelijk aan welke niveaus zij haalbaar achten en geven concrete voorbeelden over hoe zij dit aan willen pakken.</p> <p></p> <p>Bron: Implementatiestrategie Digitale-Ethiek</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/","title":"Richt een algoritmegovernance in op basis van het Three Lines-model","text":"<p>org-07OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/#maatregel","title":"Maatregel","text":"<p>Richt een algoritmegovernance in op basis van het Three Lines-model.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/#toelichting","title":"Toelichting","text":"<p>Een inrichting van algoritmegovernance die vaak wordt toegepast is het Three Lines-model:</p> <ul> <li>De eerste linie gaat over eigenaarschap, ontwikkeling, gebruik en risicobeheersing van algoritmes.</li> <li>De tweede linie identificeert, beoordeelt en rapporteert over risico\u2019s en het uitgevoerde gebruik van algoritmes.</li> <li>De derde verdedigingslinie controleert de werking van de governance en betreft interne advisering en toetsing.</li> </ul> <p>Meer informatie over het inrichten van een Three Lines-model vind je in de handreiking van het Institute of Global Auditors (IIA).</p> <p>Het toepassen van een 'three lines of defence' is slechts \u00e9\u00e9n aspect van het toepassen van algoritmegoverance.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/#risico","title":"Risico","text":"<p>Een risico van het vermijden van het three lines of defence model is dat er stappen worden overgeslagen bij het ontwikkelen van een algoritmegovernance.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten <p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/#bronnen","title":"Bronnen","text":"<ul> <li>Institute of Global Auditors (IIA) - Handreiking Three Lines Model (Nederlands).</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-07-intern-toezicht/#voorbeelden","title":"Voorbeelden","text":"<p>UWV - Risicomanagementbeleid</p> <p>Het UWV maakt sinds 2012 gebruik van het Three-lines-of-defence model als onderdeel van hun governance. Zij blijven dit model verder aanscherpen binnen hun organisatie waardoor de drie lijnen concreter worden. Zo geven ze aan dat ze toewerken naar meer uniformiteit in rapporteren van risico\u2019s uit de eerste lijn en een meer onafhankelijk oordeel over risico\u2019s en beheersing van de tweede lijn.</p> <p>Bron: Beslisnotitie vaststellen risicomanagementbeleid</p> <p>Gemeente Rotterdam - Kleur Bekennen</p> <p>De gemeente Rotterdam maakt gebruik van het three-lines-of-defence model voor het sturen en verantwoorden binnen de gemeente. De lijnen binnen Rotterdam werken iets anders dan het model van Schuett hierboven. De eerste lijn is namelijk verantwoordelijk van het realiseren van de gestelde doelen, de tweede lijn voor de kaders en het advies (onafhankelijk van de eerste lijn) en de derde lijn controleert of lijn een en twee correct functioneren/hebben gefunctioneerd.</p> <p>Zij geven ook aan wie binnen iedere lijn verantwoordelijk is. Zo zijn Proceseigenaren verantwoordelijk voor het algoritme en operationeel verantwoordelijken voor de ontwikkeling binnen de eerste lijn. In de tweede lijn is de Algoritme Expert verantwoordelijk en in de derde lijn Financial Audit.</p> <p>Bron: Kleur Bekennen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-08-beslismoment-levenscyclus/","title":"Richt vaste beslismomenten en controlepunten in in de algoritmelevenscyclus","text":"<p>org-08OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-08-beslismoment-levenscyclus/#maatregel","title":"Maatregel","text":"<p>Richt vaste beslismomenten en controlepunten in in de algoritmelevenscyclus.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-08-beslismoment-levenscyclus/#toelichting","title":"Toelichting","text":"<ul> <li>Algoritmegovernance kan op de levenscyclus aansluiten door 'gates' of controlepunten in te voeren. Deze gates bevatten belangrijke mijlpalen om te beoordelen of de juiste taken zijn uitgevoerd, of ethische afwegingen zijn gemaakt, of documentatie heeft plaatsgevonden en of akkoord is ingewonnen (go/no-go moment) bij de verantwoordelijke(n) om naar de volgende fase te mogen.</li> <li>Het is belangrijk om te weten dat toepassing van deze \u2018gates\u2019 niet altijd hetzelfde is. Dit kan namelijk verschillen afhankelijk van het type algoritme.</li> <li>Een hoog-risico-AI systeem moet aan meer vereisten voldoen dan een niet impactvol algoritme. Een hoog-risico AI-systeem moet daarom binnen de gates worden getoetst op meer onderdelen dan een niet impactvol algoritme.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-08-beslismoment-levenscyclus/#risico","title":"Risico","text":"<p>Als er geen controlepunten aanwezig zijn in de levenscyclus van een algoritmegovernance kan het moeilijk zijn om te traceren waar sommige problemen ontstaan en kunnen simpele wijzigingen in het proces over het hoofd worden gezien.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-08-beslismoment-levenscyclus/#bronnen","title":"Bronnen","text":"<ul> <li>Hulpmiddel handelingsruimte waardevolle AI in de zorg</li> <li>AI lifecycle management in de zorg, Nederlandse AI Coalitie</li> <li>UWV Beleidsdocument model risico management, Modellevenscyclus (blz 21), 29 september 2021</li> <li>Toetsingskader Algemene Rekenkamer, 1.07</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-08-beslismoment-levenscyclus/#voorbeelden","title":"Voorbeelden","text":"<p>Hieronder volgen twee voorbeelden van hoe governance effectief kan worden ge\u00efntegreerd in de levenscyclus van algoritmen en AI-modellen:</p> <p>Ministerie van Volksgezondheid, Welzijn en Sport  - Tool Handelingsruimte Waardevolle AI</p> <p>Het Ministerie van Volksgezondheid, Welzijn en Sport (VWS) heeft een hulpmiddel ontwikkeld voor het begeleiden van het innovatieproces: Tool Handelingsruimte Waardevolle AI. Binnen de tool wordt gebruikgemaakt van verschillende fases waarbij iedere fase een eigen doel in het proces heeft. Zodra een doel afgerond is, is er een faseovergang (gate) met een checklist voordat men naar de volgende fase kan gaan. Hierbij worden verschillende eisen gesteld op het gebied van waarde, toepassing, ethiek, techniek en verantwoordelijkheid. Zodra aan alle eisen is voldaan kan de volgende fase gestart worden. Op deze manier kan bij iedere fase beoordeeld worden of er moet worden bijgestuurd. Dit proces vindt plaats vanaf de probleemanalyse-fase tot monitoring- en beheer.</p> <p></p> <p>Bron: [Hulpmiddel Handelingsruimte Waardevolle AI voor gezondheid en zorg] (https://nlaic.com/download/04a-hulpmiddel-handelingsruimte-waardevolle-ai-voor-gezondheid-en-zorg/)</p> <p>UWV - Modellevenscyclus</p> <p>Het UWV heeft in 2021 haar modellevenscyclus toegelicht in een gepubliceerd beleidsdocument. Hierin wordt uitgelegd dat bij sommige controlepunten ook een stap terug gedaan kan worden in de cyclus als dit nodig blijkt. Bij iedere stap wordt een beschrijving gegeven. Daarnaast wordt ook toegelicht wat de noodzakelijke procedures zijn en wie hiervoor verantwoordelijk is. Deze procedures worden ook grafisch toegelicht per stap in de cyclus. Hieronder is een algemeen grafische weergave te zien van de algehele modellevenscyclus bestaande uit 8 stappen.</p> <p></p> <p>Bron: Algoritmelevenscyclus \u2013 UWV, pagina 21</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-09-governance-per-risicocategorie/","title":"Richt algoritmegovernance in op basis van de risicoclassificatie van algoritmes","text":"<p>org-09OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-09-governance-per-risicocategorie/#maatregel","title":"Maatregel","text":"<p>Richt algoritmegovernance in op basis van de risicoclassificatie van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-09-governance-per-risicocategorie/#toelichting","title":"Toelichting","text":"<ul> <li>Er is een verschil in de vereisten die van toepassing zijn op type algoritmes. Dit is mede afhankelijk van de risioclassificatie en de impact van het algoritme op betrokkenen.</li> <li>Zo zullen op basis van de AI-verordening meer vereisten moeten worden nageleefd bij hoog-risico AI-systemen, dan voor een AI-systeem met een beperkt risico.</li> <li>Dit betekent dat algoritmegovernance uitgebreider moet zijn voor de risicovollere, complexere toepassingen dan voor de eenvoudige, niet-risicovolle toepassingen.</li> <li>Stel daarom tijdig vast om welk type algoritme het gaat en welke vereisten hiervoor gelden. Dat draagt eraan bij dan alleen wordt gefocust op het realiseren van de vereisten waar daadwerkelijk aan moet worden voldaan. Dit zorgt ervoor dat projecten sneller kunnen worden gerealiseerd.</li> <li>Let op dat niet enkel naar de AI-verordening wordt gekeken. Ook op impactvolle algoritmes die niet vallen onder het bereik van de AI-verordening zijn vereisten van toepassing, en moet algoritmegovernance op worden toegepast.</li> <li>Is algoritmegovernance nieuw bij jouw organisatie, dan kan het helpen om een use-case met beperkt risico grondig te doorlopen om hiervan te leren.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-09-governance-per-risicocategorie/#risico","title":"Risico","text":"<p>Een risico dat kan voortkomen uit het niet hanteren van de verschillende risicoclassificaties is dat er aan meer vereisten wordt voldaan dan nodig is bij sommige types algoritmes, wat kan leiden tot onnodig werk.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-09-governance-per-risicocategorie/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-09-governance-per-risicocategorie/#voorbeelden","title":"Voorbeelden","text":"<p>Rijksoverheid: Gids AI-verordening</p> <p>De Rijksoverheid heeft een gids opgesteld over de AI-verordening. Hierin worden 4 stappen toegelicht: Risico, AI, Rol en Verplichtingen. Om te identificeren welke AI-systemen of algoritmes hoog-risico zijn, is het aan te raden om deze gids te bekijken. Meer informatie over de AI-verordening is ook te vinden op \"AI-verordening in het kort\" Naast de classificatie vermeldt deze gids vanaf pagina 11 aan welke verplichtingen een aanbieder en gebruiksverantwoordelijke moeten voldoen voor hoog-risico-AI, AI voor algemene doeleinden, generatieve AI en chatbots, maar niet voor overige AI.</p> <p>Bron: Gids AI-verordening</p> <p>Wil je meer hulp bij het vinden van de regels die specifiek voor jou gelden, gebruik dan ook de beslishulp AI-verordening.</p> <p>Gemeente Rotterdam: Processchema governance</p> <p>Hieronder staat een schematische weergave van hoe de gemeente Rotterdam algoritme governance toepast. Zij kiezen ervoor om dit alleen toe te passen op hoog-risico AI volgens de definitie van de AI-Verordening. Voor laag-risico toepassingen gebruiken ze hun standaard governanceprotocol (zie figuur hieronder). Ongeacht het risico wordt er ook een drietal vragen gesteld, waarbij verdere instrumenten ingezet moeten worden als alle vragen met \"Ja\" beantwoord worden:</p> <ul> <li>Is de werking van het algoritme niet volledig \u00e9n beknopt uit te leggen aan een gemiddelde Rotterdammer?</li> <li>Ontbreekt er een menselijke beoordeling voordat de uitkomst van het algoritme in de praktijk wordt gebracht door middel van een concrete handeling van de gemeente?</li> <li>Is het voorstelbaar dat de algoritmetoepassing uitmondt in een onrechtvaardige handeling van de gemeente tegen burgers of bedrijven?</li> </ul> <p></p> <p>Bron: Kleur bekennen - Rekenkamer Rotterdam (Pagina 72)</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-10-inrichten-taken-en-verantwoordelijkheden-algoritmegovernance/","title":"Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance","text":"<p>org-10OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-10-inrichten-taken-en-verantwoordelijkheden-algoritmegovernance/#maatregel","title":"Maatregel","text":"<p>Taken en verantwoordelijkheden zijn toebedeeld in de algoritmegovernance.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-10-inrichten-taken-en-verantwoordelijkheden-algoritmegovernance/#toelichting","title":"Toelichting","text":"<ul> <li>Bij het vormgeven van een doeltreffende algoritmegovernance is het beleggen van expliciete taken en verantwoordelijkheden cruciaal.</li> <li>Het beleggen van deze taken en verantwoordelijkheden zorgt voor een actiegerichte structuur waarin duidelijkheid bestaat over wie wanneer aan zet is.</li> <li>Denk hierbij aan het opstellen van een RACI-matrix en pas dit binnen de organisatie toe per risicoclassificatie voor algoritmes.</li> <li>Rollen en verantwoordelijkheden kunnen worden gekoppeld aan de vereisten en maatregelen die moeten worden gerealiseerd in de verschillende fasen van de levenscyclus van een algoritme.</li> <li>Organisaties zullen zelf moeten beoordelen welke taken en verantwoordelijkheden ze willen koppelen aan de beschikbare (of nieuwe) rollen binnen hun organisaties.</li> <li>Zie hieronder een mogelijk voorbeeld van hoe dit eruit kan zien.</li> <li>Bij zeer complexe processen waarbij ondersteunende rollen nodig zijn, kun je ook de uitgebreidere RASCI-matrix gebruiken, waarbij de toegevoegde S staat voor Supportive.</li> </ul> <p>De rollen en verantwoordelijkheden voor reguliere algoritmes en AI kunnen anders zijn dan voor generatieve AI. Waar het gebruik van reguliere algoritme en Al-toepassingen duidelijk onder de verantwoordelijkheid van het management valt, wordt er bij hulpmiddelen die gebruik maken van generatieve AI meer verantwoordelijkheid gevraagd van betrokken medewerkers. Hier wordt vaak ingezet om te zorgen voor bewustwording van verantwoord gebruik van deze technologie bij verschillende medewerkers.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-10-inrichten-taken-en-verantwoordelijkheden-algoritmegovernance/#risico","title":"Risico","text":"<p>Een risico dat kan worden gemitigeerd met behulp van deze maatregel is dat het werkproces rondom algoritmegovernance niet effici\u00ebnt is ingedeeld en bijvoorbeeld kan leiden tot dubbele werkzaamheden of overzicht verliezen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-10-inrichten-taken-en-verantwoordelijkheden-algoritmegovernance/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, SV.9</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-10-inrichten-taken-en-verantwoordelijkheden-algoritmegovernance/#voorbeelden","title":"Voorbeelden","text":"<p>RACI matrix - diverse organisaties</p> <p>Bij Gemeentelijke Model Architectuur (GEMMA) wordt aangegeven dat een RACI matrix rollen en verantwoordelijkheden goed weergeeft en onderscheidt. Het RACI matrix is een afkorting voor  Responsible (Verantwoordelijk), Accountable (Eindverantwoordelijk), Consulted (Raadplegen) en Informed (Informeren). In deze matrix staan horizontaal de rollen en staan verticaal de taken/producten waar een rol verantwoordelijk voor is. Deze matrix geeft veel verschillende rollen weer die in het beste geval voor verschillende functionarissen zijn. GEMMA geeft ook aan dat in kleinere organisaties (kleinere gemeenten) dit niet altijd mogelijk is. Het is dus belangrijk om te weten dat dit verschillend is per gemeente en afhankelijk van de volwassenheid van inrichting van gegevensmanagement.</p> <p></p> <p>Bron: RACI matrix</p> <p>Belastingdienst  - Werkpakketten</p> <p>Binnen de Belastingdienst Analytische en Cognitieve Technologie heeft het team CoE Cognitieve oplossingen ervaren dat het gebruik van werkpakketten goed werkt. Werkpakketten zijn een omschrijving van taken en verantwoordelijkheden in plaats van uitgewerkte functies. Op deze manier staan er een groot aantal dingen vast maar hoeft er niet op microniveau regide te staan. Alle werkpakketten zijn overlegd en besproken om kwaliteit te behouden, maar uitwerkingen kunnen het beste uit de praktijk komen. Zij geven dan ook mee; \u201cWees als algoritmegovernance nog nieuw is zeker in het begin bewust dat inrichting altijd beter kan; ga grondig maar ook flexibel te werk.\u201d</p> <p>Bron: Analytische en Cognitieve Technologie | CoE Cognitieve Oplossingen</p> <p>Verschillende organisaties  - Three-lines-model</p> <p>Er zijn verschillende organisaties waaronder het UWV en gemeente Rotterdam die gebruik maken van het three-lines-model. Dit model geeft aan dat er drie niveaus zijn van verantwoordelijkheid voor een effectieve governance. De eerste lijn gaat vaak over de directe acties, de tweede lijn over het ondersteunen van de eerste lijn en de derde lijn over het controleren van lijn een en twee.</p> <p>Meer informatie over het implementeren van het three-lines-model is te vinden onder \"Richt een algoritmegovernance in met three lines of defence\"</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl .</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-11-gebruikersbeheer/","title":"Maak afspraken over het beheer van gebruikers","text":"<p>org-11OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesTechnische robuustheid en veiligheidGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-11-gebruikersbeheer/#maatregel","title":"Maatregel","text":"<p>Richt gebruikersbeheer in, waarmee bepaald wordt wie toegang heeft tot wat, en wat er bijvoorbeeld gebeurt bij indiensttreding, functiewijziging en uitdiensttreding.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-11-gebruikersbeheer/#toelichting","title":"Toelichting","text":"<p>Gebruikersbeheer zorgt ervoor dat accounts en autorisaties beheerst worden aangevraagd, geautoriseerd, gewijzigd en ingetrokken bij indiensttreding, functiewijziging en uitdiensttreding. Ook wordt functievermenging voorkomen bij toegang en gebruik van het algoritme, de data of de uitkomsten van een algoritme.</p> <p>Bij het inrichten van gebruikersbeheer moeten aan de volgende elementen worden gedacht:</p> <ul> <li>Gebruikers en beheerders krijgen slechts toegang tot functionaliteit die zij uit hoofde van hun functie nodig hebben (need to know, need to use). Daartoe is een beschrijving beschikbaar welke rollen en rechten per applicatie bij een functie horen (BIO 6.1.2, 9.2.2 en 9.4).</li> <li>Het verlenen en muteren van accounts en toegangsrechten vindt plaats na goedkeuring door een bevoegde functionaris. Dit aan de hand van een actueel mandaatregister waaruit blijkt welke personen beslissende bevoegdheden hebben voor het verlenen van een bepaald type (niveau) toegangsrechten danwel functieprofielen (BIO 9.2.1.2, 9.2.2.1, 9.4).</li> <li>Er bestaat functiescheiding tussen het aanvragen, autoriseren en doorvoeren van wijzigingen in gebruikersaccounts en toegangsrechten (BIO 9.2.1.2, 9.2.2.1, 9.2.3).</li> <li>Functiewijzigingen en uitdiensttredingen worden bewaakt voor aanpassen van de toegangsrechten en voor intrekken van de identiteits- en authenticatiemiddelen (BIO 9.2.2, 9.2.6).</li> <li>Het aantal accounts met verhoogde rechten is beperkt en verklaard, en staat in logische verhouding tot de beheerders en of ICT-afdeling (BIO 9.1.2.(1), 9.2.3, 9.2.4).</li> <li>Gebruikersaccounts en beheeraccounts dienen altijd persoonsgebonden en verklaard te zijn, zodat handelingen altijd te herleiden zijn naar \u00e9\u00e9n verantwoordelijke (BIO 9.1, 9.4.2).</li> <li>Eindgebruikers hebben geen directe toegang tot de onderliggende componenten (zoals de database) (BIO 9.2.3, 13.1.3).</li> <li>Toegangsrechten op onderliggende componenten dienen periodiek, minimaal jaarlijks, ge\u00ebvalueerd te worden. Dit interval dient te zijn beschreven in het toegangsbeleid en zijn bepaald op basis van het risiconiveau. De uitkomsten van de evaluatie en de opvolging daarvan worden vastgelegd (BIO 9.2.5).</li> </ul> <p>Voor deze maatregelen is het van belang om aandacht te hebben voor de volgende zaken:</p> <ul> <li>Autorisatiematrix en beschrijving rollen/rechten per systeem(laag)</li> <li>Lijst met wijzigingen rollen en bijbehorende goedkeuringen</li> <li>Overzicht aantallen en rechten per (systeem)laag</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-11-gebruikersbeheer/#risico","title":"Risico","text":"<p>Er bestaan meerdere risico's wanneer er geen gebruikersbeheer is:</p> <ul> <li>Toegangsrechten kunnen niet meer up-to-date zijn, bijvoorbeeld wanneer er geen rekening wordt gehouden met het IDU-proces. Er bestaat dan het risico dat gebruikers toegang tot de omgeving van het algoritme, de data of de uitkomsten van het algoritme hebben die zij niet zouden mogen hebben.</li> <li>Wanneer functievermenging niet wordt voorkomen bij toegang en gebruik van het algoritme, bestaat het risico dat er ongeautoriseerde wijzigingen worden doorgevoerd aan het algoritme, de data of de uitkomsten van het algoritme.</li> <li>Wanneer gebruik wordt gemaakt van generieke-, groeps- of onpersoonlijke accounts, bestaat het risico dat handelingen niet te herleiden zijn naar een verantwoordelijke persoon.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-11-gebruikersbeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.10 t/m IB.17</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.01, 4.02, 4.04, 4.05</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-11-gebruikersbeheer/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/","title":"Controleer en verbeter regelmatig de kwaliteit van het algoritme","text":"<p>org-12OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderBeleid en adviesGovernanceMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/#maatregel","title":"Maatregel","text":"<p>Richt een proces in voor een periodieke evaluatie van de kwaliteit van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/#toelichting","title":"Toelichting","text":"<ul> <li>Het is van belang dat een proces wordt ingericht waarmee periodiek de kwaliteit van algoritmes wordt ge\u00ebvalueerd.</li> <li>Bij kwaliteit van een algoritme kan worden gedacht aan doeltreffenheid, doelmatigheid, betrouwbaarheid en accuraatheid (geschiktheid), non-discriminatie en menselijke controle.</li> <li>Hieronder vallen het analyseren en evalueren van ingediende klachten en incidenten.</li> <li>Hieronder vallen ook het analyseren en evalueren van besluiten door of aan de hand van het algoritme.</li> <li>Na verloop van tijd kan de accuraatheid van machine learning modellen bijvoorbeeld wijzigen of kan het gebeuren dat bepaalde groepen (indien van toepassing) anders worden behandeld.</li> <li>Het is van belang dat monitoringsactiviteiten worden ingericht om deze kwaliteitsaspecten tijdig te beoordelen.</li> <li>Als er ongewenste wijzigingen plaatsvinden met betrekking tot de kwaliteit, moeten die worden ge\u00ebvalueerd en zullen maatregelen moeten worden getroffen om deze te herstellen.</li> <li>Het proces moet er voor zorgen dat de juiste experts of stakeholders worden betrokken bij het proces van evaluatie en het treffen van passende maatregelen.</li> </ul> <p>Let op! Sommige maatregelen in het Algoritmekader gaan dieper in op het uitvoeren van risicoanalyses.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/#risico","title":"Risico","text":"<p>Zonder evaluatie van de kwaliteit van het algoritme is er geen goede sturing, beheersing en verantwoording mogelijk als er ongewenste wijzigingen plaatsvinden in het algoritme of AI-systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.15, SV.16, SV.17 </li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.08</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-12-periodieke-evaluatie-kwaliteit/#voorbeelden","title":"Voorbeelden","text":"<p>Douane - Detecteren risico\u2019s voor naleving vergunningsplicht</p> <p>De Douane maakt gebruik van een algoritme om te selecteren welke goederen een (extra) controle krijgen. Dit wordt gedaan op basis van aangiftegegevens die bedrijven aanleveren. Op basis van deze data wordt een vergelijking gemaakt met een bekend risicoprofiel. Deze risicoprofielen worden periodiek gecontroleerd aan de hand van de hoeveelheid kloppende controles. Daarnaast wordt ieder jaar per profiel gekeken of deze verfijnd, verlengd of be\u00ebindigd moeten worden. Op deze manier wordt regelmatig gecontroleerd of het algoritme nog voldoende functioneert.</p> <p>Bron: Detecteren risico\u2019s voor naleving vergunningsplicht voor de uitvoer sanctiemaatregelen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-13-wachtwoordbeheer/","title":"Maak afspraken over het beheer van wachtwoorden","text":"<p>org-13OrganisatieverantwoordelijkhedenProjectleiderOntwikkelaarTechnische robuustheid en veiligheidGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-13-wachtwoordbeheer/#maatregel","title":"Maatregel","text":"<p>Richt wachtwoordbeheer in, waarmee bepaald wordt hoe wachtwoorden worden opgeslagen, wanneer wijzigingen moeten plaatsvinden en waaraan wachtwoorden moeten voldoen. Hiermee wordt de toegang tot bijvoorbeeld ontwikkelomgevingen geregeld op een veilige manier.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-13-wachtwoordbeheer/#toelichting","title":"Toelichting","text":"<p>Bij het inrichten van wachtwoordbeheer moeten de volgende zaken worden toegepast:</p> <ul> <li>Alle wachtwoorden van gebruikers en beheerders dienen periodiek te worden gewijzigd, met een maximum van 1 jaar (BIO 9.4.3). Initi\u00eble wachtwoorden en wachtwoorden die gereset zijn, hebben een maximale geldigheidsduur van 24 uur en moeten bij het eerste gebruik worden gewijzigd.</li> <li>Voor toegang vanuit een onvertrouwde omgeving dient twee-factor authenticatie te worden gebruikt (BIO 9.4.2.1). Als er geen gebruik wordt gemaakt van twee-factor authenticatie, is de wachtwoordlengte minimaal 8 posities en complex van samenstelling. In situaties waar geen twee-factor authenticatie mogelijk is, wordt minimaal halfjaarlijks het wachtwoord vernieuwd.</li> <li>Na een periode van maximaal 15 minuten inactiviteit dient de toegang tot de applicatie te worden vergrendeld en na 10 foutieve inlogpogingen dient het account geblokkeerd te worden (BIO 11.2.9, BIO 9.4.3). De tijdsduur dat een account wordt geblokkeerd na overschrijding van het aantal keer foutief inloggen is vastgelegd.</li> <li>Wachtwoorden mogen niet in originele vorm (plaintext) worden opgeslagen, maar dienen versleuteld te worden (NIST 5.1.1.2).</li> <li>De eisen aan wachtwoorden moeten geautomatiseerd worden afgedwongen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-13-wachtwoordbeheer/#risico","title":"Risico","text":"<p>Als het wachtwoordbeheer van onvoldoende kwaliteit is, kan oneigenlijke toegang plaatsvinden tot het algoritme of uitkomsten van het algoritme, bijvoorbeeld doordat het wachtwoord te eenvoudig is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-13-wachtwoordbeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.6 t/m IB.9</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.03</li> <li>NIST 5.1.1.2</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-13-wachtwoordbeheer/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-14-wijzigingenproces/","title":"Maak afspraken over het wijzigen van de code","text":"<p>org-14OrganisatieverantwoordelijkhedenProjectleiderOntwikkelaarTechnische robuustheid en veiligheidGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-14-wijzigingenproces/#maatregel","title":"Maatregel","text":"<p>Richt een wijzigingenproces in, waarmee bepaald wordt hoe codewijzigingen plaatsvinden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-14-wijzigingenproces/#toelichting","title":"Toelichting","text":"<p>Bij het inrichten van een proces om wijzigingen aan de code te mogen aanbrengen, kunnen aan de volgende elementen worden gedacht:</p> <ul> <li>Wijzigingen dienen van te voren te worden geautoriseerd door de systeemeigenaar of product owner. (BIO 12.1.2)</li> <li>Wijzigingen worden getest in een andere omgeving dan de productieomgeving. (BIO 12.1.4, 14.2.3, 14.2.9, 14.3.1)</li> <li>Wijzigingen worden door de systeemeigenaar of product owner goedgekeurd op basis van gedocumenteerde testresultaten en pas daarna doorgevoerd in de productieomgeving. (BIO 12.1.2, 14.2.2, 14.2.9)</li> <li>Er dient functiescheiding te zijn ingericht tussen het aanvragen, goedkeuren en doorvoeren van wijzigingen om onbevoegde en onbedoelde wijzigingen te beperken. (BIO 6.1.2, 14.2.2)</li> <li>Er dient periodiek controle plaats te vinden op wijzigingen aan het systeem, zodanig dat oneigenlijke wijzigingen worden gesignaleerd. (BIO 9.4.4, 12.4.1)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-14-wijzigingenproces/#risico","title":"Risico","text":"<p>Als een formeel wijzigingenproces ontbreekt bestaat het risico van ongeautoriseerde toegang, wijziging of beschadiging van de code van het algoritme, of de uitkomsten van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-14-wijzigingenproces/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.1 t/m IB.5</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.07</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-14-wijzigingenproces/#voorbeelden","title":"Voorbeelden","text":"<p>Informatie Beveiligingsdienst - Aanwijzing Logging</p> <p>De informatie beveiligingsdienst (IBD) heeft een handreiking gepubliceerd rondom logging-beleid en -procedures. Hierin wordt onder andere uitgelegd wat voor soorten logbestanden er zijn, voor wie deze belangrijk zijn en wat er in een log moet staan. Daarnaast wordt toegelicht hoe logging gecontroleerd kan/moet worden.</p> <p>Dit document kan een goede basis vormen voor het beginnen met log bestanden maken. Zo staan er in dit document verschillende bijlagen zoals een template voor logging-beleid en verschillende infographics die het logging-proces en de controles visualiseren voor de lezer.</p> <p>Bron: Handreiking Logging</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/","title":"Stel een protocol vast voor de situatie dat er (een vermoeden van) discriminatie door een algoritme is geconstateerd en pas dit wanneer nodig toe","text":"<p>org-15OrganisatieverantwoordelijkhedenImplementatieProjectleiderBeleid en adviesBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#maatregel","title":"Maatregel","text":"<p>Stel een protocol vast voor de situatie dat er (een vermoeden van) discriminatie door een algoritme is geconstateerd en pas dit wanneer nodig toe.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#toelichting","title":"Toelichting","text":"<p>De inzet van algoritmes kan onbedoeld leiden tot discriminerende effecten. Het is van belang om als organisatie een protocol te hebben vastgesteld waarin is uitgewerkt hoe wordt omgegaan met situaties waarin (een vermoeden van) discriminatie door een algoritme is geconstateerd. In een dergelijk protocol kunnen de handelingen worden beschreven die moeten worden uitgevoerd om deze situatie te herstellen. Het vaststellen van een dergelijk protocol geeft ontwikkelaars en gebruikers (vooraf) duidelijkheid wat van hen wordt verwacht en wat zij kunnen doen om discriminatie door algoritmes te voorkomen. Een voorbeeld hiervan is het analyseren van de data op datakwaliteit en bias in de data en toets regelmatig je algoritmisch systeem op bias.</p> <p>Het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties heeft een discriminatieprotocol opgesteld wat organisaties handvatten biedt.</p> <p>Een discriminatieprotocol kan de volgende stappen bevatten:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#stap-1-vermoeden-van-onrechtmatigheid","title":"Stap 1: Vermoeden van onrechtmatigheid","text":"<p>Een vermoeden van bevooroordeeldheid of discriminatie kan vanuit verschillende partijen gemeld worden. Signalen hiervoor kunnen worden ontvangen vanuit de interne organisatie, bijvoorbeeld door de betrokken ontwikkelaars, gebruikers of beheerders, of door externe partijen, zoals belanghebbenden, toezichthouder of journalisten.</p> <ul> <li>Zorg dat signalen tijdig bij de goede medewerkers terecht komen.</li> <li>Indien er sprake is van zo'n vermoeden, zorg je dat bijvoorbeeld de uitvoerend directeur, de interne toezichthouder en/of de CIO en CDO hierover worden ge\u00efnformeerd.</li> <li>Maak met de verantwoordelijken een afweging of het betreffende systeem in werking kan blijven of dat bijvoorbeeld het noodplan voor het stopzetten van het algoritme (tijdelijk) in gang moet worden gezet.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#stap-2-inzicht-en-overzicht","title":"Stap 2: Inzicht en overzicht","text":"<p>Het is van belang om inzicht en overzicht te krijgen over de oorzaak en de gevolgen van eventuele discriminerende effecten van het algoritme. Daarvoor kan worden gedacht aan het uitvoeren van een bias analyse.</p> <ul> <li>Bepaal wie er verantwoordelijk is voor het uitvoeren van het onderzoek.</li> <li>Bepaal of je een onafhankelijk onderzoek wilt doen naar het algoritme.</li> <li>Breng in kaart wat de omvang van het probleem is. Hoe lang doet het probleem zich al voort, en hoeveel mensen betreft het?</li> <li>Ga snel met (vertegenwoordigers van) gedupeerden in gesprek over de gevolgen en de mogelijke schade.</li> <li>Trek een conclusie of er sprake is van discriminatie, of een sterk vermoeden van discriminatie.</li> <li>Onderzoek en analyseer waarom de genomen maatregelen om discriminatie tegen te gaan, zoals het uitvoeren van een biasanalyse onvoldoende hebben gewerkt. Bekijk hoe de werkwijzen in de organisatie verbeterd kunnen worden zodat dit in de toekomst voorkomen kan worden.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#stap-3-beperken-schade","title":"Stap 3: Beperken schade","text":"<p>Bepaal welke mitigerende maatregelen er genomen moeten worden. Als er in het onderzoek is vastgesteld dat er sprake is van discriminatie, dan moet het betreffende systeem worden stopgezet. Hierbij kan je denken aan:</p> <ul> <li>Het in werking stellen van het het noodplan voor het stopzetten van het algoritme, indien dat in stap 1 nog niet gebeurd is.</li> <li>Aanpassingen in het algoritme, de werkinstructies of de bijbehorende processen.</li> <li>Indien het algoritme essentieel is in de uitvoer kan er sprake zijn van een een proportionaliteitsvraagstuk. In dat geval moet er worden bezien wat de alternatieven zijn, en of er delen van het systeem kunnen worden uitgeschakeld.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#stap-4-melden-en-informeren","title":"Stap 4: Melden en informeren","text":"<p>De conclusies van de eerdere stappen moeten, indien nodig, worden gemeld bij de betreffende instanties. De eventuele gedupeerde burgers dienen te worden ge\u00efnformeerd over de gevolgen.</p> <ul> <li>Als er sprake is van een hoog-risico AI-systeem moeten ernstige incidenten worden gemeld bij de markttoezichtautoriteiten. Zie artikel 73 van de AI-verordening en artikel 3 (49.c) van de AI-verordening.</li> <li>Voor alle algoritmes geldt: Informeer de interne toezichthouder, de externe toezichthouder en de politiek, afhankelijk van hoeveel mensen geraakt en gedupeerd zijn en de impact.</li> <li> <p>Informeer de betrokken burgers over de situatie. Maak indien nodig excuses en geef de mensen die (mogelijk) geraakt zijn uitleg zodat zij:</p> <ul> <li>begrijpen wat er is gebeurd</li> <li>weten wat de waarschijnlijke gevolgen zijn</li> <li>welke mitigerende maatregelen zijn genomen</li> <li>waar mensen terecht kunnen met vragen</li> <li>op de hoogte zijn van het proces rondom de afhandeling van de schade.</li> </ul> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#stap-5-registratie-en-afhandeling","title":"Stap 5: Registratie en afhandeling","text":"<ul> <li>Registreer het algoritme in het algoritmeregister, indien dat nog niet gebeurd is.</li> <li>Zorg voor goede klachtenafhandeling en herstelprocedures.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#risico","title":"Risico","text":"<p>Als er geen protocol wordt vastgesteld voor het detecteren van discriminatie door een algoritme is er een risico op discriminatie, waarbij het niet duidelijk is voor werknemers wat de stappen zijn om dit te herkennen en tegen te gaan.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#bronnen","title":"Bronnen","text":"<ul> <li>Discriminatieprotcol van het Ministerie van Binnenlandse Zaken en Koninkrijksrelaties</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-15-discriminatieprotocol/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-16-bewustwording-en-opleiding/","title":"Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AI","text":"<p>org-16OrganisatieverantwoordelijkhedenBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-16-bewustwording-en-opleiding/#maatregel","title":"Maatregel","text":"<p>Zorg voor bewustwording en voldoende opleidingen over de risico's en kansen van algoritmes en AI.</p> <p>Let op!</p> <p>Volgens de AI-verordening moet AI-geletterdheid per 2 februari 2025 gewaarborgd worden door aanbieders en gebruiksverantwoordelijken van AI-systemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-16-bewustwording-en-opleiding/#toelichting","title":"Toelichting","text":"<p>Om algoritmes op een verantwoorde manier te gebruiken, is het noodzakelijk dat medewerkers hier voldoende kennis over hebben. Dat draagt bij om de kansen die AI biedt zo goed mogelijk te benutten, en tegelijkertijd bewust om te gaan met de risico's. Dit geldt niet alleen voor direct betrokken medewerkers en ontwikkelaars, maar ook voor bestuurders en bijvoorbeeld beleidsmakers. Om te komen tot een volwassen niveau van AI-geletterdheid is een structurele, langdurige en op maat gemaakte aanpak nodig, die rekening houdt met de context en rollen waarin mensen met AI-systemen te maken hebben.</p> <p>Denk bijvoorbeeld aan het borgen voldoende kennis en bewustzijn over:</p> <ul> <li>risico's op bias en eventuele discriminerende effecten</li> <li>de werking van een algoritme zodat betekenisvolle menselijke tussenkomst kan plaatsvinden</li> </ul> <p>Maak een meerjarig actieplan om toe te werken naar een volwassen niveau van AI-geletterdheid die past bij jouw organisatie. Stel dit bestuurlijk vast en zorg voor bestuurlijke verantwoordelijkheid en betrokkenheid. De Autoriteit Persoonsgegevens heeft een aanzet gedaan voor een passend meerjarenplan om AI-geletterdheid in jouw organsatie te bevorderen:</p> <p></p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-16-bewustwording-en-opleiding/#relevante-opleidingen","title":"Relevante opleidingen","text":"<ul> <li>E-learning Non-discriminatie in algoritmes en data</li> <li>Basistrainingen AI en generatieve AI via RADIO</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-16-bewustwording-en-opleiding/#bronnen","title":"Bronnen","text":"<ul> <li>Aan de slag met AI-geletterdheid, Autoriteit Persoonsgegevens</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.12</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.04</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/0-org-16-bewustwording-en-opleiding/#voorbeeld","title":"Voorbeeld","text":"<p>Best practices verzameld door het AI-bureau</p> <p>Het AI-bureau van de EU heeft een aantal van de lopende best practices verzameld met als doel een levend archief aan te leggen met voorbeelden van lopende praktijken op het gebied van AI-geletterdheid.</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-01-formuleren-probleemdefinitie/","title":"Beschrijf het probleem dat het algoritme moet oplossen","text":"<p>pba-01ProbleemanalyseProjectleiderGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-01-formuleren-probleemdefinitie/#maatregel","title":"Maatregel","text":"<p>Formuleer en documenteer wat de aanleiding is om een algoritme in te willen zetten. Formuleer duidelijk de probleemdefinitie en probleemafbakening waarvoor het algoritme een oplossing zou moeten vormen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-01-formuleren-probleemdefinitie/#toelichting","title":"Toelichting","text":"<p>Formuleer de probleemdefinitie en probleemafbakening zo concreet en precies mogelijk. Maak dit waar mogelijk kwantificeerbaar.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-01-formuleren-probleemdefinitie/#risico","title":"Risico","text":"<p>Het algoritme dient niet het onderliggende probleem. Zonder eenduidigheid over het op te lossen probleem is geen sturing op en verantwoording over het algoritme mogelijk.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-01-formuleren-probleemdefinitie/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, 1.01</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.1</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-01-formuleren-probleemdefinitie/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Meierijstad: Melding openbare ruimte</p> <p>De gemeente Meierijstad maakt gebruik van een melding systeem Signalen waarin inwoners situaties zoals overlast, gevaarlijke verkeerssituaties of straatmeubulair kunnen melden. De melder moet hierbij de juiste categorie kiezen (bv overlast) maar omdat er veel categorie\u00ebn waren ging dit niet altijd goed. Dit kon zorgen voor vertraging en dus langere wachttijd of meer meldingen. Tegenwoordig gebruikt de gemeente een algoritme wat de tekst van burgers analyseert en op basis daarvan een categorie bepaalt. Op deze manier hoeft de melder geen categorie meer te kiezen en wordt de vertraging verholpen.</p> <p>De gemeente maakt daarnaast gebruik van menselijke controle op meldingen waarbij de categorie met minder dan 40% zekerheid ingedeeld is.</p> <p>Bron: Meldingen openbare ruimte</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/","title":"Beschrijf het doel van het algoritme","text":"<p>pba-02ProbleemanalyseProjectleiderGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/#maatregel","title":"Maatregel","text":"<p>Het doel en de eventuele subdoelen van het algoritme moeten zo specifiek mogelijk zijn geformuleerd, en waar mogelijk gekwantificeerd. Maak de consequenties van het algoritme specifiek en zorg dat het doel van het algoritme formeel is vastgesteld en vastgelegd.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Het doel van de inzet van een algoritme dient zo concreet en specifiek mogelijk gedefinieerd te worden. Indien er meerdere doelen zijn, is het belangrijk om een zekere rangorde te maken: wat zijn de belangrijkste doelen? En waarom? Welke doelen zijn subdoelen, waarvoor het minder belangrijk is om deze te realiseren?</p> </li> <li> <p>Vertrek vanuit de uitdaging of probleemsituatie, niet vanuit een oplossing ('AI gebruiken omwille van het AI gebruiken').</p> </li> <li> <p>Indien mogelijk, dienen de doelstellingen gekwantificeerd te worden (SMART).</p> </li> <li> <p>Probeer vast te stellen wat de doelpopulatie is, zodat in een later stadium data kan worden gezocht dat representatief is daarvoor, wat bijdraagt aan de datakwaliteit van een algoritme.</p> </li> <li> <p>Om te zorgen voor voldoende draagvlak voor de beoogde doelen, is het noodzaak om voldoende belanghebbenden te betrekken. Hierbij kan het ook helpen om burgers te betrekken bij de totstandkoming van de doelstellingen, bijvoorbeeld door middel van een burgerpanel of het betrekken van belangengroepen.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/#risico","title":"Risico","text":"<p>Het algoritme dient niet het beoogde doel en onderliggend probleem. Zonder eenduidigheid over het doel is geen sturing op en verantwoording over het algoritme mogelijk. Er is dan een groter risico op fouten en/of verschillen in interpretatie.</p> <p>Wanneer doelstellingen niet meetbaar zijn gemaakt, is het onmogelijk om achteraf te kwantificeren of de doelstellingen zijn behaald. Doelstellingen zijn in dat geval moeilijk bespreekbaar.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.01, 1.02</li> <li>Impact Assessment Mensenrechten en Algoritmes, 1.2</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.3, DM.7</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-02-formuleren-doelstelling/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Arnhem \u2013 Parkeercontrole Scanauto</p> <p>De gemeente Arnhem maakt gebruik van scanautos om te controleren of auto\u2019s op de plek waar ze staan parkeerrecht hebben. Dit wordt gedaan door kentekenherkenning waarna er wordt gecontroleerd of het gescande kenteken in een database met geregistreerde parkeerrechten valt (vergunninghouder of parkeerkaart koper). Als dit niet zo is wordt dit handmatig gecontroleerd. De gemeente heeft verschillende subdoelen gesteld naast het hoofddoel van handhaven. Deze doelen zijn uitgewerkt rondom het meten en dus informatie vergaren. Het gaat hier om betaalbereidheid en parkeerdruk om zo een goed beeld te krijgen van de gemeente.</p> <p>Bron: Parkeercontrole scanauto - Gemeente Arnhem</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/","title":"Beschrijf waarom een algoritme het probleem moet oplossen","text":"<p>pba-03ProbleemanalyseProjectleiderGovernanceMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#maatregel","title":"Maatregel","text":"<p>Bepaal en documenteer waarom het gewenst of nodig is om een algoritme in te zetten om het probleem te kunnen aanpakken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Bepaal waarom het gewenst of nodig is om een algoritme in te zetten, en of er ook alternatieven zijn om het probleem op te lossen. Documenteer de onderbouwing waarom een algoritme een betere oplossing zou bieden dan een niet-geautomatiseerd of niet-digitaal proces.</p> </li> <li> <p>Maak een bewuste afweging of een algoritme het juiste middel is om het probleem op doelmatige en doeltreffende wijze op te lossen, en documenteer deze afweging.</p> </li> <li> <p>Beoordeel of de gewenste oplossing is toegestaan op grond van de AI-Verordening.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#risico","title":"Risico","text":"<p>Het algoritme is niet het juiste middel om het probleem op te lossen. Het risico daarbij bestaat dat het probleem niet wordt opgelost.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, 1.01</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.2</li> <li>Handreiking identificatie verboden AI-systemen (Powerpoint-bestand)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-03-onderbouwen-gebruik-algoritme/#voorbeelden","title":"Voorbeelden","text":"<p>Politie - HAVANK</p> <p>De politie maakt voor het identificeren van personen gebruik van vingerafdrukken. In Het Automatisch Vingerafdrukkensysteem Nederlandse Kollektie (HAVANK) worden vinger- en handpalmafdrukken verwerkt. Het algoritme controleert of de gegeven vingerafdruk met een andere afdruk overeenkomt op basis van een score. Volgens de politie is het onderzoeken en vergelijken van een vingerafdruk met grote aantallen andere afdrukken onmogelijk en onuitvoerbaar. Zij geven aan dat daarom een algoritme hierbij noodzakelijk is om zo de kans op herkenning te vergroten en de kans op fouten te verkleinen.</p> <p>Bron: HAVANK - Politie</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-04-betrek-belanghebbenden/","title":"Overleg regelmatig met belanghebbenden","text":"<p>pba-04ProbleemanalyseOntwerpImplementatieProjectleiderGovernanceFundamentele rechten</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-04-betrek-belanghebbenden/#maatregel","title":"Maatregel","text":"<p>Breng in kaart welke belanghebbenden er zijn en betrek hen op verschillende momenten in de levenscyclus.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-04-betrek-belanghebbenden/#toelichting","title":"Toelichting","text":"<p>Het betrekken van belanghebbenden is van belang in bijna alle fasen van de levenscyclus. Belanghebbenden zijn onder meer eindgebruikers, mensen en rechtspersonen die door het algoritme geraakt kunnen worden en vertegenwoordigende organisaties.</p> <p>In de fase van de probleemanalyse is het allereerst van belang in kaart te brengen welke stakeholders er zijn. Wie gaan bijvoorbeeld werken met het algoritme (eindgebruikers)? En welke demografie\u00ebn worden geraakt door een algoritme? Bij wie liggen de voordelen en bij wie liggen de nadelen? Ga in gesprek met deze belanghebbenden - al dan niet vertegenwoordigd door belangenorganisaties zoals burgerrechtenorganisaties - over het te ontwerpen algoritme en de context waarin het gebruikt wordt. Zij kunnen waardevolle inzichten en wensen delen, wat kan bijdragen aan een betere werking van het algoritme.</p> <p>Enkele voorbeelden hierbij zijn:</p> <ul> <li>Het betrekken van burgers bij het ontwerpen van een algoritme in de ontwerpfase.</li> <li>Het bespreken welke definitie en metriek van fairness past bij de context met de proceseigenaar en een ethicus.</li> <li>Het betrekken van domeinexperts in de fase van dataverkenning en datapreparatie, om zo in kaart te brengen wat de data features betekenen en waar zij vandaan komen.</li> <li>Het betrekken van eindgebruikers bij het ontwikkelen en het implementeren van het algoritme.</li> <li>Het betrekken van belanghebbenden bij het monitoren en evalueren van het algoritme.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-04-betrek-belanghebbenden/#risico","title":"Risico","text":"<p>Het niet betrekken van belanghebbenden bij de ontwikkeling en het gebruik van algoritmes kan ertoe leiden dat belangrijke inzichten of perspectieven niet worden verwerkt en het algoritme onjuist gaat functioneren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-04-betrek-belanghebbenden/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algemene Rekenkamer 2.12</li> <li>Ethics Guidelines for Trustworthy AI</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.10</li> <li>Framework for Meaningful Engagement</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-04-betrek-belanghebbenden/#voorbeelden","title":"Voorbeelden","text":"<p>Sociale verzekeringsbank  - Stakeholder analyse instrument</p> <p>De Sociale Verzekeringsbank (SVB) heeft een Ethisch Matrix ontwikkelt waarin gezocht kan worden naar de directe en indirecte stakeholders. Hierbij word gekeken naar de directe en indirecte belangen die geraakt kunnen worden en mogelijke effecten hiervan. Er zijn sessies georganiseerd om te bespreken wat de effecten zijn en welke afwegingen hierin gemaakt dienen te worden om op die manier de behoeften van een project samen te stellen.</p> <p>Bron: Algoritmes afwegen Matrix methode: Ethische matrix</p> <p>Gemeente Amsterdam  - Amsterdamse Visie op AI</p> <p>Gemeente Amsterdam heeft een visie op AI ontwikkelt in samenspraak met inwoners. Hierbij hebben ze het belang van de mens centraal gesteld om zo de maatschappelijke toegevoegde waarde te waarborgen. Dit is in samenspraak met onder andere inwoners, bedrijven en kennisinstellingen gedaan om zo het menselijke aspect op een verantwoordelijke manier te implementeren. Bron: Amsterdamse Visie op AI - Innovatie</p> <p>Algemene methoden</p> <p>Er zijn veel verschillende methoden om belanghebbenden te betrekken. Zo kan je bijvoorbeeld werken met persona\u2019s of \u2018empathy maps\u2019 maken. Ook kan je focusgroepen houden. Denk dan bijvoorbeeld aan een burgerpanel.</p> <p>Andere methoden zijn: Methodologie van Waag, Civic AI lab, Stakeholder escalation ladder. </p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/","title":"Beschrijf de wettelijke grondslag voor de inzet van het algoritme","text":"<p>pba-05ProbleemanalyseJuristGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/#maatregel","title":"Maatregel","text":"<p>Beschrijf de wettelijke grondslag voor de inzet van het algoritme en de beoogde besluiten die genomen zullen worden op basis van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/#toelichting","title":"Toelichting","text":"<ul> <li>Analyseer of er een concrete wettelijke grondslag is die de inzet van het algoritme mogelijk maakt en deze inzet voldoende voorzienbaar maakt.</li> <li>Als de verwachting is dat een algoritme tot gevolg heeft dat wordt ingegrepen in het leven of de vrijheid van mensen, en zeker als de verwachting is dat er grondrechten worden geraakt, moet er een wettelijke grondslag bestaan voor de inzet van het algoritme.</li> <li>Voor het verwerken van persoonsgegevens is een wettelijke grondslag noodzakelijk.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/#risico","title":"Risico","text":"<p>Het algoritme en beoogde besluiten voldoen niet aan wet- en regelgeving en intern beleid en kaders.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, SV.7, PRI.6</li> <li>Impact Assessment Mensenrechten en Algoritmes, 1.4</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-05-wettelijke-grondslag/#voorbeelden","title":"Voorbeelden","text":"<p>Belastingdienst: Wegenrisico\u2019s</p> <p>De Belastingdienst gebruikt een algoritme dat kijkt of een aangifte tot import van een voertuig correct is ingevuld. Het invullen van een aangifte is verplicht bij het importeren van een voertuig volgens de Wet op de belasting van personenauto's en motorrijwielen (BPM) 1992\u201d). De Belastingdienst geeft dus ook aan dat dit een van de wettelijke grondslagen is om hier een algoritme in te zetten. Dit wordt gedaan om de aangiften effici\u00ebnter en effectiever uit te voeren. Voor ieder algoritme moet een eigen grondslag bepaald worden, het is dus niet mogelijk om een \u2018one size fits all\u2019 toepassing te hebben op deze maatregel.</p> <p>Bron: [Belasting van personenauto's en motorrijwielen - Wegenrisico\u2019s (BPM - Wegenrisico\u2019s) - Algoritmeregister])https://algoritmes.overheid.nl/nl/algoritme/belasting-van-personenautos-en-motorrijwielen-wegenrisicos-bpm-wegenrisicos-belastingdienst/75246482#verantwoordGebruik)</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-06-multidisciplinair-inkoopteam/","title":"Stel een multidisciplinair team samen bij het ontwikkelen of inkopen van algoritmes","text":"<p>pba-06OntwerpProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-06-multidisciplinair-inkoopteam/#maatregel","title":"Maatregel","text":"<p>Stel een multidisciplinair team samen bij het ontwikkelen of inkopen van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-06-multidisciplinair-inkoopteam/#toelichting","title":"Toelichting","text":"<ul> <li>Bij een project gericht op het ontwikkelen of inkopen van algoritmes is het belangrijk dat betrokkenen al in een vroeg stadium samenwerken. Dit betekent dat zowel een interne opdrachtgever als het ontwikkelingsteam of de afdeling inkoop tijdig worden aangehaakt om te zorgen voor een goed afgestemd proces.</li> <li>Wanneer het gaat om het ontwikkelen of inkopen van algoritmes, is een multidisciplinair team wenselijk. Zo'n team brengt relevante kennis en ervaring samen om de behoeften en specificaties helder te krijgen. Afhankelijk van de aard en complexiteit van het algoritme kunnen de rollen binnen dit team vari\u00ebren.</li> <li>Naast een interne opdrachtgever, materiedeskundige en gebruiker kun je voor het ontwikkelen van algoritmes denken aan een data-engineer, data scientist, IT-architect, ethicus, data- en privacy-officer. Bij een overheidsopdracht gericht op de inkoop van een algoritme, horen daar nog een (aanbestedings)jurist en inkoper bij. Afhankelijk van de complexiteit van de oplossing zijn meer of minder disciplines en dus te beleggen verantwoordelijkheden binnen het team wenselijk.</li> <li>Een multidisciplinair team kan ondersteunen bij het formuleren van de probleemstelling of formuleren van de doelstellingen van een project, verkennen van de mogelijke oplossingsrichtingen en het vertalen van de gewenste oplossingsrichting naar de concrete behoefte.</li> <li>Betrek ook altijd een of meerdere leidinggevenden, en zorg dat zij de context en impact van het algoritme begrijpen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-06-multidisciplinair-inkoopteam/#risico","title":"Risico","text":"<p>Zonder een multidisciplinair team is het waarschijnlijk dat belangrijke aspecten voor een verantwoorde inzet van algoritmes niet worden geadresseerd en ongewenste algoritmes worden ontwikkeld of ingekocht.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-06-multidisciplinair-inkoopteam/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/1-pba-06-multidisciplinair-inkoopteam/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/","title":"Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmes","text":"<p>owp-01OntwerpImplementatieMonitoring en beheerProjectleiderGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#maatregel","title":"Maatregel","text":"<p>Beschrijf de rollen en verantwoordelijkheden voor het ontwikkelen en gebruiken van algoritmes. De rollen en verantwoordelijkheden worden vastgesteld door de verantwoordelijke(n).</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#toelichting","title":"Toelichting","text":"<p>Een re\u00ebel risico is dat bepaalde groepen en belanghebbenden over het hoofd worden gezien tijdens het ontwikkelproces van een algoritme. Daarom is het noodzakelijk om al vroeg in kaart te brengen welke groepen allemaal een mening over het beoogde algoritme kunnen hebben.</p> <p>Duidelijkheid en borging van rollen en verantwoordelijkheden zorgen voor een effectief en verantwoord verloop van het proces rondom de ontwikkeling, inkoop en gebruik van een algoritme. Zeker wanneer ongewenste effecten optreden en maatregelen nodig zijn, is duidelijkheid over rollen, verantwoordelijkheden en bijbehorende besluitvormingsstructuren van belang.</p> <p>Om deze reden kan het handig zijn om een matrix van belanghebbenden op te stellen. Deze matrix kan in verdere fases helpen wanneer belanghebbenden betrokken moeten worden. In deze matrix kunnen de volgende onderdelen staan:</p> <ul> <li>Per belanghebbende een beschrijving van wie deze groep is</li> <li>Mate van invloed van belanghebbende op het algoritme: wie, wanneer in de levenscyclus zorgt voor passende menselijke controle</li> <li>Impact van algoritme op de belanghebbende</li> <li>Risico\u2019s voor belanghebbende (wat zal de belanghebbende merken als het algoritme eventueel niet naar behoren functioneert).</li> </ul> <p>Een RACI-matrix/VERI-matrix is een passend middel om de verantwoordelijkheden (Responsible/Verantwoordelijk, Accountable/Eindverantwoordelijk, Consulted/Geraadpleegd, Informed/Ge\u00efnfomeerd) te bepalen. Werk specifieke, gevoelige activiteiten nader uit in concrete taken en verantwoordelijkheden, bijvoorbeeld welke stappen moeten worden gezet om data veilig te leveren ten behoeve van een onderzoek naar onbewuste vooringenomenheid.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#vaststellen-van-rollen-en-verantwoordelijkheden","title":"Vaststellen van rollen en verantwoordelijkheden","text":"<ul> <li>Laat de rollen en verantwoordelijkheden vaststellen door de verantwoordelijke(n). Het doel van vaststelling is dat de verantwoordelijke(n) de verantwoordelijkheid neemt en actief een keuze maakt om het algoritme te (laten) ontwikkelen of gebruiken op de beoogde wijze en met de bijbehorende verantwoordelijkheden. Met het vaststellen worden afspraken geformaliseerd.</li> <li>Vaststelling van de verantwoordelijkheden kan plaatsvinden door beleidsdocumenten, werkinstructies, verwerkersovereenkomst of een PIA/DPIA, mits de verantwoordelijkheden voldoende duidelijk zijn beschreven.</li> <li>Gedurende de levenscyclus kan het voorkomen dat rollen en verantwoordelijkheden opnieuw moet worden beschreven en vastgesteld.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#verwerking-van-persoonsgegevens","title":"Verwerking van persoonsgegevens","text":"<ul> <li>Bij het verwerken van persoonsgegevens moet worden vastgelegd wie de (gezamelijke) verwerkingsverantwoordelijken zijn en wie de verwerkers. Uit deze vaststelling van de rolverdeling volgen onder de AVG verschillende rechten en plichten.</li> <li>Bij de ontwikkeling en gebruiken van algoritmes is het denkbaar dat de noodzaak voor het verwerken van persoonsgegevens wijzigt en dat meer of andere verwerkingen moeten plaatsvinden. Het is van belang dat wederom wordt beoordeeld wat dit betekent voor de bijbehorende verantwoordelijkheden. Als er sprake is van een wezenlijke wijziging ten opzichte van de al vastgestelde situatie, bijvoorbeeld doordat er meer persoonsgegevens worden verwerkt door een andere partij, dan zal de verwerkingsverantwoordelijke opnieuw tot vaststelling moeten overgaan om de afspraken te formaliseren.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#risico","title":"Risico","text":"<p>De sturing en verantwoording is ontoereikend of niet geborgd, waardoor er onvoldoende betrokkenheid of capaciteit is van verantwoordelijken. Ook kan er dan onvoldoende deskundigheid in de organisatie zijn, wat de kans vergroot op fouten en ongewenste effecten. Zonder het vaststellen van rollen en verantwoordelijkheden kan er geen effectieve sturing plaatsvinden op partijen die betrokken zijn bij het ontwikkelen of gebruiken van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.06, 3.02</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.9, SV.19, PRI.1</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-01-rollen-en-verantwoordelijkheden/#voorbeelden","title":"Voorbeelden","text":"<p>RACI matrix - diverse organisaties</p> <p>Bij Gemeentelijke Model Architectuur (GEMMA) wordt aangegeven dat een RACI matrix rollen en verantwoordelijkheden goed weergeeft en onderscheidt. Het RACI matrix is een afkorting voor  Responsible (Verantwoordelijk), Accountable (Eindverantwoordelijk), Consulted (Raadplegen) en Informed (Informeren). In deze matrix staan horizontaal de rollen en staan verticaal de taken/producten waar een rol verantwoordelijk voor is. Dit matrix geeft veel verschillende rollen weer die in het beste geval voor verschillende functionarissen zijn. GEMMA geeft ook aan dat in kleinere organisaties (kleinere gemeenten) dit niet altijd mogelijk is. Het is dus belangrijk om te weten dat dit verschillend is per gemeente en afhankelijk van de volwassenheid van inrichting van gegevensmanagement.</p> <p></p> <p>Bron: RACI matrix</p> <p>UWV - Beleidsdocument model risico management</p> <p>Het UWV heeft een beleidsdocument model risico management gepubliceerd in 2021 waarin alle verantwoordelijkheden en rollen toegelicht worden. Hier is een volledig hoofdstuk aan gewijd waarin alle rollen toegelicht worden aan de hand van een korte functie-naam en beschrijving. Daarnaast worden deze ook ingedeeld in de categorie\u00ebn per verdedigingslinie (LINKIE). De rollen worden in ook los verder verduidelijkt rondom de verantwoordelijkheden die ze hebben inclusief mogelijke extra taken voor de persoon die hoofd is van deze rol.</p> <p>Bron: [Algoritmelevenscyclus - UWV], pagina 12( https://www.uwv.nl/overuwv/Images/bijlage-4-beslissing-op-bezwaar-op-wob-verzoek-software-en-algoritmes.pdf)</p> <p>Proceseigenaar</p> <p>De proceseigenaar wordt vaak verantwoordelijk gehouden voor eventuele gevolgen van het gebruik van het algoritme. Deze maatregel zorgt ervoor dat de proceseigenaar niet alle verantwoordelijkheid draagt, omdat dit vaak niet realistisch is. Met deze maatregel kunnen er heldere afspraken over de verschillende verantwoordlijkheden worden gemaakt. Hierdoor wordt het draagvlak groter, zonder ten koste te gaan van de duidelijkheid over rollen en verantwoordelijkheden.</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-02-data-beschikbaarheid/","title":"Voer voorafgaand aan een project een data beschikbaarheid, kwaliteit- en toegankelijkheidsanalayse uit","text":"<p>owp-02OntwerpProjectleiderBeleid en adviesPublieke inkoopData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-02-data-beschikbaarheid/#maatregel","title":"Maatregel","text":"<p>Voer voorafgaand aan een project een data beschikbaarheids- en datakwaliteitsanalayse uit.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-02-data-beschikbaarheid/#toelichting","title":"Toelichting","text":"<ul> <li>Het is van belang om voorafgaand aan een project vast te stellen of de data die noodzakelijk is om een algoritme te ontwikkelen of te kunnen gebruiken beschikbaar is, gaat worden en of de data van voldoende kwaliteit is.</li> <li>Er moet worden onderzocht of en hoe data vanuit de eigen organisatie, die van een eventuele externe aanbieder of elders beschikbaar kan worden gesteld, kan worden opgeslagen en of goedkeuring kan worden gegeven voor het verwerken van de data.</li> <li>De infrastructuur van de eigen organisatie en/of die van een eventuele externe aanbieder moet van voldoende niveau zijn om de beoogde verwerkingen uit te kunnen voeren.</li> <li>Een dergelijke analyse levert inzichten op welke problemen er eventueel op dit vlak kunnen ontstaan en geeft input voor de verdere ontwikkeling of (in geval van inkoop) de behoeftestelling.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-02-data-beschikbaarheid/#risico","title":"Risico","text":"<p>Het zou kunnen voorkomen dat de data niet beschikbaar is en ook niet gaat worden. Dit betekent dat een algoritme ook niet goed gemaakt of gebruikt kan worden. Ook is het belangrijk om te checken of de data beschikbaar blijft als dat nodig is voor het functioneren van het algoritme (bijv. voor het bijleren). Ook bestaat er een risico dat als de data van onvoldoende kwaliteit is, het algoritme niet goed gaat werken. Wanneer niet vooraf bepaald is of de data beschikbaar is en van voldoende kwaliteit is, kan het gebeuren dat er wel een algoritme gemaakt wordt door een derde partij, maar deze vervolgens niet gebruikt kan worden binnen de organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-02-data-beschikbaarheid/#bronnen","title":"Bronnen","text":"<ul> <li>Towards a Systematic Understanding on the Challenges of Procuring Artificial Intelligence in the Public Sector</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-02-data-beschikbaarheid/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/","title":"Beschrijf voor welk doel het algoritme persoonsgegevens gebruikt en waarom dit mag","text":"<p>owp-03OntwerpDataverkenning en datapreparatieOntwikkelenVerificatie en validatieImplementatieProjectleiderJuristPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#maatregel","title":"Maatregel","text":"<p>Het doel voor het verwerken van persoonsgegevens met een algoritme is welbepaald en omschreven.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens mogen alleen worden verwerkt voor een \u2018welbepaald, uitdrukkelijk omschreven en gerechtvaardigd\u2019 doel. De wettelijke grondslag voor de verwerking van de persoonsgegevens moet zijn beschreven.</p> <p>De verwerking van persoonsgevens voor het ontwikkelen en gebruiken van een algoritme moet verenigbaar zijn met het oorspronkelijke verwerkingsdoel (doelbinding). Eventuele verdere (subsidiaire) verwerkingen, zoals het verwerken van persoonsgegevens voor een onderzoek naar onbewuste vooringenomenheid, moeten uitdrukkelijk worden omschreven.</p> <p>Stel een overzicht op waarin is beschreven welke persoonsgegevens mogen worden verwerkt. Bij de persoonsgegevens is aangegeven om wat voor categorie persoonsgegevens het gaat. Per kenmerk is toegelicht waarom deze noodzakelijk is om te verwerken voor het ontwikkelen en gebruiken van het algoritme. Het principe van dataminimalisatie is toegepast, wat betekent dat een keuze is gemaakt of een persoonsgegevens al dan niet strikt noodzakelijk is om het doel te bereiken of dat verwerking ervan achterwege kan blijven.</p> <p>Voor het beschermen van deze persoonsgegevens wordt per kenmerk aangegeven op welke manier deze kan worden beschermd. Denk hierbij aan het anonimiseren, pseudonomiseren en aggregeren van de persoonsgegevens.</p> <p>Gebruik een DPIA om bovenstaande zaken te beschrijven.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#risico","title":"Risico","text":"<p>Als het doel voor het verwerken van persoonsgegevens onvoldoende is omschreven en onderbouwd, ontstaat het risico dat onrechtmatig persoonsgegevens worden verwerkt en een inbreuk wordt gemaakt op privacyrechten van betrokkenen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.01, 3.05</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.4</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.7</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-03-doel-verwerken-persoonsgegevens/#voorbeelden","title":"Voorbeelden","text":"<p>Stichting Inlichtingenbureau: Signaal Kostendelers</p> <p>Stichting Inlichtingenbureau (IB) maakt gebruik van het algoritme \u2018signaal kostendelers\u2019 dat aangeeft wanneer er iets is veranderd dat de hoogte van de bijstandsuitkering kan be\u00efnvloeden. Het IB krijgt informatie over wie in het huishouden woont om zo veranderingen op de kostendelersnorm door te kunnen geven aan gemeenten. Bij dit algoritme wordt onder andere gebruik gemaakt van het BSN en studie-informatie. Deze informatie is noodzakelijk om veranderingen te kunnen controleren van huishoudens. Het verwerken van deze persoonsgegevens is toegestaan onder (onder andere) \u2018Wet structuur uitvoeringsorganisatie werk en inkomen\u2019 artikel 63 en \u2018Participatiewet\u2019 artikel 64 en artikel 68. Het verwerken van deze gegevens is dus noodzakelijk voor het IB om haar functie te kunnen uitvoeren. Dit zal per organisatie verschillen maar soortgelijke wettelijke grondslag kan dus als uitgangspunt genomen worden voor controle binnen de eigen organisatie.</p> <p>Bron: Signaal Kostendelers - Stichting Inlichtingenbureau</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-04-gebruikte-techniek/","title":"Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing","text":"<p>owp-04OntwerpOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-04-gebruikte-techniek/#maatregel","title":"Maatregel","text":"<p>Beschrijf welke techniek gebruikt wordt voor de beoogde toepassing.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-04-gebruikte-techniek/#toelichting","title":"Toelichting","text":"<ul> <li>Beschrijf wat voor soort algoritme er gebruikt gaat worden voor de beoogde toepassing.</li> <li> <p>Bepaal of je gebruik wilt maken van een:</p> <ul> <li>zelflerend algoritme</li> <li>niet-zelflerend algoritme zoals een algoritme gebaseerd op rekenregels</li> </ul> </li> <li> <p>Beschrijf vervolgens ook:</p> <ul> <li>waarom er voor dit type algoritme wordt gekozen</li> <li>wat de alternatieven zijn en waarom die minder passend zijn</li> <li>waarom dit algoritme het meest geschikt is om het beoogde doel van het algoritme te bereiken.</li> </ul> </li> <li> <p>De precieze details kunnen in dit stadium van de levenscyclus waarschijnlijk nog niet ingevuld worden. Maak een goede eerste inschatting van de gebruikte techniek. Eventueel kan je er ook voor kiezen om verschillende technieken verder te onderzoeken. Dat betekent dat er meerdere algoritmes ontwikkeld worden (op basis van verschillende technieken), en je later een definitieve keuze maakt.</p> </li> <li> <p>Het is belangrijk om uiteindelijk een passend uitlegbaar algoritme te selecteren voor de context waarin het wordt toegepast. Daarin moet de afweging gemaakt worden of de technische uitlegbaarheid voldoende is in de context die de inzet van het algoritme vereist. Hierbij kan ook de conclusie worden getrokken dat een simpeler, inzichtelijker algoritme de voorkeur krijgt.</p> </li> <li> <p>Maak hierbij een bewuste afweging tussen uitlegbaarheid en prestaties van het algoritme. Over het algemeen geldt dat complexere maar minder uitlegbare algoritmes nauwkeuriger zijn.</p> </li> <li> <p>Veel (statistische) modellen zijn gebaseerd op (statistische) aannames over bijvoorbeeld eigenschappen van de data. Ga na of er aan deze aannames wordt voldaan.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-04-gebruikte-techniek/#risico","title":"Risico","text":"<p>Wanneer je geen zorgvuldige afweging maakt over de techniek die je gebruikt om het doel te bereiken, dan is het niet duidelijk of de meest geschikte techniek wordt gebruikt. Mogelijk zijn er passendere oplossingen om het doel te bereiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-04-gebruikte-techniek/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, 2A.1, 2B.1</li> <li>Onderzoekskader Auditdienst Rijk, DM.2</li> <li>Toetsingskader Algemene Rekenkamer, 2.04, 2.17</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-04-gebruikte-techniek/#voorbeelden","title":"Voorbeelden","text":"<p>Douane: Risico detectie aangiften</p> <p>De douane maakt gebruik van een algoritme om te selecteren welke goederen een (extra) controle krijgen. Dit wordt gedaan op basis van aangiftegegevens van bedrijven waarmee mogelijk verhoogde risico\u2019s worden aangegeven. In het algoritmeregister geven zij aan dat dit algoritme gebruik maakt van beslisregels gebaseerd op \u201cif-then-else\u201d combinaties. Zij geven aan dat gedaan wordt om zo aangiften effici\u00ebnter te kunnen behandelen en dus mogelijk sneller vrijgegeven kunnen worden.</p> <p>Bron: Detecteren risico\u2019s in douaneaangiften voor naleving opiumwetontheffing - Douane</p> <p>Provincie Zuid-Holland: Webapplicatie Impactmonitor Brugopening</p> <p>De Provincie Zuid-Holland (PZH) maakt gebruik van een webapplicatie om brugbedieners te ondersteunen bij het optimale moment kiezen voor het openen van de brug. De applicatie voorspelt tot 21 minuten in de toekomst en houd rekening met verkeersdoorstroom en uitstoot. In het algoritmeregister hebben zij in detail uitgelegd welke technieken gebruikt worden. Zij maken gebruik van Recurring Neural Networks (RNNs), een specifieke vorm van Artifici\u00eble Neurale Netwerken. Deze worden getraind op tijdserie data wat in dit geval belangrijk is vanwege de afhankelijkheid van drukte op en rondom de brug.</p> <p>Bron: Webapplicatie Impactmonitor Brugopening - Provincie Zuid-Holland</p> <p>Heb je een ander voorbeeld of best practice, laat het weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-05-soort-algoritme/","title":"Stel vast in welke risicogroep het algoritme valt en bepaal vervolgens welke vereisten van toepassing zijn.","text":"<p>owp-05OntwerpOntwikkelenProjectleiderBeleid en adviesPublieke inkoopGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-05-soort-algoritme/#maatregel","title":"Maatregel","text":"<p>Stel vast in welke risicogroep het algoritme valt en bepaal vervolgens welke vereisten van toepassing zijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-05-soort-algoritme/#toelichting","title":"Toelichting","text":"<p>Het verschilt per type algoritme welke vereisten hierop van toepassing is en waar een aanbieder of gebruiksverantwoordelijke aan moet voldoen.</p> <p>Dit is mede afhankelijk van de bijbehorende risicogroepen, de gebruikte techiek en of je het algoritme ontwikkelt of slechts gebruikt.</p> <p>Gebruik de beslishulp AI-verordening om de risicobepaling van jouw toepassing te bepalen.</p> <p>Let op dat niet enkel naar de AI-verordening wordt gekeken. Ook op impactvolle algoritmes die niet vallen onder het bereik van de AI-verordening zijn vereisten van toepassing. Zie hiervoor de Handreiking Algoritmeregister.</p> <p>Deze stap is van groot belang, omdat dit bijvoorbeeld voor ontwikkelteams mede bepalend is waar het te ontwikkelen systeem aan moet voldoen of welke contractuele verplichtingen moeten worden gecre\u00eberd tussen opdrachtgever en aanbieder van algoritmes.</p> <p>Je kan ook de Gids AI-verordening gebruiken om te bepalen wat de AI-verordening betekent voor jouw organisatie of toepassing.</p> <p>Tip</p> <p>De Europese Commissie publiceerde in februari 2025 extra guidance over de definitie van een AI-systeem. De richtlijnen over de definitie van een AI-systeem geven uitleg over de praktische toepassing van het wettelijke concept, zoals verankerd in de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-05-soort-algoritme/#risico","title":"Risico","text":"<p>Als de risicogroep waar een algoritme bij hoort niet wordt bepaald is er een risico op het niet naleven van de AI-verordening wat kan leiden tot sancties of boetes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-05-soort-algoritme/#bronnen","title":"Bronnen","text":"<ul> <li>Beslishulp AI-verordening</li> <li>Handreiking Algoritmeregister</li> <li>Gids AI-verordening</li> <li>Guidelines on the definition of an artificial intelligence system, Europese Commissie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-05-soort-algoritme/#voorbeelden","title":"Voorbeelden","text":"<p>Provincie Zuid-Holland - Classificatie Algoritmes</p> <p>Provincie Zuid-Holland maakt gebruik van verschillende typen algoritmes waaronder hoog-risico AI-systemen, impactvolle algoritmes en overige algoritmes. Zij hebben deze gepubliceerd in het algoritmeregister aan de hand van de drie verschillende publicatiecategorie\u00ebn. Deze drie categorie\u00ebn staan ook in de handreiking voor het Algoritmeregister.</p> <p>Bron: Provincie Zuid-Holland</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/","title":"Leg vast wat de impact van het algoritme is als het niet werkt zoals beoogd","text":"<p>owp-06ProbleemanalyseOntwerpProjectleiderOntwikkelaarTechnische robuustheid en veiligheidFundamentele rechten</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/#maatregel","title":"Maatregel","text":"<p>Leg vast wie er wordt geraakt, welke processen be\u00efnvloed worden door het algoritme en wat de impact is wanneer het systeem niet werkt zoals beoogd. Neem deze informatie proactief mee in het ontwerp en de ontwikkeling van een algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/#toelichting","title":"Toelichting","text":"<p>Er moet een analyse gemaakt worden van de impact van een algoritme dat niet werkt zoals bedoeld. Een algoritme dat niet werkt zoals bedoeld kan bijvoorbeeld betekenen dat het algoritme een foutieve beslissing maakt of dat het algoritme is uitgevallen. De analyse op wie dit een impact heeft en hoe groot die impact is, is van belang voor de ontwerpkeuzes, de risicoanalyse en de evaluatie. Wanneer een foutieve beslissing zwaarwegende gevolgen heeft, moet er in het ontwerp gezorgd worden dat de kans op deze fout verminderd wordt. In de evaluatie moet er worden bepaald of de resterende risico\u2019s acceptabel zijn. Voer de impactanalyse uit met een multidisciplinaire groep en documenteer afwegingen en keuzes hierbij. Wanneer een algoritme niet werkt als beoogd, kan dit inbreuk maken op grondrechten van eventuele betrokken burgers. Onderdeel van de impactanalyse is om te bepalen of je algoritme bepaalde grondrechten kan raken, aantasten of mogelijk schenden. Neem in de impactanalyse de volgende stappen.</p> <ul> <li> <p>Leg vast welke stakeholders worden geraakt. Denk hierbij aan de directe gebruiker, degene waarover het besluit wordt genomen en derde partijen die input leveren of de resultaten ontvangen. Houd hierbij rekening met kwetsbare groepen waarbij het nodig is om deze groep extra bescherming te bieden.</p> </li> <li> <p>Leg vast welke processen worden geraakt. Denk hierbij aan werkproces(sen) waarin het algoritme wordt gebruikt, maar ook aan vervolgprocessen of parallelle processen die be\u00efnvloed worden door de resultaten van het algoritme.</p> </li> <li> <p>Leg vast wat de impact is van een niet goed werkend algoritme (per stakeholder en proces). Bepaal per stakeholder en per proces wat het gevolg is van een niet goed werkend systeem. Indien het systeem uitvalt, hoe worden de partijen daardoor geraakt en wat is het gevolg? Zijn er processen die mogelijk stilvallen of moeten worden aangepast?</p> <p>Analyseer ook de gevolgen van foutieve beslissingen. Let op dat verschillende typen fouten een verschillende impact hebben. Bijvoorbeeld in het geval van een ziektedetectie algoritme als voorsortering of een pati\u00ebnt een uitgebreidere test moet ondergaan is de impact groter als de pati\u00ebnt ten onrechte als geen-risico wordt geclassificeerd dan als iemand ten onrechte een extra controle moet ondergaan.</p> </li> <li> <p>Bepaal welke factoren van invloed zijn op de kans dat het fout gaat. Het risico is afhankelijk van de kans dat een fout voorkomt. Voor risicoanalyse en mitigatie is het van belang om de factoren die van invloed zijn op de fouten in kaart te brengen. Deze geven input aan de ontwerpfase en mitigerende maatregelen. Denk hierbij aan factoren in de data, het soort algoritme, het gebruik en externe factoren.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/#risico","title":"Risico","text":"<p>Als er geen goede impactanalyse wordt gemaakt, kunnen risico\u2019s over het hoofd worden gezien. Een niet werkend systeem kan dan een grote impact hebben op mensen of de organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereistegrw-01Algoritmes schenden geen grondrechten of mensenrechtenavg-11Ontwerp en standaardinstellingen (defaults) zijn zo gunstig mogelijk voor de privacy van betrokkenen"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, SV.4</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-06-impactanalyse/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/","title":"Inventariseer welke grondrechten het algoritme kan schenden en maak een belangenafweging","text":"<p>owp-07ProbleemanalyseOntwerpVerificatie en validatieMonitoring en beheerProjectleiderBeleid en adviesFundamentele rechten</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/#maatregel","title":"Maatregel","text":"<p>Identificeer welke grondrechten geraakt worden door het in te zetten algoritme en maak een afweging of dit aanvaardbaar is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/#toelichting","title":"Toelichting","text":"<p>Een algoritme kan invloed hebben op grondrechten. Op een aantal grondrechten kan een algoritme sneller invloed hebben, zoals recht op persoonsgegevensbescherming, recht op behoorlijk bestuur en recht op gelijke behandeling. Deze veelvoorkomende grondrechten krijgen op andere plekken in het Algoritmekader specifieke aandacht. Er zijn echter ook grondrechten die bij minder algoritmes relevant zijn, maar desalniettemin in die gevallen zeer invloedrijk kunnen zijn. Het is van belang uiteindelijk een totale afweging te maken van alle grondrechten die (mogelijk) geraakt worden ten opzichte van de voordelen van het in te zetten algoritme. Een voorbeeld van een grondrecht dat minder snel geraakt wordt is bijvoorbeeld een algoritme om hate speech te kunnen detecteren. Zo'n algoritme zal van invloed kunnen zijn op de vrijheid van meningsuiting en het recht op informatie.</p> <p>Doorloop in lijn met deel 4 van het Impact Assessment Mensenrechten en Algoritmes de volgende stappen:</p> <ol> <li>Breng in kaart welke grondrechten geraakt kunnen worden door de inzet van het algoritme. Hiervoor kan bijlage 1 uit het Impact Assessment Mensenrechten en Algoritmes gebruikt worden.</li> <li>Als dat het geval is, is het allereerst van belang om te controleren of hiervoor specifieke wetgeving is waar de inzet van het algoritme aan moet voldoen.</li> <li>Bepaal hoe zwaar de geindentificeerde grondrechten worden geraakt door het beoogde algoritme.</li> <li>Bepaal hoe doeltreffend/effectief het algoritme in de praktijk is.</li> <li>Bepaal of de inzet van het algoritme noodzakelijk is om het beoogde doel te bereiken. Zijn er alternatieven? Of zijn er mitigerende maatregelen die genomen kunnen worden waardoor grondrechten niet of minder worden geraakt en eventuele nadelige gevolgen verzacht kunnen worden?</li> <li>Gegeven alle voorgaande stappen, bepaal of de inzet van het algoritme proportioneel is om het beoogde doel te bereiken. Wegen de voordelen op tegen de nadelen?</li> </ol> <p>Het is van belang voldoende belanghebbenden te betrekken bij het doorlopen van deze stappen om te zorgen dat alle eventueel nadelige aspecten van het in te zetten algoritme worden meegenomen. Documenteer de te doorlopen stappen en leg de keuzes en afwegingen goed vast.</p> <p>Opmerking</p> <p>Zoals vermeld in de vereiste voor beoordeling van gevolgen voor grondrechten uit de AI-verordening moeten sommige hoog-risico AI-systemen een beoordeling doen van de gevolgen voor grondrechten. Het is nog niet bekend welke vorm dit precies moet hebben.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/#risico","title":"Risico","text":"<p>Het risico is dat er grondrechten, anders dan die expliciet beschermd zijn in andere maatregelen en vereisten, aangetast worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, deel 4</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.4</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-07-afwegen-grondrechten/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Rotterdam \u2013 Evaluatierapport governance algoritmetoepassingen</p> <p>De gemeente Rotterdam maakt gebruik van het Impact Assessment Mensenrechten en Algoritmes (IAMA) na controle op hoog-risico aan de hand van de Algorithm Risk Assesment (ARA). Rotterdam gebruikt hiermee de ARA als een \u2018pre-IAMA\u2019 om daarna (waar nodig) het IAMA verder uit te werken. Zij geven aan dat het IAMA veel toegevoegde waarde heeft, zo helpt het onder andere ontwikkelaars met het onderbouwen van problemen binnen een algoritme.</p> <p>Bron: Werken aan verantwoorde algoritmisering</p> <p>Diverse organisaties  - IAMA in Actie</p> <p>In 2023 en 2024 zijn door Universiteit Utrecht (UU) en het Rijks ICT Gilde (RIG) een aantal IAMA-trajecten begeleid bij overheidsorganisaties. Hierbij zijn verschillende sessies geweest per organisatie om alle gedeelten van het IAMA te beantwoorden met behulp van de expertise van de UU- of RIG-begeleiders. In het rapport IAMA in Actie worden de bevindingen van deze IAMA-pilots uitgebreid toegelicht.</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/","title":"Maak een lijst van de meest kwetsbare groepen en bescherm hen extra","text":"<p>owp-08OntwerpBeleid en adviesFundamentele rechten</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/#maatregel","title":"Maatregel","text":"<p>Bepaal wat de impact van het in te zetten algoritme is voor betrokkenen (personen of groepen). Bepaal vervolgens of er groepen zijn waarbij de impact van het algoritme dermate groot kan zijn, dat het wenselijk is om deze groepen extra bescherming te bieden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/#toelichting","title":"Toelichting","text":"<ul> <li>Verschillende groepen kunnen op een andere manier geraakt worden door het inzetten van een algoritme. Dit is afhankelijk van de context waarin het algoritme wordt ingezet, en dient daardoor bij iedere toepassing opnieuw bekeken te worden.</li> <li>Bedenk wat er met de uitkomsten van het algoritme gedaan wordt, en wat de consequenties daarvan zijn voor burgers. Hierbij kan gedacht worden aan de volgende aspecten:<ul> <li>Worden bepaalde groepen sneller gemonitored?</li> <li>Wat als het model het fout heeft?</li> <li>Wordt het systeem gebruikt om informatie te verkrijgen, om besluiten voor te bereiden of om zelfstandige besluiten te nemen en welke gevolgen heeft dat voor de mate waarin het algoritme bepalend zal zijn in de praktijk?</li> <li>Worden de gegevens veilig en vertrouwelijk behandeld; welke gevolgen zou een datalek hebben voor groepen of categorie\u00ebn personen?</li> <li>Worden data gedeeld met andere partijen en wat is het gevaar dat die misbruik maken van de data met negatieve gevolgen voor groepen of categorie\u00ebn personen?</li> </ul> </li> <li>Houd hierbij ook rekening met de impact van het in te zetten algoritme op de samenleving (vanuit sociaal, democratisch en milieu/ecologisch perspectief).</li> <li>Om de impact op groepen te bepalen, kan het handig zijn een mensenrechtentoets zoals het Impact Assessment Mensenrechten en Algoritmes toe te passen.</li> <li>Bepaal of er maatregelen genomen kunnen worden om de ge\u00efdentificeerde groepen extra bescherming te bieden. Hierbij kan men denken aan de volgende aspecten: Kan de (extra) administratieve druk voor bepaalde groepen worden weggenomen? Worden resultaten van het algoritme naast de resultaten van een expert gelegd? Is het wenselijk om een proces in te richten waarbij zowel algoritme als een expert een uitkomst geven? Kunnen we de betreffende groep extra hulp aanbieden? Is het wenselijk bij negatieve uitkomsten een vier-ogen-principe toe te passen?</li> <li>De impact van het algoritme op de groepen die ge\u00efdentificeerd worden in deze stap, kunnen mogelijk onderzocht worden in een biasanalyse. Daarbij kan ge\u00efdentificeerd worden of bepaalde groepen over- of ondervertegenwoordigd zijn in selecties, of dat het algoritme andere of meer fouten maakt voor bepaalde groepen.</li> <li>Merk op dat het onmogelijk is om de risico's voor alle specifieke groepen af te vangen. Hierbij kan het helpen om te focussen op de meest kwetsbare groepen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/#risico","title":"Risico","text":"<p>De impact van het algoritme op de besluitvorming en op personen, doelgroepen en/of de samenleving is niet inzichtelijk, waardoor onvoldoende maatregelen zijn getroffen om ongewenste effecten (zoals bias en discriminatie) te voorkomen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader algoritmes, Auditdienst Rijk, SV.4 en DM.16</li> <li>Advies Dienst Toeslagen (Kamerstukken II 2023/24, 31066-1374)</li> <li>Impact Assessment Mensenrechten en Algoritmes, 4.1</li> <li>Handreiking non-discriminatie by design, 1.7, 1.8 en 1.15</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-08-kwetsbare-groepen/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-09-archiveren-documenten/","title":"Bepaal welke documenten voor hoe lang gearchiveerd moeten worden","text":"<p>owp-09OntwerpOntwikkelenOntwikkelaarProjectleiderJuristTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-09-archiveren-documenten/#maatregel","title":"Maatregel","text":"<p>Stel vast welke documenten, (samengesteld geheel van) data, informatie van of in het algoritme gelden als \"archiefbescheiden\" in de zin van artikel 1c Archiefwet en documenteer daarvan een overzicht, bij voorkeur vastgesteld door een daartoe bevoegde. Bepaal de bijbehorende bewaartermijnen vast voor de archiefbescheiden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-09-archiveren-documenten/#toelichting","title":"Toelichting","text":"<ul> <li>Bij archiefbescheiden kan worden gedacht aan de broncode, trainings- en testdata, (technische) documentatie en de output.</li> <li>Deze archiefbescheiden moeten voor een bepaalde tijd worden bewaard (de bewaartermijn).</li> <li>Overleg hierover met de verantwoordelijke binnen de organisatie voor het toepassen van de Archiefwet.</li> <li>Het is mogelijk dat de selectielijsten nog niet duiden welke informatie of data, specifiek bij de toepassing van algoritmes, moet worden toegepast en hier dus ook nog geen termijnen bij zijn gekoppeld.</li> <li>Stel vast of beperkingen aan openbaarheid van de archiefbescheiden moeten worden gesteld. Er zijn gevallen waarbij het openbaren van archiefbescheiden is uitgesloten. Stem in het begin van het proces (pro-actief) met de opdrachtgever af wat de wenselijkheid is t.a.v. transparantie en openheid (uitgangspunt zou 'open, tenzij' moeten zijn).</li> <li>Stel vast hoe de archiefbescheiden op een duurzame wijze toegankelijk kunnen worden gemaakt. Het moet mogelijk zijn dat de archiefbescheiden daadwerkelijk overhandigd kunnen worden aan betrokken partijen. Denk hierbij aan burger, onderneming, toezichthouder of rechter. Duurzaam betekent hier met behoud van functie en kwaliteit voor langere tijd. Onderzoek welke voorziening hiervoor beschikbaar is binnen de organisatie.</li> </ul> <p>Tip</p> <p>Formeer hierbij een multi-discipinaire groep (bestaande uit bijvoorbeeld een inkoper, ontwikkelaar, data scientist, proceseigenaar en archiefdeskundige) om deze maatregel toe te passen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-09-archiveren-documenten/#risico","title":"Risico","text":"<p>Bij het niet vaststellen van de archeifbescheiden loop je als organisatie het risico dat je niet voldoet aan de archiefwet, en dat informatie moeilijk te traceren is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-09-archiveren-documenten/#bronnen","title":"Bronnen","text":"<ul> <li>Rekenen en rekenschap, essay over algoritmes en de Archiefwet, Inspectie Overheidsinformatie en Erfgoed</li> <li>Toetsingskader Algemene Rekenkamer 4.06</li> <li>Onderzoekskader Auditdienst Rijk, DM.13</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-09-archiveren-documenten/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-10-projectstartarchitectuur/","title":"Maak een Project Startarchitectuur (PSA) voor de ontwikkeling of inkoop van algoritmes","text":"<p>owp-10OntwerpOntwikkelenVerificatie en validatieImplementatieProjectleiderBeleid en adviesTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-10-projectstartarchitectuur/#maatregel","title":"Maatregel","text":"<p>Voer een Project Startarchitectuur (PSA) uit als algoritmes worden ontwikkeld of ingekocht.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-10-projectstartarchitectuur/#toelichting","title":"Toelichting","text":"<ul> <li>Een Project Startarchitectuur (PSA) is een hulpmiddel dat bij een project wordt ingezet om veranderingen van A naar B beter te faciliteren.</li> <li>De PSA richt zich daarbij op de kaders die op een project van toepassing zijn en wat de oplossing bijdraagt aan het realiseren van de gewenste, toekomstige architectuur, wat de implicaties zullen zijn voor bestaande voorzieningen en waar het project zal afwijken van bestaande beelden.</li> <li>Met de PSA wordt een concreet en doelgericht ICT-architectuurkader opgesteld, waarbinnen het project moet worden uitgevoerd.</li> <li>De PSA maakt concreet wat architectuur voor een project betekent.</li> <li>Door een PSA uit te voeren ontstaan inzichten hoe het betreffende algoritme zo optimaal mogelijk onderdeel kan worden gemaakt van het bestaande applicatielandschap, waarmee bijvoorbeeld kan worden voorkomen dat het algoritme of AI-systeem na verloop van tijd geen input meer kan ontvangen door onverwachte wijzigingen in systemen.</li> <li>Onderwerpen als privacy en informatiebeheer worden hierin ook globaal meegenomen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-10-projectstartarchitectuur/#risico","title":"Risico","text":"<p>Het algoritme kan niet of na verloop van tijd niet meer functioneren, doordat onverwachte of ongewenst wijzigingen in het applicatielandschap plaatsvinden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-10-projectstartarchitectuur/#bronnen","title":"Bronnen","text":"<ul> <li>Project Startarchitectuur, NORA</li> <li>PSA Format</li> <li>PSA Handleiding</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-10-projectstartarchitectuur/#voorbeelden","title":"Voorbeelden","text":"<p>Nederlandse Overheid Referentie Architectuur \u2013 PSA format</p> <p>Op het platform van de Nederlandse Overheid Referentie Architectuur (NORA) staan zowel een format als een handleiding voor een Project Start Architectuur (PSA).</p> <p>Deze twee documenten zijn voor iedere organisatie te downloaden en verder uit te werken. Er wordt per hoofdstuk benoemd waar aan gedacht moet worden en hoe dit verder uitgewerkt moet worden.</p> <p>Bron: PSA(Project Startarchitectuur)</p> <p>Gemeente Amsterdam \u2013 WPI model onderzoekswaardigheid uitkeringsaanvragen</p> <p>Gemeente Amsterdam heeft bij het ontwikkelen van een analyse algoritme gebruik gemaakt van een Architectuurnotitie, vergelijkbaar met een Project Start Architectuur (PSA). Hierin wordt toegelicht hoe dit project (het algoritme) stand houdt ten opzichte van andere projecten, belanghebbenden en belangrijke documenten (wetgeving). Naast deze toelichting wordt ook uitgelegd hoe het algoritme tot stand komt, bijvoorbeeld: wat zijn de uitgangspunten voor het ontwikkelen, welke risico\u2019s zijn in beeld en hoe worden deze voorkomen, wat is de uiteindelijke doel architectuur, etc.</p> <p>Bron: Architectuurnotitie Risicomodel</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/","title":"Beschrijf welke data gebruikt wordt voor de beoogde toepassing","text":"<p>owp-11OntwerpDataverkenning en datapreparatieOntwikkelaarBeleid en adviesData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/#maatregel","title":"Maatregel","text":"<p>Beschrijf welke data gebruikt wordt voor de beoogde toepassing.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/#toelichting","title":"Toelichting","text":"<ul> <li>Maak in een vroege fase van de ontwikkeling een inschatting van welke data er gebruikt gaat worden voor het algoritme.</li> <li>Leg na het uitvoeren van een beschikbaarheids-, kwaliteits- en toegankelijkheidsanalyse vast welke data wordt verwerkt voor het ontwikkelen en gebruiken van het algoritme.</li> <li>Beschrijf daarbij om wat voor gegevens het gaat en uit welke bron deze komen.</li> <li>Bepaal of het is toegestaan om deze data te verwerken.</li> <li>Het is denkbaar dat het onderzoek van de kwaliteit van de data in een latere fase in de levenscyclus pas grondig kan worden uitgevoerd.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/#generatieve-ai","title":"Generatieve AI","text":"<p>Bij generatieve AI kan er sprake zijn van een model dat verder getraind wordt door ingegeven data.</p> <ul> <li>Bepaal of het model verder getraind zal worden, en zo ja, met welke data.</li> <li>Beschrijf of deze data wordt opgeslagen, wie toegang heeft, en hoe de integriteit hiervan wordt gewaarborgd.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/#risico","title":"Risico","text":"<p>Als er niet wordt beschreven welke data wordt gebruikt voor een toepassing wordt het risico gelopen dat bij gebruik van een algoritme er kans is op bias-vorming en mindere transparantie. Bij generatieve AI kan er ook sprake zijn van data die ongewenst wordt verwerkt in de AI-toepassing.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/#bronnen","title":"Bronnen","text":"<ul> <li>Impact Assessment Mensenrechten en Algoritmes, 2A.2.1</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-11-gebruikte-data/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/","title":"Koop duurzaam algoritmes in","text":"<p>owp-12OntwerpProjectleiderBeleid en adviesPublieke inkoopDuurzaamheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#maatregel","title":"Maatregel","text":"<p>Kies softwareoplossingen van aanbieders die duurzaamheid bevorderen, en stel heldere eisen aan energieverbruik, hernieuwbare energiebronnen en transparantie over de milieuprestaties van software.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#toelichting","title":"Toelichting","text":"<p>Door software duurzaam in te kopen, kun je als organisatie al vroeg in het ontwikkelproces bijdragen aan de verduurzaming van je algoritmes. Kies daarom softwareoplossingen van aanbieders die maatschappelijk verantwoord ondernemen (MVI) en energie-effici\u00ebntie vooropstellen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#duurzaamheidscriteria-en-selectie-van-aanbieders","title":"Duurzaamheidscriteria en selectie van aanbieders","text":"<p>Om software duurzaam in te kopen, kun je aanbieders beoordelen op specifieke duurzaamheidscriteria. Enkele belangrijke criteria zijn:</p> <ul> <li>het energieverbruik van de software</li> <li>het gebruik van hernieuwbare energiebronnen in de benodigde datacenters</li> <li>het beperken van CO\u2082-uitstoot tijdens de levenscyclus van de software.</li> </ul> <p>Vraag om inzicht in milieuprestaties en certificeringen, zoals ISO-14001, om de toewijding van aanbieders aan duurzaamheid te toetsen. De ISO-14001 is een internationaal geaccepteerde standaard met eisen voor een milieumanagementsysteem.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#inkoopvoorwaarden-en-contractuele-eisen","title":"Inkoopvoorwaarden en contractuele eisen","text":"<p>Stel bij het inkopen duidelijke eisen aan duurzaamheidscriteria, zoals het gebruik van \"groene technologie\u00ebn\", het aanbieden van Software-as-a-Service (SaaS) en open standaarden. Zo maak je duurzame keuzes die bijdragen aan een langere levensduur en energie-effici\u00ebntie van je algoritmes. Door KPI\u2019s op te nemen voor energie-effici\u00ebntie en CO\u2082-reductiedoelen kun je de voortgang van deze doelen concreet monitoren. Je kunt deze voorwaarden opnemen als standaard inkoopvoorwaarden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#bonus-malusregeling-en-monitoring","title":"Bonus-malusregeling en monitoring","text":"<p>Om naleving van duurzame doelstellingen te stimuleren, kun je een bonus-malusregeling inzetten. Aanbieders ontvangen een bonus wanneer zij duurzame doelstellingen halen, en kunnen worden aangesproken als beloofde duurzaamheidsnormen niet worden behaald. Monitoring via jaarlijkse rapportages helpt om de voortgang van de duurzaamheidsdoelen te evalueren en, indien nodig, bij te sturen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#extra-overwegingen","title":"Extra overwegingen","text":"<p>Extra overwegingen die je kunt maken bij het aankopen van algoritmes, zoals genoemd in de handreiking 'Hoe maak ik mijn inkoop van software duurzamer?' van PIANOo en het eindrapport 'Generatieve AI en duurzaamheid' van de Universiteit Utrecht:</p> <ul> <li>Ga na of je de software wel echt moet inkopen.</li> <li>Maak waar mogelijk gebruik van al bestaande modellen of fine-tune deze.</li> <li>Onderzoek of je gebruik kunt maken van een AI-toepassing die bij een andere overheidsorganisatie in beheer is.</li> <li>Gebruik alleen een groot model als dit veel toegevoegde waarde heeft.</li> <li>Probeer zoveel mogelijk uit te vragen in een SaaS-oplossing.</li> <li>Vraag een oplossing in een Cloud-omgeving.</li> <li>Ga na of \u2018serverless\u2019 ook een oplossing is.</li> <li>Vraag om de broncode van de software.</li> <li>Denk goed na over de technische levensduur van verschillende componenten.</li> <li>Open standaarden zijn een vorm van duurzaamheid.</li> <li>Pas containerisatie en virtualisatie toe.</li> <li>Neem eisen op over opschalingsmogelijkheden.</li> <li>Vraag de afdrukcijfers op.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#risico","title":"Risico","text":"<p>Zonder duurzaamheidscriteria bij het inkopen van software loop je het risico op hogere energie- en kostenlasten en beperk je de mogelijkheden om duurzaamheidsdoelstellingen te halen bij je algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking: Hoe maak ik mijn inkoop van software duurzamer? (PIANOo)</li> <li>Eindrapport 'Generatieve AI en duurzaamheid' (Universiteit Utrecht)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-12-duurzaam-inkopen/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/","title":"Ontwerp algoritmes zo eenvoudig mogelijk","text":"<p>owp-13OntwerpOntwikkelenOntwikkelaarDuurzaamheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#maatregel","title":"Maatregel","text":"<p>Ontwerp algoritmes gericht op eenvoud en effici\u00ebntie, zodat het energieverbruik en de benodigde rekenkracht tijdens gebruik minimaal blijven.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#toelichting","title":"Toelichting","text":"<p>Complexe algoritmes vereisen vaak aanzienlijke rekenkracht, wat energie-intensief kan zijn. Door algoritmes minder complex en rekenintensief te ontwerpen, verlaag je de benodigde middelen en energie bij het trainen en uiteindelijk toepassen van deze algoritmes. Een effici\u00ebnter ontwerp maakt de algoritmes energiezuiniger in de trainings- en gebruiksfase en draagt zo bij aan duurzaamheid in de gehele levenscyclus.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#modellen-vereenvoudigen-en-focussen-op-kernfunctionaliteit","title":"Modellen vereenvoudigen en focussen op kernfunctionaliteit","text":"<p>Wanneer je een nieuw algoritme ontwikkelt, kun je de omvang en rekenbelasting beperken door alleen noodzakelijke functionaliteit op te nemen. Focus op de kernfunctionaliteit, zodat je gebruik maakt van een kleiner model dat beter te begrijpen en gemakkelijker te beheren is. Het vermijden van overbodige functionaliteiten maakt het algoritme minder zwaar en verlaagt de milieu-impact aanzienlijk.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#minder-complexiteit-door-divide-and-conquer-en-dynamisch-programmeren","title":"Minder complexiteit door divide-and-conquer en dynamisch programmeren","text":"<p>Een populaire methode om complexiteit te verlagen is het divide-and-conquer principe, waarbij je een grote algoritmische berekening opsplitst in kleinere, overzichtelijke deelberekeningen en deze vervolgens oplost (je splitst hierbij het technische probleem in meerdere kleinere problemen). Dit vermindert de rekenlast aanzienlijk en verhoogt de effici\u00ebntie. Ook kun je met dynamisch programmeren optimalisaties toevoegen door eerder berekende resultaten op te slaan en te hergebruiken, wat herhaling van berekeningen voorkomt en de rekenkracht vermindert.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#minder-complexiteit-door-modeloptimalisatie","title":"Minder complexiteit door modeloptimalisatie","text":"<ul> <li>Door gebruik te maken van pruning kunnen minder relevante verbindingen en nodes in een neuraal netwerk worden verwijderd, waardoor de rekenbelasting vermindert.</li> <li>Quantization verlaagt de precisie van numerieke waarden in een model, wat opslag en rekenkracht verlaagt zonder de prestaties significant te be\u00efnvloeden.</li> <li>Knowledge distillation kan verder helpen door de kennis van een groot model over te dragen naar een kleiner, minder complex model, dat vervolgens effici\u00ebnter werkt.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#risico","title":"Risico","text":"<p>Ontwerpen zonder oog voor effici\u00ebntie kan leiden tot energie-intensieve algoritmes die hoge kosten en milieubelasting met zich meebrengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#bronnen","title":"Bronnen","text":"<ul> <li>What is knowledge distillation? (IBM)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-13-eenvoudigere-algoritmes/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-14-verwerkersovereenkomst-onderdeel-aanbesteding/","title":"Maak het opstellen van een verwerkersovereenkomst onderdeel van de aanbesteding als persoonsgegevens worden verwerkt","text":"<p>owp-14OntwerpMonitoring en beheerProjectleiderBeleid en adviesPublieke inkoopPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-14-verwerkersovereenkomst-onderdeel-aanbesteding/#maatregel","title":"Maatregel","text":"<p>Het opstellen van een verwerkersovereenkomst met aanbieder is onderdeel van de aanbesteding als persoonsgegevens worden verwerkt of noodzakelijk zijn voor het trainen of genereren van output door algoritmes van de aanbieder.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-14-verwerkersovereenkomst-onderdeel-aanbesteding/#toelichting","title":"Toelichting","text":"<p>Een verwerkersovereenkomst moet worden opgesteld als persoonsgegevens worden verwerkt voor het trainen of het genereren van output door algoritmes van de aanbieder. Met een verwerkersovereenkomst worden een aantal afspraken schriftelijk vastgelegd het bij de verwerking van persoonsgegevens. Het gaat om de volgende zaken:</p> <ul> <li> <p>Algemene beschrijving. Een omschrijving van het onderwerp, de duur, de aard en het doel van de verwerking, het soort persoonsgegevens, de categorie\u00ebn van betrokkenen en uw rechten en verplichtingen als verwerkingsverantwoordelijke.</p> </li> <li> <p>Instructies voor de verwerking. De verwerking vindt in principe uitsluitend plaats op basis van uw schriftelijke instructies. De verwerker mag de persoonsgegevens niet voor eigen doeleinden gebruiken.</p> </li> <li> <p>Geheimhoudingsplicht. Personen in dienst van of werkzaam voor de verwerker hebben een geheimhoudingsplicht.</p> </li> <li> <p>Beveiliging. De verwerker treft passende technische en organisatorische maatregelen om de verwerking te beveiligen. Bijvoorbeeld pseudonimisering en versleuteling van persoonsgegevens, permanente informatiebeveiliging, herstel van beschikbaarheid en toegang tot gegevens bij incidenten en regelmatige beveiligingstesten.</p> </li> <li> <p>Subverwerkers. De verwerker schakelt geen subverwerker(s) in zonder uw voorafgaande schriftelijke toestemming. De verwerker legt aan een subverwerker in een subverwerkersovereenkomst dezelfde verplichtingen op als de verwerker richting u heeft. In de overeenkomst kunt u ook direct afspreken dat de verwerker subverwerkers mag inschakelen en onder welke voorwaarden. Komt de subverwerker de verplichtingen niet na? Dan blijft de verwerker volledig aansprakelijk richting u voor het nakomen van de verplichtingen van de subverwerker (artikel 28, vierde lid, van de AVG).</p> </li> <li> <p>Privacyrechten. De verwerker helpt u om te voldoen aan uw plichten als betrokkenen hun privacyrechten uitoefenen (zoals het recht op inzage, correctie, verwijdering en dataportabiliteit).</p> </li> <li> <p>Andere verplichtingen. De verwerker helpt u ook om andere verplichtingen na te komen. Zoals bij het melden van datalekken, het uitvoeren van een data protection impact assessment (DPIA) en bij een voorafgaande raadpleging.</p> </li> <li> <p>Gegevens verwijderen. Na afloop van de verwerkingsdiensten verwijdert de verwerker de gegevens. Of bezorgt de verwerker de gegevens aan u terug, als u dat wilt. Ook verwijdert de verwerker kopie\u00ebn. Tenzij de verwerker wettelijk verplicht is de gegevens te bewaren.</p> </li> <li> <p>Audits. De verwerker werkt mee aan uw audits of die van een derde partij. En stelt alle relevante informatie beschikbaar om te kunnen controleren of de verwerker zich houdt aan de hierboven genoemde verplichtingen (artikel 28 AVG).</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-14-verwerkersovereenkomst-onderdeel-aanbesteding/#risico","title":"Risico","text":"<p>Er is sprake van een onrechtmatige verwerking van persoonsgegevens als geen verwerkersovereenkomst is opgesteld tussen de verwerker en de verwerkingsverantwoordelijke.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-14-verwerkersovereenkomst-onderdeel-aanbesteding/#bronnen","title":"Bronnen","text":"<ul> <li>Verwerkersovereenkomst</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-14-verwerkersovereenkomst-onderdeel-aanbesteding/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Geertruidenberg: Verwerkersovereenkomst</p> <p>De Gemeente Geertruidenberg heeft op 4 juli 2024 een aankondiging gedaan voor een opdracht over het leveren, implementeren  en onderhouden van een zaak-/archiefsysteem. Bij het cre\u00ebren van de opdracht is een verwerkersovereenkomst gepubliceerd. Op deze manier is het direct onderdeel van de aanbesteding zodat de aanbieder weet wat er van hen verwacht wordt.</p> <p>Bron: Zaak-/archiefsysteem</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/","title":"Bespreek de vereisten die gelden voor een verantwoorde inzet van algoritmes met aanbieders","text":"<p>owp-15OntwerpOntwikkelenProjectleiderPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/#maatregel","title":"Maatregel","text":"<p>Bespreek de vereisten die gelden voor een verantwoorde inzet van algoritmes met een aanbieder.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/#toelichting","title":"Toelichting","text":"<p>Ga met een aanbieder in gesprek over in hoeverre zij invulling kunnen geven aan de vereisten die gelden voor een verantwoorde inzet van algoritmes. Dit kan worden gedaan bijvoorbeeld bij een informatiesessie met aanbieders voorafgaand aan een aanbesteding.</p> <p>Hiervoor is het van belang om te bepalen om wat voor type algoritme het gaat en wat de bijbehorende risicoclassificatie is. Maak op basis daarvan inzichtelijk welke vereisten hierop van toepassing zijn.</p> <p>Op basis van nieuwe of gewijzigde wet- en regelgeving of de totstandkoming van nieuwe standaarden, is het denkbaar dat aanbieders van algoritmes nog niet of niet meer voldoen aan deze vereisten. Het is van belang dat deze inzichten bijvoorbeeld tijdens een aanbesteding worden verkregen. Indien van toepassing, laat de aanbieder inzichtelijk maken welke stappen deze gaat zetten om hieraan te gaan voldoen. Dit is ook relevant bij reeds afgesloten contracten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/#risico","title":"Risico","text":"<p>Door de vereisten voor een verantwoorde inzet van algoritmes niet te bespreken met aanbieders, is het voor hen (deels) onduidelijk aan welke vereisten diens algoritmes moet voldoen om te kunnen contracteren met overheidsorganisaties.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-15-bespreek-vereisten-met-aanbieders/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/","title":"Maak vereisten voor algoritmes onderdeel van algemene inkoopvoorwaarden en de contractovereenkomst","text":"<p>owp-16OntwerpProjectleiderBeleid en adviesPublieke inkoopTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/#maatregel","title":"Maatregel","text":"<p>Maak vereisten voor algoritmes onderdeel van contractvoorwaarden en de contractovereenkomst.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/#toelichting","title":"Toelichting","text":"<ul> <li>Door vereisten die gelden voor algoritmes onderdeel te maken van contractvoorwaarden, is voor een aanbieder vooraf duidelijk aan welke voorwaarden zij moeten voldoen als zij algoritmes willen aanbieden aan overheidsorganisaties.</li> <li>Het is van belang om een afweging te maken welke vereisten voor algoritmes als 'algemene contractvoorwaarden' kunnen gelden en welke aanvullend in een contractovereenkomst moeten worden opgenomen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/#risico","title":"Risico","text":"<p>Door de vereisten voor een verantwoorde inzet van algoritmes niet te communiceren met aanbieders, is het voor hen (deels) onduidelijk aan welke vereisten diens algoritmes moet voldoen om te kunnen contractueren met overheidsorganisaties.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.11</li> <li>Specificeren algemene inkoopvoorwaarden</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-16-vereisten-onderdeel-algemene-inkoopvoorwaarden-en-contractovereenkomst/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam - Modelbepalingen</p> <p>De gemeente Amsterdam heeft contractvoorwaarden voor algoritmen opgesteld waarin sommige vereisten opgenomen zijn. Hieronder vallen bijvoorbeeld \u201cHoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteem\u201d en \"Organisaties kunnen duidelijk uitleggen waarom en hoe algoritmes leiden tot een besluit\u201d. Deze staan respectievelijk in artikel 6.2 en artikel 5.4 verder uitgewerkt. Op dit moment zijn de vereisten impliciet verwerkt in deze voorwaarden in tegenstelling tot een expliciete verwijzing. Het is goed dit explicieter te benoemen zodat de aanbieder hier volledig van op de hoogte is.</p> <p>Gebruik generieke inkoopvoorwaarden als template of inspiratie voor andere inkoopvoorwaarden.</p> <p>Bron: Contractvoorwaarden voor algoritmen - Innovatie</p> <p>Europese Inkoopvoorwaarden</p> <p>De Europese Commissie biedt Europese modelcontractbepalingen voor laag- en hoog-risico-AI.</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-17-leveren-bewijs-voldoen-aan-vereisten-algoritme-aanbieder/","title":"Maak het leveren van bewijs voor het voldoen aan de vereisten voor algoritmes onderdeel van de beoordeling van een inschrijving","text":"<p>owp-17OntwerpProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-17-leveren-bewijs-voldoen-aan-vereisten-algoritme-aanbieder/#maatregel","title":"Maatregel","text":"<p>Maak het leveren van bewijs voor het voldoen aan de vereiste onderdeel van de beoordeling van een inschrijving.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-17-leveren-bewijs-voldoen-aan-vereisten-algoritme-aanbieder/#toelichting","title":"Toelichting","text":"<p>Het leveren van bewijs door aanbieder dat de ontwikkelde algoritmes voldoen aan de vereisten draagt bij aan het kunnen beoordelen of een aanbieder geschikt is om mee te contracteren. Bij het leveren van bewijs kan worden gedacht aan het overhandigen van bijvoorbeeld een certificaat of een EU-conformiteitsverklaring voor hoog risico AI-systemen.</p> <p>Daarbij is het relevant om te beoordelen in hoeverre er is voldaan aan geharmoniseerde standaarden. Deze standaarden zijn momenteel in ontwikkeling. In de (nabije) toekomst zal dit naar verwachting op een vergelijkbare manier kunnen worden benaderd als bij het moeten leveren van een NEN-ISO 27001 certificaat (voldoen aan informatiebeveiligingsvereisten) door een leverancier.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-17-leveren-bewijs-voldoen-aan-vereisten-algoritme-aanbieder/#risico","title":"Risico","text":"<p>Er wordt gecontracteerd met een aanbieder die niet voldoet aan de vereisten voor een verantwoorde inzet van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-17-leveren-bewijs-voldoen-aan-vereisten-algoritme-aanbieder/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-17-leveren-bewijs-voldoen-aan-vereisten-algoritme-aanbieder/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/","title":"Laat aanbieder(s) bewijs leveren dat de door hen ontwikkelde algoritmes geen inbreuk maken op de auteursrechten van derden met de trainingsdata en de output","text":"<p>owp-18Dataverkenning en datapreparatieVerificatie en validatieProjectleiderBeleid en adviesPublieke inkoopData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#maatregel","title":"Maatregel","text":"<p>Maak het al dan niet kunnen leveren van bewijs door een aanbieder dat auteursrechten niet worden geschonden met de trainingsdata en output van diens algoritme van bijvoorbeeld een aanbesteding.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#toelichting","title":"Toelichting","text":""},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#trainingsdata","title":"Trainingsdata","text":"<ul> <li> <p>Algoritmes worden veelal getraind aan de hand van een omvangrijke hoeveelheid data. Wanneer grote hoeveelheden data, bijvoorbeeld door deze te scrapen van internet, worden gebruikt is het zeer aannemelijk (of: nagenoeg zeker) dat zich onder de gescrapete inhoud (ook) veel auteursrechtelijk beschermde werken bevinden, zoals bijvoorbeeld e-books en afbeeldingen. De gebruikte auteursrechtelijke werken kunnen soms bijvoorbeeld uit illegale bron verkregen zijn, en ook los daarvan zijn rechthebbenden veelal niet op de hoogte van het feit dat hun auteursrechtelijke werken voor de ontwikkeling van een algoritme of AI gebruikt worden.</p> </li> <li> <p>Onder auteursrechtjuristen wordt aangenomen dat het gebruik van auteursrechtelijk beschermde werken ter training van algoritmes (waarschijnlijk) als kopi\u00ebren geldt: een handeling die de rechthebbende kan verbieden. Dat betekent dat aanbieders van algoritmes het gebruik van auteursrechtelijk beschermd materiaal in de inputfase steeds moeten kunnen legitimeren op grond van (a) toestemming van de rechthebbende(n) of (b) een in de wet neergelegde exceptie op het auteursrechtelijke verveelvoudigingsrecht.</p> </li> <li> <p>Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen op welke manier de trainingsdata is verkregen en of dit rechtmatig was. Laat de aanbieders(s) ook aantonen welke maatregelen er zijn getroffen om dit te voorkomen en ga hier eventueel over in gesprek. Maak een jurist onderdeel van de beoordeling hiervan.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#output","title":"Output","text":"<p>Laat de aanbieder(s) uitleggen en (aantoonbaar) onderbouwen op welke manier de trainingsdata is verkregen en of dit rechtmatig was. Laat de aanbieders(s) ook aantonen welke maatregelen er zijn getroffen om dit te voorkomen. Maak een jurist onderdeel van de beoordeling hiervan. Overweeg om een bronvermelding te laten opnemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#risicomanagement","title":"Risicomanagement","text":"<p>Het is van belang dat de (rest)risico's inzichtelijk zijn gemaakt als er sprake is van een (potenti\u00eble) schending van auteursrechten. Laat een aanbieder deze risico's inzichtelijk maken, zodat aanbieder en gebruiksverantwoordelijke maatregelen kunnen treffen en handelen als dit nodig is. Beoordeel of deze rest(risico's) acceptabel zijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#contractovereenkomst","title":"Contractovereenkomst","text":"<p>Neem in de conceptovereenkomst op dat de aanbieder garandeert dat auteursrechten niet worden geschonden met de trainingsdata of output van het algoritme en dat aanbieder dit gedurende de ontwikkeling en levensduur actief bewaakt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#risico","title":"Risico","text":"<p>Dat wordt gecontracteerd met een aanbieder waarbij niet kan worden uitgesloten dat auteursrechten worden geschonden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#bronnen","title":"Bronnen","text":"<ul> <li>Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat</li> <li>ARVODI (24.7) en ARBIT (art 8.5 &amp; 8.6)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-18-leveren-bewijs-door-aanbieder-niet-schenden-auteursrechten/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-19-beoordeel-aansprakelijkheidsvoorwaarden-van-aanbieder/","title":"Aansprakelijkheidsvoorwaarden van een aanbieder worden beoordeeld in de aanbesteding","text":"<p>owp-19OntwerpImplementatieJuristBeleid en adviesPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-19-beoordeel-aansprakelijkheidsvoorwaarden-van-aanbieder/#maatregel","title":"Maatregel","text":"<p>Maak de aansprakelijkheidsvoorwaarden die een aanbieder stelt ten aanzien van auteursrechten een vast onderdeel om te beoordelen in de aanbesteding.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-19-beoordeel-aansprakelijkheidsvoorwaarden-van-aanbieder/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Eindgebruikers van algoritmes kunnen er niet altijd op vertrouwen, of (eenvoudig) nagaan, of datgene wat zij door middel van een algoritme laten genereren, inbreuk maakt op rechten van anderen. Het is onwenselijk dat een eindgebruiker aansprakelijk wordt gesteld voor het maken van een inbreuk op rechten van derden, als deze gebruik maakt van algoritmes die worden aangeboden door aanbieders. Organisaties moeten daarom afspraken hierover maken met aanbieders.</p> </li> <li> <p>Hoe groot de kans is dat eindgebruikers vanwege het gebruik van algoritmes aansprakelijk worden gesteld, is nog onduidelijk. Er zijn wel voorbeelden waarbij eindgebruikers voor een eventuele inbreuk aansprakelijk kunnen worden gesteld.</p> </li> <li> <p>Op dit moment zijn (nog) geen gevallen of rechtszaken bekend waarin eindgebruikers (of hun werkgevers) aansprakelijk zijn gesteld voor een inbreuk op het intellectuele eigendomsrecht vanwege het gebruik van op basis van algoritme. Feit is echter wel dat een dergelijke aansprakelijkstelling in voorkomende gevallen dus mogelijk is, te meer nu de aanbieders van algoritmes in hun algemene voorwaarden het risico voor aansprakelijkheid volledig of grotendeels uitsluiten, of zelfs verlangen dat gebruikers hen vrijwaren voor de gevolgen van eventuele aansprakelijkstellingen.</p> </li> <li> <p>Het is daarom van belang om een beoordeling te maken in hoeverre de aansprakelijkheidsvoorwaarden van de aanbieder passend zijn. Maak een jurist onderdeel van de beoordeling.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-19-beoordeel-aansprakelijkheidsvoorwaarden-van-aanbieder/#risico","title":"Risico","text":"<p>Er wordt gecontracteerd met een aanbieder die ongewenste aansprakelijkheidsvoorwaarden hanteert.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-19-beoordeel-aansprakelijkheidsvoorwaarden-van-aanbieder/#bronnen","title":"Bronnen","text":"<p>Advies Landsadvocaat Pels Rijcken over het gebruik van generatieve AI-tools door medewerkers van de Staat</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-19-beoordeel-aansprakelijkheidsvoorwaarden-van-aanbieder/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-20-maak-vereisten-onderdeel-van-subgunningscriteria/","title":"Maak vereisten onderdeel van (sub)gunningscriteria bij een aanbesteding","text":"<p>owp-20OntwerpOntwikkelaarPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-20-maak-vereisten-onderdeel-van-subgunningscriteria/#maatregel","title":"Maatregel","text":"<p>Maak vereisten onderdeel van (sub)gunningscriteria bij een aanbesteding.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-20-maak-vereisten-onderdeel-van-subgunningscriteria/#toelichting","title":"Toelichting","text":"<ul> <li>Door een vereiste onderdeel te maken van (sub)gunningscriteria, ontstaat een mogelijkheid voor aanbieders om zich te onderscheiden van andere aanbieders.</li> <li>Dit kan zorgen voor een extra stimulatie op kwaliteitsaspecten van algoritmes.</li> <li>In de context van algoritmes is dit in het bijzonder relevant, bijvoorbeeld in relatie tot vereisten als non-discriminatie, het eerbiedigen van fundamentele rechten of het verbod op schenden auteursrechten.</li> <li>Door vereisten te vertalen naar (sub)gunningscriteria, kan een inhoudelijke beoordeling worden gemaakt in hoeverre een aanbieder voldoet aan deze vereisten.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-20-maak-vereisten-onderdeel-van-subgunningscriteria/#risico","title":"Risico","text":"<p>Een risico van vereisten geen onderdeel te maken van (sub)gunningscriteria is dat bepaalde vereisten worden overgeslagen of gemist, wat kan leiden tot het niet voldoen aan deze vereisten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-20-maak-vereisten-onderdeel-van-subgunningscriteria/#bronnen","title":"Bronnen","text":"<ul> <li>Keuze gunningscriterium en opstellen (sub)gunningscriteria</li> <li>Handreiking Beste prijs-kwaliteitsverhouding:de basis</li> <li>Beste prijs-kwaliteitsverhouding</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-20-maak-vereisten-onderdeel-van-subgunningscriteria/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/","title":"Cre\u00eber ruimte om met een aanbieder samen te gaan werken om specifieke vereisten te realiseren","text":"<p>owp-21OntwerpOntwikkelenProjectleiderPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/#maatregel","title":"Maatregel","text":"<p>Cre\u00eber ruimte om met een aanbieder samen te gaan werken om specifieke vereisten te realiseren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Om op een betekenisvolle manier invulling te geven aan bepaalde vereisten, kan het noodzakelijk zijn dat opdrachtgever en aanbieder (innovatief) moeten gaan samenwerken. Op basis van nieuwe wet- en regelgeving (bv. AI-Verordening) of geharmoniseerde standaarden kunnen aanbieders mogelijk nog niet voldoen aan nieuwe vereisten. Het kan ook onduidelijk zijn hoe moet worden voldaan aan vereisten nu de technologie zich snel ontwikkelt of dat de specifieke omstandigheden van het beoogde gebruik vragen om een samenspel tussen opdrachtgever en aanbieder.</p> </li> <li> <p>Bij een verantwoorde inzet van algoritmes kan het bij vereisten zoals non-discriminatie, transparantie, menselijke controle en grondrechten van belang zijn om samen te onderzoeken hoe hier invulling aan moet worden gegeven. Het is belangrijk om bij de behoeftestelling al te verkennen om welke onderwerpen dit mogelijk van toepassing is. Bij een marktverkenning of informatiesessie kan worden verkend hoe aanbieders ervoor staan. Op basis hiervan kan worden beoordeeld in hoeverre bijvoorbeeld in een aanbesteding contractuele ruimte moet worden gecre\u00eberd voor opdrachtgever en aanbieder om hieraan te werken.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/#risico","title":"Risico","text":"<p>Door niet te kunnen samenwerken aan vereisten kan de situatie ontstaan dat uiteindelijk niet op een betekenisvolle manier wordt voldaan aan deze vereisten voor een verantwoorde inzet van algoritmes. Gebrek aan samenwerking kan leiden tot onvermogen om de benodigde vereisten voldoende in de praktijk te garanderen. Ook is het belangrijk dat de verantwoordelijke goed genoeg begrijpt hoe het algoritme werkt en welke keuzes er gemaakt zijn tijdens het ontwerp, omdat alleen dan goed beoordeeld kan worden welke vereisten zijn voldaan en welke risico\u2019s nog niet of minder goed zijn afgedekt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/#bronnen","title":"Bronnen","text":"<ul> <li>Inspiratiebundel: Ruimte voor innovatie in het contract, PIANOo</li> <li>Aanbesteding Ethische Beeldinwinning en Objectherkenning Openbare Ruimte</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-21-ruimte-voor-samenwerking-met-aanbieder/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-22-vaststellen-aanleveren-informatie-technische-documentatie/","title":"Vul technische documentatie van aanbieder aan met relevante informatie vanuit de gebruiksverantwoordelijke","text":"<p>owp-22OntwerpProjectleiderBeleid en adviesOntwikkelaarPublieke inkoopTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-22-vaststellen-aanleveren-informatie-technische-documentatie/#maatregel","title":"Maatregel","text":"<p>Vul technische documentatie van de aanbieder aan met relevante informatie vanuit de gebruiksverantwoordelijke, zodat alle relevante onderdelen van het algoritme zijn beschreven.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-22-vaststellen-aanleveren-informatie-technische-documentatie/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Het is van belang dat duidelijke afspraken worden gemaakt over het opstellen, aanvullen en actueel houden van technische documentatie van algoritmes. Bij het inkopen van algoritmes moet hier rekening mee worden gehouden. De aanbieder zal een belangrijk deel van de technische documentatie moeten aanleveren, maar bij gebruik door de gebruiksverantwoordelijke zal deze informatie moeten worden aangevuld.</p> </li> <li> <p>Bespreek met het projectteam welke onderdelen van de technische documentatie, als genoemd in de Bijlage 4 AI-verordening, van het AI-systeem door welke partij (aanbieder of gebruiksverantwoordelijke) moeten worden ingevuld of aangevuld.</p> </li> <li> <p>Hierbij is het van belang dat de documentatie aansluit bij de verschillende gebruikers van het systeem, waarbij rekening wordt gehouden met verschillende toepassingen of versies. Bespreek met het projectteam welke onderdelen van de technische documentatie voor AI-systemen, als genoemd in de Bijlage 4 AI-verordening, door welke partij (aanbieder of gebruiksverantwoordelijke) moeten worden ingevuld of aangevuld.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-22-vaststellen-aanleveren-informatie-technische-documentatie/#risico","title":"Risico","text":"<p>Door de technische documentatie niet volledig op te stellen, is niet geheel transparant hoe het algoritme functioneert en kan daar geen verantwoording voor worden afgelegd.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-22-vaststellen-aanleveren-informatie-technische-documentatie/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-22-vaststellen-aanleveren-informatie-technische-documentatie/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/","title":"Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst","text":"<p>owp-23OntwerpProjectleiderBeleid en adviesPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/#maatregel","title":"Maatregel","text":"<p>Neem het kunnen uitvoeren van een audit over de vereiste op in contractvoorwaarden en de contractovereenkomst.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat de opdrachtgever mogelijkheden heeft om te controleren in hoeverre door de aanbieder of opdrachtnemer wordt voldaan aan naleving van de contractvoorwaarden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/#risico","title":"Risico","text":"<p>Er kunnen geen controles of inspecties worden uitgevoerd om te beoordelen of de algoritmes van een aanbieder nog voldoen aan de vereisten voor een verantwoorde inzet van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/#bronnen","title":"Bronnen","text":"<ul> <li>Contractvoorwaarden gemeente Amsterdam</li> <li>Europese modelcontractbepalingen voor laag- en hoog-risico-AI</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-23-uitvoeren-audit-voor-naleving-vereisten/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam - Modelbepalingen</p> <p>Gemeente Amsterdam heeft contractvoorwaarden geformuleerd waarin verschillende aspecten van inkoop uitgelicht worden. Een onderdeel hiervan is het uitvoeren van audits of andersoortige controles. Hierin is opgenomen hoe deze uitgevoerd worden en wat de voorwaarden zijn.</p> <p>Meer informatie over generieke inkoopvoorwaarden die je kunt gebruiken.</p> <p>Bron: Contractvoorwaarden voor algoritmen - Innovatie</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-24-invloed-besluitvorming-algoritmes-aanbieders/","title":"Bepaal in een aanbesteding of algoritmes van een aanbieder bepalende invloed hebben in een besluit richting personen","text":"<p>owp-24OntwerpProjectleiderBeleid en adviesOntwikkelaarPublieke inkoopTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-24-invloed-besluitvorming-algoritmes-aanbieders/#maatregel","title":"Maatregel","text":"<p>Ga na of algoritmes van een aanbieder een bepalende invloed hebben in een besluit richting personen en laat de aanbieder onderbouwen in hoeverre dit wel of niet het geval is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-24-invloed-besluitvorming-algoritmes-aanbieders/#toelichting","title":"Toelichting","text":"<ul> <li> <p>Als overheidsorganisaties algoritmes willen gebruiken van aanbieders, dan zal bijvoorbeeld tijdens een aanbestedingsproces moeten worden beoordeeld in hoeverre deze algoritmes invloed hebben op besluitvormingprocessen van deze organisaties. Algoritmes kunnen namelijk gebruikers ondersteunen bij de totstandkoming van besluiten, maar ook de besluitvorming van gebruikers overnemen. De mate van menselijke tussenkomst speelt daarbij een belangrijk rol.</p> </li> <li> <p>Een opdrachtgever moet zelf bepalen welke algoritmes, gezien de specifieke context, wenselijk en toegestaan zijn. Vervolgens moet worden beoordeeld of de algoritmes die worden aangeboden door de aanbieder daarbij aansluiten.</p> </li> <li> <p>Tijdens het aanbestedingsproces moeten daarom inzichten worden verkregen hoe de algoritmes van aanbieders functioneren om tot een beoordeling te kunnen komen. Laat de aanbieder dit toelichten.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-24-invloed-besluitvorming-algoritmes-aanbieders/#risico","title":"Risico","text":"<p>Algoritmes van aanbieders nemen besluitvormende taken over, zonder dat daar zicht op is of dat dit is beoordeeld.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-24-invloed-besluitvorming-algoritmes-aanbieders/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, PRI.10</li> <li>Toetingskader Algemene Rekenkamer, 2.10</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-24-invloed-besluitvorming-algoritmes-aanbieders/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-25-kennisoverdracht-en-ondersteuning-aanbieder/","title":"Laat de aanbieder aangeven welke mate van opleiding en ondersteuning bij de implementatie nodig is om de beoogde algoritmes verantwoord te gebruiken","text":"<p>owp-25OntwerpProjectleiderBeleid en adviesOntwikkelaarPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-25-kennisoverdracht-en-ondersteuning-aanbieder/#maatregel","title":"Maatregel","text":"<p>Laat de aanbieder aangeven welke mate van kennisoverdracht (opleiding en training) en ondersteuning bij de organisatorische implementatie nodig is om de beoogde algoritmes verantwoord te kunnen gebruiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-25-kennisoverdracht-en-ondersteuning-aanbieder/#toelichting","title":"Toelichting","text":"<p>Beoordeel of de kennisoverdracht en ondersteuning van aanbieder voldoende is om voor een langere periode zelfstandig op een verantwoorde wijze gebruikt te kunnen maken van de algoritmes.</p> <p>Laat de aanbieder aangeven op welk niveau de noodzakelijkerwijs te leveren trainingen passend zijn voor het beoogde gebruik, waarbij de opdrachtgever vooraf inzicht geeft in het bestaande niveau zodat een aanbieder concreet kan zijn over eventuele verschillen tussen beiden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-25-kennisoverdracht-en-ondersteuning-aanbieder/#risico","title":"Risico","text":"<p>Zonder kennisoverdracht aan de organisaties en gebruikers ontstaat het risico dat algoritmes onjuist worden toegepast of dat de output onjuist wordt ge\u00efnterpreteerd en zo fouten ontstaan bij het uitvoeren van overheidstaken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-25-kennisoverdracht-en-ondersteuning-aanbieder/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-25-kennisoverdracht-en-ondersteuning-aanbieder/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-26-risico-analyse-informatiebeveiliging-leverancier/","title":"Voer een risico-analyse met de aanbieder uit op het gebied van informatiebeveiliging bij een uitbestedingstraject","text":"<p>owp-26OntwerpProjectleiderBeleid en adviesTechnische robuustheid en veiligheidPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-26-risico-analyse-informatiebeveiliging-leverancier/#maatregel","title":"Maatregel","text":"<p>Voer een risico-analyse met de aanbieder uit op het gebied van informatiebeveiliging bij een uitbestedingstraject.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-26-risico-analyse-informatiebeveiliging-leverancier/#toelichting","title":"Toelichting","text":"<ul> <li>Stel vast of een aanbieder voldoet aan de Baseline Informatiebeveiliging Overheid (BIO).</li> <li>Bespreek de informatiebeveiligingseisen met de aanbieder die verband houden met de beschikbaarheid, integriteit en vertrouwelijkheid van de informatie en de informatiesystemen.</li> <li>Bepaal of er, gezien de restrisico's, aanvullende beveiligingsmaatregelen (door de aanbieder of opdrachtgever) moeten worden getroffen om deze te beschermen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-26-risico-analyse-informatiebeveiliging-leverancier/#risico","title":"Risico","text":"<p>Er is onvoldoende zicht op risico's op het gebied van informatiebeveiliging als gebruik wordt gemaakt van algoritmes van aanbieders.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-26-risico-analyse-informatiebeveiliging-leverancier/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, BIO 15.1.1.1</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.29</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-26-risico-analyse-informatiebeveiliging-leverancier/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/","title":"Maak vereisten onderdeel van het programma van eisen bij een aanbesteding","text":"<p>owp-27OntwerpProjectleiderBeleid en adviesOntwikkelaarPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/#maatregel","title":"Maatregel","text":"<p>Maak vereisten onderdeel van het programma van eisen bij een aanbesteding.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/#toelichting","title":"Toelichting","text":"<ul> <li>Door vereisten onderdeel te maken van het programma van eisen bij een aanbesteding is het voor aanbieders duidelijk aan welke specifieke eisen een oplossing moet voldoen.</li> <li>Op basis hiervan kan een aanbieder een zo goed mogelijke aanbieding doen.</li> <li>Afhankelijk van de behoeftestelling kan het relevant zijn om bepaalde vereisten te verfijnen in het Programma van Eisen (PvE) en aan te geven wanneer hieraan voldaan is, bijvoorbeeld met betrekking tot de transparantievereiste. Bepaal met het inkoopteam bij welke vereisten dit noodzakelijk is.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/#risico","title":"Risico","text":"<p>Er is niet gespecificeerd en daarmee achteraf niet afdwingbaar dat algoritmes aan bepaalde vereisten moeten voldoen die van belang zijn voor de betreffende overheidsorganisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/#bronnen","title":"Bronnen","text":"<ul> <li>Hoe specificeer ik mijn vraag? (PIANOo - Inkopen in het kort</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-27-maak-vereisten-onderdeel-van-programma-van-eisen/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement/","title":"Maak vereisten voor algoritmes onderdeel van de Service Level Agreement","text":"<p>owp-28OntwerpProjectleiderBeleid en adviesOntwikkelaarPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement/#maatregel","title":"Maatregel","text":"<p>Maak de vereiste onderdeel van Service Level Agreement (SLA).</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement/#toelichting","title":"Toelichting","text":"<ul> <li>Met een SLA kunnen specifieke afspraken worden gemaakt over de kwaliteit van de dienstverlening van de aanbieder.</li> <li>Hierbij kan worden gedacht aan onderwerpen als incidentmanagement, servicemanagement, verantwoordelijkheden matrix, hersteltijd, prestatiecriteria, reproduceerbaarheid, versiebeheer van de gebruikte algoritmes en informatiebeveiliging.</li> <li>Onderzoek met het inkoopteam welke vereiste voor een verantwoorde inzet van algoritmes onderdeel moeten worden gemaakt van de Service Level Agreement.</li> <li>Laat de aanbieder aangeven welke vormen van onderhoud aan de betreffende algoritmes nodig zijn en de snelheid waarmee signalen vanuit gebruik, ongeacht de bron, kunnen worden verwerkt in het systeem en welke expertise hiervoor beschikbaar is.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement/#risico","title":"Risico","text":"<p>Zonder concrete afspraken te maken in de SLA ontstaat het risico dat aloritmes (tijdelijk) of te langdurig niet kunnen worden gebruikt, onjuist fuctioneren of dat er geen verantwoording over de output kan worden afgelegd.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.11</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.05</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-28-maak-vereisten-onderdeel-van-service-level-agreement/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-29-contractuele-afspraken-data-en-artefacten/","title":"Maak (contractuele) afspraken over data en artefacten met een aanbieder","text":"<p>owp-29OntwerpImplementatieJuristPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-29-contractuele-afspraken-data-en-artefacten/#maatregel","title":"Maatregel","text":"<p>Maak (contractuele) afspraken met de aanbieder wie eigenaar is van de data en artefacten die ontstaan bij het gebruik van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-29-contractuele-afspraken-data-en-artefacten/#toelichting","title":"Toelichting","text":"<p>Hier kan worden gedacht aan (initi\u00eble) trainingsdatasets, outputdata (richting gebruikers) en nieuwe trainingsdata (vanuit gebruikers).</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-29-contractuele-afspraken-data-en-artefacten/#risico","title":"Risico","text":"<p>Een risico dat kan ontstaan is dat er onduidelijkheid is over wie de verantwoordelijk heeft voor bepaalde aspecten van het gebruik van een algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-29-contractuele-afspraken-data-en-artefacten/#bronnen","title":"Bronnen","text":"<p>Geen bron beschikbaar voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-29-contractuele-afspraken-data-en-artefacten/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam: Contractvoorwaarden</p> <p>De gemeente Amsterdam heeft contractvoorwaarden voor algoritmen opgesteld waarin ook duidelijke afspraken over data en artefacten staan. Dit staat in artikel 3 van \u201cModelbepalingen voor gemeenten voor verantwoord gebruik van Algoritmische toepassingen\u201d. Zo komt de trainingsdata (genoemd \u201cverstrekte data\u201d) en output en nieuwe trainingsdata (genoemd \u201cGecre\u00eberde en verzamelde data\u201d) de gemeente toe. Een mogelijke toevoeging die gedaan kan worden zit op het aspect van auteursrechten. Deze worden op dit moment niet expliciet genoemd en kunnen door toevoeging voor verheldering zorgen.</p> <p>Meer informatie over generieke inkoopvoorwaarden die je kunt gebruiken.</p> <p>Bron: Contractvoorwaarden voor Algoritmen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-30-informeer-betrokkenen/","title":"Stel vast welke betrokkenen ge\u00efnformeerd moeten worden en welke informatie zij nodig hebben","text":"<p>owp-30OntwerpOntwikkelenProjectleiderBeleid en adviesTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-30-informeer-betrokkenen/#maatregel","title":"Maatregel","text":"<p>Stel vast welke betrokkenen ge\u00efnformeerd moeten worden over de ontwikkeling en het gebruik van algoritmes en welke informatie zij hierover nodig hebben.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-30-informeer-betrokkenen/#toelichting","title":"Toelichting","text":"<p>Welke informatie over algoritmes relevant is, verschilt per partij. Het is van belang om deze partijen in beeld te brengen en vast te stellen welke informatie voor hen relevant is. Raadpleeg hierbij vastgestelde beleidskaders, waarin is beschreven welke informatie in welke gevallen moet worden gecommuniceerd.</p> <p>Stel bijvoorbeeld de volgende vragen:</p> Vragen Acties die je kan ondernemen Wie heeft informatie nodig over het ontwikkelen en gebruiken van algoritmes? Stel vast welke betrokken(en) binnen of buiten de organisatie iets over het algoritme wil of zou moeten weten. Wat voor informatie voor algoritmes heeft deze betrokken partij nodig? Toets dit ook bij vastgesteld beleid.    Ga na wat de doelgroep moet weten over de werking of inzet van het algoritme. Bepaal om welk technisch niveau dit gaat. Op wat voor manier informeer je de betrokken partij? Pas de juiste methodes toe om de doelgroep te informeren. Wanneer wordt deze informatie gebruikt? Ga na in welke fase van de levenscyclus de gewenste informatie over de werking of inzet van het algoritme wordt gebruikt. Hoe verschilt de informatiebehoefte in elke fase van de levenscyclus? Wie is er verantwoordelijk voor de informatieverstrekking? Bepaal wie er informatie over het algoritme moet ophalen, en wie er voor die informatie kan zorgen. <p>Maak bij het vaststellen van de informatiebehoefte onderscheid tussen transparantie, uitlegbaarheid en interpreteerbaarheid. Houd daarbij ook rekening met zaken die moeten worden gecommuniceerd. Denk hierbij aan het kunnen uitleggen hoe een automatisch genomen besluit tot stand is gekomen, of de mogelijkheid om niet onderworpen te worden aan geautomatiseerde besluitvorming.</p> <p>Stel een communicatieplan op over de ontwikkeling en gebruik van het algoritme. Bepaal vervolgens aan de hand van de levenscyclus wanneer welke informatie beschikbaar moet worden gesteld. Stel vast wie verantwoordelijk is voor het opstellen of het leveren van een bijdrage aan deze informatie. In het communicatieplan kunnen verder zaken worden opgenomen als:</p> <ul> <li>Het doel van het algoritme.</li> <li>Mogelijkheden van het algoritme.</li> <li>Beperkingen van het algoritme.</li> <li>Context waarin het algoritme wordt toegepast.</li> <li>Wie heeft informatie nodig?</li> <li>Wat voor informatie heeft deze betrokken partij nodig?</li> <li>Op wat voor manier informeer je de betrokken partij?</li> <li>Wanneer wordt deze informatie gebruikt?</li> <li>Wie is er verantwoordelijk voor de informatieverstrekking?</li> <li>Hoe en naar wie communiceer je in het geval van een incident?</li> <li>Wat is de planning voor de communicatieactiviteiten?</li> </ul> <p>Overleg regelmatig met betrokkenen en belanghebbenden in hoeverre de informatieverstrekking aansluit bij de (nieuwe) behoeften.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-30-informeer-betrokkenen/#risico","title":"Risico","text":"<p>Het risico is dat partijen niet of onvolledig worden ge\u00efnformeerd over de ontwikkeling en gebruik van algoritmes en hierdoor hun rechten niet kunnen effectueren of belangen kenbaar kunnen maken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-30-informeer-betrokkenen/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algemene Rekenkamer, 2.09, 3.13, 3.15</li> <li>Bouwstenen van een communicatieplan</li> <li>Wmo Voorspelmodel met handreiking</li> <li>Maatwerkscan UWV</li> <li>Slimme keuzehulp aangifte internetoplichting: Ik heb iets gekocht, maar niets ontvangen</li> <li>Chatbot gemeente Hillegom</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-30-informeer-betrokkenen/#voorbeelden","title":"Voorbeelden","text":"<p>Communicatiekompas \u2013 Bouwstenen van een communicatieplan</p> <p>Vanuit de Rijksoverheid is het communicatiekompas gemaakt voor het ondersteunen van communicatieprofessionals. Hier staat onder andere het hulpmiddel \u201cBouwstenen van een communicatieplan\u201d waar de losse onderwerpen die in een plan horen worden toegelicht. Met een communicatieplan kunnen betrokkenen op een goede en tijdige manier worden ge\u00efnformeerd.</p> <p>Bron: Bouwstenen van een communicatieplan</p> <p>Vereniging van Nederlandse Gemeenten \u2013  Wmo voorspelmodel</p> <p>De Vereniging van Nederlandse Gemeenten (VNG) bied een zogenaamd voorspelmodel van de Wet maatschappelijke ondersteuning (Wmo). Hiermee kunnen gemeenten een beter inzicht krijgen in de toekomst om zo op het gebied van beleid, financi\u00ebn en inkooptrajecten betere verwachtingen te kunnen doen voor Wmo-voorzieningen. Dit model is publiekelijk toegankelijk en heeft een uitleg waar ook een uitgebreide toelichting staat. In de uitleg wordt toelichting gegeven over onder andere het doel, de mogelijkheden en de beperkingen. Daarnaast wordt in de uitgebreide toelichting verder uitgelegd hoe de data en het model stap voor stap gebruikt kunnen worden. Op deze manier worden minder ervaren gebruikers meegenomen in het proces.</p> <p>Bron: Wmo voorspelmodel (toelichting via \u201cColofon &amp; uitleg\u201d)</p> <p>Politie \u2013  Keuzehulp Internetoplichting</p> <p>De politie maakt gebruik van een keuzehulp voor mogelijke internet oplichting. De keuzehulp maakt gebruik van een video om aan gebruikers uit te legen wat zij in moeten voeren om goed geholpen te worden en waarom deze keuzehulp bestaat.</p> <p>Op deze manier wordt duidelijk toegelicht hoe het algoritme gebruikt moet worden en in welke context het werkt. Om het toegankelijk en duidelijk te maken is gekozen voor een video format.</p> <p>Bron: Keuzehulp Internetoplichting</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-31-pas-vastgestelde-beleidskaders-zijn-nageleefd/","title":"Pas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmes","text":"<p>owp-31OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-31-pas-vastgestelde-beleidskaders-zijn-nageleefd/#maatregel","title":"Maatregel","text":"<p>Pas vastgestelde interne beleidskaders toe en maak aantoonbaar dat deze zijn nageleefd bij het ontwikkelen, inkopen en gebruiken van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-31-pas-vastgestelde-beleidskaders-zijn-nageleefd/#toelichting","title":"Toelichting","text":"<ul> <li>Vastgestelde (interne) beleidskaders, zoals specifiek beleid voor de inzet van algoritmes, moeten worden toegepast bij het ontwikkelen, inkopen of gebruiken van algoritmes.</li> <li>Het is van belang dat tijdig, bijvoorbeeld in de probleemanalyse fase, inzichtelijk wordt gemaakt welke interne beleidskaders moeten worden toegepast.</li> <li>Hierbij kan worden gedacht aan definities die moeten worden gehanteerd, het naleven van inkoopbeleid, strategisch beleid volgen met betrekking tot het mogen inzetten van algoritmes binnen de organisaties of het doorlopen van processen en protocollen die moeten worden toegepast.</li> <li>Vraag de betrokken experts welke beleidskaders van toepassing zijn vanuit diens specifieke expertise.</li> <li>Ten behoeve van controles en audits is het van belang dat aantoonbaar wordt gemaakt dat de vastgestelde beleidskaders zijn nageleefd.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-31-pas-vastgestelde-beleidskaders-zijn-nageleefd/#risico","title":"Risico","text":"<p>De in te zetten algoritmes voldoen niet aan vastgestelde beleidskaders.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-31-pas-vastgestelde-beleidskaders-zijn-nageleefd/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.8</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-31-pas-vastgestelde-beleidskaders-zijn-nageleefd/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/","title":"Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze","text":"<p>owp-32OntwerpProjectleiderBeleid en adviesOntwikkelaarTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#maatregel","title":"Maatregel","text":"<p>Pas uitlegbaarheidstechnieken toe en evalueer en valideer deze.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#toelichting","title":"Toelichting","text":"<p>Uitlegbaarheidstechnieken helpen om de werking van een algoritme transparant te maken. De keuze voor het type algoritme bepaalt hoe transparant je kunt zijn. Van rekenregels kun je namelijk precies uitleggen hoe deze tot een beslissing komen. Aan de andere kant kunnen complexe AI-systemen een black box zijn. Het is dan onduidelijk hoe deze systemen beslissingen maken.</p> <p>Afhankelijk van het type algoritme zijn er uitlegbaarheidstechnieken beschikbaar om de werking en keuzes van een algoritme bloot te leggen. Er moet eerst een keuze worden gemaakt welk type algoritme geschikt is gezien de informatiebehoefte. Het is belangrijk om samen met de betrokken partijen vast te leggen welke uitlegbaarheidstechnieken moeten worden toegepast. Bij bronnen kan informatie worden geraadpleegd die helpen bij het vinden van de juiste methodiek.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#gebruik-uitlegbaarheid-bij-besluiten","title":"Gebruik uitlegbaarheid bij besluiten","text":"<p>Onderzoek hoe uitlegbaarheidstechnieken kunnen bijdragen aan het motiveren van besluiten. Dit kan bijvoorbeeld door:</p> <ul> <li>De output van het algoritme te koppelen aan het zaakdossier, met een toelichting op de interpretatie van die output.</li> <li>De output of een samenvatting hiervan op te nemen in de beschikking.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#generatieve-ai","title":"Generatieve AI","text":"<p>Bij gebruik van generatieve AI is het haast onmogelijk om direct uitlegbaar te maken hoe een uitkomst tot stand is gekomen. Om toch (deels) uitleg te kunnen geven over de werking van een generatief AI-model kun je uitleg verschaffen over de capaciteiten, beperkingen en trainingsdata van het AI-model. Daarnaast is het verstanding om te onderzoeken wat de risico's zijn als de uitkomsten van een generatief AI-systeem niet uitgelegd kunnen worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#beperkingen-en-veiligheid","title":"Beperkingen en veiligheid","text":"<p>Vanuit veiligheidsoverwegingen kan bij specifieke algoritmes besloten worden om bepaalde informatie over de werking van een algoritme niet aan iedereen vrij te geven. Denk hierbij aan de beperkingen die de Wet Open Overheid oplegt. Houd ook rekening met mogelijke risico\u2019s op aanvallen die kunnen ontstaan door het gebruik van uitlegbaarheidstechnieken, zoals omschreven in: A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#evaluatie-en-validatie","title":"Evaluatie en validatie","text":"<p>Evalueer de uitlegbaarheid van het systeem op functionele, operationele, bruikbaarheids- en veiligheidsvereisten in samenwerking met betrokkenen zoals gebruikers. Valideer of de uitkomst van het algoritme begrijpelijk genoeg is voor een gebruiker om hier op een verantwoorde wijze mee te werken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#risico","title":"Risico","text":"<p>Als er geen rekening wordt gehouden met de uitlegbaarheid van een algoritme binnen een bepaalde context ontstaat het risico dat de output van het algoritme niet wordt begrepen of verkeerd wordt ge\u00efnterpreteerd, wat kan leiden tot onjuist gebruik.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, DM.11</li> <li>Toetsingskader Algoritmes, Algemene Rekenkamder, 2.04</li> <li>Toolkit voor implementatie</li> <li>An introduction to explainable AI with Shapley values</li> <li>Benchmarking eXplainable AI - A Survey on Available Toolkits and Open Challenges</li> <li>UXAI: Design Strategy</li> <li>Overzicht (evaluatie van) metrieken XAI</li> <li>Part 2: Explaining AI in practice | ICO</li> <li>A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</li> <li>Towards Transparency by Design for Artificial Intelligence, Science and Engineering Ethics</li> <li>From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-32-toepassen-uitlegbaarheidstechnieken/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam - Slimme check levensonderhoud</p> <p>Gemeente Amsterdam heeft in een pilot gebruik gemaakt van een algoritme dat medewerkers helpt om te bepalen of een aanvraag levensonderhoud onderzoekswaardig is. De gemeente heeft ook een document waarin wordt toegelicht hoe verwerkte data gebruikt wordt. Dit is gedaan aan de hand van bijvoorbeeld een belangrijkheids-score per kenmerk. Op deze manier wordt inzichtelijk en uitlegbaar wat de invloed is van individuele kenmerken.</p> <p>Bron: Overzicht Verwerkte Data en Features</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/","title":"Identificeer en implementeer technische interventies die robuustheid vergroten","text":"<p>owp-33OntwerpOntwikkelenOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/#maatregel","title":"Maatregel","text":"<p>Bepaal in het ontwerp welke technische interventies bijdragen aan de robuustheid van het algoritme. Deze keuzes moeten in lijn zijn met het beoogde doel en de context.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/#toelichting","title":"Toelichting","text":"<p>Maak in de ontwerpfase de volgende afwegingen:</p> <ul> <li> <p>Identificeer en implementeer technische interventies die de robuustheid vergroten</p> <p>In het ontwerp en in de training kunnen extra interventies worden genomen die de robuustheid vergroten. Dit kan op verschillende niveaus. Denk bijvoorbeeld aan:</p> <ul> <li>Data Augmentation: op data niveau kan de dataset uitgebreid worden met variaties op de oorspronkelijke data, bijvoorbeeld door het toevoegen van extra ruis aan de dataset;</li> <li>Regularisatie: tijdens training kunnen interventies worden gebruikt die overfitting voorkomen zoals dropout of weight decay.</li> <li>Cross-validation: tijdens training kunnen meerdere combinaties van train- en testsets gebruikt worden om generalisatie te waarborgen.</li> <li>Model ensembles: er kunnen meerdere modellen gecombineerd worden om samen een beslissing te maken, dit minimaliseert de impact van een fout van \u00e9\u00e9n model.</li> <li>Adversarial training: het trainen met speciale voorbeelden die bedoeld zijn om het model te misleiden.</li> <li>Ook zijn er andere methoden die generalisatie kunnen verbeteren, zoals invariant risk minimization, robust optimization, transfer learning en causal learning.</li> </ul> </li> <li> <p>Bepaal de factoren waarop je interventies voor robuustheid beoordeelt     Afhankelijk van de context, verschillen de factoren waarop je deze afwegingen maakt.     Denk aan complexiteit van de data, invoerdata en resultaten, risico en impact als het fout gaat, belang van betrouwbaarheid versus nauwkeurigheid, of belang van robuustheid versus transparantie.</p> </li> <li> <p>Leg de beargumenteerde keuze vast     Leg vast welke keuzes er gemaakt zijn en waarom deze keuzes zijn gemaakt.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/#risico","title":"Risico","text":"<p>Wanneer robuustheid niet in het ontwerp wordt meegenomen, kan er voor een model worden gekozen waar het niet mogelijk is robuustheid voldoende te waarborgen. Het model wordt dan ofwel ingezet met de risico\u2019s van dien of de innovatie moet later stop gezet worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereisteaia-06Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/#bronnen","title":"Bronnen","text":"<ul> <li>Kenniscentrum Data &amp; Maatschappij, Ethisch principe 2: technische robuustheid en veiligheid</li> <li>Europese Commissie, Ethische richtsnoeren voor betrouwbare KI</li> <li>A. Tocchetti et al., A.I. Robustness: a Human-Centered Perspective on Technological Challenges and Opportunities</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-33-technische-interventies-robuustheid/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-34-voorkom-kwetsbaarheden-supplychain/","title":"Voorkom kwetsbaarheden die ge\u00efntroduceerd worden in de supply-chain van het algoritme","text":"<p>owp-34OntwerpOntwikkelaarBeleid en adviesJuristPublieke inkoopDataTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-34-voorkom-kwetsbaarheden-supplychain/#maatregel","title":"Maatregel","text":"<p>Het in gebruik nemen van algoritmes die door anderen zijn ontwikkeld brengt risico\u2019s met zich mee waar je je tegen moet beschermen. Deze risico\u2019s moeten adequaat afgedekt worden door afhankelijkheden te analyseren en afspraken te maken met leveranciers en controles uit te voeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-34-voorkom-kwetsbaarheden-supplychain/#toelichting","title":"Toelichting","text":"<p>Veel algoritmes zullen niet zelf ontwikkeld worden, maar bijvoorbeeld compleet ingekocht worden of op een externe server getraind worden. Redenen om dit te doen zijn het reeds beschikbaar zijn van een voorgetraind algoritme of bijvoorbeeld een gebrek aan technische kennis, een gebrek aan voldoende trainingsdata en een gebrek aan rekenkracht binnen de eigen organisatie.</p> <p>Echter is het een stuk lastiger om deze modellen te beschermen tegen aanvallen zoals [backdoors] omdat er geen (directe) controle is op het correct uitvoeren van een trainingsproces.</p> <p>Een eerste stap is om in kaart te brengen welke afhankelijkheden er zijn en te onderzoeken of deze beheersbaar zijn. Er moeten duidelijke afspraken gemaakt worden met leveranciers, bijvoorbeeld in de vorm van een Service Level Agreement (SLA). Op deze manier kan bijvoorbeeld afgesproken worden wie er verantwoordelijk is voor bijvoorbeeld het correct trainen en functioneren van het algoritme en hoe incidenten afgehandeld moeten worden.</p> <p>Tot slot kunnen extra maatregelen genomen worden om te verifi\u00ebren dat het model inderdaad functioneert zoals afgesproken. Zo kunnen er formele methodes gebruikt worden om het algoritme te verifi\u00ebren en kan het gedrag van het algoritme getest worden tegen bekende, foutieve invoerwaarden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-34-voorkom-kwetsbaarheden-supplychain/#risico","title":"Risico","text":"<p>Als onvoldoende duidelijk is hoe een algoritme werkt en tot stand is gekomen kan deze onverwachts gedrag vertonen tijdens het gebruik.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-34-voorkom-kwetsbaarheden-supplychain/#bronnen","title":"Bronnen","text":"<ul> <li>TNO, Ministerie van Justitie en Veiligheid, Verkenning van het raakvlak van cybersecurity en AI</li> <li>AIVD, AI-systemen: ontwikkel ze veilig</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-34-voorkom-kwetsbaarheden-supplychain/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-35-genereren-bronvermelding/","title":"Maak gebruik van een algoritme dat bronvermelding kan genereren bij de output","text":"<p>owp-35OntwerpVerificatie en validatieProjectleiderBeleid en adviesTransparantiePublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-35-genereren-bronvermelding/#maatregel","title":"Maatregel","text":"<p>Maak gebruik van een algoritme dat bronvermelding kan genereren bij de output.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-35-genereren-bronvermelding/#toelichting","title":"Toelichting","text":"<p>Bij het gebruik van generatieve AI (bijvoorbeeld LLM\u2019s) is bronvermelding van belang. Hiermee kan tot op zekere hoogte een beoordeling worden gegeven in hoeverre bij het trainen van het AI-model rechtmatig gebruik is gemaakt van bronnen. Bronvermelding is daarnaast essentieel om de output van het AI-model inhoudelijk te kunnen controleren, wat ook informatie geeft in hoeverre het AI-model bijvoorbeeld al dan niet hallucineert of manipuleert.</p> <p>Voor het ontwikkelen van een AI-model is bronvermelding noodzakelijk, omdat het voor ontwikkelaars de enige manier is om te kunnen controleren of het model goed werkt. Dit geldt ook voor ontwikkelaars die pre-trained modellen gebruiken.</p> <p>Neem het kunnen generenen van een bronvermelding mee als een 'requirement' voor het te ontwikkelen AI-model in de ontwerpfase of maakt het onderdeel van de behoeftestelling en specificeer deze behoefte in het inkoopproces.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-35-genereren-bronvermelding/#risico","title":"Risico","text":"<p>Het niet vermelden van een bron bij het gebruik van generatieve AI kan leiden tot sancties aangezien er niet wordt voldaan aan de AI-verordening. Hiernaast kan het voor onduidelijkheden zorgen bij het gebruik van een algoritme wat verantwoord gebruik in de weg kan zitten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-35-genereren-bronvermelding/#bronnen","title":"Bronnen","text":"<p>Geen beschikbare bron voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-35-genereren-bronvermelding/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-36-maak-of-koopbeslissing/","title":"Bepaal of een algoritme moet worden ontwikkeld of ingekocht","text":"<p>owp-36OntwerpProjectleiderPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-36-maak-of-koopbeslissing/#maatregel","title":"Maatregel","text":"<p>Bepaal of een algoritme moet worden ontwikkeld of ingekocht</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-36-maak-of-koopbeslissing/#toelichting","title":"Toelichting","text":"<p>Als in de probleemanalyse fase duidelijk is geworden welke doelstellingen en behoeften gerealiseerd moeten worden, dan moet in de ontwerpfase worden bepaald of het beoogde algoritme zelf moet worden ontwikkeld of moet worden ingekocht. Er zijn grofweg vier oplossingsrichtingen:</p> <ul> <li>Een kant-en-klare oplossing inkopen (\"off the shelf\") bij een aanbieder.</li> <li>Een kant-en-klare oplossing inkopen bij een aanbieder waar nog enig maatwerk bij nodig is.</li> <li>Een nieuwe oplossing laten ontwikkelen door een aanbieder.</li> <li>Een nieuwe oplossing binnen de eigen organisatie ontwikkelen.</li> </ul> <p>Het is van belang dat een analyse wordt gedaan welke oplossingsrichting het meest wenselijk is. PIANOo heeft een bruikbaar (algemeen) afwegingskader en stappenplan opgesteld om deze analyse grondig uit te voeren. Denk hierbij aan maken van:</p> <ul> <li>Een kwantitatieve kostenanalyse</li> <li>Kwalitatieve productiecriteria</li> <li>Kwalitatieve uitbestedingscriteria</li> </ul> <p>Met een grondige analyse kan worden voorkomen dat bijvoorbeeld een algoritme dat al bestaat zelfstandig wordt ontwikkeld of dat de ontwikkeling van een algoritme onbeheersbaar wordt. Er is bij zo'n analyse een betere inschatting gemaakt van de voor en nadelen en bijbehorende kosten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-36-maak-of-koopbeslissing/#risico","title":"Risico","text":"<p>Al ontwikkelde algoritmes die aansluiten bij de behoeftestelling worden onnodig opnieuw ontwikkeld of het zelfstandig ontwikkelen is verkeerd ingeschat waardoor de ontwikkeling te duur of onbeheersbaar wordt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-36-maak-of-koopbeslissing/#bronnen","title":"Bronnen","text":"<ul> <li>Maak of koopbeslissing (PIANOo)</li> <li>Afwegingskader en stappenplan maak/koopbeslissing (PIANOo)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/2-owp-36-maak-of-koopbeslissing/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-01-datakwaliteit/","title":"Controleer de datakwaliteit","text":"<p>dat-01Dataverkenning en datapreparatieOntwikkelaarData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-01-datakwaliteit/#maatregel","title":"Maatregel","text":"<p>Stel vast of de gebruikte data van voldoende kwaliteit is voor de beoogde toepassing.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-01-datakwaliteit/#toelichting","title":"Toelichting","text":"<ul> <li>Stel functionele eisen voor de datakwaliteit vast en analyseer structureel of er aan deze eisen wordt voldaan.</li> <li>De kwaliteit van de data die als input voor het algoritme wordt gebruikt is bepalend voor de uitkomsten van het algoritme. Hier wordt soms ook naar gerefereerd als garbage in = garbage out.</li> <li>Een vraag die gesteld dient te worden: beschrijft de data het fenomeen dat onderzocht dient te worden? Oftewel: is de data representatief voor de doelpopulatie?</li> <li> <p>Het Raamwerk gegevenskwaliteit bevat een breed toepasbare set van kwaliteitsdimensies:</p> <ul> <li>juistheid</li> <li>compleetheid</li> <li>validiteit</li> <li>consistentie</li> <li>actualiteit</li> <li>precisie</li> <li>plausibiliteit</li> <li>traceerbaarheid</li> <li>begrijpelijkheid</li> </ul> <p>Deze dimensies zijn aangevuld met kwaliteitsattributen welke gebruikt kunnen worden om de verschillende dimensies meetbaar te maken.</p> </li> <li> <p>De vraag of de data kwaliteit voldoende is, hangt sterk samen met de vraag of er bias in de onderliggende data zit. Analyseer daarom ook welke bias en aannames er besloten zijn in de onderliggende data. Denk hierbij onder andere aan de volgende vormen van bias:</p> <ul> <li>historische bias</li> <li>meetbias</li> <li>representatie bias</li> </ul> </li> <li> <p>Zorg dat je data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) is.</p> </li> <li> <p>Bepaal of de data voldoende representatief is voor de doelpopulatie en of de data voldoende representatief is voor eventuele relevante subgroepen uit de productiedata.</p> </li> </ul> <p>Let op!</p> <p>Wanneer je een algoritme inkoopt en de ontwikkeling van het algoritme uitbesteedt aan een derde partij, houdt er dan dan rekening mee dat data traceerbaar en reproduceerbaar moet zijn. Maak hier heldere afspraken over met de aanbieder.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-01-datakwaliteit/#risico","title":"Risico","text":"<ul> <li>Door onjuiste beslissingen van gegevens kunnen verkeerde beslissingen genomen worden.</li> <li>Het model cre\u00ebert onwenselijke systematische afwijking voor specifieke personen, groepen of andere eenheden. Dit kan leiden tot ongelijke behandeling en discriminerende effecten met eventuele schade voor betrokkenen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-01-datakwaliteit/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, DM.7, DM.9, DM.19</li> <li>Toetsingskader Algoritmes, Algemene Rekenkamder, 2.18</li> <li>NORA, Raamwerk gegevenskwaliteit</li> <li>Impact Assessment Mensenrechten en Algoritmes, 2A.2.2</li> <li>Handreiking non-discriminatie by design</li> <li>Norm: \"Artificial intelligence - Data quality for analytics and machine learning (ML) - Part 2: Data quality measures\"</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-01-datakwaliteit/#voorbeelden","title":"Voorbeelden","text":"<p>Voorbeeld: Gemeente Rotterdam - Avola</p> <p>In de Gemeente Rotterdam wordt gebruik gemaakt van een ondersteunend advies algoritme voor een toetsing voor recht op een uitkering, Avola. Dit algoritme maakt gebruik van beslisregels gebaseerd op wet- en regelgeving waarmee een advies aan een consulent van Werk en Inkomen gegeven wordt. De data waarop dit advies gebaseerd is, wordt gedeeltelijk door de burger zelf aangeleverd.</p> <p>In het rapport van de Rekenkamer Rotterdam \u201cKleur bekennen\u201d wordt aangegeven dat er bij het gebruik van Avola ook aandacht is voor de kwaliteit van de gebruikte data. Deze data wordt tijdens het aanvraagproces gecontroleerd door zowel de burger als consulent. Hierbij wordt op onjuistheden getoetst voordat de data gebruikt wordt. Dit zou verder verbeterd kunnen worden door duidelijk aan te geven hoe de gegevens worden gecontroleerd.</p> <p>Bron: Kleur bekennen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-02-toetsen-geschiktheid-variabelen/","title":"Toets en analyseer of de inputvariabelen of risicoindicatoren geschikt zijn voor het beoogde algoritme","text":"<p>dat-02Dataverkenning en datapreparatieVerificatie en validatieOntwikkelaarBeleid en adviesDataBias en non discriminatiePrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-02-toetsen-geschiktheid-variabelen/#maatregel","title":"Maatregel","text":"<p>Toets en analyseer of de inputvariabelen of risicoindicatoren geschikt zijn voor de beoogde toepassing.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-02-toetsen-geschiktheid-variabelen/#toelichting","title":"Toelichting","text":"<p>Deze maatregel dekt (een gedeelte van) een eis die vanuit het advies vanuit de Autoriteit Persoonsgegevens (AP) over geautomatiseerde besluitvorming wordt gesteld, namelijk dat het risico op discriminatoire verwerkingen is onderzocht en ondervangen.</p> <p>Analyseer welke variabelen en risicoindicatoren geschikt en wenselijk zijn om te gebruiken als inputdata voor het beoogde algoritme.</p> <p>Opmerking</p> <p>Deze maatregel is specifiek relevant voor de situatie van risicoprofilering. Maar ook voor andere toepassingen zijn deze stappen aanbevolen.</p> <p>Doorloop voor iedere potenti\u00eble indicator de volgende stappen:</p> <ol> <li> <p>Ga na of het wettelijk gezien is toegestaan om de variabele te gebruiken voor de beoogde toepassing:</p> <ul> <li>De Algemene Wet Gelijke Behandeling verbiedt het directe onderscheid op basis van verschillende kenmerken die bijvoorbeeld relatie hebben met ras of nationaliteit.</li> <li>De Algemene Verordening Gegevensbescherming verbiedt het onrechtmatig verwerking van persoonsgegevens.</li> </ul> </li> <li> <p>Ga na of de variabele of indicator een proxy is voor kwetsbare groepen. Controleer bijvoorbeeld of er een correlatie bestaat tussen de variabele en nationaliteit of ras, of maak gebruik van bestaande (wetenschappelijke) inzichten uit bijvoorbeeld openbare data. Wanneer je data wilt verwerken om deze proxy's te onderzoeken, houdt dan rekening met geldende wet- en regelgeving. Het verzamelen en verwerken van data over kwetsbare groepen kan in strijd zijn met privacy vereisten uit bijvoorbeeld de Algemene Verordening Gegevensbescherming. Het is daarom van belang om duidelijk afwegingen te maken tussen privacy en het analyseren van proxy's die rekening houdt met de juridische en ethische vereisten.</p> </li> <li> <p>Bepaal of de datakwaliteit van de variabele of indicator voldoende is. Bepaal of de beschikbare data voldoende representatief is voor het fenomeen dat bedoeld wordt.</p> </li> <li> <p>Ga na of de variabele of indicator een statistisch verband heeft met het beoogde doel. Maak hiervoor gebruik van een aselecte steekproef uit de relevante populatie om de hypothese dat de variabele verband heeft met het beoogde doel statistisch te toetsen. Toets of dit verband significant is.</p> </li> <li> <p>Ga na of de variabele of indicator een inhoudelijk verband heeft met het beoogde doel. Naast een statistisch verband kan ook een inhoudelijk verband bijdragen om het gebruik van de indicator te rechtvaardigen.</p> </li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-02-toetsen-geschiktheid-variabelen/#risico","title":"Risico","text":"<p>Indien de variabelen niet voldoende worden getoetst op geschikheid bestaat het risico dat deze variabelen onrechtmatig worden gebruikt, of dat het gebruik van deze variabelen leidt tot nadelige effecten. Dit kan leiden tot discriminerende effecten van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-02-toetsen-geschiktheid-variabelen/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens</li> <li>AP-advies geautomatiseerde besluitvorming</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-02-toetsen-geschiktheid-variabelen/#voorbeeld","title":"Voorbeeld","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/","title":"Geef data zoals persoonsgegevens een bewaartermijn met een vernietigingsprocedure","text":"<p>dat-03OntwikkelenMonitoring en beheerJuristProjectleiderTechnische robuustheid en veiligheidPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/#maatregel","title":"Maatregel","text":"<p>Bepaal de bewaartermijnen en richt een vernietigingsprocesdure in voor de verwerkte (persoons)gegevens.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/#toelichting","title":"Toelichting","text":"<ul> <li>(Persoons)gegevens die het algoritme verwerkt worden niet langer bewaard dan voor de verwezenlijking van de verwerkingsdoeleinden noodzakelijk is.</li> <li>Beschrijf de bewaartermijnen voor de gegevens, bijvoorbeeld in een DPIA.</li> <li>Beschrijf hoe de (persoons)gegevens moeten worden vernietigd.</li> <li>Zorg ervoor dat de vereisten met betrekking tot bewaartermijnen correct zijn of worden vertaald naar het algoritme en de onderliggende (zaak)systemen.</li> <li>Controleer of deze maatregelen voor de bewaartermijnen en vernietiging van de (persoons)gegevens (in de onderliggende systemen) zijn getroffen en zorg dat dit aantoonbaar is, bijvoorbeeld met logbestanden.</li> <li>Maak aantoonbaar dat persoonsgegevens zijn vernietigd, bijvoorbeeld met logbestanden.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/#risico","title":"Risico","text":"<p>Een risico dat kan voorkomen bij deze maatregel is dat bewaartermijnen van (persoons)gegevens kunnen worden overschreden zonder dat dit op tijd kenbaar wordt doordat er geen (volledige) vernietigingsprocedure is vastgesteld.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.11</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.17</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-03-bewaartermijnen-persoonsgegevens/#voorbeelden","title":"Voorbeelden","text":"<p>UWV: Klantapplicatie WW</p> <p>Het UWV heeft in haar privacy statement aangegeven dat zij zich houdt aan de richtlijnen van de Archiefwet voor het bewaren van persoonsgegevens. Hierin staat beschreven welke data bewaard/verwijderd moet worden en op welke termijn. Er staat hier ook een kopje over \u201cUitvoering Vernietiging\u201d waarin uitgelegd staat dat een afdeling binnen het UWV de vernietiging uitvoert.</p> <p>Dit voorbeeld zou verder uitgebreid kunnen worden door de vernietigingsprocedure verder toe te lichten. Op dit moment wordt niet uitgelegd over hoe elektronische of fysieke data vernietigd wordt.</p> <p>Bron: Selectielijst UWV - Nationaal Archief</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-04-pseudonimiseren-anonimiseren/","title":"Bescherm persoonsgegevens door data te anonimiseren, pseudonimiseren of te aggregeren","text":"<p>dat-04Dataverkenning en datapreparatieOntwikkelenOntwikkelaarJuristPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-04-pseudonimiseren-anonimiseren/#maatregel","title":"Maatregel","text":"<p>Pas maatregelen toe als pseudonimiseren, anonimiseren of aggregeren van persoonsgegevens toe bij het verwerken van de data.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-04-pseudonimiseren-anonimiseren/#toelichting","title":"Toelichting","text":"<ul> <li>Als is vastgesteld welke persoonsgegevens mogen worden verwerkt voor het ontwikkelen en gebruiken van algoritmes, moet worden nagegaan of er maatregelen kunnen worden getroffen om deze te beschermen.</li> <li>Het algoritme verwerkt niet meer persoonsgegevens dan noodzakelijk; de verwerkte gegevens zijn proportioneel en substantieel.</li> <li>Hierbij kan worden gedacht aan het pseudonomiseren, anonimiseren of aggregeren van persoonsgegevens.</li> <li>Het bepalen of persoonsgegevens mogen worden verwerkt voor algoritmes moet worden bekeken in samenhang met maatregelen die kunnen worden getroffen om deze gegevens te beschermen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-04-pseudonimiseren-anonimiseren/#risico","title":"Risico","text":"<p>Het niet goed pseudonimiseren, anonimiseren of aggregeren van persoonsgegevens kan leiden tot onterecht gebruik van deze gegevens en kan daarbij een inbreuk op privacy veroorzaken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-04-pseudonimiseren-anonimiseren/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, PRI.5</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.20, 3.06</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-04-pseudonimiseren-anonimiseren/#voorbeelden","title":"Voorbeelden","text":"<p>Groep Gegevensbescherming: Artikel 20 (WP 216)</p> <p>In een advies van de 'Artikel 29 Werkgroep' (tegenwoordig vervangen door de European Data Protection Board (EDPB)) over anonimiseringstechnieken staan verschillende technieken benoemd voor het pseudonimiseren en anonimiseren van persoonsgegevens. Hierbij wordt gekeken naar de factoren: Herleidbaarheid, Koppelbaarheid en Deduceerbaarheid. Hierbij worden ook vaak gemaakte fouten aangegeven zodat deze voorkomen kunnen worden. Er wordt bij iedere techniek een voorbeeld gegeven, maar de exacte implementatie moet zelf verder bekeken worden. Dit voorbeeld kan ondersteunen bij het kiezen van een vorm van gegevensbescherming. Volgens de Autoriteit Persoonsgegevens werkt de EDPB aan guidelines over anonimiseren en pseudonimiseren. Zodra hier meer over bekend is, zal dit toegevoegd worden.</p> <p>Bron: Opinion 05/2014 on 'Anonymisation Techniques'</p> <p>Gemeente Amsterdam: Blurring as a Service</p> <p>De Gemeente Amsterdam maakt gebruik van een algoritme waarmee mensen op straat beter geanonimiseerd kunnen worden; Blurring as a Service. Hierbij worden persoonsgegevens zoals gezicht en andere lichaamskenmerken (biometrische persoonsgegevens) vervaagd of \u2018geblurd\u2019.</p> <p>Bron: Gemeente Amsterdam - Blurring as a Service</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-05-schending-auteursrechten/","title":"Controleer de auteursrechten van eigen data","text":"<p>dat-05OntwerpDataverkenning en datapreparatieJuristData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-05-schending-auteursrechten/#maatregel","title":"Maatregel","text":"<p>Controleer of eventueel door de eigen organisatie verstrekte data binnen of buiten auteursrechten vallen. Bij voorkeur blijven de data eigendom van de (verstrekkende) overheidsorganisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-05-schending-auteursrechten/#toelichting","title":"Toelichting","text":"<p>Het is van belang om te controleren of de te verwerken data waar overheidsorganisaties zelf over beschikken rechtmatig zijn verkregen en geen inbreuken maken op auteursrechten. Hier kan worden gedacht aan data die is gescraped van het internet en zou kunnen worden gebruikt voor de ontwikkeling van een algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-05-schending-auteursrechten/#risico","title":"Risico","text":"<p>Onrechtmatig gebruik van data dat niet toege\u00ebigend is aan de organisatie die de data gebruikt voor ontwikkeling van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-05-schending-auteursrechten/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, SV.11</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-05-schending-auteursrechten/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/","title":"Gebruik duurzame datacenters","text":"<p>dat-06OntwerpDataverkenning en datapreparatieOntwikkelenImplementatieMonitoring en beheerOntwikkelaarProjectleiderBeleid en adviesDuurzaamheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/#maatregel","title":"Maatregel","text":"<p>Maak gebruik van datacenters die gebruik maken van duurzame energiebronnen en energie-effici\u00ebnte technologie\u00ebn voor de opslag en verwerking van data.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/#toelichting","title":"Toelichting","text":"<p>Door data op te slaan en algoritmes te laten draaien in datacenters die hernieuwbare energiebronnen inzetten en bijvoorbeeld de ontstane restwarmte recyclen, kan je de ecologische voetafdruk van de algoritmes aanzienlijk verkleinen. Datacenters die zich op duurzaamheid richten, verlagen de CO\u2082-uitstoot van hun infrastructuur en bieden mogelijk duurzaamheidsrapportages. Let bij het kiezen van een aanbieder op mogelijke greenwashing; dit gebeurt wanneer bedrijven beweren groen te zijn zonder dit met concrete maatregelen te onderbouwen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/#technologieen-voor-energie-efficiente-datacenters","title":"Technologie\u00ebn voor energie-effici\u00ebnte datacenters","text":"<p>Om datacenters energie-effici\u00ebnt te maken, zijn er verschillende benaderingen:</p> <ul> <li>Gebruik van groene energiebronnen: kies voor datacenters/aanbieders die hernieuwbare energie gebruiken. Maak bijvoorbeeld afspraken over een doel, zoals een DCie-score van minimaal 50%, gewogen over een heel jaar. De DCie score van elk Overheids Datacenter (ODC) kun je hier bekijken. Je kunt ook kijken of naast duurzame stroom ook restwarmte van servers wordt benut om bijvoorbeeld nabijgelegen gebouwen te verwarmen.</li> <li>Koeling en energiebeheer optimaliseren: adiabatische koeling, waarbij water en lucht worden gebruikt in plaats van elektriciteit, verlaagt het energieverbruik. Effici\u00ebnte stroomverdeling en warmteterugwinning dragen verder bij aan een lagere ecologische voetafdruk.</li> <li>Monitoren: Blijf controleren op duurzame prestaties door te letten op certificeringen, zoals ISO 14001, ISO 50001 en BREEAM, en vraag naar energierapportages en details over het energieverbruik en de herkomst van stroom. Dit helpt om claims van duurzaamheid te toetsen en te voorkomen dat je in greenwashing trapt.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/#risico","title":"Risico","text":"<p>Door geen gebruik te maken van duurzame datacenters loop je het risico op een hogere CO\u2082-uitstoot en wordt je daardoor niet aangesloten bij Rijksbreed beleid. Ook loop je risico op hogere energiekosten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/#bronnen","title":"Bronnen","text":"<ul> <li>Rijks ICT Dashboard - Duurzaamheid</li> <li>Denk Doe Duurzaam - Doelen voor ICT</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-06-duurzame-datacenters/#voorbeelden","title":"Voorbeelden","text":"<p>Groep Gegevensbescherming: Artikel 20 (WP 216)</p> <p>De Rijksdienst voor Ondernemend Nederland (RvO) heeft een jaarlijks verplichte rapportage van datacentra die meer dan 500 Kilowatt gebruiken. Hiervoor moeten de datacentra een vragenlijst invullen met onder andere informatie over hernieuwbare energie. Een soortgelijke vragenlijst kan ook naar partijen gestuurd worden waar mee wordt samengewerkt. Dit voorbeeld valt onder een wettelijke verplichting en zal dus ook een groot aantal vragen bevatten die niet direct relevant zijn. Daarnaast staan hier geen voorbeelden in om direct een duurzaam datacentrum te vinden.</p> <p>Bron: Rapportageplicht energie-effici\u00ebntie datacentra</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/","title":"Gebruik bij machine learning technieken gescheiden train-, test- en validatiedata en houd rekening met underfitting en overfitting","text":"<p>dat-07Dataverkenning en datapreparatieOntwikkelenOntwikkelaarDataTechnische robuustheid en veiligheidBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/#maatregel","title":"Maatregel","text":"<p>Indien je gebruik maakt van machine learning technieken, maak een passende keuze voor gescheiden train-, test- en validatiedata en houd hierbij rekening met underfitting en overfitting.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/#toelichting","title":"Toelichting","text":"<p>Verdeel je dataset in drie delen:</p> <ol> <li> <p>De trainingset</p> <p>Deze dataset wordt gebruikt om het model te trainen. Uit deze dataset worden de onderliggende patronen of relaties geleerd die later gebruikt kunnen worden om voorspellingen mee te doen.</p> <p>De kwaliteit van deze dataset moet goed zijn en zo representatief mogelijk van de doelpopulatie. Eventuele bias of vooroordelen in deze dataset kunnen door het trainen in het model sluipen.</p> <p>Let bij het samenstellen van de traningset op dat de data waarop het model gebaseerd is, niet beschikbaar is voordat de uitkomsten zijn geobserveerd. Met andere woorden, zorg ervoor de de voorspellingen geen onderdeel kunnen zijn van de inputvariabelen.</p> </li> <li> <p>De validatieset</p> <p>De validatieset fungeert als een onafhankelijke, onbevooroordeelde dataset voor het vergelijken van de prestaties van verschillende algoritmes die zijn getraind op de trainingset.</p> <p>Verschillende modellen kunnen getraind worden op de trainingset. Zo kan je bijvoorbeeld vari\u00ebren in de (hyper)parameters of de inputvariabelen. Dit leidt tot verschillende varianten van het model. Om de prestaties van de verschillende modellen te vergelijken, moeten we een nieuwe dataset gebruiken: de validatieset. Zou je hiervoor de trainingset gebruiken, kan dat leiden tot overfitting, omdat het model te specifiek afgestemd is op 1 dataset. Het model kan dan niet voldoende generaliseren voor nieuwe situaties.</p> </li> <li> <p>De testset</p> <p>Nadat er met behulp van de validatieset een keuze is gemaakt voor een passend model en bijbehorende (hyper)parameters, moet je het model nog testen op nieuwe data. Dit geeft een beeld van de werkelijke prestaties van het model in nieuwe omstandigheden.</p> <p>Let op dat je pas naar deze resultaten kijkt als laatste stap. Inzichten uit deze testdataset mogen niet worden meegenomen in de ontwikkeling, omdat dit kan leiden tot overfitting. Het model zal dan in productie mogelijk minder goed presteren.</p> </li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/#grootte-van-de-drie-datasets","title":"Grootte van de drie datasets","text":"<p>Er is geen optimale verdeling van de drie datsets. Veelvoorkomende verhoudingen om data te splitten zijn:</p> <ul> <li>80% trainingsset, 10% validatieset, 10% testset</li> <li>70% trainingsset, 15% validatieset, 15% testset</li> <li>60% trainingsset, 20% validatieset, 20% testset</li> </ul> <p>Afhankelijk van de hoeveelheid beschikbare data en de context maak je hierin een keuze. Houdt hierbij rekening met:</p> <ul> <li>Hoe minder trainingdata, hoe groter de variatie van het model tijdens het trainen. De patronen en relaties die ontdekt zijn bevatten dan een grotere onzekerheid.</li> <li>Hoe minder validatie- en testdata je gebruikt, hoe groter de variatie en de onzekerheid in de verwachte prestaties van het algoritme.</li> <li>Hoe complexer het model en hoe meer (hyper)parameters er zijn om te optimaliseren, hoe groter de validatieset moet zijn om het model met optimale presetaties te vinden. Wanneer er weinig hyperparameters zijn, is een relatief kleine validatieset vaak voldoende.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/#k-fold-cross-validation","title":"K-fold cross validation","text":"<p>Naast dat je de datasets willekeurig kan verdelen in drie delen (aselect), kan je ook meer geavanceerde technieken gebruiken. Een robuuste en veelgebruikte techniek is k-fold cross validation, waarbij het model k keer wordt getraind op verschillende delen van de data.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/#risico","title":"Risico","text":"<p>Door onjuiste training van het model presteert het model in de praktijk minder goed dan bij de tests. Als training-, validatie- en testdata door elkaar lopen (\"data leakage\"), kan dit leiden tot overfitting waardoor het model beter lijkt te presteren dan in werkelijkheid het geval is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader algoritmes, Auditdienst Rijk, DM.5 en DM.6</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.15, 2.21</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-07-training-validatie-en-testdata/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam: Lokaliseren van lantaarnpalen</p> <p>Gemeente Amsterdam heeft een systeem voor het herkennen van lantaarnpalen. Hiervoor is een subset van de data gebruikt uit Amsterdam-Oost om te trainen. Het testen is onder andere gebeurd in Weesp wat in het Zuid-Oosten van de gemeente ligt. Het uiteindelijke doel is het gehele gebied gemeente Amsterdam. Het grootste punt van verbetering zou zijn om de trainingdata en validatiedata expliciet te benoemen. Daarnaast zou de trainingdata het beste uit verschillende delen van het gebied gemeente Amsterdam gehaald kunnen worden om zo overfitting op Amsterdam-Oost te voorkomen.</p> <p>Bron: Lokaliseren lantaarnpalen - Algoritmeregister</p> <p>Gemeente Ede \u2013 WOZ-taxatiemodellen</p> <p>De gemeente Ede heeft een algoritme in gebruik als ondersteuning bij het bepalen (en controleren) van de WOZ-waarde van woningen. Dit wordt gedaan aan de hand van Machine Learning modellen die op basis van onder andere woning- en locatiekenmerken gecombineerd met markt- en verkoop condities de WOZ-waarde kan bepalen. Hierbij wordt bepaald welke kenmerken het meeste gewicht hebben voor deze bepaling. Dit algoritme is getraind op 80% van de data om vanuit daar verbanden tussen transactieprijzen en kenmerken te leren. Voor de testset is 20% van de data gebruik om te valideren of nieuwe (onbekende) data ook correct gewaardeerd wordt.</p> <p>Bron: WOZ-taxatiemodellen - Gemeente Ede</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-08-eigenaarschap-data/","title":"Zorg dat je controle of eigenaarschap hebt over de data","text":"<p>dat-08Dataverkenning en datapreparatieProjectleiderDataPublieke inkoop</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-08-eigenaarschap-data/#maatregel","title":"Maatregel","text":"<p>De organisatie heeft volledige controle of eigenaarschap over de data. Wanneer dit niet mogelijk is, zijn afspraken gemaakt om de functionele eisen te waarborgen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-08-eigenaarschap-data/#toelichting","title":"Toelichting","text":"<p>Wanneer een algoritme ontwikkeld of ingekocht wordt, is het belangrijk om toegang tot de gebruikte data goed te regelen. Maak bijvoorbeeld afspraken over wie ervoor zorgt dat de data:</p> <ul> <li>Op een centrale plek beschikbaar wordt gesteld.</li> <li>Van voldoende kwaliteit is.</li> <li>Goed beveiligd is.</li> </ul> <p>Wanneer een algoritme wordt ontwikkeld door een derde partij en dus niet wordt beheerd door de eigen organisatie, maak je duidelijke afspraken over eigenaarschap van de data. Dat geldt zowel voor de inputdata als de outputdata. Zorg dat de inputdata tot je beschikking blijft, zodat resultaten altijd reproduceerbaar zijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-08-eigenaarschap-data/#risico","title":"Risico","text":"<p>De organisatie is afhankelijk van de data of het model afhankelijk van derden en kan daardoor reproduceerbaarheid en prestatie niet garanderen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-08-eigenaarschap-data/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader algoritmes, Auditdienst Rijk, DM.23</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-08-eigenaarschap-data/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/","title":"Beperk de omvang van datasets voor energie-effici\u00ebntie","text":"<p>dat-09Dataverkenning en datapreparatieOntwikkelenOntwikkelaarProjectleiderDataDuurzaamheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/#maatregel","title":"Maatregel","text":"<p>Houd datasets beperkt tot het noodzakelijke en voldoende specifiek om onnodige energieconsumptie te voorkomen tijdens de verwerking en opslag van data voor algoritmes. We noemen dit ook wel dataminimalisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/#toelichting","title":"Toelichting","text":"<p>Hoe meer je bewaart, hoe meer ruimte dat kost om op te slaan. Bovendien verbruikt elk apparaat dat nodig is om data op te slaan stroom. Dat heeft grote invloed op de CO\u2082-uitstoot van een datacentrum. Grote datasets brengen daarom hoge energie- en opslagkosten met zich mee. Door de dataset bewust te beperken tot relevante gegevens, kun je ook de energie-effici\u00ebntie van algoritmes aanzienlijk verbeteren. Vooral bij de ontwikkeling van AI-systemen kan het verminderen van data bijdragen aan lagere energiebehoeften en CO\u2082-uitstoot.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/#technieken-voor-dataminimalisatie","title":"Technieken voor dataminimalisatie","text":"<ul> <li>Slimme selectie van trainingdata: Gebruik methoden die irrelevante data uit de dataset filteren, zoals dataselectie-algoritmes en sampling-technieken. Door te focussen op relevante data, beperk je de omvang zonder de prestaties van het model te be\u00efnvloeden.</li> <li>Verwijderen van redundante en dubbele data: Deduplicatie van data minimaliseert onnodige verwerkingskracht. Door alleen unieke en relevante gegevens op te slaan, wordt de opslagbehoefte verder beperkt.</li> <li>Opschonen en archiveren van verouderde data: Regelmatige archivering of verwijdering van verouderde data in je dataset zorgt voor een verminderde voetafdruk en verhoogt ook de effici\u00ebntie.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/#risico","title":"Risico","text":"<p>Zonder dataminimalisatie loopt je organisatie het risico op onnodig hoge energie- en opslagkosten, en een grotere ecologische impact.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, PRI.5</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.20</li> <li>Rijks ICT-dashboard</li> <li>Sustainable artificial intelligence \u2013 TU Delft</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-09-dataminimalisatie/#voorbeelden","title":"Voorbeelden","text":"<p>Basisregistratie Personen: Dataminimalisatie</p> <p>De Basisregistratie Personen (BRP) heeft in 2023 een experiment uitgevoerd rondom dataminimalisatie. BRP-gegevens zoals naam en geslacht werden vertaald naar direct bruikbare informatie zoals aanschrijfnaam. Op deze manier werd informatie op een effici\u00ebntere manier doorgegeven. Het experiment van BRP is een indirecte vorm van energie-effici\u00ebntie omdat er minder (onnodige) data verstrekt wordt aan de aanvrager. Hierdoor hoeft de aanvrager minder data op te slaan en te verwerken.</p> <p>Bron: Experimentbesluit BRP dataminimalisatie</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/","title":"Controleer de data op manipulatie en ongewenste afhankelijkheden","text":"<p>dat-10Dataverkenning en datapreparatieMonitoring en beheerOntwikkelaarBeleid en adviesDataTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/#maatregel","title":"Maatregel","text":"<p>De dataset die gebruikt wordt om een model te (her)trainen moet periodiek gecontroleerd worden op manipulatie (data poisoning). Voorkom ongewenste afhankelijkheden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/#toelichting","title":"Toelichting","text":"<p>Manipulatie van data wordt een \u201cdata poisoning\u201d aanval genoemd <sup>1</sup> <sup>2</sup> <sup>3</sup>. Een kwaadwillende kan op verschillende manieren te werk gaan:</p> <ul> <li>Bewust verkeerde informatie aan de dataset toevoegen. Dit is bijvoorbeeld mogelijk door als aanvaller zelf een foutieve dataset beschikbaar te stellen. Controleer daarom goed of een afgenomen dataset de kenmerken heeft die je verwacht. Daarnaast kun je ook nog verifi\u00ebren of bijvoorbeeld het proces waarmee de dataset vergaard is op de juiste manier is uitgevoerd. Tot slot is het verstandig om te voorkomen dat de dataset afhankelijk is van een enkele bron.</li> <li>Een aanvaller kan een bestaande dataset aanpassen, door bijvoorbeeld labels om te draaien. In dit geval moet een aanvaller toegang krijgen tot de locatie van de dataset. Bescherming hiertegen begint met algemene beveiligingsmaatregelen, bijvoorbeeld zoals beschreven in de BIO. Daarnaast moet er ook gekeken worden naar het voorkomen van een insider aanval. Dit kan door selectief te zijn in het verlenen van toegang tot de locatie van de data en bijvoorbeeld het toepassen van een vier-ogen principe.</li> <li>In lijn met het aanpassen van de dataset kan een aanvaller ook een deel van de dataset verwijderen. Dit is naar verwachting makkelijker te realiseren dan het selectief aanpassen van de data. Door bijvoorbeeld alle data over een bepaalde groep personen uit de dataset te verwijderen functioneert het model minder goed voor die groep. Controleer daarom of de dataset waarmee uiteindelijk getraind wordt precies hetzelfde is als de origineel bedoelde data. Dit kan bijvoorbeeld door middel van een handtekening die geverifieerd moet worden.</li> </ul> <p>Op deze manieren kan een aanvaller een model slecht laten functioneren, of alleen fouten laten maken op specifiek gekozen invoerwaarden. Een aanvaller kan de trainingsdata zo be\u00efnvloeden dat nummerborden met een stip altijd foutief gelezen worden, waardoor criminelen kentekencontroles kunnen ontwijken. In dit geval wordt ook wel gesproken over een \u201cbackdoor\u201d aanval.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/#adversarial-training","title":"Adversarial training","text":"<p>Daarnaast kan het principe van adversarial training worden toegepast door zelf bewust foutieve invoerwaarden aan de trainingsdata toe te voegen. Door een algoritme hierop te laten trainen kan deze beter bestand gemaakt worden tegen aanvallen tijdens het gebruik.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/#risico","title":"Risico","text":"<p>Een aanvaller kan proberen om de trainingset te manipuleren om het uiteindelijke model doelbewust fouten te laten maken. Dit kan leiden tot verkeerde antwoorden, vooroordelen of zelfs kwetsbaarheden in het model.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/#bronnen","title":"Bronnen","text":"<ul> <li>Crowdstrike, Data Poisoning: The Exploitation of Generative AI</li> <li>TNO, Ministerie van Justitie en Veiligheid, Verkenning van het raakvlak van cybersecurity en AI</li> <li>AIVD, AI-systemen: ontwikkel ze veilig</li> <li>Kurakin, et al., Adversarial Machine Learning at Scale</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-10-datamanipulatie/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p> <ol> <li> <p>Crowdstrike, Data Poisoning: The Exploitation of Generative AI \u21a9</p> </li> <li> <p>Ministerie van Justitie en Veiligheid, Verkenning van het raakvlak van cybersecurity en AI \u21a9</p> </li> <li> <p>AIVD, AI-systemen: ontwikkel ze veilig \u21a9</p> </li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/","title":"Controleer de input van gebruikers op misleiding","text":"<p>dat-11Dataverkenning en datapreparatieMonitoring en beheerOntwikkelaarDataTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/#maatregel","title":"Maatregel","text":"<p>Controleer de inputdata van gebruikers op misleiding.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/#toelichting","title":"Toelichting","text":"<p>Een algemeen belangrijke stap in cyberveiligheid is het valideren of de inputdata voldoet aan de verwachting. Zo moet gecontroleerd worden of de input valide, compleet en consistent is. Bijvoorbeeld door te verifi\u00ebren of een leeftijd niet negatief is en of er geen tegenstrijdige informatie gegeven wordt. Dit wordt typisch \u201cinput sanitization\u201d genoemd. Veel programmeertalen en software bibliotheken bieden standaard oplossingen voor input sanitization.</p> <p>In de context van algoritmes is het raadzaam om ook nog specifieker te monitoren wat voor inputs er gegeven worden aan bijvoorbeeld een AI-systeem. Zo kan het herhaaldelijk gebruiken van dezelfde input waarden met minimale aanpassingen wijzen op een poging tot een model engineering of een model inversion aanval.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/#generatieve-ai","title":"Generatieve AI","text":"<p>In het specifieke geval van generatieve AI moet er rekening gehouden worden met prompt injection attacks. Dit zijn aanvallen waarbij aanvallers een kwaadaardige opdracht dusdanig verhullen dat standaard checks het niet doorhebben en het model bijvoorbeeld gemanipuleerd wordt om desinformatie te verspreiden, gevoelige data te lekken of zelfs kwaadaardige software uit te voeren. Op dit moment is nog weinig bekend over hoe dit over het algemeen effectief gemodereerd kan worden. Echter kunnen in bepaalde situaties bepaalde opdrachten uitgesloten worden. Een ontwikkelaar zal dus moeten onderzoeken om wat voor opdrachten het gaat. Zo hoeft een AI-systeem dat een klantenservice ondersteunt waarschijnlijk nooit een stuk code uit te voeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/#risico","title":"Risico","text":"<p>Als inputdata gemanipuleerd wordt dan kan dit leiden tot verkeerd gebruik van het algoritme. Een aanvaller kan bijvoorbeeld doelbewust een afwijkende input kiezen om ervoor te zorgen dat het algoritme op een andere manier gebruikt kan worden. Daarnaast kunnen onbewuste fouten ertoe leiden dat het model niet meer goed functioneert.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/#bronnen","title":"Bronnen","text":"<ul> <li>IBM, What is a prompt injection attack?</li> <li>Onderzoekskader Auditdienst Rijk, DM.9</li> <li>Toetsingskader Algemene Rekenkamer, 2.08</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-11-controleren-inputdata/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Montferland - Montferland AI</p> <p>De gemeente Montferland heeft een chatbot (MAI) ontwikkeld voor het beantwoorden van algemene vragen. Op deze manier is algemene informatie binnen de gemeente 24/7 bereikbaar voor haar inwoners en worden de medewerkers ontlast van de live chat. Omdat deze chatbot generatief is heeft gemeente Montferland ook goed gecontroleerd op gebruikers-input. Hierbij wordt er onder andere gebruik gemaakt van systeeminstructies en filter op de inhoud van input en output. Hiermee wordt zowel respectievelijk de chatbot in de basis ge\u00efnstrueerd en tijdens gebruik gecontroleerd.</p> <p>Bron: Mai (Montferland AI) - Gemeente Montferland</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/","title":"Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie","text":"<p>dat-12Dataverkenning en datapreparatieOntwikkelaarData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#maatregel","title":"Maatregel","text":"<p>Maak waardevolle data vindbaar, toegankelijk, interoperabel en herbruikbaar (FAIR) binnen en buiten de eigen organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#toelichting","title":"Toelichting","text":"<p>De internationale FAIR-principes zijn richtlijnen voor de manier van beschrijven, opslag en publicatie van data.</p> <ul> <li>Findable (vindbaar): metadata moet gemakkelijk te vinden zijn voor zowel mensen als computers.</li> <li>Accessible (toegankelijk): gebruikers moeten weten hoe toegang tot de data verkregen kan worden (autorisatie en authenticatie).</li> <li>Interoperable (uitwisselbaar): data moet meestal ge\u00efntegreerd worden met andere data en bijbehorende applicaties, opslag en processen.</li> <li>Reusable (herbruikbaar): het uiteindelijke doel van FAIR is om hergebruik van data te optimaliseren.</li> </ul> <p>Wanneer je voldoet aan de 15 principes is je data 'machine actionable'. Dit maakt het mogelijk dat de data effectief gebruikt kan worden voor verschillende algoritmes.</p> <p>FAIR data betekent niet per definitie dat data open data is. Juist ook voor (privacy) gevoelige data (gesloten data) kan het heel zinvol zijn om te voldoen aan de principes voor FAIR data, om juist daarmee specifieke geautoriseerde toegang tot gevoelige data mogelijk te kunnen maken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#15-principes-voor-fair-data","title":"15 principes voor FAIR data","text":"<p>Er zijn 15 principes voor FAIR data geformuleerd:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#findable-vindbaar","title":"Findable (vindbaar)","text":"<ul> <li> <p>F1: Aan (meta)data wordt een wereldwijd unieke en permanente identifier toegevoegd</p> <p>Voorbeeld</p> <p>Met behulp van Persistent Identifiers (PID) zorg je ervoor dat jouw data (bijvoorbeeld onderzoeksdata) altijd vindbaar blijft. PID's kun je vergelijken met het ISBN-nummer bij boeken. Het idee is dat ook als de locatie of de onderliggende infrastructuur verandert, de verwijzing intact blijft.</p> </li> <li> <p>F2: Data wordt beschreven met rijke metadata</p> <p>Voorbeeld</p> <p>Het team van data.overheid.nl heeft de metadata standaard DCAT-AP-DONL ontwikkeld die speciaal voor de uitwisseling van dataset informatie voor de Nederlandse situatie is ingericht. Dit is gebaseerd op de Data Catalog Vocabulary (DCAT) versie die de Europese Unie heeft opgesteld. Je kan hierover meer lezen op de site van data.overheid.nl.</p> </li> <li> <p>F3: Metadata bevat duidelijk en expliciet de identificatie van de data die ze beschrijven</p> </li> <li>F4: (Meta)data worden geregistreerd of ge\u00efndexeerd in een doorzoekbare bron</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#accessible-toegankelijk","title":"Accessible (toegankelijk)","text":"<ul> <li>A1: (Meta)data zijn opvraagbaar op basis van hun identificatiecode met behulp van een gestandaardiseerd communicatieprotocol</li> <li>A1.1: Het protocol is open, vrij en universeel implementeerbaar</li> <li>A1.2: Het protocol maakt waar nodig een authenticatie- en autorisatieprocedure mogelijk</li> <li>A2: Metadata zijn toegankelijk, ook als de data niet meer beschikbaar zijn</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#interoperable-uitwisselbaar","title":"Interoperable (uitwisselbaar)","text":"<ul> <li>I1: (Meta)data gebruikt een formele, toegankelijke, gedeelde en breed toepasbare taal voor kennisrepresentatie</li> <li> <p>I2: (Meta)data gebruikt gegevenswoordenboeken of vocabulaires die FAIR-principes volgen</p> <p>Voorbeeld woordenboek</p> <p>In het woordenboek Hitte staan ongeveer 230 definities van termen rond het thema hitte die gebruikt worden in het klimaatadaptatieveld. Dit woordenboek is ontwikkeld in opdracht van het ministerie van Infrastructuur en Waterstaat door overheidsstichting Geonovum.</p> </li> <li> <p>I3: (Meta)data bevat gekwalificeerde verwijzingen naar andere (meta)data</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#reusable-herbruikbaar","title":"Reusable (herbruikbaar)","text":"<ul> <li>R1: (Meta)data wordt rijkelijk beschreven met een veelheid aan nauwkeurige en relevante attributen</li> <li>R1.1: (Meta)data wordt vrijgegeven met een duidelijke en toegankelijke licentie voor datagebruik</li> <li> <p>R1.2: (Meta)data wordt geassocieerd met gedetailleerde herkomst</p> <p>Voorbeeld</p> <p>PROV-DM is een conceptueel datamodel dat gebruikt kan worden voor de herkomstinformatie (provenance) van data.</p> </li> <li> <p>R1.3: (Meta)data voldoet aan domein-relevante normen</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#risico","title":"Risico","text":"<p>Data is niet gebruiksvriendelijk en het is onduidelijk hoe de data hergebruikt kan worden wat kan leiden tot ineffici\u00ebnt datagebruik.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#bronnen","title":"Bronnen","text":"<ul> <li>GO FAIR Foundation</li> <li>3-point FAIRification framework 3PFF</li> <li>Toolbox verantwoord datagebruik, 2b</li> <li>NORA online</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/3-dat-12-fair-data/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/","title":"Ontwerp en ontwikkel het algoritme volgens de principes van \u2018security by design\u2019","text":"<p>owk-01OntwikkelenProjectleiderOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/#maatregel","title":"Maatregel","text":"<p>Hanteer principes van \u2018security by design\u2019 (informatiebeveiligingsmaatregelen) als uitgangspunten bij de ontwikkeling van het algoritme. Stel vast welke principes horen bij security by design en welke relevant zijn voor het ontwerp of de ontwikkeling van het algoritme. Mogelijke documenten waarin deze principes kunnen worden opgenomen zijn het security beleid of ontwikkelbeleid. Bij het bepalen en vaststellen van de juiste principes kunnen interviews met de ontwikkelaar en software-architecten helpen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/#toelichting","title":"Toelichting","text":"<p>Security by design is gehanteerd en terug te zien als uitgangspunt. (BIO 14.2.1.1)</p> <p>Security by design benadrukt het belang van het in een vroeg stadium integreren van securitymaatregelen. Op die manier kan worden voldaan aan regelgeving, maar wordt de weerbaarheid tegen bijvoorbeeld cyberaanvallen verhoogd. In een vroeg stadium nadenken over security betekent dat vroeg al de benodigde expertise wordt betrokken, zoals een security officer.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/#risico","title":"Risico","text":"<p>Wanneer tijdens het ontwerp en de inrichting van het algoritmisch systeem niet voldoende rekening wordt gehouden met vastgestelde security-by-design principes kan dit leiden tot een onvoldoende veilige (software-)omgeving. Dit kan tot gevolg hebben: oneigenlijke toegang, wijzigingen of vernietigingen van het algoritme, de data of uitkomsten van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, (BIO 14.2.1.1)</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.28</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.09</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-01-security-by-design/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/","title":"Maak een noodplan voor het stoppen van het algoritme","text":"<p>owk-02OntwikkelenImplementatieProjectleiderOntwikkelaarGovernanceMenselijke controleTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#maatregel","title":"Maatregel","text":"<p>Stel een duidelijk proces in voor situaties waarin het algoritme niet meer werkt zoals beoogd. Dit moet bevatten welke personen welke acties moeten doen en hoe er gewerkt wordt zonder het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#toelichting","title":"Toelichting","text":"<p>Er moet gezorgd worden dat er een alternatief plan is voor als het algoritme niet meer werkt zoals beoogd. Dit kan betekenen dat het hele systeem (tijdelijk) wordt stopgezet, dat delen van het systeem (tijdelijk) worden uitgeschakeld of dat er een alternatief systeem gebruikt wordt.</p> <p>Dit proces bevat in ieder geval de volgende stappen:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#leg-vast-wanneer-het-algoritme-niet-meer-werkt-zoals-beoogd","title":"Leg vast wanneer het algoritme niet meer werkt zoals beoogd","text":"<ul> <li>Leg vast wat de beoogde werking van het algoritme is.</li> <li>Bepaal of de ge\u00efmplementeerde werking overeenkomt met de vastgelegde beoogde werking en wanneer het algoritme gestopt moet worden. Dit gebeurt tijdens een evaluatie of door de continue monitoring.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#zorg-dat-beslissingen-kunnen-worden-herzien","title":"Zorg dat beslissingen kunnen worden herzien","text":"<ul> <li>Leg vast hoe het mogelijk is na te gaan op welk moment het algoritme stopte met werken zoals beoogd. Wanneer de melding vanuit continue monitoring komt is het vaak duidelijk wanneer deze waarde wordt overschreden. Bij vaste evaluatiemomenten moet dit worden herleid. Zorg dat door middel van het loggen van de juiste informatie het mogelijk is te herleiden wanneer het algoritme stopte met werken zoals beoogd.</li> <li>Zorg dat beslissingen die zijn genomen vanaf het moment dat het algoritme stopte met werken zoals beoogd kunnen worden herzien. Indien het algoritme niet direct is gestopt zodra het niet meer werkte zoals beoogd, moet er opnieuw gekeken worden naar de beslissingen die daarna zijn genomen. Leg vast op welke manier deze beslissingen herzien worden.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#leg-vast-wat-de-vervolgacties-zijn","title":"Leg vast wat de vervolgacties zijn","text":"<ul> <li>Leg in een proces vast hoe het gebruik van het algoritme moet worden stopgezet.</li> <li>Leg vast hoe er gewerkt worden zonder het algoritme en wat de impact daarvan is op het werkproces.</li> <li>Leg vast wie er binnen en buiten de organisatie ge\u00efnformeerd moeten worden.</li> <li>Het is van belang dat bij het ontwerp van algoritmes er rekening wordt gehouden met dat het werkproces ook zonder het algoritme kan worden uitgevoerd.</li> <li>In het geval van risicoselectie kan er bijvoorbeeld worden teruggevallen op het enkel uitvoeren van een aselecte steekproef als selectieinstrument.</li> <li>Als blijkt dat het algoritme ongewenst functioneert moeten (technische) maatregelen zijn getroffen waarmee het gebruik daadwerkelijk kan worden stopgezet. Denk hierbij aan een stopknop en werkinstructies hoe het gebruik kan worden be\u00ebindigd.</li> <li>Maak aantoonbaar dat deze maatregelen zijn getroffen.</li> <li>De proceseigenaar of een menselijk toezichthouder moet in staat zijn om het algoritme op elk moment te kunnen be\u00ebindigen.</li> <li>Het stopzetten van het gebruik van een algoritme mag niet tot gevolg hebben dat betrokkenen niet meer kunnen achterhalen hoe besluiten tot stand zijn gekomen of dat gevolgen niet meer kunnen worden gecorrigeerd als dat noodzakelijk is.</li> </ul> <p>Indien er sprake is van discriminerende effecten van een algoritme, kan je gebruik maken van het discriminatieprotocol.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#risico","title":"Risico","text":"<p>Als er geen duidelijke acties zijn gedefinieerd, kan dat bijvoorbeeld leiden tot de volgende risico\u2019s: het werkproces komt stil te liggen door een niet-werkend algoritme, er worden verkeerde beslissingen genomen doordat het algoritme nog wordt gebruikt terwijl het niet goed meer werkt of kwaadwillenden hebben langer toegang tot het algoritme en/of organisatiedata.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.18</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.03</li> <li>Impact Assessment Mensenrechten en Algoritmes, 1.5</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-02-stopzetten-gebruik/#voorbeelden","title":"Voorbeelden","text":"<p>Ministerie van Economische Zaken - Uitwijkplan</p> <p>Het Ministerie van Economische zaken heeft een template voor een Disaster Recovery Plan (DRP) opgesteld. Aan de hand van dit document kunnen duidelijke handelingen en verantwoordelijkheden opgeschreven worden wanneer een algoritme stop gezet moet worden. Dit DRP is vrij algemeen en heeft geen specificaties voor algoritmes in het template staan. Dit zal dus verder uitgewerkt moeten worden, maar dit DRP zou als inspiratie kunnen dienen.</p> <p>Bron: Uitwijk- en herstelplan</p> <p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/","title":"Analyseer de privacy-risico\u2019s en neem maatregelen om deze risico\u2019s laag te houden","text":"<p>owk-03OntwerpOntwikkelenMonitoring en beheerProjectleiderJuristPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/#maatregel","title":"Maatregel","text":"<p>Uitvoeren risicoanalyse en formuleren mitigerende maatregelen voor privacyrisico.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/#toelichting","title":"Toelichting","text":"<ul> <li>Verifieer of een DPIA is uitgevoerd over het werkproces dat wordt of zal worden ondersteund met een algoritme. Zo nee, voer een risico analyse (DPIA) uit om de risico's voor de rechten en vrijheden van betrokkenen met de inzet van algoritmes in beeld te brengen.</li> <li>Organisatorische en technische maatregelen moeten worden getroffen om persoonsgegevens bij de ontwikkeling en het gebruik van het algoritme te beschermen.</li> <li>Beleg de mitigerende maatregelen bij betrokken actoren. Denk bijvoorbeeld aan het toekennen van de maatregelen als anonimiseren en pseudonimiseren van persoonsgegevens aan een data engineer, voordat deze kunnen worden gebruikt ten behoeve van het ontwikkelen of controleren van het algoritme.</li> <li>Bepaal welke maatregelen moeten zijn gerealiseerd voordat mag worden gestart met de verwerking van de persoonsgegevens en welke moeten worden gemonitord.</li> <li>Bepaal of er sprake is van geautomatiseerde besluitvorming. Indien dat het geval is dient er beargumenteerd te worden of dat is toegestaan volgens de AVG.</li> <li>Monitor de voortgang op het realiseren van de maatregelen en zorg voor bewijsstuken als deze zijn gerealiseerd. Deze bewijsstukken kunnen onderdeel worden van een audit.</li> <li>Als er een noodzaak is om na verloop van tijd meer persoonsgegevens te verwerken of om andere verwerkingen uit te voeren, zal opnieuw een beoordeling moeten plaatsvinden of er privacyrisico's ontstaan en hoe deze kunnen worden gemitigeerd. Gedurende de levenscyclus van het algoritme moet aandacht blijven voor het uitvoeren van de risicoanalyse voor privacyrisico's.</li> <li>Bij hoge risico's voor het verwerken van persoonsgegevens is een voorafgaande raadpleging bij de Autoriteit Persoonsgegevens onder artikel 36 AVG verplicht. Bepaal of raadpleging noodzakelijk is.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/#risico","title":"Risico","text":"<p>Privacyrisico's met de inzet van algoritmes worden niet gemitigeerd, waardoor privacyrechten van betrokkenen worden geschonden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.2, PRI.3, PRI.10</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.03, 3.06, 3.10</li> <li>Besluit inzake lijst van verwerkingen van persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens (Staatscourant 2019, 64418)</li> <li>Model DPIA Rijksdienst</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-03-privacyrisico/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-04-logging/","title":"Maak logbestanden waarin staat wie wanneer toegang had tot de data en de code","text":"<p>owk-04OntwikkelenMonitoring en beheerOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-04-logging/#maatregel","title":"Maatregel","text":"<p>Zorg ervoor dat logbestanden worden gecre\u00eberd waarin informatie wordt geregistreerd over gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen. Door goede logging is te achterhalen wanneer en door wie er toegang is geweest tot code en data (audit trail). Er kan loginformatie gegenereerd, bewaard, toegankelijk gemaakt en gemonitord worden. Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren. Bedenk wat deze informatie betekent in de context van de werking van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-04-logging/#toelichting","title":"Toelichting","text":"<ul> <li>Met logbestanden is te achterhalen wanneer en door wie er (ongewenste) aanpassingen zijn gedaan (audit trail).</li> <li>Loginformatie moet worden gegenereerd, bewaard, gemonitord en toegankelijk worden gemaakt.</li> <li>Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren.</li> <li>Bedenk wat deze informatie betekent in de context van de werking van het algoritme. loginformatie gegenereerd, bewaard, toegankelijk gemaakt en gemonitord worden. Logbestanden bevatten vaak gebeurtenissen die gebruikersactiviteiten, uitzonderingen en informatiebeveiligingsgebeurtenissen registreren.</li> <li>Stel vast welke informatie bij het ontwikkelen en gebruiken van algoritmes relevant is om te loggen.</li> <li>Log behalve het aanpassen van gegevens ook het uitlezen van gegevens waar dat relevant is. Bijvoorbeeld als persoonsgegevens worden opgevraagd.</li> <li>Logs dienen periodiek (of doorlopend) gecontroleerd to worden op relevante incidenten. Dat betekent dat wat er gelogd wordt geschikt moet zijn om relevante beveiligingsincidenten op te merken.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-04-logging/#risico","title":"Risico","text":"<p>Wanneer loginformatie ontbreekt, is niet te achterhalen wanneer er (eventueel ongewenste) aanpassingen zijn gedaan (audit trail) op (de code van) het algoritme, of door wie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-04-logging/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, BIO 12.3.1.1, 12.3.1.4, 12.3.1.5, 12.4.1.1, 12.4.2.2</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.27</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.06</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-04-logging/#voorbeelden","title":"Voorbeelden","text":"<p>Informatie Beveiligingsdienst: Aanwijzing Logging</p> <p>De informatie beveiligingsdienst (IBD) heeft een handreiking gepubliceerd rondom logging-beleid en -procedures. Hierin wordt onder andere uitgelegd wat voor soorten logbestanden er zijn, voor wie deze belangrijk zijn en wat er in een log moet staan. Daarnaast wordt toegelicht hoe logging gecontroleerd kan/moet worden. Dit document kan een goede basis vormen voor het beginnen met log bestanden maken. Zo staan er in dit document verschillende bijlagen zoals een template voor logging-beleid en verschillende infographics die het logging-proces en de controles visualiseren voor de lezer.</p> <p>Bron: Handreiking Logging</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/","title":"Kies energiezuinige programmeermethoden","text":"<p>owk-05OntwikkelenOntwikkelaarDuurzaamheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/#maatregel","title":"Maatregel","text":"<p>Gebruik energie-effici\u00ebnte programmeertechnieken en methoden die de benodigde rekenkracht minimaliseren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/#toelichting","title":"Toelichting","text":"<p>Energiezuinig programmeren maakt het mogelijk om de voetafdruk van algoritmes te verkleinen door minder energie en middelen te verbruiken. Door specifieke technieken toe te passen, zoals optimalisatie van processen en effici\u00ebnte geheugenbeheerstrategie\u00ebn, kun je als ontwikkelaar bijdragen aan het verduurzamen van algoritmes.</p> <p>Dit geldt zeker voor generatieve AI, dat veel rekenkracht vereist. Je kunt modellen zo (laten) ontwikkelen dat ze kunnen draaien op apparaten die niet veel energie verbruiken, zoals microcontrollers. Dit in tegenstelling tot een GPU, die veel energie verbruikt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/#technieken-voor-energiezuinige-softwareontwikkeling","title":"Technieken voor energiezuinige softwareontwikkeling","text":"<ol> <li> <p>Lean coding en minimalisatie van code bloat    Lean coding richt zich op het gebruik van alleen de benodigde code zonder overbodige complexiteit of libraries, wat resulteert in lagere energieconsumptie. Door \u201ccode bloat\u201d te vermijden, zorg je ervoor dat het algoritme minder verwerkingskracht en geheugen verbruikt.</p> </li> <li> <p>Gebruik van energiezuinige programmeertalen en frameworks    Programmeren in talen zoals Rust, Go en Elixir draagt bij aan energie-effici\u00ebntie doordat deze ontworpen zijn voor lage resource-omvang en hoge effici\u00ebntie. Ook frameworks die lichtgewicht en modulair zijn, ondersteunen energiezuinige processen.</p> </li> <li> <p>Parallel processing en multi-core optimalisaties    Door parallelle verwerking en multi-core optimalisaties toe te passen, wordt rekenwerk verdeeld over meerdere cores. Dit reduceert de totale verwerkingstijd, bespaart energie en verhoogt de prestaties van je code op het vlak van duurzaamheid.</p> </li> <li> <p>Microservices en modulaire architecturen    Een modulaire architectuur, zoals microservices, zorgt ervoor dat je onderdelen van de applicatie alleen activeert wanneer dat nodig is. Dit voorkomt onnodige belasting en beperkt energieverbruik behoorlijk.</p> </li> <li> <p>Geoptimaliseerd geheugenbeheer    Door effici\u00ebnt geheugenbeheer, zoals caching en lazy loading, voorkom je onnodige data-opslag en bewerkingen. Dit verlaagt de energievraag en verbetert de snelheid van het algoritme aanzienlijk.</p> </li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/#risico","title":"Risico","text":"<p>Zonder energie-effici\u00ebnte methoden kan het algoritme onnodig veel energie verbruiken, wat leidt tot hogere operationele kosten en een grotere milieu-impact.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/#bronnen","title":"Bronnen","text":"<ul> <li>Eindrapport 'Generatieve AI en duurzaamheid' (Universiteit Utrecht)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-05-energiezuinige-programmeermethoden/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/","title":"Optimaliseer AI-trainingsprocessen voor energie-effici\u00ebntie","text":"<p>owk-06OntwikkelenOntwikkelaarDuurzaamheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/#maatregel","title":"Maatregel","text":"<p>Streef naar energiezuinige methoden voor AI-training, zoals het beperken van trainingscycli en het gebruik van energie-effici\u00ebnte hardware.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/#toelichting","title":"Toelichting","text":"<p>Het trainen van AI, vooral generatieve AI-modellen, vergt aanzienlijke energie en heeft daardoor een grote ecologische voetafdruk. Een enkele trainingsronde kan al een enorme hoeveelheid CO\u2082 uitstoten. Door enkele concrete methoden toe te passen, kun je deze impact beperken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/#energie-optimalisatie-door-hardwarekeuze-en-serverbeheer","title":"Energie-optimalisatie door hardwarekeuze en serverbeheer","text":"<ul> <li>Gebruik energie-effici\u00ebnte hardware zoals specifiek afgestemde GPU's, die geschikt zijn voor de trainingsbehoeften van het model. Door bijvoorbeeld te kiezen voor GPU\u2019s die optimaal bij je model passen in plaats van de krachtigste beschikbare hardware, kan het energieverbruik drastisch worden verminderd. Houd hiermee rekening in je keuze voor een trainingsomgeving.</li> <li>Verder kan servergebruik geoptimaliseerd worden door onnodige trainingsomgevingen tijdig te stoppen of voor andere trainingsomgevingen of testomgevingen te kiezen. Ook kun je servers dynamisch schalen met tools zoals Kubernetes of autoscaling technologie.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/#slimme-data-en-trainingsoptimalisatie","title":"Slimme data- en trainingsoptimalisatie","text":"<p>Niet alle beschikbare data dragen bij aan de modelprestaties. Door een dataselectiestrategie toe te passen, gebruik je enkel relevante datasets (dataminimalisatie), wat zorgt voor minder intensieve rekenbelasting tijdens het trainingsproces. Daarnaast kan slimme caching helpen om repetitieve data-opvragingen te beperken, wat bijdraagt aan een lagere energievraag. Bovendien kun je hertrainingscycli van AI beperken door enkel updates te doen wanneer nieuwe data dit echt vereist. Dit voorkomt overbodige trainingscycli en bespaart energie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/#risico","title":"Risico","text":"<p>Zonder energie-effici\u00ebnte methoden kan AI-training leiden tot hoge operationele kosten en een aanzienlijke ecologische impact, met name door overmatig gebruik van rekenkracht en energie-intensieve hardware.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/#bronnen","title":"Bronnen","text":"<ul> <li>How to Make Generative AI Greener - Harvard Business Review</li> <li>GreenOps: 4 Tips om AI-training duurzamer te maken - AG Connect</li> <li>Duurzame kunstmatige intelligentie - TU Delft</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-06-optimaliseer-AI-training/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/","title":"Zorg voor reproduceerbaarheid van de uitkomsten","text":"<p>owk-07OntwikkelenOntwikkelaarTechnische robuustheid en veiligheidTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#maatregel","title":"Maatregel","text":"<p>Zorg ervoor dat uitkomsten van het algoritme herhaald of herleid kunnen worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#toelichting","title":"Toelichting","text":"<p>De reproduceerbaarheid omschrijft of de resultaten van een algoritme herhaald of herleid kunnen worden. Het betekent dat dezelfde input leidt tot dezelfde output in alle situaties. In ieder geval moet het algoritme dezelfde werking vertonen.</p> <p>Reproduceerbaarheid is sterk gelinkt aan herleidbaarheid en traceerbaarheid. Uitkomsten moeten altijd herleid kunnen worden aan de hand van het model en de data.</p> <p>Om te zorgen voor reproduceerbaarheid van de uitkomsten, kan je de volgende stappen nemen:</p> <ol> <li>Bepaal welke mate van reproduceerbaarheid nodig is</li> <li>Implementeer verschillende stappen die bijdragen aan reproduceerbaarheid</li> <li>Test of het algoritme het gewenste niveau van reproduceerbaarheid heeft</li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#bepaal-welke-mate-van-reproduceerbaarheid-nodig-is","title":"Bepaal welke mate van reproduceerbaarheid nodig is","text":"<p>Afhankelijk van de toepassing moeten de resultaten van het algoritme precies te reproduceren zijn. Wanneer er gebruik wordt gemaakt van generatieve AI hoeft de output niet altijd exact hetzelfde te zijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#implementeer-verschillende-stappen-die-bijdragen-aan-reproduceerbaarheid","title":"Implementeer verschillende stappen die bijdragen aan reproduceerbaarheid","text":"<p>Om te zorgen dat uitkomsten reproduceerbaar zijn, implementeer je het volgende in je processen en systemen:</p> <ul> <li>Zorg voor versiebeheer op de code en de bijbehorende systemen. Dit geldt zowel tijdens ontwikkeling als tijdens operatie. Tools als GitHub of GitLab kunnen ondersteunen bij versiebeheer van code.</li> <li>Zorg dat de data (trainings- en testdata) kan worden gereproduceerd. Maak gebruik van versiebeheer op de data, maak backups van de data, sla snapshots van de data op en maak gebruik van timestamps.</li> <li>Documenteer wijzigingen aan het algoritme of de systemen daaromheen.</li> <li>Beheer afhankelijkheden van software bibliotheken en de beschikbare versies. Verschillende versies van veelgebruikte open-source software bibliotheken kunnen leiden tot verschillende resultaten. Gebruik bijvoorbeeld tools als Docker om deze versies te beheren.</li> <li>Logging van tussenresultaten, eindresultaten, parameters en andere benodigde informatie.</li> <li>Houd de documentatie compleet en compact.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#test-of-het-algoritme-het-gewenste-niveau-van-reproduceerbaarheid-heeft","title":"Test of het algoritme het gewenste niveau van reproduceerbaarheid heeft","text":"<p>Het is belangrijk om het algoritme te testen op de mate van reproduceerbaarheid. Dit kan je doen door:</p> <ul> <li>Experimenten meerdere keren te herhalen.</li> <li>Te testen of kan worden achterhaald hoe een bepaald resultaat tot stand is gekomen. Is het duidelijk welke data is gebruikt, en welke versie van het algoritme is gebruikt? Test of het resultaat op basis van deze informatie opnieuw kan worden gegenereerd.</li> <li>Rekening te houden met willekeur in het systeem. Dit is bijvoorbeeld relevant wanneer er gebruikt wordt gemaakt van seeds en/ of random number generators. Experimenteer wat de invloed is van verschillende seeds op de uitkomsten, en analyseer of het systeem dezelfde resultaten geeft voor een vaste seed. Indien van belang, documenteer de seed die gebruikt wordt.</li> <li> <p>Test of een versie van het algoritme opnieuw gereconstrueerd kan worden op basis van de gedocumenteerde informatie:</p> <ul> <li>trainingsdata</li> <li>parameters</li> <li>versies van gebruikte software (softwarebibliotheken)</li> <li>etc.</li> </ul> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#generatieve-ai","title":"Generatieve AI","text":"<p>Bij generatieve AI is het vaak lastiger om de reproduceerbaarheid te testen. Je kunt het volgende doen om dit risico te beperken:</p> <ul> <li>Maak gebruik van open applicaties of modellen, waar mogelijk open source-applicaties en -modellen. Deze bieden meer inzicht op het gebied van transparantie. Let wel op dat deze transparantie niet ten koste mag gaan van de veiligheid.</li> <li>Test wat de uitkomsten zijn voor dezelfde of heel vergelijkbare prompts, en controleer of deze exact of nagenoeg hetzelfde zijn.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#risico","title":"Risico","text":"<p>Wanneer uitkomsten niet herhaald kunnen worden, kan er niet worden gegarandeerd dat vergelijkbare casussen tot vergelijkbare uitkomsten komen. Dit maakt de uitkomsten van het algoritme mogelijk oneerlijk. Wanneer een herhaald experiment niet tot dezelfde uitkomsten leidt, kan het experiment niet vertrouwd worden. Als uitkomsten niet herleid kunnen worden, kan er geen uitleg worden gegeven waarom een bepaalde beslissing tot stand is gekomen. Hierdoor kan geen verantwoording worden geboden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereisteaia-10Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, DM.14</li> <li>MLOps Principles: Reproducability</li> <li>Ministerie van Infrastructuur en Waterstaat, AI Impact Assessment</li> <li>Harald Semmelrock, et al., Reproducibility in Machine Learning-Driven Research</li> <li>Odd Erik Gundersen, et al., Do machine learning platforms provide out-of-the-box reproducibility?</li> <li>Odd Erik Gundersen, et al., State of the Art: Reproducibility in Artificial Intelligence </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-07-reproduceerbaarheid/#voorbeelden","title":"Voorbeelden","text":"<p>Dienst Toeslagen: Populatiebepaling Kindregeling</p> <p>De Dienst Toeslagen maakt gebruik van een algoritme als ondersteuning om in kaart te brengen welke (pleeg)kinderen in aanmerking komen voor een tegemoetkoming van de kindregeling. Op deze manier kan effici\u00ebnter, nauwkeuriger en consistenter herkend worden wie hier voor in aanmerking komen. Om er voor te zorgen dat deze bepaling reproduceerbaar is wordt gebruik gemaakt van versie-beheer. Hierbij worden wijzigingen in de populatie doorgevoerd en bijgehouden. Hiernaast wordt ook aanvullende informatie die tijdens de kritieke periode bekend was in een aparte kolom gezet om zo reproduceerbaarheid te kunnen garanderen.</p> <p>Bron: Populatiebepaling kindregeling - Dienst Toeslagen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/","title":"Bepaal welke feedbackloops van invloed zijn op het algoritme","text":"<p>owk-08OntwerpOntwikkelenProjectleiderOntwikkelaarTechnische robuustheid en veiligheidBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#maatregel","title":"Maatregel","text":"<p>Stel vast op welke manier de uitkomst of de inzet van het algoritme van invloed kan zijn op het proces en de werking in een latere fase. Probeer deze \u2018feedbackloops\u2019 in kaart te brengen zodat ze mogelijk voorkomen kunnen worden of gemonitored kunnen worden op mogelijke negatieve effecten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#toelichting","title":"Toelichting","text":"<p>Een feedbackloop kan zich voordoen wanneer de uitkomst van een algoritme wordt gebruikt als nieuwe input voor het algoritme. Deze feedbackloops kunnen een vertekend beeld van de werkelijkheid geven en de robuustheid van het algoritme over tijd in gevaar brengen. Dit is met name van belang wanneer algoritmes bijleren (continue of periodiek).</p> <p>Opmerking</p> <p>Merk op dat feedbackloops ook een positief effect kunnen hebben, wanneer bijvoorbeeld gebruikerservaring wordt meegenomen in de doorontwikkeling van het algoritme.</p> <p>Er zijn verschillende vormen van feedbackloops:</p> <ul> <li> <p>Sampling feedbackloop: wanneer de beslissing die volgt uit het algoritme effect heeft op de kans dat bepaalde groepen in een volgende selectie terechtkomen.</p> </li> <li> <p>Individual feedbackloop: wanneer de mening of visie van een beoordelaar verandert door het gebruiken van het algoritme(het overnemen van de \u2018vooroordelen van een systeem\u2019).</p> </li> <li> <p>Feature feedbackloop: bijvoorbeeld wanneer de uitkomst dat een subsidie niet verstrekt wordt, ook als kenmerk \u2018eerdere weigering van subsidie\u2019 wordt gebruikt door het algoritme.</p> </li> <li> <p>Outcome feedbackloop: wanneer burgers of bedrijven op basis van de uitkomst ander gedrag gaan vertonen. In het voorbeeld van de subsidie betekent dit bijvoorbeeld dat burgers hun uitgavepatroon veranderen.</p> </li> <li> <p>Machine-learning model feedbackloop: wanneer nieuwe data die beschikbaar komt is be\u00efnvloed door de beslissing van het algoritme zelf en deze data wordt gebruikt om een machine-learning model mee te (her)trainen. Een ander voorbeeld is wanneer alleen data wordt gebruikt van de personen die daadwerkelijk subsidie ontvangen om het algoritme op te (her)trainen. De groep die geen subsidie ontvangt ontbreekt dan in de dataset.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#adversarial-feedbackloops","title":"Adversarial feedbackloops","text":"<p>Soms kunnen feedbackloops opzettelijk ingezet worden als \u2018aanval\u2019 op het systeem. Dit hoeft niet per se vijandig te zijn, maar het kan gaan om het opzettelijk reageren op of aanpassen van de beslissingen die uit een algoritme volgen. Bijvoorbeeld wanneer mensen liegen bij het invullen van een vragenlijst van de GGD wanneer ze een soa-test willen doen, omdat ze weten dat ze dan gekwalificeerd worden voor een gratis test <sup>1</sup>. Wanneer de belanghebbende het gedrag aanpast zonder dat zijn of haar kenmerken daadwerkelijk veranderen, omdat het heeft geleerd hoe het algoritme oordeelt, is dat voorbeeld van een adversarial feature feedbackloop. Deze feedbackloops wil je het liefste voorzien en mitigeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#monitoring-en-ophalen-informatie","title":"Monitoring en ophalen informatie","text":"<p>Feedbackloops kunnen ook een positieve werking hebben op het algoritme. Het is verstandig om feedback op te halen om in te zien wat de reactie is van mensen op (beslissingen van) een algoritme. Dit kan bijvoorbeeld door gebruikers of belanghebbende burgers vragenlijsten te laten invullen met vragen over hun gedrag en de ontwikkelingen hierin te monitoren. Daarnaast kan het ophalen van ervaringen met het algoritme worden gebruikt voor doorontwikkeling en verbetering van het algoritme waarbij de gewenste en ongewenste effecten meegenomen worden.</p> <p>Ten slotte verdient bias specifieke aandacht. Houd goed in de gaten hoe het algoritme gebruikmaakt van de kenmerken van gevoelige groepen en wat de effecten van de uitkomsten zijn op hun gedrag en de datadistributie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#risico","title":"Risico","text":"<p>Feedbackloops kunnen invloed hebben op verschillende onderdelen van het systeem waarin een algoritme zit. Als dit onopgemerkt gebeurt kan dit een negatief effect hebben op de accuraatheid en betrouwbaarheid van het algoritme, of ongewenste bias ontwikkelen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten <p>Geen vereisten beschikbaar voor deze maatregel.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#bronnen","title":"Bronnen","text":"<ul> <li>Luc\u00eda Vicente, et al., Humans inherit artificial intelligence biases</li> <li>Nicol\u00f2 Pagan, et al., A Classification of Feedback Loops and Their Relation to Biases in Automated Decision-Making Systems</li> <li>Jonathan Stray, The AI Learns to Lie to Please You: Preventing Biased Feedback Loops in Machine-Assisted Intelligence Analysis</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-08-feedbackloops/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p> <ol> <li> <p>Zie https://nos.nl/op3/artikel/2143511-soa-sjoemelaars-liegen-voor-gratis-test\u00a0\u21a9</p> </li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/","title":"Ontwerp en train het algoritme om bestand te zijn tegen (cyber)aanvallen","text":"<p>owk-09OntwikkelenBeleid en adviesOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#maatregel","title":"Maatregel","text":"<p>Ontwerp en train het algoritme om bestand te zijn tegen adversarial aanvallen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#toelichting","title":"Toelichting","text":"<p>De impact van een adversarial AI-aanval hangt af van de mate van autonomie waarmee een algoritme wordt ingezet. Een algemene impact-beperkende maatregel is daarom om menselijke gebruikers duidelijke instructies mee te geven om de uitkomsten van de algoritmes te controleren.</p> <p>Voor de verschillende types adversarial AI-aanvallen zijn specifieke maatregelen mogelijk:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#poisoning-aanval","title":"Poisoning aanval","text":"<p>Bij een poisoning aanval wordt het AI-systeem vergiftigd doordat een aanvaller aanpassingen aan de trainingsdata doet, waardoor het AI-systeem fouten gaat maken. Bijvoorbeeld een spamfilter die getraind is op gemanipuleerde data en zo bepaalde spam e-mails doorlaat. Maatregelen gericht op het behoud van de integriteit van de trainingsdata kunnen hiertegen worden ingezet.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#input-of-evasion-aanval","title":"Input- of evasion aanval","text":"<p>Bij een input- of evasion aanval voegt een aanvaller hele kleine bewerkingen toe aan input zodat een AI-systeem wordt misleid: het trekt een foute conclusie. Een voorbeeld hiervan is het plakken van een gele post-it op een stopbord, waardoor een auto met AI gebaseerde omgevingsherkenning het bord niet meer goed kan herkennen en zijn snelheid aanpast. Op evasion aanvallen kan geanticipeerd worden bij het testen van de robuustheid van algoritmes. Bijvoorbeeld door als onderdeel van een representatieve testomgeving ook rekening te houden met moedwillig, subtiel aangepaste input.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#backdoor","title":"Backdoor","text":"<p>Een backdoor in een algoritme geeft een aanvaller toegang en/ of de mogelijkheid om deze te manipuleren. Een voorbeeld hiervan is een nummerbord herkenningsalgoritme dat tijdens de ontwikkelfase van een backdoor voorzien is van een aanvaller, waardoor via een speciale toevoeging aan een nummerbord deze niet meer herkend wordt. Maatregelen gericht op controle van verwerking van trainingsdata, gebruik van ontwikkeltools en halffabricaten en het trainingsproces beperken de mogelijkheid om aanvallers backdoors te laten injecteren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#model-stealing","title":"Model stealing","text":"<p>Bij model stealing of model reverse engineering brengt een aanvaller in kaart hoe een algoritme in elkaar zit. Hierdoor kan een aanvaller het algoritme voor andere doeleinden misbruiken, zoals het vinden van kwetsbaarheden of van evasion tactieken voor het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#inversion-of-inference-aanval","title":"Inversion of inference aanval","text":"<p>Met inversion of inference aanvallen kan een aanvaller achterhalen wat voor (mogelijk vertrouwelijke) trainingsdata is gebruikt. Zo kunnen gevoelige informatie worden blootgelegd, waaronder privacygevoelige gegevens en intellectueel eigendom.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#risico","title":"Risico","text":"<p>Adversarial AI-aanvallen kunnen leiden tot ongewenste misleiding, manipulatie of uitschakeling van de werking van een algoritme of tot verlies van gevoelige gegevens.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#bronnen","title":"Bronnen","text":"<ul> <li>Adversarial AI in het cyberdomein, TNO</li> <li>OWASP Top 10 for Large Language Model Applications</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-09-adversarial-aanvallen/#voorbeelden","title":"Voorbeelden","text":"<p>Sandia: Defending against Adversarial Examples</p> <p>Adversarial aanvallen zijn er zoals hierboven uitgelegd op verschillende manieren wat er voor zorgt dat per aanval een andere aanpak nodig is. Sandia, een Amerikaanse nationale veiligheidsorganisatie, heeft onderzoek gedaan naar een aantal van deze aanvallen en is met maatregelen gekomen. De meerderheid van deze maatregelen zijn redelijk technisch en kunnen het beste in context geplaatst worden aan de hand van het artikel. Een maatregel daarentegen kan redelijk gemakkelijk uitgevoerd worden en dat is het analyseren van mogelijke risico\u2019s. Sandia geeft drie categori\u00ebn aan: defensible, semi-defensible, en indefensible; respectievelijk verdedigbaar, semi-verdedigbaar en onverdedigbaar. Verdedigbare modellen zijn in de juiste omstandigheden goed te vertrouwen. Semi-verdedigbare modellen hebben minstens \u00e9\u00e9n hoog-risico grens waar op een manier omheen gewerkt kan worden. Onverdedigbare modellen geven toegang tot input en output data, vaak zijn dit real-time algoritmes of algoritmes waar de trainingsdata openbaar (toegankelijk) is. In alle drie de gevallen moet voorzichtig worden omgegaan met het ontwerp, maar in het geval van semi-verdedigbaar en onverdedigbaar moet er extra goed gemonitored worden.</p> <p>Bron: Defending against Adversarial Examples</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/","title":"Zorg dat (gevoelige) informatie niet kan lekken op basis van de output van het algoritme","text":"<p>owk-10OntwikkelenImplementatieMonitoring en beheerOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#maatregel","title":"Maatregel","text":"<p>Zorg dat (gevoelige) informatie niet kan lekken op basis van de output van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#toelichting","title":"Toelichting","text":"<p>Een aanvaller kan aan de hand van de uitkomsten van een model proberen om bepaalde eigenschappen over het model of de dataset te achterhalen. In de brochure van de AIVD wordt specifiek gewaarschuwd voor \u201cmodel engineering\u201d, \u201cmodel inversion\u201d en \u201cinference\u201d aanvallen.</p> <ul> <li> <p>Model engineering refereert naar aanvallen die als bedoeling hebben om te achterhalen hoe het model werkt. Dit kan bijvoorbeeld als doel hebben om intellectueel eigendom te stelen of om effectiever zwakheden in het model te kunnen onderzoeken.</p> </li> <li> <p>Model inversion beschrijft aanvallen waarbij het doel is om de trainingsdata te reconstrueren. Dit kan wederom interessant zijn voor het stelen van intellectueel eigendom, maar ook het achterhalen van priv\u00e9 gegevens als het bijvoorbeeld om een medische dataset gaat.</p> </li> <li> <p>Inference aanvallen zijn ook gericht op het achterhalen van informatie over de trainingsdata. In tegenstelling tot model inversion is het doel niet om de gehele trainingsdata terug te krijgen, maar specifieke informatie. Zo kan het doel bijvoorbeeld zijn om te achterhalen of een bepaald persoon onderdeel was van de trainingsdata of kan met een deel van de informatie over een persoon geprobeerd worden om missende informatie te achterhalen. Dit type aanvallen is vaak makkelijker uit te voeren van een volledige model inversion.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#technieken-voor-voorkomen-van-lekken","title":"Technieken voor voorkomen van lekken","text":""},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#statistical-disclosure-control","title":"Statistical Disclosure Control","text":"<p>Statistical Disclosure Control (SDC) is een veelgebruikte techniek om ervoor te zorgen dat er geen gevoelige informatie lekt uit de uitkomst van een datagedreven onderzoek. Alhoewel SDC vooral gericht is op traditionele data-analyses kan het ook gebruikt worden in de context van algoritmes. Er zijn verschillende voorbeelden hoe SDC kan worden toegevoegd aan een AI-systeem, zoals The SACRO-ML package.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#k-anonimity","title":"k-anonimity","text":"<p>Daarnaast bestaan er ook nieuwere technieken die kunnen helpen bij het onherkenbaar maken van mogelijk gevoelige informatie in de outputs van algoritmes. Zo zijn er technieken gebaseerd op het generaliseren van data om individuen onherkenbaar te maken, zoals k-anonimity.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#differential-privacy","title":"Differential privacy","text":"<p>Ook bestaan er technieken die ruis toevoegen aan de uitkomst, met wiskundige garanties van de veiligheid. De meest populaire techniek voor het toevoegen van ruis is differential privacy.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#rate-limiting","title":"Rate limiting","text":"<p>De hierboven benoemde oplossingen focussen op het beveiligen van \u00e9\u00e9n output van het algoritme. Veel aanvallen berusten echter ook op het veelvuldig aanroepen van een algoritme. Een andere oplossing die dit tegen kan gaan is het limiteren van het aantal interacties dat een gebruiker mag hebben met een algoritme, ook wel bekend als rate limiting.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#transparantie-vs-veiligheidsrisico","title":"Transparantie vs veiligheidsrisico","text":"<p>Tot slot moet er ook afgewogen worden op welke manier transparantie van het algoritme leidt tot extra veiligheidsrisico\u2019s. Intu\u00eftief kan een aanvaller makkelijker dingen te weten komen over een algoritme als er informatie gepresenteerd wordt over waarom bijvoorbeeld een AI-systeem een bepaalde keuze maakt. Zo is een veelgebruikte techniek voor inference aanvallen om te kijken hoe 'zeker' een model is voor een bepaalde input. Een beslissing met hoge zekerheid duidt er in veel gevallen op dat de input inderdaad in de trainingsdata zat. Ook het gebruik van explainable AI kan leiden tot extra veiligheidsrisico\u2019s. Zo kan een uitleg gebaseerd op een tegenvoorbeeld makkelijk informatie over een persoon lekken als deze het tegenvoorbeeld is. In 2024 is er een overzicht van bekende gevaren van specifieke uitlegbaarheidstechnieken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#risico","title":"Risico","text":"<p>Als een gebruiker teveel informatie te zien krijgt kan dit bijvoorbeeld leiden tot het lekken van trainingsdata of eigenschappen van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#bronnen","title":"Bronnen","text":"<ul> <li>Smith, et al., Safe machine learning model release from Trusted Research Environments: The SACRO-ML package</li> <li>Sweeney, et al., k-anonymity: a model for protecting privacy</li> <li>Dwork, et al., Differential privacy</li> <li>Nguyen, et al., A Survey of Privacy-Preserving Model Explanations: Privacy Risks, Attacks, and Countermeasures</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-10-voorkom-lekken-op-basis-van-output/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-11-documenteer-parameters/","title":"Documenteer en beargumenteer de keuze voor gebruikte modellen en parameters","text":"<p>owk-11OntwikkelenImplementatieOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-11-documenteer-parameters/#maatregel","title":"Maatregel","text":"<p>Documenteer en beargumenteer de keuze voor gebruikte modellen en parameters.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-11-documenteer-parameters/#toelichting","title":"Toelichting","text":"<p>Documenteer en beargumenteer tijdens de ontwikkeling van een algoritme de technische keuzes die gemaakt worden voor het betreffende model.</p> <p>Dit houdt in dat ten minste het volgende wordt gedocumenteerd en beargumenteer:</p> <ul> <li>Keuzes voor (hyper)parameters.</li> <li>Keuzes voor het gebruikte model.</li> <li>Of wordt er voldaan aan onderliggende (statistische) aannames van het model?</li> </ul> <p>Onderbouw deze keuzes van parameters en verschillende modellen bijvoorbeeld op basis van de gemeten nauwkeurigheid.</p> <p>Goede documentatie zorgt er voor dat opgebouwde kennis door kan worden gegeven.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-11-documenteer-parameters/#risico","title":"Risico","text":"<p>Wanneer keuzes niet goed worden gedocumenteerd en onderbouwd is later niet te herleiden waarom welke keuzes zijn gemaakt in ontwerp en implementatie, waardoor transparantie en verantwoording niet mogelijk is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-11-documenteer-parameters/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Auditdienst Rijk, DM.2</li> <li>Toetinskader Algemene Rekenkamer, 2.02, 2.03, 2.16, 2.17</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-11-documenteer-parameters/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/","title":"Gebruik een passende licentie bij publicatie of gebruik van (open) data","text":"<p>owk-12OntwikkelenDataverkenning en datapreparatieMonitoring en beheerOntwikkelaarJuristData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/#maatregel","title":"Maatregel","text":"<p>Gebruik bij het publiceren of gebruiken van data een passende licentie die aansluit bij het beoogde doel en de bescherming van burgers. Overweeg hierbij zorgvuldig welke voorwaarden nodig zijn, zoals bronvermelding of het delen onder gelijke voorwaarden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/#toelichting","title":"Toelichting","text":"<p>Het kiezen van de juiste licentie is belangrijk bij het publiceren en gebruiken van datasets en algoritmes. Dit zorgt voor betere datakwaliteit (zie o.a. R1.1 uit FAIR). In de huidige digitale samenleving, met name door de opkomst van generatieve AI, is het belangrijk om de balans te vinden tussen openheid en traceerbaarheid. Overweeg bij het kiezen van een licentie de volgende aspecten:</p> <ul> <li>Bronvermelding: wil je gebruikers van bijvoorbeeld de dataset verplichten om de oorspronkelijke bron te vermelden?</li> <li>Share-alike: wil je gebruikers verplichten om afgeleide werken van hetgeen zij gebruiken, onder dezelfde voorwaarden / licentie te delen?</li> <li>Commercieel gebruik: bepaal of en onder welke voorwaarden commercieel gebruik is toegestaan.</li> <li>Herroepbaarheid: houd rekening met toekomstige aanpassingen van de licentie.</li> </ul> <p>Voorbeelden van licenties zijn:</p> <ul> <li>Creative Commons BY-SA: vereist bronvermelding en het delen onder gelijke voorwaarden.</li> <li>Creative Commons BY: vereist alleen bronvermelding.</li> <li>Publiek Domein met bronvermeldingsplicht: voor maximale openheid met behoud van traceerbaarheid.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/#licenties-voor-software-en-code","title":"Licenties voor software en code","text":"<p>Voor software en algoritmes zijn er specifieke licenties beschikbaar die beter aansluiten bij het publiceren van broncode. Creative Commons (CC) raadt het gebruik van CC-licenties voor software expliciet af.</p> <p>Voor Nederlandse overheidssoftware wordt de European Union Public License (EUPL) als standaard aanbevolen, zoals beschreven in Overwegingen bij Open tenzij en Aanpak open source. Voor een overzicht en vergelijking van softwarelicenties kan bovendien de website choosealicense.com geraadpleegd worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/#risico","title":"Risico","text":"<p>Enkele risico's bij het niet vermelden van de passende licentie:</p> <ul> <li>Onduidelijke licentievoorwaarden kunnen leiden tot onbedoeld gebruik van de dataset.</li> <li>Te restrictieve licenties kunnen hergebruik onnodig beperken.</li> <li>Te open licenties (zoals CC0) kunnen leiden tot oncontroleerbare mis- en desinformatie.</li> <li>Onherroepelijke licenties bieden geen flexibiliteit voor toekomstige aanpassingen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algemene Rekenkamer, 2.13</li> <li>Licentiewijzer voor overheden - voor licenties bij software</li> <li>Licensing Assistant - tool van de Europese commissie, ook voor licenties bij software</li> <li>FAIR Data Principles - R1.1</li> <li>Creative Commons licenties</li> <li>Open Data Handboek</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/4-owk-12-licentiegebruik/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een  voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/","title":"Controleer regelmatig of het algoritme werkt zoals het bedoeld is","text":"<p>ver-01OntwikkelenVerificatie en validatieMonitoring en beheerProjectleiderOntwikkelaarTechnische robuustheid en veiligheidBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#maatregel","title":"Maatregel","text":"<p>Stel vast dat het algoritme voortdurend functioneert in lijn met de vastgestelde doelstelling.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#toelichting","title":"Toelichting","text":"<ul> <li>Vertaal de vastgestelde doelstelling naar functionele eisen voor het algoritme. Werk het vastgestelde doel uit in een beschrijving in logische taal/ pseudo code of documentatie die handvatten biedt aan de ontwikkelaar.</li> <li>Monitor de mate waarin aan deze eisen wordt voldaan door het algoritme.</li> <li>Bepaal en leg vast hoe eventuele parameters, business rules en indicatoren bepaald worden. Zorg dat dit breed wordt afgestemd in de organisatie (ontwikkelteam, opdrachtgevers en beheer).</li> <li>Houd hier rekening met eventuele (statistische) bias: meten we daadwerkelijk wat we denken te meten?</li> <li>Wanneer het algoritme meerdere doelen dient, is het belangrijk ook te evalueren op meerdere functionele eisen.</li> <li>Wanneer er sprake is van een (handmatige) behandeling, bepaal dan wanneer deze behandeling als 'succesvol' gezien kan worden.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#risico","title":"Risico","text":"<p>Het algoritme functioneert niet in lijn met geformuleerde doelstellingen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.01, 2.07</li> <li>Impact Assessment Mensenrechten en Algoritmes, 1</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, DM.1, DM.4</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-01-functioneren-in-lijn-met-doeleinden/#voorbeelden","title":"Voorbeelden","text":"<p>Belastingdienst \u2013 Signaal Omzetbelasting Grote Ondernemingen</p> <p>De Belastingdienst controleert aangiftes, waaronder omzetbelasting voor grote ondernemingen. Dit doen ze met behulp van het algoritme Signaalmodel OB GO (SOB GO), dat een risicobeoordeling geeft aan aangiftes die hieronder vallen. Het algoritme is intern ontwikkeld en wordt ook intern onderhouden en gecontroleerd. Dit gebeurt onder andere aan de hand van de bedrijfsregels binnen de Belastingdienst en een kwaliteitsframework.</p> <p>De bedrijfsregels worden jaarlijks ge\u00ebvalueerd, waarbij ook resultaten uit een steekproef van de aangiften worden meegenomen. Het kwaliteitsframework bestaat uit regels en afspraken die gevolgd moeten worden bij het ontwikkelen van algoritmes, waaronder SOB GO. Dit framework wordt op vaste momenten gebruikt om te kijken of SOB GO nog steeds aan de kwaliteitseisen voldoet.</p> <p>Bron: Signaalmodel Omzetbelasting Grote Ondernemingen (SOB GO) - Belastingdienst</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/","title":"Evalueer de nauwkeurigheid van het algoritme","text":"<p>ver-02OntwikkelenVerificatie en validatieMonitoring en beheerOntwikkelaarProjectleiderTechnische robuustheid en veiligheidBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/#maatregel","title":"Maatregel","text":"<p>Test en evalueer de nauwkeurigheid van het algoritme om te zorgen dat deze accurate uitkomsten geeft.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/#toelichting","title":"Toelichting","text":"<p>De nauwkeurigheid van het algoritme wil zeggen: geeft het algoritme de juiste uitkomst voor het gewenste doel; maakt het correcte berekeningen, voorspellingen, aanbevelingen, beslissingen of classificeringen.</p> <p>Voor het evalueren van de nauwkeurigheid zijn de volgende stappen essentieel:</p> <ul> <li>Bepaal met welke methoden en metriek(en) je de nauwkeurigheid wilt gaan meten. Pas dit aan op de ontwerpkeuzes, het beoogde doel en de bepaalde risico\u2019s.</li> <li>Controleer of de data volledig en actueel is om de metrieken te kunnen meten.</li> <li> <p>Bepaal welke foutmarge acceptabel is:</p> <ul> <li>Bepaal hoe vaak het algoritme een bepaalde fout maakt. Houd rekening met verschillende fouten die gemaakt kunnen worden, zoals false positives en false negatives. Welke fouten zijn erger om te maken?</li> <li>De foutmarge is afhankelijk van welke schade wordt veroorzaakt bij onnauwkeurige of foutieve voorspellingen.</li> <li>Heb hierbij aandacht voor de afweging tussen nauwkeurigheid en betrouwbaarheid. Een model met hoge nauwkeurigheid op de testset kan vaak slechter generaliseren naar situaties net buiten de test set (overfitting).</li> <li> <p>Bepaal interventies voor als het restrisico hoger is dan acceptabel.</p> </li> <li> <p>Wanneer de nauwkeurigheid niet voldoende is tijdens de ontwikkelfase kan er besloten worden door te ontwikkelen, andere maatregelen te treffen (bijvoorbeeld in menselijke interventies) om het restrisico acceptabel te maken of door te stoppen met de ontwikkeling van het systeem.</p> </li> <li>Wanneer monitoring aangeeft dat de nauwkeurigheid onvoldoende is, moet er een passende afweging worden gemaakt om het systeem te verbeteren dan wel over te gaan op het stoppen van het systeem.</li> </ul> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/#metrieken","title":"Metrieken","text":"<p>Afhankelijk van het type algoritme zijn er verschillende metrieken waarmee je de nauwkeurigheid kan meten. Veelgebruikte metrieken/methoden zijn:</p> <ul> <li>accuraatheid (accuracy)</li> <li>precisie (precision)</li> <li>recall</li> <li>F1-score</li> <li>mean-squared-error</li> <li>mean-absolute-error</li> <li>ROC-curve</li> </ul> <p>Leg vast welke keuze je maakt voor bepaalde metrieken en waarom. In verschillende omgevingen en onder verschillende datasets moeten de relevante metrieken voor jouw toepassing worden ge\u00ebvalueerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/#risico","title":"Risico","text":"<p>Een onnauwkeurig algoritme geeft de verkeerde uitkomsten waardoor situaties of mogelijk personen verkeerd beoordeeld kunnen worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereisteaia-06Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatieaia-10Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveiligawb-01Organisaties die algoritmes gebruiken voor publieke taken nemen besluiten zorgvuldig"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/#bronnen","title":"Bronnen","text":"<ul> <li>Europese Commissie, Ethische richtsnoeren voor betrouwbare KI</li> <li>Toetingskader Algemene Rekenkamer, 2.03</li> <li>Onderzoekskader algoritmes, Auditdienst Rijk, DM.1 en DM.4</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-02-evalueer-nauwkeurigheid/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam \u2013 Public Eye</p> <p>De gemeente Amsterdam maakt gebruik van een algoritme \u2013 Public Eye \u2013 om te bepalen hoeveel mensen er op een afbeelding staan. Public Eye wordt gebruikt om te kunnen monitoren hoeveel voetgangers er op plekken in de stad zijn, om zo onveilige situaties en drukte goed te kunnen begeleiden.</p> <p>De gemeente geeft aan dat zij een minimum nauwkeurigheid van 70% hanteert om relevante inzichten te krijgen. In de praktijk levert Public Eye een hogere nauwkeurigheid van 90%, afgeleid van trainingsbeelden. Deze data is handmatig geannoteerd door een selecte groep werknemers die dit periodiek doet.</p> <p>Bron: Public Eye-Amsterdam Algoritmeregister</p> <p>Gemeente Ede \u2013 WOZ-taxatiemodellen</p> <p>De gemeente Ede heeft een algoritme in gebruik als ondersteuning bij het bepalen (en controleren) van de WOZ-waarde van woningen. Dit wordt gedaan aan de hand van machine-learning modellen die op basis van onder andere woning- en locatiekenmerken, gecombineerd met markt- en verkoopconditites, de WOZ-waarde kunnen bepalen. Hierbij wordt bepaald welke kenmerken het meeste gewicht hebben voor deze bepaling.</p> <p>Om deze uitkomsten te kunnen controleren wordt er aan de hand van ratio's bekeken of het algoritme nauwkeurig werkt (zie afbeelding hieronder). Aan de hand van deze ratio's wordt gecontroleerd of het algoritme aansluit bij het marktniveau. Als de waarden van de ratio's buiten de bandbreedte liggen, wordt de WOZ-waarde aangepast of wordt deze afwijking verder verklaard.</p> <p></p> <p>Bron: WOZ-taxatiemodellen - Gemeente Ede</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/","title":"Toets het algoritme op bias en voer een rechtvaardigingstoets uit","text":"<p>ver-03OntwerpVerificatie en validatieMonitoring en beheerProjectleiderBeleid en adviesOntwikkelaarJuristBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#maatregel","title":"Maatregel","text":"<p>Analyseer regelmatig of het gebruik van het algoritme of het proces daaromheen leidt tot onwenselijke of onrechtmatige verschillen in de behandeling van individuen en/of groepen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#toelichting","title":"Toelichting","text":"<p>Deze maatregel dekt (een gedeelte van) een eis die vanuit het advies vanuit de Autoriteit Persoonsgegevens (AP) over geautomatiseerde besluitvorming wordt gesteld, namelijk dat het risico op discriminatoire verwerkingen is onderzocht en ondervangen.</p> <p>Het uitvoeren van een analyse over onwenselijke of onrechtmatige verschillen bestaat grofweg uit 3 stappen:</p> <ul> <li>Stap 1: analyseer of er sprake is van bias: systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen.</li> <li>Stap 2: voer een rechtvaardigingstoets uit om te bepalen of het geconstateerde verschil uit stap 1 te rechtvaardigen is.</li> <li>Stap 3: voer een ethische wenselijkheidstoets uit om te bepalen of het geconstateerde verschil uit stap 1 ethisch wenselijk is.</li> </ul> <p>Voor alle stappen geldt dat het belangrijk is om de gemaakte keuzes en afwegingen zorgvuldig te onderbouwen en te documenteren. De 3 stappen worden hieronder verder toegelicht.</p> <p>Opmerking</p> <p>Deze maatregel is in ieder geval van toepassing op natuurlijke personen. Voor andere rechtspersonen zoals bedrijven kan dit ook van toepassing zijn. Denk bijvoorbeeld aan een gelijke behandeling tussen eenmanszaken en grotere bedrijven.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#stap-1-analyseer-of-er-sprake-is-van-bias","title":"Stap 1: Analyseer of er sprake is van bias","text":"<p>In deze stap is het doel om te bepalen in welke mate er sprake is van een systematisch verschil in behandeling van bepaalde objecten, mensen of groepen in vergelijking met anderen. Dit verschil kan zowel op een directe als een indirecte manier ontstaan.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#toetsen-op-direct-onderscheid","title":"Toetsen op direct onderscheid","text":"<p>Toetsen op direct onderscheid is in vergelijking tot toetsen op indirect onderscheid relatief eenvoudig.</p> <p> Bepaal of de inputvariabelen die gebruikt worden leiden tot een direct onderscheid op basis van godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, nationaliteit, hetero- of homoseksuele gerichtheid<sup>1</sup> of burgelijke staat.</p> <p>Het is niet mogelijk om een uitputtend overzicht te geven van alle selectiecriteria die mogelijk tot direct onderscheid op \u00e9\u00e9n van deze gronden leiden. Wel is duidelijk dat verschillende criteria verband houden met bijvoorbeeld nationaliteit of ras. Gebruik van deze factoren wordt dan gezien als direct onderscheid en is verboden. De volgende criteria duiden in ieder geval (niet limitatief) op een onderscheid op ras<sup>2</sup>: huidskleur, eventueel andere geracialiseerde uiterlijke kenmerken zoals gezicht of haar, etniciteit, etnische achtergrond, allochtoon/autochtoon, migratieachtergrond, buitenlandse afkomst of nationale oorsprong, specifiek benoemde afkomst (bijv. Marokkaans, Antilliaans etc.), \u2018niet-Westers\u2019 klinkende naam, \u2018Roma\u2019 of \u2018woonwagenbewoners\u2019.</p> <p>Wel zijn in de jurisprudentie verschillende voorbeelden en aanknopingspunten te vinden. Zo staat vast dat selectie op basis van fysieke etnische kenmerken, zoals huidskleur, direct onderscheid op grond van ras oplevert<sup>2</sup>. Een ander voorbeeld is dat onderscheid op grond van een niet-westers klinkende naam direct onderscheid op grond van afkomst (en dus ras) oplevert<sup>2</sup>.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#toetsen-op-indirect-onderscheid","title":"Toetsen op indirect onderscheid","text":"<p>Ook selectiecriteria die op het eerste gezicht geen enkele link lijken te hebben met een discriminatiegrond kunnen leiden tot indirect onderscheid op grond van een discriminatiegrond. Enkele voorbeelden van zulke 'ogenschijnlijk neutrale' selectiecriteria die verband hebben met ras of nationaliteit zijn: postcode, hoogte van het inkomen, kenteken, familielid in het buitenland, laaggeletterdheid. Indirect onderscheid is in vergelijking met direct onderscheid lastiger te signaleren en te voorkomen. Daarom is het belangrijk jouw algoritmische toepassing regelmatig te analyseren op eventueel indirect onderscheid. Het toetsen op indirect onderscheid bestaat uit 5 stappen:</p> <ol> <li> <p>Bepaal wat de kwetsbare groepen zijn. Eventueel kan dit aangevuld worden op basis van de discriminatiegronden uit non-discriminatie wetgeving. Of andere groepen waarvoor verschillen in behandeling ethisch onwenselijk zijn.</p> </li> <li> <p>Bepaal wat \"verschillen in behandeling\" betekent in de context van het algoritme. In deze stap is het belangrijk om voorafgaand aan de daadwerkelijke analyse met een brede groep stakeholders te bepalen wat 'eerlijk' en 'rechtvaardig' wordt bevonden in de context van het betreffende algoritme. Er zijn veel verschillende manieren waarop je kan kijken naar onderscheid bij het gebruik van algoritmes. Voorbeelden van manieren waarop je naar onderscheid kan kijken zijn:</p> <ul> <li>Onderscheid op basis van gelijke uitkomsten (representatie). De belangrijkste vraag die hier mee beantwoord wordt is: hebben personen uit verschillende groepen gelijke kans om geselecteerd te worden door het algoritme? Of is er sprake van een over- of ondervertegenwoording van bepaalde groepen in de selectie ten opzichte van de betreffende populatie?</li> <li>Onderscheid op basis van gelijke prestaties (fouten). De belangrijkste vraag die hier mee beantwoord wordt is: presteert het algoritme gelijk voor personen uit verschillende groepen? Met andere woorden: maakt het algoritme vaker fouten bij bepaalde groepen? Dat kan er eventueel toe leiden dat bepaalde groepen vaker onterecht wel of niet geselecteerd worden door het algoritme.</li> </ul> <p>Om te toetsen of er sprake is van onderscheid op basis van gelijke prestaties, is het noodzakelijk om de prestaties van het algoritme goed te analyseren. In het geval van classificatie is het daarvoor nodig om een zogeheten confusion matrix op te stellen. Een confusion matrix is een tabel waarin de voorspellingen van het algoritme worden vergeleken met de werkelijke waarden (de ground truth).</p> <p>De verschillende maten/metrieken waarop gekeken kan worden naar onderscheid, worden in de (wetenschappelijke) literatuur ook wel fairness metrieken genoemd. Veel van deze metrieken kunnen op basis van de confusion matrix berekend worden. Een hulpmiddel om de meest passende metrieken te kiezen in jouw situatie is de Fairness tree.</p> <p>Door te denken vanuit verschillende perspectieven, zullen er in de praktijk meerdere metrieken van belang zijn. Het kan echter voorkomen dat deze metrieken elkaar tegenspreken. Maak een duidelijke prioritering van de verschillende metrieken om afwegingen te maken tussen de verschillende opvattingen van eerlijkheid.</p> </li> <li> <p>Verzamel de benodigde data die nodig is om bovenstaande groepen te bepalen. Bepaal welke data nodig is om te analyseren of er verschillen zijn tussen bepaalde groepen. In veel gevallen zal data nodig zijn die demografische en beschermde kenmerken van groepen omschrijft. Het verzamelen en verwerken van deze data kan in strijd zijn met privacy vereisten uit bijvoorbeeld de Algemene Verordening Gegevensbescherming. Het is daarom van belang om duidelijk afwegingen te maken tussen privacy en het analyseren van bias die rekening houdt met de juridische en ethische vereisten.</p> <p>Uitzondering voor hoog risico AI-systemen</p> <p>De AI-verordening biedt een uitzondering voor het verwerken van bijzondere categorie\u00ebn persoonsgegevens voor het monitoren, opsporen en corrigeren van bias bij AI-systemen met een hoog risico. Zie artikel 10.5, AI-verordening.</p> <p>Om de data op een veilige en rechtmatige manier te gebruiken voor een biasanalyse dient de data van voldoende kwaliteit te zijn. Denk hier goed na of de data eventuele bias bevat die kan duiden op een bepaalde vooringenomenheid in de biasanalyse zelf (historische bias of representatie bias). De data dient bijvoorbeeld voldoende actueel en volledig te zijn.</p> <p>Voor sommige groepen zal het onmogelijk zijn om te beschikken over data van voldoende kwaliteit om zorgvuldig te toetsen op bias. De laaggeletterdheid van burgers of personen is bijvoorbeeld lastig meetbaar en in veel gevallen niet beschikbaar. Bepaal in zo'n situatie of er andere mogelijkheden zijn deze groepen te helpen, of er andere mogelijkheden zijn om eventuele ongelijke behandeling bij deze groepen te constateren. Bijvoorbeeld door hierop te monitoren in de klacht- en bezwarenprocedure.</p> </li> <li> <p>Bereken de verschillen in behandeling en/of uitkomsten van het algoritme. Bepaal of er sprake is van een onderscheid en of dit significant is. Er zijn verschillende open source softwarepakketten die je hierbij kunnen ondersteunen, zoals fairlearn, Aequitas, fairml, fairness of AI Fairness 360.</p> </li> <li> <p>Probeer te verklaren hoe het geconstateerde onderscheid is ontstaan. Als er in de vorige stap een significant onderscheid is geconstateerd, is het belangrijk om na te gaan hoe en waar in het proces dit onderscheid is ontstaan. Dit kan bijvoorbeeld ontstaan door:</p> <ul> <li>Een vorm van bias in de onderliggende inputdata. Je kan hierbij denken aan:<ul> <li>Historische bias: in hoeverre beschrijft de data de huidige situatie?</li> <li>Representatie bias: is de data waarop getraind wordt representatief voor de bijbehorende populatie? Zijn trends uit de gebruikte data generaliseerbaar naar de totale populatie?</li> <li>Meetbias: beschrijven de inputvariabelen wel wat ze moeten beschrijven? In hoeverre zijn dit benaderingen waarbij eventuele factoren worden weggelaten?</li> </ul> </li> <li>Een vorm van bias in het proces na afloop van het algoritme:<ul> <li>Is er sprake van automatiseringsbias of bevestigingsbias in de (handmatige) beoordeling?</li> </ul> </li> </ul> </li> </ol> <p> Wanneer duidelijker is hoe de geconstateerde bias is ontstaan, is het goed om te verkennen of er mogelijkheden zijn om dit (in de toekomst) te voorkomen.</p> <p>Het is belangrijk hier een brede groep aan belanghebbenden bij te betrekken. De oorzaken van bias komen in veel gevallen uit de 'echte wereld', waarbij patronen in datasets historische, demografische en sociale verschillen weerspiegielen. Het verklaren en voorkomen van bias vraagt daarmee niet alleen om technische oplossingen, maar het is belangrijk de hele socio-technische omgeving waarin het algoritme wordt ingezet mee te nemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#stap-2-voer-een-rechtvaardigingstoets-uit","title":"Stap 2: Voer een rechtvaardigingstoets uit","text":"<p>Wanneer er in Stap 1 is geconstateerd dat er sprake is van een onderscheid, dient de volgende vraag beantwoord te worden:</p> <p>Valt dit onderscheid te rechtvaardigen?</p> <p>Een geconstateerd systematisch onderscheid is niet altijd fout en is niet altijd verboden, maar het vraagt wel altijd om aandacht en zorgvuldigheid. Het geconstateerde onderscheid kan in bepaalde situaties en onder bepaalde strikte voorwaarden gerechtvaardigd zijn:</p> <ul> <li>Voor direct onderscheid kan er bijvoorbeeld sprake zijn van een wettelijke uitzondering die het gemaakte onderscheid toelaat.</li> <li>Voor indirect onderscheid geldt dat behalve een wettelijke uitzondering er ook een objectieve rechtvaardiging kan bestaan, waarmee het geconstateerde onderscheid in bepaalde gevallen toelaatbaar kan zijn.</li> </ul> <p>Vier subvragen die hierbij beantwoord moeten worden zijn:</p> <ul> <li>Streeft het in te zetten algoritme een legitiem doel na?</li> <li>Is het in te zetten algoritme geschikt om het doel te bereiken?</li> <li>Is het algoritme noodzakelijk? Zijn er geen redelijke, minder bezwaarlijke alternatieven?</li> <li>Is het algoritme alles afwegend proportioneel?</li> </ul> <p>Wanneer er geen rechtvaardiging is voor het gemaakte onderscheid, spreken we van een verboden direct of indirect onderscheid, ofwel discriminatie. Het algoritme mag in dat geval niet gebruikt worden.</p> <p>Voor meer toelichting over het uitvoeren van een rechtvaardigingstoets, verwijzen we naar het Toetsingskader Risicoprofilering van het College voor de Rechten van de Mens.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#stap-3-voer-een-ethische-wenselijkheidstoets-uit","title":"Stap 3: Voer een ethische wenselijkheidstoets uit","text":"<p>Bepaal of het geconstateerde onderscheid uit Stap 1 ethisch wenselijk is. Dit hangt samen met de algemene wenselijkheid van de inzet van het algoritme.</p> <p>In sommige gevallen kan het zo zijn dat ondanks dat er een objectieve rechtvaardiging bestaat voor het gemaakte onderscheid, dit vanuit ethisch perspectief toch onwenselijk is. Bepaal met een grote groep belanghebbenden wat eventuele (nadelige) effecten van het gemaakte onderscheid kunnen zijn, of jullie dit eerlijk vinden en of er eventuele alternatieven zijn.</p> <p>Opmerking</p> <p>De bepaling over wat eerlijk is en wat ethisch wenselijk is kan in sommige gevallen ook politiek bevonden worden. Houd hier rekening met de politiek-bestuurlijke verantwoordelijkheden en zorg indien nodig dat de politiek-bestuurlijke verantwoordelijkhden duidelijk zijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#risico","title":"Risico","text":"<p>Wanneer er geen zorgvuldige analyse naar (onwenselijke) bias is uitgevoerd bestaat het risico dat het gebruik van het algoritme discriminerende effecten met zich meebrengt. Dit kan leiden tot een ongelijke behandeling van burgers met eventuele schade voor betrokkenen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.18, 2.19, 3.08, 3.09</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, DM.16, DM.17, DM.18, DM.20, DM.21, DM.22</li> <li>Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens</li> <li>AP-advies geautomatiseerde besluitvorming</li> <li>Handreiking non-discriminatie by design</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-03-biasanalyse/#voorbeelden","title":"Voorbeelden","text":"<p>Algorithm Audit \u2013 Addendum Vooringenomenheid voorkomen</p> <p>Algorithm Audit heeft de risicoprofilering in het Controle Uitwonendenbeurs-proces (CUB-proces) onderzocht op verzoek van Dienst Uitvoering Onderwijs (DUO). DUO heeft tussen 2010 en 2023 gebruik gemaakt van een risicoprofiel voor het tegengaan van onrechtmatig gebruik van de uitwonendenbeurs. Dit is in 2023 in opspraak geraakt en DUO heeft verzocht om hier verder onderzoek naar te doen.</p> <p>Hieruit bleek dat er inderdaad onvoldoende statistisch verband was tussen een aantal selectiecriteria. Dit is gebleken uit een kwantitatieve analyse aan de hand van verschillende onderzoeksvragen. Zij hebben hun analyses ook publiekelijk online gezet op GitHub, zodat andere organisaties een soortgelijke analyse kunnen uitvoeren.</p> <p>Bron: Addendum Vooringenomenheid voorkomen, Algorithm Audit</p> <p>Voorbeeld: PricewaterhouseCoopers \u2013 Onderzoek misbruik uitwonendenbeurs</p> <p>PricewaterhouseCoopers (PwC) heeft onderzoek gedaan op verzoek van het Ministerie van Onderwijs, Cultuur en Wetenschap (OCW) naar de controle op het misbruik en oneigenlijk gebruik van uitwonendenbeurs (controleproces MUB). Het gaat om de uitwonendenbeurs die de Dienst Uitvoering Onderwijs (DUO) destijds onder deze naam verstrekte (tegenwoordig Controle Uitwonendenbeurs-proces (CUB-proces)). PwC heeft een kwalitatief onderzoek gedaan naar de procedures rond de opzet, validatie en evaluatie van het MUB-proces.</p> <p>Dit kwalitatieve onderzoek is uitgevoerd aan de hand van een eerder opgesteld analysekader voor onderzoek naar selectiesystemen bij andere Nederlandse overheden. Het analysekader bestaat uit drie delen: procedures rond opzet, de gevolgen van de inrichting en omgang met risicosignalen. In het rapport van PwC staat dit in sectie 1.3.1 in meer detail uitgelegd.</p> <p>Bron: Onderzoek misbruik uitwonendenbeurs, PricewaterhouseCoopers</p> <p>Rijks ICT Gilde \u2013 Bias toetsing 'Kort Verblijf Visa' aanvragen</p> <p>Het Rijks ICT Gilde (RIG) heeft op verzoek van het Ministerie van Buitenlandse Zaken (BZ) een bias-toetsing uitgevoerd rondom beslissingen van bepaalde visumaanvragen. Hierbij heeft het RIG onderzoek gedaan naar welke typen bias zich voordoen en hoe deze bias verminderd kan worden.</p> <p>Zij hebben een kwantitatief onderzoek gedaan en hieruit bleek dat er aanzienlijk verschil (dus bias) was op basis van nationaliteit. Daarom heeft het RIG geadviseerd om het gebruik van profielscore en risicogroepen te be\u00ebindigen.</p> <p>Bron: Bias toetsing 'Kort Verblijf Visa' aanvragen, Rijks ICT Gilde</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p> <ol> <li> <p>Er is een wetsvoorstel om de term 'hetero- of homoseksuele gerichtheid' in de Algmemene wet gelijke behandeling (Awgb) te wijzigingen in 'seksuele gerichtheid'. Met deze wijziging sluit de Awgb aan bij een eerdere wijziging van artikel 1 van de Grondwet.\u00a0\u21a9</p> </li> <li> <p>Zie voor meer informatie het Toetsingskader Risicoprofilering van het College voor de Rechten van de Mens.\u00a0\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/","title":"Zorg voor een representatieve testomgeving","text":"<p>ver-04Verificatie en validatieOntwikkelaarProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/#maatregel","title":"Maatregel","text":"<p>Test het algoritme in verschillende scenario\u2019s en omstandigheden die zoveel mogelijk overeenkomen met de operationele context.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/#toelichting","title":"Toelichting","text":"<p>Representatieve testomstandigheden zijn essentieel om een goed onderbouwd vertrouwen te krijgen in de prestaties en de toegevoegde waarde van het algoritme. Houd daarbij bijvoorbeeld rekening met voldoende variatie en ruis die voorkomt tijdens het operationeel gebruik of de verschillende type gebruikers die interacteren met het algoritme. Neem bij het inrichten van een testomgeving de volgende aspecten mee:</p> <ul> <li>De factoren uit de impactanalyse.</li> <li>Zorg voor een testomgeving waarin je betrouwbaarheid, nauwkeurigheid en reproduceerbaarheid kan evalueren.</li> <li>Analyseer de verschillen tussen de dataset en operationeel gebruik.</li> <li>Wanneer een gebruikerstest wordt gedaan, zorg voor een representatieve groep gebruikers. Denk bijvoorbeeld aan verschillend enthousiasme en verschillend niveau van digitale/ AI-vaardigheden.</li> <li>Neem verschillende typen (cyber)aanvallen mee.</li> <li>Valideer dat de testomgeving de risicoanalyse en het beslissingsproces ondersteunt.</li> </ul> <p>Voorbeelden om bij te dragen aan een representatieve testomgeving:</p> <ul> <li>Voeg extra ruis toe aan de testdata.</li> <li>Test op gevallen die niet passen in de verdeling van variabelen waarop een classificatiemodel is getraind (de out-of-distribution scenario\u2019s).</li> <li>Test op uitzonderlijke gevallen (outliers) en minderheidsgroepen</li> <li>Stel specifieke testscenario\u2019s op. Dit kan bijvoorbeeld met de \u2018What if tool\u2019 van Google, om specifieke data scenario\u2019s voor een machinelearning model te onderzoeken.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/#risico","title":"Risico","text":"<p>Als het algoritme niet getest wordt, of getest wordt in niet-representatieve omstandigheden, kan er een onterecht vertrouwen in het algoritme ontstaan. De evaluatie geeft dan goede resultaten, maar het model zal minder presteren in de operationele context waar meer variatie aanwezig is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereisteaia-03Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteemaia-11Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteemaia-33AI-testomgevingen die persoonsgegevens verwerken, voldoen aan strenge voorwaarden"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/#bronnen","title":"Bronnen","text":"<ul> <li>Bo Li, et al., Trustworthy AI: From Principles to Practices</li> <li>Onderzoekskader Auditdienst Rijk, DM.7</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-04-representatieve-testomgeving/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-05-vertaling-wetgeving-naar-systeem/","title":"Controleer regelmatig of het algoritme voldoet aan alle wetten en regels en het eigen beleid","text":"<p>ver-05Verificatie en validatieMonitoring en beheerJuristGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-05-vertaling-wetgeving-naar-systeem/#maatregel","title":"Maatregel","text":"<p>Stel regelmatig vast dat wetgeving en (lokaal) beleid correct is vertaald naar de uitvoering van het te ondersteunen werkproces en de onderliggende systemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-05-vertaling-wetgeving-naar-systeem/#toelichting","title":"Toelichting","text":"<ul> <li>Systemen die overheidsorganisaties inzetten voor bijvoorbeeld het verlenen van subsidies, vergunningen of bijstandsuitkeringen moeten de regels en processtappen volgen die in wetgeving zijn voorgeschreven.</li> <li>Er is een vertaling nodig van deze regels en processtappen naar de uitvoering van het werkproces, het datagebruik en onderliggende systemen.</li> <li>Algoritmes moeten ook voldoen aan deze regels en processtappen.</li> <li>Als algoritmes worden ontwikkeld, moet worden onderzocht wat deze regels zijn en hoe deze moeten worden toegepast bij het ontwikkelen van algoritmes.</li> <li>Het moeten voldoen aan wetgeving en beleid kan dus in zekere zin 'begrenzend' werken op wat mag worden gedaan met algoritmes. Dit is mede afhankelijk van de risico classificatie van de specifieke toepassing.</li> <li>Voor algoritmes, bijvoorbeeld regelgebaseerde rekenregels, moet bijvoorbeeld nauwkeurig worden geprogrammeerd in welke gevallen welke bedragen moeten worden uitgekeerd voor een bijstandsuitkering.</li> <li> <p>Voor machine learning algoritmes moet bijvoorbeeld worden vastgesteld of de trainingsdata wel tot stand is gekomen in lijn met wetgeving en vastgesteld beleid (datakwaliteit) en welke verbanden en patronen (inputvariabelen) al dan niet passend zijn bij het ondersteunen van wettelijke taken.</p> </li> <li> <p>Er is een multidisciplinaire samenwerking nodig tussen de proceseigenaar, gebruikers, juristen, informatieanalisten en ontwikkelaar om deze vertaling zorgvuldig en doorlopend te maken.</p> </li> <li>Voorafgaand aan het (laten) ontwikkelen van een algoritme moet dit zijn uitgevoerd.</li> <li>De toegepaste 'business rules' en de verwerkte data voor de uitvoering van het te ondersteunen werkproces met algoritmes moeten worden onderzocht en beoordeeld.</li> <li>Diepgaande procesanalyses (bijv. BPMN niveau Analytisch) en procesbeschrijvingen kunnen hierbij ondersteunen.</li> <li>Als blijkt dat een werkproces niet (meer) conform (gewijzigde) wetgeving of beleid wordt uitgevoerd, dan moet worden beoordeeld of de verworven data of welke deel van de data geschikt is voor het ontwikkelen een algoritme.</li> <li>Het is dan raadzaam om de uitvoering van het betreffende werkproces en de werking van onderliggende systemen eerst te 'herstellen' en om hiermee een nieuw datafundament te cre\u00eberen (eerst een groot aantal zaken behandelen) die later als trainingsdata kan worden gebruikt.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-05-vertaling-wetgeving-naar-systeem/#risico","title":"Risico","text":"<p>Een beslissing of besluit wordt niet conform wetgeving genomen en is daarmee onrechtmatig als er geen goede vertaling wordt gemaakt van wetgeving naar het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-05-vertaling-wetgeving-naar-systeem/#bronnen","title":"Bronnen","text":"<ul> <li>Wetsanalyse</li> <li>Onderzoekskader Auditdienst Rijk, DM.15</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.05</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-05-vertaling-wetgeving-naar-systeem/#voorbeelden","title":"Voorbeelden","text":"<p>Belastingdienst \u2013 Handleiding Wetsanalyse in de praktijk</p> <p>Bij de Belastingdienst is een team dat zich focust op de verdere ontwikkeling van Wendbare Wetsuitvoering. Hieronder valt onder andere de handleiding \"Wetsanalyse in de praktijk\". In dit document staat hoe de vertaling van wetgeving naar inrichting van de uitvoeringspraktijk gedaan kan worden. Hierin wordt ook tastbaar gemaakt waarom dit nodig is aan de hand van een aantal voorbeelden.</p> <p>In het eerste inhoudelijke hoofdstuk wordt toegelicht wat wetsanalyse inhoudt aan de hand van karakteristieken. In het tweede hoofdstuk worden de daadwerkelijke handelingen verder uitgelegd.</p> <p>Bron: Handleiding Wetsanalyse in de praktijk - Wendbare wetsuitvoering</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/","title":"Evalueer de betrouwbaarheid van het algoritme","text":"<p>ver-06OntwikkelenVerificatie en validatieMonitoring en beheerOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#maatregel","title":"Maatregel","text":"<p>Evalueer de betrouwbaarheid van het algoritme door het algoritme te testen op verschillende input en in verschillende situaties.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#toelichting","title":"Toelichting","text":"<p>De betrouwbaarheid van een algoritme omschrijft of het algoritme in staat is om onder verschillende omstandigheden en met alle mogelijke input tot een correcte uitkomst te komen. In sommige gevallen is het wenselijk om duidelijk aan te geven wat de onzekerheid is van een uitkomst, dat het juiste antwoord niet bepaald kan worden of dat er kans is op fouten.</p> <p>Om de betrouwbaarheid te evalueren kan je de volgende stappen doorlopen:</p> <ol> <li>Bepaal methodes en metrieken.</li> <li>Zorg voor een representatieve testset.</li> <li>Bepaal welke mate van betrouwbaarheid noodzakelijk is.</li> <li>Bepaal interventies voor als het restrisico hoger is dan acceptabel.</li> <li>Zorg en controleer of de betrouwbaarheid van een uitkomst wordt meegegeven in de output.</li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#bepaal-methodes-en-metrieken","title":"Bepaal methodes en metrieken","text":"<p>Bepaal met welke methodes je betrouwbaarheid wil evalueren en welke metrieken je daarvoor wilt gebruiken. De metrieken voor prestatie kunnen gelijk zijn aan die van nauwkeurigheid, alleen gaat het om de score hierop in een onbekende situatie. Het testen van betrouwbaarheid kan bijvoorbeeld door precisie of recall te meten onder extreme omstandigheden of met ruis in de data.</p> <p>Methodes om te testen op betrouwbaarheid</p> <p>Afhankelijk van het type algoritme zijn er verschillende methodes om betrouwbaarheid te testen. In de literatuur gaat het ook over generalisatie wanneer we spreken over het correct presteren op nieuwe of minder voorkomende inputs en omstandigheden. Hieronder enkele voorbeelden van methoden die gebruikt kunnen worden:</p> <ul> <li>De monkey test is een manier om voor willekeurige, invalide of onverwachte inputs de werking van het algoritme te testen. Het idee is om een onvoorspelbare gebruiker (of een script) willekeurige acties te laten uitvoeren om te kijken hoe het systeem erop reageert.</li> <li>Door een out-of-sample test kan worden getest hoe een machine-learning algoritme presteert bij een dataset verdeling die niet in de training is meegegeven.</li> <li>Door stresstesten test je de prestatie van het algoritme onder extreme omstandigheden of ruis in de data.</li> <li>Met synthetische data kunnen goed uitlegbare en controleerbare distributieshifts worden gesimuleerd om te testen of het algoritme in een onbekende situatie, waar geen data van bruikbaar of beschikbaar is, presteert.</li> <li>De AI Blindspots kaartenset kan helpen om risico\u2019s voor betrouwbaarheid (en specifiek bias) te identificeren.</li> </ul> <p>Pas de methodes en metrieken aan op de ontwerpkeuzes, zoals de context waarin het algoritme gebruikt wordt en het soort algoritme. Onderzoek of er specifieke situaties of omstandigheden zijn waarvan bekend is dat deze kunnen vari\u00ebren.</p> <p>Voorbeeld</p> <p>Analyseer welke veranderingen of wisselingen in de inputdata er kunnen plaatsvinden. Bijvoorbeeld door economische schommelingen of door veranderingen in gebruikersgedrag. Test of het algoritme goed blijft presteren onder deze omstandigheden.</p> <p>Voorbeeld</p> <p>De verdeling van de inputdata kan invloed hebben op de prestaties van een machine-learning algoritme (distributieshift). Test hoe het algoritme presteert onder andere verdelingen van de inputdata.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#zorg-voor-een-representatieve-testset","title":"Zorg voor een representatieve testset","text":"<p>Zorg dat er een representatieve testset beschikbaar is waarin het algoritme kan worden getest in verschillende scenario's. Test het algoritme in verschillende omstandigheden:</p> <ul> <li>gebruikers</li> <li>omgeving</li> <li>interface</li> <li>verschillende datasets</li> </ul> <p>Test je algoritme op generaliseerbaarheid van de uitkomsten buiten de standaard omgeving.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#bepaal-welke-mate-van-betrouwbaarheid-noodzakelijk-is","title":"Bepaal welke mate van betrouwbaarheid noodzakelijk is","text":"<ul> <li>Bedenk onder welke variaties het systeem betrouwbaar moet werken en hoe goed het moet kunnen werken onder rand- of uitzonderlijke gevallen.</li> <li>Afhankelijk van de toepassing moeten resultaten altijd dezelfde uitkomst geven of niet (reproduceerbaarheid). In het geval van generatieve AI hoeft het antwoord bijvoorbeeld niet altijd exact hetzelfde te zijn.</li> <li>Houd hierbij aandacht voor de afweging tussen nauwkeurigheid en betrouwbaarheid. Een model met hoge nauwkeurigheid op de testset kan vaak slechter generaliseren naar situaties net buiten de test set (overfitting).</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#bepaal-interventies-voor-als-het-restrisico-hoger-is-dan-acceptabel","title":"Bepaal interventies voor als het restrisico hoger is dan acceptabel","text":"<p>Bepaal wat er moet gebeuren wanneer de betrouwbaarheid niet voldoende is. Hiervoor zijn verschillende mogelijkheden:</p> <ul> <li> <p>Verder ontwikkelen aan het algoritme en andere maatregelen treffen om het restrisico acceptabel te maken. Bijvoorbeeld door:</p> <ul> <li>meer menselijke controle toe te voegen</li> <li>een ander soort algoritme of techniek te gebruiken.</li> <li>bij machinelearning algoritmes kan je overfitting voorkomen door verschillende trainingsdatasets en testdatasets te gebruiken, zoals bij k-fold-cross-validation.</li> <li>door (hyper)parameters aan te passen kan het algoritme worden aangepast zodat het beter presteert in verschillende testsituaties.</li> </ul> </li> <li> <p>Te stoppen met de ontwikkeling en/of het gebruik van het systeem.</p> </li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#zorg-en-controleer-of-de-betrouwbaarheid-van-een-uitkomst-wordt-meegegeven-in-de-output","title":"Zorg en controleer of de betrouwbaarheid van een uitkomst wordt meegegeven in de output","text":"<p>Voorspellingen of uitkomsten van een algoritme kunnen onzeker zijn. Zorg dat de (on)zekerheid van een uitkomst wordt meegegeven in de output van een algoritme. Dat kan bijvoorbeeld door een foutmarge mee te geven. In veel gevallen kan het wenselijk zijn dat het systeem aangeeft wanneer een uitkomst te onzeker is of soms zelfs geen antwoord geeft vanwege de onzekerheid. Dit kan bijdragen aan het vertrouwen in het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#zorg-voor-continue-monitoring-op-betrouwbaarheid","title":"Zorg voor continue monitoring op betrouwbaarheid","text":"<p>Zorg dat het algoritme continu wordt gemonitored op de betrouwbaarheid en de prestaties van het systeem. Maak gebruik van periodieke updates en valideer regelmatig de kwaliteit van de gebruikte data.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#risico","title":"Risico","text":"<p>Een onbetrouwbaar algoritme kan in een nieuwe of onverwachte situatie de verkeerde uitkomsten geven.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereisteaia-10Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#bronnen","title":"Bronnen","text":"<ul> <li>Bo Li, et al., Trustworthy AI: From Principles to Practices</li> <li>Pablo Soldati, et al., Design Principles for Model Generalization and Scalable AI Integration in Radio Access Networks</li> <li>Jiashuo Liu, et al., Towards Out-Of-Distribution Generalization: A Survey</li> <li>Kenniscentrum Data &amp; Maatschappij - Tool: AI Blindspots 2.0</li> <li>Kaiyang Zhou, et al., Domain Generalization: A Survey</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/5-ver-06-evalueer-betrouwbaarheid/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/","title":"Stel een werkinstructie op voor gebruikers","text":"<p>imp-01ImplementatieProjectleiderBeleid en adviesMenselijke controleTransparantieGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/#maatregel","title":"Maatregel","text":"<p>Stel een werkinstructie op voor gebruikers zodat zij weten hoe het algoritme correct gebruikt kan worden en hoe ze om kunnen gaan met de (veiligheids)risico's.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/#toelichting","title":"Toelichting","text":"<p>Het is belangrijk dat gebruikers een werkinstructie ontvangen met informatie over hoe zij met het algoritme kunnen en moeten werken. Hierin worden zaken beschreven als:</p> <ul> <li>Op wat voor manier het algoritme ondersteunt bij het uitvoeren van (wettelijke) taken en hoe het past in de werkwijze. Maak hierbij een duidelijke keuze rondom de rol van het systeem/algoritme bij de werkwijze van medewerkers.</li> <li>Wat de mogelijkheden en beperkingen zijn bij het gebruik van het algoritme. Op welke manieren mag het algoritme gebruikt worden? En op welke manieren niet? Wat zijn de grenzen van toepasbaarheid? En wat zijn de voorwaarden waaronder het model gebruikt kan worden en waaronder niet?</li> <li>Maak duidelijke werkinstructies en protocollen om te voorkomen dat beslissingen, gebaseerd op de output van het systeem, door (automation) bias worden be\u00efnvloed.</li> <li>Welke informatie mag er worden ingevoerd in het systeem? En welke informatie niet?</li> <li>Wat de impact is van het gebruik van het algoritme op de samenleving en individuen (denk aan fundamentele rechten en energieverbruik of dat een besluit met rechtsgevolgen wordt genomen).</li> <li>Zorg dat medewerkers weten waar ze eventuele problemen met het systeem kunnen melden. Bespreek regelmatig met de betrokken medewerkers welke uitdagingen of verbeteringen zij zien bij het gebruik van het systeem.</li> <li> <p>Wat de risico's zijn die aan het gebruik verbonden zijn. Denk aan:</p> <ul> <li>verschillende vormen van bias, zoals automation bias,</li> <li>foutieve beslissingen</li> <li>veiligheidsrisico's.</li> </ul> </li> <li> <p>Welke maatregelen zijn getroffen om deze risico's te beperken (bijv. bias analyse, 'stopknop' ingebouwd, transparantie over de output).</p> </li> <li>Hoe de output van het algoritme moet worden ge\u00efnterpreteerd en hoe het algoritme tot deze beslissing is gekomen. Zorg dat de output op een eenduidige manier kan worden ge\u00efnterpreteerd.</li> <li>Hoe het werkproces kan worden uitgevoerd, zonder ondersteuning van het algoritme.</li> <li>Hoe kan je weten dat het systeem niet (meer) goed werkt?</li> <li>Welke protocollen er zijn als incidenten zich voordoen.</li> <li>Waar je op moet letten om veiligheidsrisico's te verminderen.</li> <li>Welke waarschuwingen het systeem kan en zou moeten geven op basis van continue monitoring. Hoe er omgegaan moet worden bij deze waarschuwingen.</li> </ul> <p>Denk hierbij na over het eventueel bijscholen van medewerkers als het kennisniveau nog onvoldoende is om de werkinstructies goed te begrijpen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/#risico","title":"Risico","text":"<p>Het algoritme wordt onjuist gebruikt of verkeerd ge\u00efnterpreteerd door gebruikers waardoor onjuiste belissingen of besluiten worden genomen. Als gebruikers niet weten hoe ze veilig moeten werken, kunnen ze (onbewust) toegang bieden aan kwaadwillenden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.07</li> <li>Onderzoekskader algoritmes, Auditdienst Rijk, DM.3, DM.10 en DM.12</li> <li>Ethics Guidelines of Trustworthy AI</li> <li>Handreiking non-discriminatie by design</li> <li>Impact Assessment Mensenrechten en Algoritmes</li> <li>Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-01-werkinstructies-gebruikers/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Utrecht: Handleiding Generatieve AI</p> <p>De gemeente Utrecht heeft in April 2024 een handleiding gepubliceerd voor Generatieve AI (GenAI), bijvoorbeeld ChatGPT. Hierin wordt uitgelegd hoe het systeem gebruikt kan worden om zo medewerkers uit te leggen welke risico\u2019s vastzitten aan het gebruik van GenAI. Daarnaast wordt benoemd hoe de beslissingen rondom deze handleiding tot stand zijn gekomen.</p> <p>Deze handleiding is breed opgesteld en zal dus voor een specifiek algoritme binnen een organisatie aangepast moeten worden. De opzet voor een handleiding staat al en kan ter inspiratie gebruikt worden voor andere handleidingen.</p> <p>Bron: Handleiding Generatieve AI - Gemeente Utrecht</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-02-aselecte-steekproeven/","title":"Doe aselecte steekproeven om algoritmes met 'risicogestuurde selectie\u2019 te controleren","text":"<p>imp-02Dataverkenning en datapreparatieImplementatieMonitoring en beheerOntwikkelaarBias en non discriminatieTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-02-aselecte-steekproeven/#maatregel","title":"Maatregel","text":"<p>Uitvoeren van aselecte steekproeven als aanvulling wanneer gebruik gemaakt wordt van risicogestuurde selectie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-02-aselecte-steekproeven/#toelichting","title":"Toelichting","text":"<p>Deze maatregel dekt (een gedeelte van) een eis die vanuit het advies vanuit de Autoriteit Persoonsgegevens (AP) over geautomatiseerde besluitvorming wordt gesteld, namelijk dat het risico op discriminatoire verwerkingen is onderzocht en ondervangen.</p> <p>Aselecte steekproeven kunnen een waardevolle toevoeging zijn bij risicogestuurde selectie.</p> <p>Het toevoegen van aselecte steekproeven maakt het mogelijk om over tijd te beoordelen of het algoritme nog voldoende effectief is. Populaties veranderen immers over tijd. Een selectie die het meest effectief was bij ingebruikname kan over tijd dat niet meer zijn. Door alleen risicogestuurd te selecteren wordt dit niet inzichtelijk, omdat bepaalde groepen zelden tot nooit gecontroleerd worden. Door de aanvullende mogelijkheid van monitoring, kan over tijd beoordeeld worden of er nog steeds sprake is van de meest proportionele vorm. Als dat niet zo is, kan bijvoorbeeld gekozen worden voor aanpassing van de risicogestuurde selectie of overgaan op volledig aselect.</p> <p>De maatregel gaat daarmee niet direct discriminatie tegen, omdat er sprake kan zijn van discriminatie ongeacht de effectiviteit van de risicogestuurde selectie. Een lagere effectiviteit maakt het echter lastiger het gemaakte onderscheid te rechtvaardigen.</p> <p>Het gebruik van een aselecte steekproef is in veel gevallen essentieel om het systeem te kunnen toetsen op vooringenomenheid. Een aselecte steekproef geeft ook inzicht in een deel van de populatie dat doorgaans niet geselecteerd en behandeld wordt door het betreffende risicogestuurde algoritme. Dit maakt het mogelijk om te toetsen of er sprake is van een over- of ondervertegenwoordiging van bepaalde groepen, of om te bepalen of bepaalde typen fouten vaker gemaakt worden in bepaalde groepen.</p> <p>Bij AI-systemen die verder leren op basis van verkregen data kan daarnaast sprake zijn van een reinforcing feedbackloop, omdat zij geen representatieve data krijgen. Het toevoegen van aselecte steekproeven kan deze feedbackloop doorbreken.</p> <p>Het is aan te bevelen om, waar mogelijk, behandelaars niet in te lichten of een casus toegewezen is op basis van een risicogestuurd of aselecte selectie. Daardoor wordt beperkt dat een behandelaar met tunnelvisie een zaak bekijkt. De behandelaar weet immers dat er tussen de selecties zaken zitten waar niet sprake is van verhoogd risico. Op die manier kan automation bias beperkt te worden. Niet in alle gevallen zal dit mogelijk zijn, omdat de behandelaar ook uit andere aangeleverde gegevens kan halen op basis waarvan een casus geselecteerd is. Het is dan van belang om op andere wijze de tunnelvisie tegen te gaan.</p> <p>De precieze inzet van aselecte steekproeven zal afhangen van de context. Zo verschilt het per context hoeveel zaken aselect geselecteerd moeten worden. Bepaal welke groepen er precies vergeleken dienen te worden en bepaal aan de hand daarvan een passende steekproefgrootte zodanig dat er gesproken kan worden over statistische significantie.</p> <p>In sommige gevallen zal de impact van een selectie ook dusdanig zijn dat het zich niet leent voor aselecte steekproef. Zo kan een aselecte steekproef wel de basis zijn voor bureauonderzoek, maar mogelijk niet als enige basis voor een huisbezoek. Deze belangenenafweging moet per context gemaakt worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-02-aselecte-steekproeven/#risico","title":"Risico","text":"<ul> <li>Historical bias</li> <li>Representation bias</li> <li>Automation bias en Reinforcing Feedback Loop</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-02-aselecte-steekproeven/#bronnen","title":"Bronnen","text":"<ul> <li>Rapportage Algoritmerisico's Nederland voorjaar 2024 (pp. 36-41)</li> <li>AP-advies geautomatiseerde besluitvorming</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-02-aselecte-steekproeven/#voorbeelden","title":"Voorbeelden","text":"<p>Algorithm Audit: analyse Controle Uitwonendenbeurs</p> <p>Stichting Algorithm Audit heeft de risicoprofilering in het Controle Uitwonendenbeurs-proces (CUB-proces) onderzocht op verzoek van Dienst Uitvoering Onderwijs (DUO). DUO heeft tussen 2010 en 2023 gebruik gemaakt van een risicoprofiel voor het tegengaan van onrechtmatig gebruik van de uitwonendenbeurs. Dit is in 2023 in opspraak geraakt en DUO heeft Algorithm Audit verzocht hier verder onderzoek naar te doen. Tijdens de kwantitatieve analyse heeft Algorithm Audit gewerkt aan de hand van aselecte steekproeven. Aan de hand van deze data hebben ze verschillende deelvragen beantwoord en blijkt dat tussen een aantal selectiecriteria onvoldoende statistisch verband gebleken is. Door middel van de aselecte steekproef blijkt hierdoor dat de selectie(criteria) aangepast moet(en) worden.</p> <p>Bron: Algorithm Audit: analyse Controle Uitwonendenbeurs</p> <p>Rijksdienst voor Ondernemend Nederland: Risicocontrole Subsidieaanvragen</p> <p>De Rijksdienst voor Ondernemend Nederland (RVO) maakt gebruik van een algoritme bij het behandelen van subsidieaanvragen. Hierbij wordt bij iedere aanvraag een risico-indicatie gemaakt op basis van een aantal regels. Als er volgens het algoritme geen risico\u2019s zijn wordt de aanvraag automatisch aangemaakt, zo niet wordt de aanvraag nog beoordeeld door een adviseur.</p> <p>Daarnaast wordt het algoritme gecontroleerd aan de hand van een steekproef. Op deze manier wordt getest of het algoritme tot de juiste conclusie is gekomen of aangescherpt moet worden. Mocht door de steekproef blijken dat het algoritme niet goed werkt geeft de RVO ook aan dat de keuze gemaakt kan worden om het algoritme niet te gebruiken. Op deze manier wordt aan de hand van steekproeven gecontroleerd dat het algoritme naar behoren werkt.</p> <p>Bron: Rijksdienst voor Ondernemend Nederland: Risicocontrole Subsidieaanvragen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/","title":"Richt bij besluitvorming betekenisvolle menselijke tussenkomst in","text":"<p>imp-03OntwerpImplementatieMonitoring en beheerProjectleiderBeleid en adviesMenselijke controleGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#maatregel","title":"Maatregel","text":"<p>Richt controle op algoritmes z\u00f3 in dat voldaan wordt aan de vereiste van menselijke tussenkomst in de zin van artikel 22 van de Algemene Verordening Gegevensbescherming (AVG).</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#toelichting","title":"Toelichting","text":"<p>Bij situaties waar de AVG van toepassing is, is het op grond van artikel 22 van de AVG verboden om volledig geautomatiseerd besluiten te nemen die rechtsgevolgen of aanmerkelijke effecten hebben. Er zijn uitzonderingen op dit verbod, zoals het bestaan van een wettelijke grondslag voor dergelijke besluitvorming. Het is van belang dat de menselijke tussenkomst daadwerkelijk \u2018betekenisvol\u2019 is. De AVG beschrijft niet hoe betekenisvolle menselijke tussenkomst eruit moet zien. In het SCHUFA-arrest van 7 december 2023 heeft het Hof van Justitie wel bepaald dat er in ieder geval geen sprake is van betekenisvolle menselijke tussenkomst als een bepaalde output van het gebruikte algoritme zo goed als altijd leidt tot een bepaald besluit, ook wanneer dat besluit wel nog door een natuurlijk persoon genomen wordt.</p> <p>De publicatie 'Handvatten betekenisvolle menselijke tussenkomst' van de Autoriteit Persoonsgegevens (AP) geeft de volgende richtlijnen voor het inrichten van betekenisvolle menselijke tussenkomst:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#mens","title":"Mens","text":"<p>De AP geeft aan dat de mens eigenschappen heeft die algoritmes niet hebben. Om die eigenschappen betekenisvol tot uiting te laten komen, zijn de volgende onderdelen belangrijk:</p> <ul> <li>Beoordelaars moeten alle relevante factoren kunnen betrekken.</li> <li>Beoordelaars moeten hun eigen menselijk inzicht kunnen inzetten.</li> <li>Beoordelaars moeten voldoende bekwaam zijn om het algoritme, de output en de totstandkoming van het besluit te beoordelen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#technologie-en-ontwerp","title":"Technologie en ontwerp","text":"<p>De AP waarschuwt dat niet alleen de mens invloed moet kunnen uitoefenen, maar dat de technologie ook de mens kan be\u00efnvloeden. Zo kan bijvoorbeeld automation bias optreden, waarbij mensen de prestaties en nauwkeurigheid van algoritmes overschatten. Zo wordt te snel de output van het algoritme zonder kritische blik gevolgd. Aan de andere kant kan ook algorithmic aversion ontstaan, waarbij juist sprake is van een onderschatting van dezelfde eigenschappen van het algoritme. Dit heeft als risico dat menselijke bias in de besluitvorming wordt ge\u00efntroduceerd. Om de technologie zo in te richten dat menselijke tussenkomst op betekenisvolle wijze mogelijk blijft, zijn de volgende onderdelen belangrijk.</p> <ul> <li>De interface moet zo worden ontworpen en vormgegeven dat neutraliteit wordt gewaarborgd en betekenisvolle tussenkomst wordt gestimuleerd.</li> <li>De beoordelaar moet de data kunnen zien die relevant zijn bij de beoordeling, zonder dat dit onoverzichtelijk wordt.</li> <li>De beoordelaar moet de data in een relevante context kunnen zien.</li> <li>De beoordelaar moet de data in een zo neutraal mogelijke volgorde te zien krijgen.</li> <li>De wijze van beoordelen moet op een gevarieerde wijze plaatsvinden om te voorkomen dat het routinematig wordt en daarmee zijn functie verliest.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#proces","title":"Proces","text":"<p>De AP geeft aan dat de betekenis van menselijke tussenkomst be\u00efnvloed kan worden door het proces daaromheen. Om het proces rond de menselijke tussenkomst zo in te richten dat deze optimaal betekenisvol is, zijn de volgende onderdelen belangrijk.</p> <ul> <li>Het moment binnen de besluitvorming waarop de menselijke tussenkomst plaatsvindt moet passend zijn bij het besluit en de werking van het algoritme. Het kan nodig zijn dat de menselijke tussenkomst op meerdere momenten plaatsvindt.</li> <li>Beoordelaars moeten voldoende tijd krijgen om beslissingen te maken.</li> <li>Beoordelaars moeten bevoegdheid hebben om tegen het algoritme in te gaan en zich vrij voelen dat ook daadwerkelijk te doen.</li> <li>Beoordelaars moeten voldoende ondersteuning hebben bij het nemen van beslissingen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#governance","title":"Governance","text":"<p>De AP noemt dat binnen een organisatie het belang van betekenisvolle menselijke tussenkomst moet worden onderschreven en dat de organisatie steeds verantwoordelijkheid moet blijven nemen voor de inzet van algoritmes en de daarvoor noodzakelijke inrichting van de menselijke tussenkomst. Om te waarborgen dat binnen een organisatie de juiste personen daarvoor verantwoordelijk blijven, zijn de volgende onderdelen belangrijk.</p> <ul> <li>De organisatie legt haar beleid over betekenisvolle menselijke tussenkomst vast in procedures.</li> <li>De organisatie traint en instrueert beoordelaars voldoende om hun rol te kunnen vervullen.</li> <li>De verantwoordelijke toetst en monitort het proces en de gebruikte algoritmes en voert wijzigingen door bij blijkende onvoldoende betekenisvolle menselijke tussenkomst.</li> </ul> <p>De AP heeft in de publicatie 'Handvatten betekenisvolle menselijke tussenkomst' een groot aantal vragen opgenomen die verantwoordelijken zich dienen te stellen bij de inrichting van betekenisvolle menselijke tussenkomst ter invulling van de hierboven omschreven onderdelen. Het is raadzaam die handvatten te gebruiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#risico","title":"Risico","text":"<p>Wanneer algoritmen een rol spelen in besluitvormingsprocessen met rechtsgevolgen of andere aanmerkelijke effecten voor betrokkene en hierbij geen betekenisvolle menselijke tussenkomst is ingericht, dan kan dit kwalificeren als volledig geautomatiseerde besluitvorming die in strijd is met het verbod van artikel 22 van de AVG. Ook kan de kwaliteit van de besluitvorming lager zijn zonder betekenisvolle menselijke tussenkomst.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#bronnen","title":"Bronnen","text":"<ul> <li>Autoriteit Persoonsgegevens - 'Handvatten betekenisvolle menselijke tussenkomst'</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.11</li> <li>Menselijke tussenkomst | Algoritmes | Algemene Rekenkamer</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.5, SV.6</li> <li>Advies landsadvocaat over geautomatiseerde selectietechnieken, p.9</li> <li>Recht op een menselijke blik bij besluiten | Autoriteit Persoonsgegevens</li> <li>Kamerstukken IT 2017-2018, 34 851, nr. (MvT UAVG), p. 120-121</li> <li>Ethics guidelines for trustworthy AI | Shaping Europe\u2019s digital future, deel (64)</li> <li>Towards Digital Life: Een toekomstvisie op AI anno 2032, TNO</li> <li>Algoritmes afwegen | Rathenau Instituut</li> <li>Managing supplier delivery reliability risk under limited information: Foundations for a human-in-the-loop DSS - ScienceDirect</li> <li>Human control of AI systems: from supervision to teaming | AI and Ethics (springer.com)</li> <li>Zijn er beperkingen op het gebruik van geautomatiseerde besluitvorming? - Europese Commissie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-03-menselijke-tussenkomst/#voorbeelden","title":"Voorbeelden","text":"<p>Hof van Justitie van de Europese Unie: Prejudici\u00eble verwijzing</p> <p>In 2021 heeft een burger SCHUFA (een Duits bedrijf wat kredietwaardigheid informatie deelt met derden) aangeklaagd naar aanleiding van een niet ingewilligd verzoek tot inzage en wissing van diens persoonsgegevens. De reden hiervoor kwam door een afwijzing van ondersteuning op basis van geautomatiseerde individuele besluitvorming. Het Hof van Justitie oordeelde dat, zoals bij de kredietscores van SCHUFA het geval was, er geen sprake is van betekenisvolle menselijke tussenkomst als de uitkomsten van het gebruikte algoritme zo goed als altijd leiden tot een bepaalde uitkomst voor de betrokkene.</p> <p>Bron: HvJEU december 2023, ECLI:EU:C:2023:957 (SCHUFA Scoring)</p> <p>Rijksdienst voor Ondernemend Nederland: Risicocontrole SDE++ Subsidieaanvragen</p> <p>De Rijksdienst voor Ondernemend Nederland (RVO) maakt gebruik van een algoritme bij het behandelen van subsidieaanvragen. Per ronde komen er duizenden aanvragen binnen. Het algoritme geeft elke aanvraag een risico-indicatie. Elke aanvraag met een risico-indicatie wordt beoordeeld door een adviseur. De adviseur bekijkt het onderdeel met een risico-indicatie. Als de aanvraag niet volledig is of als de informatie niet voldoende is, dan kan de aanvrager de kans krijgen om extra informatie aan te leveren of iets uit te leggen. Het algoritme zorgt nooit voor een directe afwijzing. Aanvragen voor ingewikkelde technieken of aanvragen boven een bepaald bedrag worden altijd helemaal door een adviseur beoordeeld en niet alleen op het onderdeel met een risico.</p> <p>Bron: Rijksdienst voor Ondernemend Nederland: Risicocontrole SDE++ Subsidieaanvragen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/","title":"Publiceer impactvolle algoritmes en hoog-risico AI-systemen in het Algoritmeregister","text":"<p>imp-04ImplementatieMonitoring en beheerProjectleiderBeleid en adviesTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/#maatregel","title":"Maatregel","text":"<p>Publiceer het algoritme  in het Nederlandse Algoritmeregister.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/#toelichting","title":"Toelichting","text":"<ul> <li>De regering wil dat de overheid algoritmes verantwoord gebruikt. Mensen moeten erop kunnen vertrouwen dat algoritmes voldoen aan de waarden en normen van de samenleving.</li> <li>Wanneer de overheid open is over algoritmes en hun toepassing kunnen burgers, organisaties en media haar kritisch volgen.</li> <li>Impactvolle algoritmes en hoog-risico AI-systemen moeten daarom worden gepubliceerd in het Algoritmeregister.</li> <li>In het Algoritmeregister moet uitleg zijn over hoe algoritmes of het proces wat hiermee wordt ondersteund werkt.</li> <li>Er is een Handreiking Algoritmeregister opgesteld met informatie over het publiceren van algoritmes in het Algoritmeregister.</li> <li>De Algoritmeregister Publicatiestandaard kan overheidsorganisaties ondersteunen bij het helpen invullen van het Algoritmeregister.</li> <li>Sommige overheidsorganisaties publiceren hun algoritmes ook in een eigen Algoritmeregister, zodat burgers dit makkelijker kunnen vinden. Bijvoorbeeld het Algoritmeregister van de Gemeente Rotterdam, het Algoritmeregister van de Gemeente Amsterdam of het Algoritmeregister van het UWV.</li> <li>Zorg na publicatie dat de informatie in het Algoritmeregister up-to-date blijft en indien nodig regelmatig wordt aangepast.</li> <li>Eventueel kan je meer informatie over het algoritme openbaar beschikbaar stellen. Bijvoorbeeld door het publiceren van de modelcode op een site zoals GitHub of GitLab.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/#risico","title":"Risico","text":"<p>Betrokkenen zijn niet op de hoogte dat hun persoonsgegevens worden verwerkt met een algoritme, waardoor zij hier geen controle over hebben.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking Algoritmeregister</li> <li>Algoritmeregister Publicatiestandaard</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 2.11, 3.12, 3.14, 3.16</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, SV.14, PRI.8</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-04-publiceren-algoritmeregister/#voorbeelden","title":"Voorbeelden","text":"<p>Best Beschreven Algoritme Award</p> <p>Het algoritme 'Eerste Hulp bij Geldzaken' van de gemeente Groningen is het best beschreven algoritme van 2023 in het Algoritmeregister. Volgens de jury zijn de technische en ethische aspecten helder beschreven. En burgers krijgen een volledig beeld over de manier waarop de gemeente het algoritme inzet en gebruikt. Hierbij verwijst de gemeente naar externe pagina\u2019s voor meer uitleg.</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-05-vermelding-in-privacyverklaring/","title":"Vermeld het gebruik van persoonsgegevens in een privacyverklaring","text":"<p>imp-05ImplementatieProjectleiderJuristPrivacy en gegevensbeschermingTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-05-vermelding-in-privacyverklaring/#maatregel","title":"Maatregel","text":"<p>Neem het gebruik van een algoritme op in de privacyverklaring als hierbij persoonsgegevens worden verwerkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-05-vermelding-in-privacyverklaring/#toelichting","title":"Toelichting","text":"<ul> <li>Door in een privacyverklaring te vermelden welke persoonsgegevens worden verwerkt voor het gebruik van een algoritme wordt een betrokkene ge\u00efnformeerd over de verwerking van diens persoonsgegevens.</li> <li>Een privacyverklaring kan op organistieniveau worden opgesteld en ook voor specifieke verwerkingen.</li> <li> <p>In een privacyverklaring wordt in ieder geval het volgende opgenomen:</p> </li> <li> <p>De identiteit en contactgegevens van uw organisatie. En ook die van vertegenwoordigers in de Europese Unie (EU), als deze er zijn.</p> </li> <li>De contactgegevens van de functionaris gegevensbescherming (FG), als een organistie deze heeft.</li> <li>De doeleinden van de verwerking en de AVG-grondslag.</li> <li>De (categorie\u00ebn van) ontvangers van de persoonsgegevens.</li> <li>De persoonsgegevens die worden gegeven buiten de EER of aan een internationale organisatie. En zo ja, op welke juridische grond.</li> <li>De bewaartermijn van de gegevens.</li> <li>De privacyrechten van de betrokkenen, zoals het recht op inzage, rectificatie en gegevens verwijderen.</li> <li>Het recht van de betrokkenen om de toestemming die zij voor een bepaalde verwerking hebben gegeven, altijd weer te mogen intrekken.</li> <li>Dat de betrokkenen een klacht kunnen indienen bij de privacytoezichthouder. In Nederland is dat de Autoriteit Persoonsgegevens (AP).</li> <li>Of de betrokkenen verplicht zijn de persoonsgegevens te verstrekken. En zo ja, waarom. Vermeld dan ook wat de gevolgen zijn als zij de gegevens niet verstrekken.</li> <li>Of er sprake is van geautomatiseerde besluitvorming, inclusief profilering. En zo ja, hoe deze beslissing wordt genomen.</li> <li> <p>Als persoonsgegevens van een andere organisatie zijn ontvangen: de bron waar de persoonsgegevens vandaan komen. En of de gegevens afkomstig zijn van openbare bronnen.</p> </li> <li> <p>Het is denkbaar dat in een specifieke privacyverklaring informatie over onderliggende logica van het algoritme, alsmede het belang en de verwachte gevolgen van die verwerking voor de betrokkene wordt opgenomen. Het is ook denkbaar dat deze informatie in het algoritmeregister wordt opgenomen.</p> </li> <li>Als ervoor wordt gekozen om het algoritme uit te faseren, dan moet informatie in het algoriteregister hierop worden aangepast.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-05-vermelding-in-privacyverklaring/#risico","title":"Risico","text":"<p>Betrokkenen zijn niet op de hoogte dat hun persoonsgegevens worden verwerkt met een algoritme, waardoor zij hier geen controle over hebben en zich niet kunnen beroepen op hun privacyrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-05-vermelding-in-privacyverklaring/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader algoritmes, Auditdienst Rijk, PRI.8</li> <li>Autoriteit Persoonsgegevens</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.12</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-05-vermelding-in-privacyverklaring/#voorbeelden","title":"Voorbeelden","text":"<p>UWV: Privacyverklaring</p> <p>In de algemene privacyverklaring van het UWV staat per situatie wat voor persoonsgegevens kunnen worden verwerkt. Daarnaast staat in heldere taal uitgelegd waarvoor de verwerking van persoonsgegevens binnen UWV in het algemeen nodig is. Daarnaast wordt het \u201cGeautomatiseerd nemen van besluiten en profilering\u201d toegelicht.</p> <p>Bron: Privacyverklaring UWV</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-06-klacht-bezwaar-beroep/","title":"Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme en monitor dit proces","text":"<p>imp-06ImplementatieMonitoring en beheerProjectleiderOntwikkelaarGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-06-klacht-bezwaar-beroep/#maatregel","title":"Maatregel","text":"<p>Richt een proces in zodat burgers of andere belanghebbenden een klacht, bezwaar of beroep kunnen indienen over het gebruik van het algoritme. Zorg voor goede monitoring van dit proces zodat het projectteam op de hoogte is van klachten, bezwaren en beroepen over het systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-06-klacht-bezwaar-beroep/#toelichting","title":"Toelichting","text":"<ul> <li>Een goede datahuishouding van de binnengekomen bezwaren, klachten en beroepen is essentieel om de informatie rondom de klachten, bezwaren en beroepen vanuit datagedreven perspectief te kunnen monitoren.</li> <li>Goede monitoring kan ervoor zorgen dat eventuele patronen in bezwaar, klacht en beroep snel gesignaleerd worden. Eventuele patronen in klacht, bezwaar en beroep kunnen duiden op problemen in het functioneren van het algoritme. Dit kan bijvoorbeeld duiden op discriminerende effecten van het algoritme, waardoor nader onderzoek wenselijk is.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-06-klacht-bezwaar-beroep/#risico","title":"Risico","text":"<p>Een risico van het niet gebruik maken van een proces voor het indienen van klachten, bezwaren of beroepen is dat dit kan leiden tot het niet overzichtelijk hebben van eventuele problemen bij het functioneren van een algoritme, en hierdoor niet de correcte maatregelen kunnen nemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-06-klacht-bezwaar-beroep/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader algoritmes, Auditdienst Rijk, SV.17 en PRI.9</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.08</li> <li>Onderzoek misbruik uitwonendenbeurs, PricewaterhouseCoopers</li> <li>Intern onderzoek controle uitwonendenbeurs, DUO</li> <li>Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-06-klacht-bezwaar-beroep/#voorbeelden","title":"Voorbeelden","text":"<p>UWV: Klacht, melding en bezwaar</p> <p>Het UWV heeft een losse pagina met uitleg over wanneer het beste een klacht, melding of bezwaar gemaakt kan worden. Hieronder valt bijvoorbeeld ook een klacht over de manier waarop het UWV een zaak behandelt. In deze uitleg worden verschillende manieren aangeboden om een klacht aan te bieden en hoe deze behandeld wordt. Daarnaast wordt gemonitord wat voor klachten binnen komen en zijn deze publiekelijk beschikbaar.</p> <p>Bron: Melding, klacht of bezwaar | UWV</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-07-vermelding-in-verwerkingsregister/","title":"Vermeld het gebruik van persoonsgegevens in het verwerkingsregister","text":"<p>imp-07ImplementatieProjectleiderJuristTransparantiePrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-07-vermelding-in-verwerkingsregister/#maatregel","title":"Maatregel","text":"<p>Neem de ontwikkeling en gebruik van een algoritme op in het verwerkingsregister als persoonsgegevens worden verwerkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-07-vermelding-in-verwerkingsregister/#toelichting","title":"Toelichting","text":"<ul> <li>Door in het verwerkingsregister te vermelden welke persoonsgegevens worden verwerkt voor het gebruik van een algoritme wordt een betrokkene ge\u00efnformeerd over de verwerking van diens persoonsgegevens.</li> <li>Hiermee is ook voor de organisatie intern inzichtelijk welke persoonsgegevens voor welke toepassingen worden verwerkt.</li> <li>Het is van belang dat vanaf het moment dat persoonsgegevens worden verwerkt, meteen een vermelding hiervan wordt gemaakt in het verwerkingsregister.</li> <li>Dat betekent dat als persoonsgegevens worden verwerkt bij het ontwikkelen en trainen van het algoritme en deze nog niet in gebruik zijn genomen, al een vermelding moet worden gedaan in het verwerkingsregister.</li> <li>Bij be\u00ebindiging van het gebruik van het algoritme moet het verwerkingsregister worden aangepast.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-07-vermelding-in-verwerkingsregister/#risico","title":"Risico","text":"<p>Betrokkenen en de interne organisatie zijn niet op de hoogte welke persoonsgegevens worden verwerkt met een algoritme, waardoor zij hier geen controle over hebben.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-07-vermelding-in-verwerkingsregister/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.8</li> <li>Autoriteit Persoonsgegevens</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 3.04</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-07-vermelding-in-verwerkingsregister/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam: Blurring as a Service</p> <p>De Gemeente Amsterdam maakt gebruik van een algoritme waarmee mensen op straat beter geanonimiseerd kunnen worden; Blurring as a Service. Hierbij worden persoonsgegevens zoals gezicht en andere lichaamskenmerken (biometrische persoonsgegevens) vervaagd of \u2018geblurd\u2019.</p> <p>Het verwerken van deze gegevens is opgenomen in het volledige verwerkingsregister en is te vinden op pagina 239 onder het kopje \u201c3.1.4. Blurring as a Service\u201d.</p> <p>Bron: Het verwerkingsregister AVG - Gemeente Amsterdam</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-08-politiek-bestuurlijk-besluit/","title":"Maak een openbaar besluit over de inzet van het algoritme","text":"<p>imp-08OrganisatieverantwoordelijkhedenImplementatieProjectleiderGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-08-politiek-bestuurlijk-besluit/#maatregel","title":"Maatregel","text":"<p>Een politieke-bestuurlijk besluit wordt genomen over de inzet van een impactvol algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-08-politiek-bestuurlijk-besluit/#toelichting","title":"Toelichting","text":"<ul> <li>Door een politiek-bestuurlijk besluit te nemen over de inzet of be\u00ebindiging van een impactvol algoritme wordt een afweging en keuze gemaakt over de wenselijkheid, haalbaarheid, transparantie, invulling van menselijke controle en eventueel de mate van onbewuste vooringenomenheid van het betreffende algoritme.</li> <li>Impactvolle algoritmes bevatten aspecten die vragen om politieke afwegingen en niet enkel door de ambtelijke organistie mogen worden beoordeeld.</li> <li>Een voorbeeld van een politiek afweging is wanneer er wel of geen sprake is van een gerechtvaardigd onderscheid wat wordt gemaakt door een algoritme.</li> <li>Het is van belang dat overheidsorganisaties een politiek-bestuurlijk kader opstellen waarin wordt beschreven hoe wordt omgegaan met dergelijke gevallen.</li> <li>Een openbaar besluit draagt bij aan de legitimiteit van de inzet van het algoritme en de controleerbaarheid van de overheidsorganisatie.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-08-politiek-bestuurlijk-besluit/#risico","title":"Risico","text":"<p>De ambtelijke organisatie maakt politieke-bestuurlijke afwegingen en beslissingen bij de inzet of be\u00ebindiging van het gebruik van impactvolle algoritmes, terwijl deze daar niet toe bevoegd is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-08-politiek-bestuurlijk-besluit/#bronnen","title":"Bronnen","text":"<p>Kleur bekennen, Rekenkamer Rotterdam</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-08-politiek-bestuurlijk-besluit/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Amsterdam: College van burgemeester en wethouders</p> <p>Het college van burgemeester en wethouders (CBW) van Gemeente Amsterdam heeft in januari 2024 een openbaar besluit genomen rondom het algoritme Slimme Check. Dit algoritme was bedoeld om de afdeling Handhaving te ondersteunen bij het inschatten van de onderzoekswaardigheid van aanvragen levensonderhoud. Het algoritme maakt een voorselectie van inkomende aanvragen en of deze eerst onderzocht moeten worden of in behandeling genomen kunnen worden. Bij een analyse van de pilot is de conclusie getrokken dat het model niet ge\u00efmplementeerd kon worden vanwege verschillende redenen. Er zouden meerdere veranderingen gedaan moeten worden om Slimme Check verder door te ontwikkelen.</p> <p>Het CBW heeft aan de hand van deze eindevaluatie bepaald dat Slimme Check niet verder ontwikkeld wordt. Dit is gepubliceerd op de website van Gemeente Amsterdam naast besluiten en nieuws rondom andere zaken.</p> <p>Bron: Nieuws uit B en W 24 januari 2024 - Gemeente Amsterdam</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/","title":"Neem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomen","text":"<p>imp-09ImplementatieOntwikkelenOntwikkelaarProjectleiderBeleid en adviesTechnische robuustheid en veiligheidMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#maatregel","title":"Maatregel","text":"<p>Neem technische interventies op in de gebruikersinterface om verkeerd gebruik te voorkomen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#toelichting","title":"Toelichting","text":"<p>Een algoritme wat volledig correcte uitkomsten geeft maar vervolgens verkeerd wordt gebruikt kan leiden tot problemen. Neem bijvoorbeeld een algoritme wat een tekstdocument controleert en voorstelt aan de gebruiker of het compleet is, of nog onderdelen mist. Wanneer je dan een \u2018goedgekeurd\u2019 knop rood maakt, en een \u2018afgekeurd\u2019 knop groen, is er een kans dat de gebruiker uit gewoonte op de verkeerde klikt en daarmee alsnog een onjuiste beslissing neemt. Als deze keuze vervolgens als feedback ook weer wordt doorgevoerd in het systeem kan het algoritme ook nog verkeerd gedrag aanleren.</p> <p>Werk bijvoorbeeld aan de hand van User Centered Design principes om de gebruiker centraal te stellen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#evaluatie","title":"Evaluatie","text":"<p>Breng risico\u2019s in kaart door het goed testen van het systeem in een praktijksetting. Evalueer hier het gedrag van de gebruiker in het grotere systeem.</p> <p>Onderdelen hiervan zijn:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#aandacht-van-de-gebruiker","title":"Aandacht van de gebruiker","text":"<p>Oog en muisbewegingen kunnen inzicht geven waar de aandacht van de gebruiker naartoe gaat. Als er bijvoorbeeld een controle gedaan moet worden over de uitkomst van het algoritme voor het maken van een definitieve beslissing wil je inzicht krijgen of de gebruiker naar de juiste elementen kijkt om die beslissing te maken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#interactiegedrag-van-de-gebruiker","title":"Interactiegedrag van de gebruiker","text":"<p>Clicks, scrollen, of het gebruik van het algoritme op zich (in plaats van zelf tot een beslissing komen) horen bij het gedrag van de gebruiker. Dit kan inzicht geven of het systeem correct wordt gebruikt, maar ook waar gebruikers mogelijk juist blijven hangen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#feedback-mechanismes","title":"Feedback mechanismes","text":"<ul> <li>Zijn er manieren waarop de gebruiker feedback kan geven over de uitkomsten wanneer deze naar vermoeden niet kloppen?</li> <li>Zijn er manieren waarop de gebruiker om hulp kan vragen en wat voor vragen zijn dit?</li> <li>Op wat voor manier worden errors in het systeem doorgegeven aan de gebruiker?</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#transparantie-en-uitlegbaarheid","title":"Transparantie en uitlegbaarheid","text":"<p>Een correct gebruik begint bij een duidelijke instructie en inzicht hoe een algoritme werkt en hoe daar mee om te gaan. Evalueer of de gebruikte methodes hiervoor hun doel bereiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#toegankelijkheid","title":"Toegankelijkheid","text":"<p>Het is belangrijk om te controleren of het algoritme toegankelijk in gebruik is voor iedereen, inclusief personen met een beperking.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#beveiliging-en-controle","title":"Beveiliging en controle","text":"<p>Het onjuist gebruik waarvoor specifiek gedrag opgemerkt kan worden bij bovenstaande evaluaties moet worden gemonitored. Vervolgens kunnen er beveiligingen (denk aan een melding \u2018weet je het zeker?\u2019) ingebouwd worden als zulk gedrag wordt geregistreerd. Kijk vervolgens of deze interventies effectief zijn om fouten te voorkomen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#risico","title":"Risico","text":"<p>Een gebruikersinterface die verkeerd gebruik door gebruikers mogelijk maakt, kan ervoor zorgen dat gebruikers verkeerde invoerwaarden geven, zich niet aan de beoogde werkwijze houden of per ongeluk toegang geven aan kwaadwillenden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#bronnen","title":"Bronnen","text":"<ul> <li>Valid Useful User Experience Measurement </li> <li>7 fundamental user experience (UX) design principles all designers should know (2024) - UX Design Institute</li> <li>Web Content Accessibility Guidelines (WCAG) 2.2</li> <li>User Centered Design (UCD)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-09-interventies-ux/#voorbeelden","title":"Voorbeelden","text":"<p>Verschillende overheden \u2013 Octobox Anonimiseren</p> <p>Verschillende overheden maken gebruik van Octobox Anonimiseren, een anonimiseringstool die (persoons)gegevens aanduidt voor maskering. Octobox zoekt deze (persoons)gegevens binnen het document, ongeacht de inhoud. Na deze aanduiding moet er door een vakinhoudelijk persoon gecontroleerd worden of deze gegevens inderdaad gemaskeerd moeten worden of niet. Deze kunnen goed- en afgekeurd worden en ook gewijzigd worden voor goedkeuring. Daarnaast is er de optie om handmatig informatie te maskeren om zo andere (of gemiste) informatie te maskeren. De tool is op deze manier op een intu\u00eftieve manier te gebruiken door medewerkers.</p> <p>Bron: Octobox Anonimiseren</p> <p>Gemeente Veere \u2013 AI-analyse tool </p> <p>De gemeente Veere heeft een analyse tool voor het versnellen en vergemakkelijken van het verwerken van input bij participatieprocessen. Hierbij worden bijvoorbeeld samenvattingen en categorie\u00ebn gemaakt om zo de gebruiker te helpen bij het analyseren. De gebruikersinterface zorgt ervoor dat de originele bron data ook standaard mee getoond worden om zo te verduidelijken waar de informatie vandaan komt. Daarnaast worden ook altijd referenties naar bron meegenomen in de samenvattingen. De interface maakt de gebruiker ook bewust van mogelijke fouten of hallucinaties die gemaakt kunnen worden door waarschuwingen te tonen.</p> <p>Bron: AI-analyse tool (AI Sensemaking) - Gemeente Veere</p> <p>Gemeente Ede  \u2013 WOZ-Taxatiemodellen </p> <p>De gemeente Ede heeft een algoritme in gebruik als ondersteuning bij het bepalen (en controleren) van de WOZ-waarde van woningen. Dit wordt gedaan aan de hand van Machine Learning modellen die op basis van onder andere woning- en locatiekenmerken gecombineerd met markt- en verkoop condities de WOZ-waarde kan bepalen. Hierbij wordt bepaald welke kenmerken het meeste gewicht hebben voor deze bepaling.</p> <p>Als de taxateurs de WOZ-waarde gaan bepalen, zien zij ook de algoritmisch bepaalde waarde. Hierbij is aan de hand van kleuren de zekerheid van de waarde aangegeven. Groen geeft een hoge zekerheid aan, oranje een redelijke zekerheid en rood een matige zekerheid. Op deze manier wordt voor taxateurs direct duidelijk en intu\u00eftief wat de waarden inhouden.</p> <p>Bron: WOZ-Taxatiemodellen</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-10-proces-privacyrechten/","title":"Spreek af hoe de organisatie omgaat met privacy-verzoeken","text":"<p>imp-10OrganisatieverantwoordelijkhedenOntwikkelenProjectleiderBeleid en adviesJuristPrivacy en gegevensbeschermingGovernanceData</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-10-proces-privacyrechten/#maatregel","title":"Maatregel","text":"<p>Richt een proces in waarmee betrokkenen hun privacyrechten kunnen inroepen als algoritmes worden ontwikkeld of gebruikt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-10-proces-privacyrechten/#toelichting","title":"Toelichting","text":"<ul> <li>Betrokkenen moeten hun persoonsgegevens kunnen inzien, rectificeren, laten verwijderen of het gebruik ervan beperken bij het toepassen van algoritmes.</li> <li>Betrokkenen moeten hun verzoek kunnen indienen bij de betreffende organisatie. Denk hierbij aan het inrichten van een privacyloket.</li> <li>Er zullen afspraken moeten worden gemaakt door servicemanagement om in te richten hoe deze verzoeken effectief kunnen worden behandeld door bijvoorbeeld het ontwikkel- of beheerteam (aanbieder).</li> <li>Bij het inrichten van servicemanagement moet zijn nagedacht over hoe een verzoek tot het inzien, rectificeren, verwijderen of beperken van de verwerking van persoonsgegevens op een betekenisvolle manier kan of moet worden behandeld.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-10-proces-privacyrechten/#risico","title":"Risico","text":"<p>Betrokkenen hebben geen controle over hun persoonsgegevens doordat ze geen beroep kunnen doen op hun privacyrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-10-proces-privacyrechten/#bronnen","title":"Bronnen","text":"<p>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.9</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/6-imp-10-proces-privacyrechten/#voorbeelden","title":"Voorbeelden","text":"<p>Ministerie van Algemene Zaken: Privacyverzoek</p> <p>Het Ministerie van Algemene Zaken (AZ) heeft een online formulier waar burgers een privacyverzoek kunnen doen. Dit kan zowel via post als digitaal. Op deze pagina staat ook uitgelegd welke gegevens nodig zijn voor een (correcte) aanvraag. Daarnaast wordt vermeld hoe de gegevens verwerkt worden en hoe lang deze bewaard blijven voor de aanvraag. Als laatste wordt ook aangegeven bij wie men terecht kan voor vragen of klachten.</p> <p>Bron: Formulier Privacyverzoek - Ministerie van Algemene Zaken</p> <ul> <li>Privacyverzoek Gemeente Amsterdam</li> </ul> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-01-backups-maken/","title":"Maak back-ups van algoritmes","text":"<p>mon-01OntwikkelenMonitoring en beheerOntwikkelaarBeleid en adviesTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-01-backups-maken/#maatregel","title":"Maatregel","text":"<p>Back-up kopie\u00ebn van informatie, software en systeemafbeeldingen dienen regelmatig te worden gemaakt en getest. Idealiter gebeurt dit in overeenstemming met een afgesproken back-up beleid. Maak back-ups van de omgeving van het algoritme en zorg ervoor dat het algoritme en de data hersteld kunnen worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-01-backups-maken/#toelichting","title":"Toelichting","text":"<p>Er is een back-up beleid waarin de eisen voor het bewaren en beschermen zijn gedefinieerd en vastgesteld. Dit beleid moet vervolgens worden vertaald naar (technische) maatregelen om het kunnen maken van back-ups te realiseren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-01-backups-maken/#risico","title":"Risico","text":"<p>Als er geen regelmatige back-ups worden gemaakt en de restore-procedure niet regelmatig wordt getest, bestaat het risico dat er geen hersteloptie is en er een mogelijkheid van gegevensverlies is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-01-backups-maken/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, 12.3.1.1, 12.3.1.4, 12.3.1.5.</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.26</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.08</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-01-backups-maken/#voorbeelden","title":"Voorbeelden","text":"<p>Voorbeeld: Informatie Beveligingsdienst - Handreiking back-up en herstel</p> <p>De Informatiebeveiligingsdienst van de Vereniging Nederlandse Gemeenten (VNG) heeft een handreiking back-up en herstel ontwikkeld. Hierin staat uitleg over de wetgeving rondom back-ups en het herstellen van back-ups.</p> <p>Aan het einde van deze handreiking staat ook een voorbeeld voor beleid voor gemeentes. Hierin staan al een aantal uitgangspunten die de gemeente alleen hoeft te kopi\u00ebren en te ondertekenen.</p> <p>Bron: Producten - Informatiebeveiligingsdienst</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/","title":"Beveilig de software","text":"<p>mon-02Dataverkenning en datapreparatieOntwikkelenMonitoring en beheerProjectleiderBeleid en adviesOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/#maatregel","title":"Maatregel","text":"<p>Zorg voor een goede beveiliging van de verschillende softwarecomponenten van een algoritme. Bepaal of de data voldoende is beveiligd en maak hierin onderscheid tussen de inputdata en de outputdata.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/#toelichting","title":"Toelichting","text":"<p>Er zijn beheersmaatregelen die kunnen helpen bij het zorgen voor een goede beveiliging van verschillende (software-)componenten van een algoritme. Hierbij kan worden gedacht aan: Het toepassen van wachtwoordbeheer, Baseline Informatiebeveiliging Overheid, de NCSC Handreiking voor implementatie van detectieoplossingen en het Impact Assessment Mensenrechten en Algoritmes.</p> <ul> <li>Inzicht cre\u00ebren in de beoogde opzet van de IT-infrastructuur (de architectuur) en de werkelijk geconfigureerde hard- en software. (CIS Control 1, BIO 8.1.1).</li> <li>Inrichten van een formeel proces voor het beheer van technische kwetsbaarheden. Dit omvat minimaal periodieke (geautomatiseerde) controle op de aanwezigheid van kwetsbaarheden in de te toetsen systemen, een risicoafweging en navolgbare afwerking daarvan of risicoacceptatie (BIO 12.6).</li> <li>Beoordelen, patchen en updaten van kwetsbaarheden in IT-systemen als deze bekend zijn. (BIO 12.6.1)</li> <li>Verwijderen of deactiveren van softwarecomponenten en services die niet noodzakelijk zijn voor het functioneren van het algoritme om beveiligingsrisico\u2019s te beperken. (BIO 12.6.1)</li> <li>Er vindt zonering plaats binnen de technische infrastructuur conform de uitgangspunten die zijn vastgelegd in een operationeel beleidsdocument, waarbij minimaal sprake is van scheiding tussen vertrouwde en onvertrouwde netwerken (BIO 9.4.2). Denk ook aan het scheiden in netwerken (BIO 13.1.3).</li> <li>Actieve monitoring van de algoritmedata vindt plaats zodat beveiligingsincidenten en -gebeurtenissen in een vroeg stadium worden gedetecteerd. (BIO 12.4.1, NCSC Handreiking voor implementatie van detectieoplossingen).</li> <li>Netwerkverkeer en componenten worden actief gemonitord (BIO 12.4.1).</li> <li>Beoordeel of de data ten behoeve van het ontwikkelen en gebruiken van het algoritme voldoende is beveiligd. Maak hierin onderscheid tussen de trainingsdata, inputdata en de outputdata.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/#risico","title":"Risico","text":"<p>Oneigenlijke toegang van buitenaf kan plaatsvinden via zwakheden in het systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.18 t/m IB.25</li> <li>NCSC Handreiking voor implementatie van detectieoplossingen</li> <li>Handleiding Quickscan Information Security</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-02-beveiliging-algoritme/#voorbeelden","title":"Voorbeelden","text":"<p>Voorbeeld: Nationaal Cyber Security Centrum - Richtlijnen veilig software ontwikkelen</p> <p>In een publicatie van het Nationaal Cyber Security Centrum van het Ministerie van Justitie en Veiligheid over het ontwikkelen van veilige software staat beschreven hoe op beleidsmatig en beheersingsniveau beveiligingsrichtlijnen toegepast kunnen worden. Daarnaast wordt het uitvoeringsdomein (voor implementatie) ook benoemd, maar wordt deze opgesplitst in webapplicaties en mobiele apps.</p> <p>Bron: Beleids- en beheersingsrichtlijnen voor de ontwikkeling van veilige software.</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-03-informatiebeveiligingsincidenten/","title":"Maak een noodplan voor beveiligingsincidenten","text":"<p>mon-03OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderBeleid en adviesJuristTechnische robuustheid en veiligheidGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-03-informatiebeveiligingsincidenten/#maatregel","title":"Maatregel","text":"<p>Richt een proces in waarmee beveiligingsincidenten met betrekking tot algoritmes en data zo spoedig mogelijk worden opgelost.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-03-informatiebeveiligingsincidenten/#toelichting","title":"Toelichting","text":"<p>Er zijn procedures aanwezig die borgen dat beveiligingsincidenten met betrekking tot algoritmes en data zo spoedig mogelijk, afhankelijk van de kwalificatie van het incident, worden opgepakt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-03-informatiebeveiligingsincidenten/#risico","title":"Risico","text":"<p>Te late reactie op incidenten kan ervoor zorgen dat de BIV (beschikbaarheid, integriteit en vertrouwelijkheid) van het algoritme of data kan worden aangetast.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-03-informatiebeveiligingsincidenten/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid, BIO 12.3.1.1, 12.3.1.4, 12.3.1.5</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, IB.30</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 4.06</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-03-informatiebeveiligingsincidenten/#voorbeelden","title":"Voorbeelden","text":"<p>Voorbeeld: Ministerie van Economische Zaken - Uitwijk- en herstelplan</p> <p>Het Ministerie van Economische zaken heeft een template voor een Disaster Recovery Plan (DRP) opgesteld. Aan de hand van dit document kunnen duidelijke handelingen en verantwoordelijkheden opgeschreven worden voor wanneer een algoritme stopgezet moet worden.</p> <p>Dit DRP is vrij algemeen en heeft geen specificaties voor algoritmes in het template staan. Dit zal dus verder uitgewerkt moeten worden, maar dit DRP kan als basis dienen voor het verder uitwerken.</p> <p>Bron: Uitwijk- en herstelplan</p> <p>Voorbeeld: Netwerk Informatiebeveiliging en Privacy - Incident Management</p> <p>Het Netwerk Informatiebeveiliging en Privacy (IBP) voor primair en voortgezet onderwijs heeft een template voor incidentmanagementbeleid, het incidentmanagementproces en een beveiligingsincident stappenplan &amp; logboek. In het procestemplate staat onder andere een procesflow, een beschrijving van alle processtappen en een communicatieplan.</p> <p>Deze documenten zijn specifiek voor primair en voortgezet onderwijs maar zijn gemakkelijk aan te passen.</p> <p>Bron: Incidentmanagement</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/","title":"Maak een evaluatieplan voor tijdens het gebruik van het algoritme","text":"<p>mon-04Monitoring en beheerProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#maatregel","title":"Maatregel","text":"<p>Maak een evaluatieplan voor wanneer het algoritme in gebruik is. Dit plan bevat wanneer, wat en hoe er ge\u00ebvalueerd dient te worden om te valideren of het model nog in lijn is met de vastgestelde doelstelling.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#toelichting","title":"Toelichting","text":"<p>Het evaluatieplan moet aangeven op welke momenten er wordt ge\u00ebvalueerd, wat er opnieuw wordt ge\u00ebvalueerd en hoe dat wordt gedaan.</p> <p>Voor het opstellen van het evaluatieplan zijn de volgende stappen nodig:</p> <ol> <li>Bepaal of periodieke controle noodzakelijk is</li> <li>Bepaal bij welke gebeurtenissen het algoritme ge\u00ebvalueerd moet worden</li> <li>Bepaal wat er ge\u00ebvalueerd moet worden</li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#bepaal-of-periodieke-controle-noodzakelijk-is","title":"Bepaal of periodieke controle noodzakelijk is","text":"<p>Stel vast of er periodieke momenten zijn vanuit bijvoorbeeld wetgeving, organisatiebeleid of risicomanagement waarop het wenselijk is dat het algoritme ge\u00ebvalueerd wordt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#bepaal-bij-welke-gebeurtenissen-het-algoritme-geevalueerd-moet-worden","title":"Bepaal bij welke gebeurtenissen het algoritme ge\u00ebvalueerd moet worden","text":"<p>Wat zijn gebeurtenissen die om een nieuwe evaluatie vragen? Denk bijvoorbeeld aan momenten waarop het bijtrainen van het model noodzakelijk is, zoals:</p> <ul> <li>Een wijziging in de data of het algoritme.</li> <li>Aangepaste wetgeving.</li> <li>Andere context of tijd waarin het algoritme gebruikt wordt.</li> <li>Een nieuwe werkwijze.</li> <li>Het optreden van een incident.</li> <li>Gebruikersfeedback.</li> <li>Een verandering in de gebruikscontext (bijv. een situatie als COVID-19).</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#bepaal-wat-er-geevalueerd-moet-worden","title":"Bepaal wat er ge\u00ebvalueerd moet worden","text":"<p>Bepaal welke onderdelen van het algoritme ge\u00ebvalueerd dienen te worden bij een periodieke controle of wanneer er een gebeurtenis plaatsvindt waardoor evaluatie wenselijk is.</p> <p>Wat minimaal periodiek ge\u00ebvalueerd moet worden is:</p> <ul> <li>nauwkeurigheid</li> <li>betrouwbaarheid</li> <li>reproduceerbaarheid</li> <li>bias</li> <li>veiligheid</li> <li>grondrechten</li> <li>privacy.</li> </ul> <p>Bij een evaluatie hoeft niet altijd alles weer ge\u00ebvalueerd te worden. Dit hangt af van het type wijzigingen die er zijn geweest en van de aspecten die continu worden gemonitored. Leg vast wat er wanneer ge\u00ebvalueerd dient te worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#documenteer-voor-en-tijdens-iedere-evaluatie","title":"Documenteer voor en tijdens iedere evaluatie","text":"<p>Zorg dat de benodigde informatie voor de evaluatie wordt opgeslagen en beschikbaar is voor de evaluatiemomenten. Denk aan invoerwaarden, resultaten en gebruikersstatistieken.</p> <p>Betrek bij het opstellen van dit plan een diverse groep van belanghebbenden met o.a. ontwikkelaars, gebruikers en ethisch adviseurs. Zorg dat het evaluatieplan periodiek wordt herzien of deze nog voldoet.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#risico","title":"Risico","text":"<p>Er zullen veranderingen plaatsvinden in de gebruikscontext, de data en in het algoritme zelf (bijv. door bijtrainen). Wanneer niet wordt ge\u00ebvalueerd tijdens het gebruik is het onbekend of het algoritme nog steeds werkt zoals beoogd en voldoet aan de acceptatiecriteria.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereisteaia-03Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteemaia-18Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder inaia-22De werking van hoog-risico-AI-systemen wordt gemonitordaia-34Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algemene Rekenkamer, 2.14</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-04-evaluatieplan/#voorbeelden","title":"Voorbeelden","text":"<p>UWV - Claim beoordelings- en borgingsysteem</p> <p>Om te bepalen of iemand nog kan werken en hoeveel maakt het UWV gebruik van een 'Claim beoordelings- en borgingsysteem' (CBBS). Dit systeem bepaalt aan de hand van onder andere de beoordeling van de verzekeringsarts en de UWV-polisadministratie het arbeidsongeschiktheidspercentage. Deze waarde wordt gebruikt als basis om een geschikte baan te vinden voor het individu dat beoordeeld wordt. Het UWV geeft aan CBBS iedere dag te testen om zo te kijken of het goed werkt. Daarnaast wordt er specifiek gecontroleerd na wijzigingen in bijvoorbeeld wet- en regelgeving, bij functieveranderingen of als de zwaarte van een functie veranderd. Dit evaluatiebeleid geeft dus aan wat er gecontroleerd wordt en wanneer.</p> <p>Bron: Claim Beoordelings- en Borgingsysteem</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-05-evalueer-bij-veranderingen-in-data/","title":"Monitor regelmatig op veranderingen in de data. Bij veranderingen evalueer je de prestaties en output van het algoritme.","text":"<p>mon-05Monitoring en beheerOntwikkelaarDataTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-05-evalueer-bij-veranderingen-in-data/#maatregel","title":"Maatregel","text":"<p>Monitor regelmatig op veranderingen in de inputdata. Bij geconstateerde veranderingen evalueer je de prestaties en de output van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-05-evalueer-bij-veranderingen-in-data/#toelichting","title":"Toelichting","text":"<p>De inputdata kan voortdurend veranderen. Dat kan komen doordat de context waarin het algoritme wordt gebruikt verandert, of door een technische fout wanneer de data bijvoorbeeld niet goed is ingelezen of aangeleverd. Het te laat opmerken van zo'n verandering kan grote gevolgen hebben. Daarom is het belangrijk om regelmatig te controleren en evalueren of:</p> <ul> <li>De data van voldoende kwaliteit is voor de beoogde toepassing.</li> <li>Het algoritme nog presteert in lijn met de vastgestelde doelen.</li> <li>De gegevens op de juiste en volledige manier worden verwerkt.</li> </ul> <p>Zeker wanneer er gebruikt wordt gemaakt van informatie van derden is het belangrijk om regelmatig te controleren of er veranderingen in de data zijn. Goede monitoring op datakwaliteit zorgt ervoor dat je voldoende controle hebt over de kwaliteit van de data, zelfs als je hiervoor afhankelijk bent van andere partijen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-05-evalueer-bij-veranderingen-in-data/#risico","title":"Risico","text":"<p>Door veranderingen in de data presteert het model niet meer zoals verwacht.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-05-evalueer-bij-veranderingen-in-data/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader algoritmes, Auditdienst Rijk, DM.8</li> <li>Toetsingskader Algoritmes Algemene Rekenkamer, 1.02, 1.08, 2.06, 2.08, 2.13</li> <li>Norm: \"Information technology - Artificial intelligence - Data life cycle framework\"</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-05-evalueer-bij-veranderingen-in-data/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Den Haag: Quality-Bot</p> <p>De gemeente Den Haag maakt gebruik van een datakwaliteit algoritme: Quality-Bot (Q-Bot). Dit algoritme controleert bestaande en nieuwe patronen in de data om zo de bronhouder nieuwe inzichten te kunnen geven in de data. Op deze manier kan datakwaliteit ingeschat worden en kunnen fouten worden ontdekt. Dit algoritme monitort dus geen directe veranderingen autonoom maar communiceert deze naar de werknemer. Op deze manier kan gecontroleerd worden of wat voor data veranderingen er optreden. Het evalueren van (vervolg) prestaties is niet mogelijk omdat dit algoritme niet direct is aangesloten op een vervolg algoritme maar gezien kan worden als een voor-traject.</p> <p>Bron: Algoritme datakwaliteit - Gemeente Den Haag</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/","title":"Meten, monitoren en rapporteren van milieu-impact van algoritmes","text":"<p>mon-06OntwerpMonitoring en beheerOntwikkelaarBeleid en adviesProjectleiderDuurzaamheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#maatregel","title":"Maatregel","text":"<p>Inventariseer en monitor de milieu-impact van algoritmes (bijvoorbeeld door het doen van een impact-assessment) zowel tijdens ontwerp als bij het gebruik en rapporteer deze om duurzame keuzes mogelijk te maken.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#toelichting","title":"Toelichting","text":"<p>Tref bijvoorbeeld de volgende maatregelen, wanneer je de milieu-impact van algoritmes gaat inventariseren of monitoren:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#digital-product-passports","title":"Digital Product Passports","text":"<p>De milieu-impact van algoritmes kan worden gemeten en geoptimaliseerd door een Digital Product Passport (DPP) te overwegen. DPP's bieden een platform voor duurzame rapportage door middel van real-time informatie over onder andere CO\u2082-uitstoot, herkomst en energiegebruik, wat kan helpen om de ecologische voetafdruk van een algoritme transparant te maken. Door deze gegevens structureel te verzamelen en te delen, kunnen gebruikers en bedrijven inzicht krijgen in de duurzaamheidsprestaties. De milieu-impact van verschillende algoritmes/ modellen kan een rol spelen bij het kiezen van een model in de ontwerpfase. Ook kan het ervoor zorgen dat je later kiest om een ander model te gebruiken of ervoor kiest om het gebruik van een model of systeem zelfs te be\u00ebindigen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#milieu-impact-assessments","title":"Milieu-impact assessments","text":"<p>Wanneer de milieu-impact (in bepaalde mate) inzichtelijk is, kan er een milieu-impact assessment worden gedaan. Ga na of je organisatie er een heeft of overweeg deze te ontwikkelen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#periodieke-monitoring","title":"Periodieke monitoring","text":"<p>Probeer ook periodieke monitoringsrapporten op te stellen waarin de milieu-impact van algoritmes wordt bijgehouden. Hiermee vergroot je de duurzaamheid door tijdig verbeteringen te signaleren en door te voeren. Hierbij kan ook een onderscheid worden gemaakt in de impact tijdens de trainingsfase van het algoritme en de gebruiksfase.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#risico","title":"Risico","text":"<p>Wanneer in de ontwerpfase niet wordt nagedacht over milieu-impact kan onbewust voor een algoritme of model worden gekozen dat meer energie verbruikt (en wellicht hogere kosten met zich mee brengt) dan een model dat misschien even goed presteert voor het gekozen doel. Zonder structurele monitoring van de milieu-impact kan de organisatie onbewust bijdragen aan een hoge CO\u2082-uitstoot en hoge energieverbruikskosten.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#bronnen","title":"Bronnen","text":"<ul> <li>Coalitie Duurzame Digitalisering - Digital Product Passport</li> <li>Onderzoekskader Algoritmes Auditdienst Rijk, DM.24</li> <li>Ethische richtsnoeren voor betrouwbare KI, Hoofdstuk II 1.6: Maatschappelijk en milieuwelzijn</li> <li>Eindrapport 'Generatieve AI en duurzaamheid' (Universiteit Utrecht)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-06-meten-milieu-impact/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/","title":"Stel een plan op voor continue monitoring","text":"<p>mon-07Monitoring en beheerProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#maatregel","title":"Maatregel","text":"<p>Maak een plan voor wat er continu gemonitored moet worden tijdens het gebruik van het algoritme. Dit plan bevat niet alleen wat en hoe er gemonitored wordt, maar ook bij welke overschrijdingen actie moet worden ondernomen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#toelichting","title":"Toelichting","text":"<p>Het plan voor monitoring moet aangeven wat er continu moet worden gemonitored en op welke manier dit moet gebeuren. Daarnaast bevat het plan in welke situaties er actie moet worden ondernomen, en wie daarbij betrokken moet zijn.</p> <p>Voor het opstellen van het plan voor monitoring zijn de volgende stappen nodig:</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#bepaal-waar-je-continu-op-wilt-monitoren","title":"Bepaal waar je continu op wilt monitoren","text":"<p>Denk hierbij aan:</p> <ul> <li>Bias en discriminerende effecten.</li> <li>Toegankelijkheid van het model (uitvallen of haperingen).</li> <li>Foutmeldingen.</li> <li>Prestaties: werkt het model nog zoals beoogd.</li> <li>Datakwaliteit en data drift (de data die in het systeem wordt ingevoerd kan veranderen over tijd).</li> <li>Invoerwaarden (probeert een gebruiker het systeem te manipuleren).</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#bepaal-hoe-je-het-gaat-meten-en-welke-informatie-je-hiervoor-nodig-hebt","title":"Bepaal hoe je het gaat meten en welke informatie je hiervoor nodig hebt","text":"<p>Welke metrieken worden er gebruikt om de vastgelegde aspecten te meten? Welke informatie moet er opgeslagen worden om deze metrieken te kunnen meten? Analyseer ook of er aspecten zijn die niet met metrieken gemeten kunnen worden en hoe je die aspecten kan monitoren.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#bepaal-de-grenswaarden-bij-welke-overschrijding-moet-er-actie-worden-genomen","title":"Bepaal de grenswaarden: bij welke overschrijding moet er actie worden genomen?","text":"<p>Voor een effectieve monitoring is het van belang dat duidelijk is wanneer er actie moet worden ondernomen op de resultaten. Leg vast voor elk van de aspecten die gemonitored worden bij welke waarden er actie moet worden genomen. Hiervoor is het noodzakelijk om een duidelijke omschrijving te hebben wat de beoogde werking van het systeem is. Het is ook mogelijk om meerdere waarden per monitor te bepalen, waarbij bij een eerste overschrijding alleen een waarschuwing wordt gegeven en bij een tweede bij het algoritme bijvoorbeeld wordt overgegaan tot het noodplan.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#bepaal-welke-acties-genomen-moeten-worden-bij-een-overschrijding","title":"Bepaal welke acties genomen moeten worden bij een overschrijding","text":"<p>Je legt hier in eerste instantie vast of het algoritme moet worden stopgezet, beperkt moet worden in de inzet of in gebruik kan blijven. Ten tweede bepaal je wat voor andere acties er moeten worden genomen, bijvoorbeeld of er een nieuwe uitgebreide evaluatie moet plaatsvinden, moet het algoritme worden bijgewerkt, moet er nieuwe data verzameld worden, moet de beveiliging verbeterd worden of moet er worden overgestapt op plan B.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#leg-vast-hoe-en-aan-wie-er-een-waarschuwing-wordt-gegeven-wanneer-een-waarde-wordt-overschreden","title":"Leg vast hoe en aan wie er een waarschuwing wordt gegeven wanneer een waarde wordt overschreden","text":"<p>Om effectief te kunnen ingrijpen is het van belang dat wordt vastgelegd in het monitoringsplan op welke manier er een waarschuwing wordt gegeven, aan wie deze waarschuwing wordt gegeven en welke informatie deze persoon nodig heeft. Bepaal bijvoorbeeld ook of een systeem automatisch wordt uitgeschakeld of dat een mens die keuze moet maken.</p> <p>Betrek bij het opstellen van dit plan een diverse groep van belanghebbenden met onder andere ontwikkelaars, gebruikers en ethisch adviseurs. Zorg dat het evaluatieplan periodiek wordt herzien of deze nog voldoet.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#risico","title":"Risico","text":"<p>Tijdens dagelijks gebruik wil je continu monitoren of het systeem nog werkt zoals beoogd. Wanneer dit niet gebeurt worden mogelijke fouten en veiligheidsrisico\u2019s niet opgemerkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#bijbehorende-vereisten","title":"Bijbehorende vereiste(n)","text":"Bekijk alle vereisten IDVereisteaia-03Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteemaia-18Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder inaia-22De werking van hoog-risico-AI-systemen wordt gemonitordaia-34Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#bronnen","title":"Bronnen","text":"<ul> <li>Toetsingskader Algemene Rekenkamer, 2.14</li> <li>Toetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit, College voor de Rechten van de Mens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-07-plan-continue-monitoring/#voorbeelden","title":"Voorbeelden","text":"<p>Gemeente Montferland - Montferland AI</p> <p>De gemeente Montferland heeft een chatbot (MAI) ontwikkeld voor het beantwoorden van algemene vragen. Op deze manier is algemene informatie binnen de gemeente 24/7 bereikbaar voor haar inwoners en worden de medewerkers ontlast van de live chat. Om privacy te waarborgen wordt MAI continu via een automatisch systeem op locatie gemonitored via het controleren van de logbestanden per chat. Als in dit logbestand privacygevoelige informatie gesignaleerd wordt, wordt er direct melding van gemaakt. In dat geval wordt een mail verstuurd naar de servicedesk, systeembeheer en naar de hoofdontwikkelaar van MAI. Daarnaast wordt er een incident aangemaakt door de servicedesk en wordt het incident getoond op het grote scherm bij de systeembeheerders.</p> <p>Bron: Mai (Montferland AI) - Gemeente Montferland</p> <p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl </p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/","title":"Controleer regelmatig of een algoritme voldoende weerbaar is tegen bekende aanvallen","text":"<p>mon-08OntwikkelenVerificatie en validatieMonitoring en beheerOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/#maatregel","title":"Maatregel","text":"<p>Controleer regelmatig of je algoritme bestand is tegen aanvallen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/#toelichting","title":"Toelichting","text":"<p>Veel algoritmes veranderen in de loop van tijd. Daarom is het belangrijk om periodiek te blijven testen of de ingebouwde defensiemechanismen goed werken. In traditionele cyber security wordt hiervoor de term red teaming of pentesting gebruikt.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/#pentesting","title":"Pentesting","text":"<p>Met pentesting wordt in feite een interactie tussen een aanvaller en het algoritme nagebootst. Verschillende bedrijven die gespecialiseerd zijn in traditionele pentesting van IT systemen bieden nu ook specifiek pentesting van AI aan. Indien er voldoende kennis aanwezig is, is het mogelijk  dit zelf te implementeren. Dit kan bijvoorbeeld met behulp van de open-source ontwikkelde Adversarial Robustness Toolbox (ART) ontwikkeld door IBM (en nu in beheer door de Linux Foundation).</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/#top-10-security-risicos-van-llms","title":"Top-10 security risico\u2019s van LLM\u2019s","text":"<p>Het is lastig in te schatten met wat voor aanvallen er rekening gehouden moet worden voor een AI-systeem. Hiervoor heeft OWASP een top 10 opgesteld van security risico\u2019s van LLM\u2019s. Veel risico's zijn waarschijnlijk ook van toepassing op andere soorten AI-systemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/#risico","title":"Risico","text":"<p>Als niet periodiek getest wordt of een algoritme nog bestand is tegen aanvallen, wordt de kans groter dat een aanvaller succesvol is.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/#bronnen","title":"Bronnen","text":"<ul> <li>Nightfall, AI Model Red Teaming</li> <li>IBM, Adversarial Robustness Toolbox</li> <li>OWASP Top 10 for Large Language Model Applications</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/7-mon-08-test-weerbaarheid-tegen-aanvallen/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/8-uit-01-archiveren/","title":"Bij uitfaseren en doorontwikkeling wordt correct omgegaan met data en modelinformatie","text":"<p>uit-01UitfaserenOntwerpOntwikkelaarTechnische robuustheid en veiligheidPrivacy en gegevensbeschermingTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/8-uit-01-archiveren/#maatregel","title":"Maatregel","text":"<p>Verwijder bij uitfasering van je algoritme gevoelige gegevens in het kader van privacy en gegevensbescherming, maar behoud essenti\u00eble modelinformatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/8-uit-01-archiveren/#toelichting","title":"Toelichting","text":"<p>Als het doel van het algoritme niet langer bestaat, kan een algoritme (zowel data als model) uitgeschakeld of verwijderd worden. Tegelijkertijd kan dit voor door het algoritme gemaakte beslissingen betekenen dat niet meer te achterhalen is welke data is gebruikt en waarom het model deze zo beoordeeld heeft. In de ontwerpfase van het algoritme wordt daarom vastgelegd welke elementen bewaard dienen te worden en waarom.</p> <p>Door op een juiste manier om te gaan met uitfaseren kan worden voorkomen dat de potenti\u00eble latere effecten van algoritmes worden geadresseerd. De werking van een algoritme en de manier waarop beslissingen in het verleden zijn genomen, blijven behouden. Dit zorgt voor transparantie en controleerbaarheid of auditeerbaarheid. Zo kan worden vastgesteld of de uitkomsten zijn aangepast, waardoor bijvoorbeeld fraude onzichtbaar zou worden in geval van verwijdering. Ook in geval een organisatie later juridisch aansprakelijk wordt gesteld, is inzicht in hoe beslissingen tot stand zijn gekomen belangrijk. Tegelijkertijd kan data die niet essentieel is worden verwijderd, om zo de kans op misbruik en lekken van data te voorkomen.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/8-uit-01-archiveren/#risico","title":"Risico","text":"<p>Het niet correct uitfaseren van een algoritme heeft mogelijk negatieve effecten op het gebied van uitlegbaarheid, transparantie en verantwoording.</p>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/8-uit-01-archiveren/#bronnen","title":"Bronnen","text":"<ul> <li>Onderzoekskader Algoritmes Auditdienst Rijk, PRI.11</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/maatregelen/8-uit-01-archiveren/#voorbeelden","title":"Voorbeelden","text":"<p>Heb je een ander voorbeeld of best practice, laat het ons weten via algoritmes@minbzk.nl</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/","title":"Vereisten voor de overheid","text":""},{"location":"voldoen-aan-wetten-en-regels/vereisten/#vereisten-voor-de-overheid","title":"Vereisten voor de overheid","text":"<p>Overzicht van de belangrijkste vereisten voor overheden die algoritmes of AI-systemen ontwikkelen of gebruiken.</p> ZoekenWetgevingAI-verordeningAVGAWBArchiefwetAuteursrechtBZKBIODatabankenwetGrondwetWOORollenbeleid-en-adviesjuristontwikkelaarprojectleiderLevenscyclusdataverkenning-en-datapreparatieimplementatiemonitoring-en-beheerontwerpontwikkelenorganisatieverantwoordelijkhedenprobleemanalyseuitfaserenverificatie-en-validatieOnderwerpenbias-en-non-discriminatiedatafundamentele-rechtengovernancemenselijke-controleprivacy-en-gegevensbeschermingtechnische-robuustheid-en-veiligheidtransparantieKies je AI-verordeningprofiel of gebruik de beslishulp AI-verordening om vereisten te filteren.Jouw AI-verordening profiel:  Wijzig je profiel of open de beslishulp AI-verordening.Er zijn 63 resultaten gevonden Exporteer vereistenExcel (XLSX)OpenDocument Spreadsheet (ODS)VereistenWetgevingRollenLevenscyclusOnderwerpenVerboden AI mag niet worden gebruiktAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               probleemanalyse                               governance              Personeel en gebruikers zijn voldoende AI-geletterdAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               menselijke-controle                               governance              Beoordeling als niet 'hoog-risico-AI-systeem' is gedocumenteerdAI-verordening                  projectleider                               ontwerp                               governance                               transparantie              Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteemAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               governance              Hoog-risico-AI-systemen vormen geen risico voor kwetsbare groepen zoals kinderenAI-verordening                  projectleider                               beleid-en-advies                               ontwerp                               monitoring-en-beheer                               fundamentele-rechten                               bias-en-non-discriminatie              Datasets voor hoog-risico-AI-systemen voldoen aan kwaliteitscriteriaAI-verordening                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               data              Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatieAI-verordening                  projectleider                               ontwikkelaar                               dataverkenning-en-datapreparatie                               ontwikkelen                               verificatie-en-validatie                               transparantie              Hoog-risico-AI-systemen loggen automatisch bepaalde gegevensAI-verordening                  ontwikkelaar                               projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Hoog-risico-AI-systemen zijn op een transparante manier ontwikkeld en ontworpenAI-verordening                  projectleider                               ontwikkelaar                               beleid-en-advies                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              Hoog-risico-AI-systemen staan onder menselijk toezichtAI-verordening                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               menselijke-controle              Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveiligAI-verordening                  projectleider                               beleid-en-advies                               ontwikkelaar                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteemAI-verordening                  projectleider                               beleid-en-advies                               organisatieverantwoordelijkheden                               governance              Documentatie over hoog-risico-AI-systemen wordt 10 jaar bewaard door de aanbiederAI-verordening                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               transparantie                               technische-robuustheid-en-veiligheid              Logs van hoog-risico-AI-systemen worden zes maanden bewaard door de aanbiederAI-verordening                  projectleider                               ontwerp                               monitoring-en-beheer                               uitfaseren                               technische-robuustheid-en-veiligheid              Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedureAI-verordening                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              Hoog-risico-AI-systemen zijn voorzien van een EU-conformiteitsverklaringAI-verordening                  jurist                               projectleider                               verificatie-en-validatie                               implementatie                               governance              Hoog-risico-AI-systemen zijn voorzien van een CE-markeringAI-verordening                  projectleider                               implementatie                               transparantie              Hoog-risico-AI-systemen zijn geregistreerd in de EU-databankAI-verordening                  projectleider                               implementatie                               transparantie              Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder inAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               menselijke-controle                               technische-robuustheid-en-veiligheid              Hoog-risico-AI-systemen voldoen aan de toegankelijkheidseisenAI-verordening                  projectleider                               ontwikkelaar                               ontwerp                               menselijke-controle                               technische-robuustheid-en-veiligheid              Hoog-risico-AI-systemen worden gebruikt volgens de gebruiksaanwijzingAI-verordening                  projectleider                               beleid-en-advies                               implementatie                               governance              Menselijk toezicht van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkhedenAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               governance                               menselijke-controle              De werking van hoog-risico-AI-systemen wordt gemonitordAI-verordening                  projectleider                               monitoring-en-beheer                               menselijke-controle              Logs voor hoog-risico-AI-systemen worden bewaard door de gebruiksverantwoordelijkeAI-verordening                  projectleider                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Werknemers weten dat hun organisatie een hoog-risico AI-systeem gebruiktAI-verordening                  projectleider                               implementatie                               transparantie              Gebruiksverantwoordelijken controleren de registratie van het hoog-risico AI-systeem in de EU-databankAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               implementatie                               monitoring-en-beheer                               transparantie                               governance              Mensen over wie besluiten worden genomen door een hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluitenAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               ontwerp                               monitoring-en-beheer                               governance                               fundamentele-rechten                               transparantie              Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechtenAI-verordening                  projectleider                               beleid-en-advies                               ontwerp                               verificatie-en-validatie                               fundamentele-rechten              AI-systemen worden zo ontworpen en gebruikt, dat mensen begrijpen wanneer zij met een AI-systeem communiceren en welke content gemaakt is door een AI-systeemAI-verordening                  projectleider                               ontwikkelaar                               ontwikkelen                               implementatie                               transparantie              AI-modellen voor algemene doeleinden zijn voorzien van voldoende technische documentatie en informatieAI-verordening                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico treffen extra maatregelenAI-verordening                  projectleider                               ontwikkelaar                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Als AI-modellen voor algemene doeleinden met systeemrisico\u2019s ernstige incidenten veroorzaken, wordt dit gedocumenteerd en gerapporteerdAI-verordening                  projectleider                               monitoring-en-beheer                               governance                               transparantie              AI-modellen voor algemene doeleinden met systeemrisico\u2019s zijn voldoende beveiligd tegen cyberaanvallenAI-verordening                  ontwikkelaar                               ontwikkelen                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              AI-testomgevingen die persoonsgegevens verwerken, voldoen aan strenge voorwaardenAI-verordening                  jurist                               ontwikkelaar                               projectleider                               organisatieverantwoordelijkheden                               ontwikkelen                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               data              Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteemAI-verordening                  projectleider                               monitoring-en-beheer                               technische-robuustheid-en-veiligheid              Ernstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouderAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance              Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordeningAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               monitoring-en-beheer                               governance                               menselijke-controle              Aanbieders van AI-systemen kunnen een klacht indienen over de aanbieder van hun AI-modelAI-verordening                  projectleider                               organisatieverantwoordelijkheden                               fundamentele-rechten              Hoog-risico-AI-systemen zijn getestAI-verordening                  projectleider                               ontwikkelaar                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               verificatie-en-validatie                               technische-robuustheid-en-veiligheid              Er is beleid opgesteld ter naleving van auteursrechten en naburige rechten door aanbieders van AI-modellen voor algemene doeleindenAI-verordening                  projectleider                               ontwerp                               ontwikkelen                               monitoring-en-beheer                               transparantie              Informatie over algoritmes wordt in goede, geordende en toegankelijke staat gebracht, bewaard en vernietigd wanneer nodigArchiefwet                  projectleider                               ontwikkelaar                               uitfaseren                               monitoring-en-beheer                               ontwikkelen                               transparantie                               data              Auteursrechten zijn beschermdAuteursrecht                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               data              Persoonsgegevens worden op een rechtmatige manier verwerktAVG                  projectleider                               jurist                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              Persoonsgegevens worden zo kort mogelijk bewaardAVG                  ontwikkelaar                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               uitfaseren                               privacy-en-gegevensbescherming              Persoonsgegevens worden zo min mogelijk verwerktAVG                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               ontwikkelen                               privacy-en-gegevensbescherming              Persoonsgegevens en andere data verwerken gebeurt proportioneel en subsidiairAVG                  jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               fundamentele-rechten                               privacy-en-gegevensbescherming              Persoonsgegevens zijn juist en actueelAVG                  ontwikkelaar                               projectleider                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              Organisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerkenAVG                  jurist                               ontwerp                               dataverkenning-en-datapreparatie                               governance                               privacy-en-gegevensbescherming              Organisaties zijn transparant over het verwerken van persoonsgegevensAVG                  ontwikkelaar                               projectleider                               implementatie                               monitoring-en-beheer                               privacy-en-gegevensbescherming                               transparantie              Gevoelige persoonsgegevens worden alleen gebruikt als hiervoor een wettelijke uitzondering geldtAVG                  projectleider                               jurist                               beleid-en-advies                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming                               bias-en-non-discriminatie              Betrokkenen kunnen een beroep doen op hun privacyrechtenAVG                  ontwikkelaar                               organisatieverantwoordelijkheden                               ontwikkelen                               privacy-en-gegevensbescherming                               data              Besluiten met rechtsgevolgen of aanmerkelijke effecten zijn niet volledig geautomatiseerdAVG                  projectleider                               beleid-en-advies                               ontwerp                               implementatie                               privacy-en-gegevensbescherming                               menselijke-controle              Ontwerp en standaardinstellingen (defaults) zijn zo gunstig mogelijk voor de privacy van betrokkenenAVG                  beleid-en-advies                               projectleider                               jurist                               ontwikkelaar                               ontwerp                               dataverkenning-en-datapreparatie                               privacy-en-gegevensbescherming              Data zoals persoonsgegevens zijn voldoende beveiligd tegen ongelukken en cyberaanvallenAVG                  jurist                               ontwikkelaar                               organisatieverantwoordelijkheden                               privacy-en-gegevensbescherming                               technische-robuustheid-en-veiligheid              Een gegevensbeschermingseffectbeoordeling (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personenAVG                  jurist                               projectleider                               ontwerp                               dataverkenning-en-datapreparatie                               verificatie-en-validatie                               privacy-en-gegevensbescherming              Organisaties die algoritmes gebruiken voor publieke taken nemen besluiten zorgvuldigAWB                  projectleider                               beleid-en-advies                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               fundamentele-rechten                               menselijke-controle              Organisaties kunnen duidelijk uitleggen waarom en hoe algoritmes leiden tot een besluitAWB                  projectleider                               ontwikkelaar                               ontwerp                               implementatie                               monitoring-en-beheer                               transparantie              Computersystemen zijn voldoende beveiligd tegen ongelukken en cyberaanvallenBIO                  beleid-en-advies                               ontwikkelaar                               organisatieverantwoordelijkheden                               technische-robuustheid-en-veiligheid              Impactvolle algoritmes en hoog-risico-AI-systemen staan in het Nederlandse AlgoritmeregisterBZK                  projectleider                               implementatie                               monitoring-en-beheer                               transparantie              Databanken worden alleen gebruikt met toestemming van de databank-producentDatabankenwet                  jurist                               dataverkenning-en-datapreparatie                               data              Algoritmes schenden geen grondrechten of mensenrechtenGrondwet                  projectleider                               jurist                               probleemanalyse                               ontwerp                               verificatie-en-validatie                               monitoring-en-beheer                               fundamentele-rechten              Algoritmes discrimineren nietGrondwet                  projectleider                               ontwerp                               ontwikkelen                               verificatie-en-validatie                               monitoring-en-beheer                               bias-en-non-discriminatie              Iedereen kan openbare informatie over algoritmes vinden of aanvragenWOO                  jurist                               projectleider                               organisatieverantwoordelijkheden                               transparantie"},{"location":"voldoen-aan-wetten-en-regels/vereisten/#wetten-en-regels","title":"Wetten en regels","text":"<p>De vereisten zijn gebaseerd op de wetten en regels voor het uitvoeren van wettelijke taken, zoals de:</p> <ul> <li>AI-verordening</li> <li>Algemene verordening gegevensbescherming (AVG)</li> <li>Algemene wet bestuursrecht (Awb)</li> <li>Algemene wet gelijke behandeling (Awgb)</li> <li>Auteurswet</li> <li>Baseline Informatiebeveiliging Overheid (BIO)</li> <li>Grondwet</li> </ul> <p>Bij elke vereiste staat de bron er duidelijk bij.</p> <p>Let op!</p> <p>Het Algoritmekader biedt een overzicht van de belangrijkste vereisten. Dit is niet volledig. Sectorspecifieke wetgeving is bijvoorbeeld niet meegenomen. Hierdoor kan het zijn dat er meer regelgeving van geldt voor jouw toepassing.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/#aantal-vereisten-verschilt-per-situatie","title":"Aantal vereisten verschilt per situatie","text":"<p>Welke vereisten gelden voor jouw organisatie, hangt af van:</p> <ul> <li>de technologie die je gebruikt: rekenregels, machinelearning of generatieve AI</li> <li>de risicoclassificatie van het algoritme dat je gebruikt</li> <li>je rol: ben je ontwikkelaar of alleen gebruiker van het algoritme?</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/#voorbeeld","title":"Voorbeeld","text":"<p>Impactvolle algoritmes en AI-systemen worden gepubliceerd in het Nederlandse algoritmeregister.</p> <p>Deze vereiste geldt alleen voor impactvolle algoritmes en hoog-risico-AI-systemen. Een niet-impactvolle rekenregel hoef je niet te registreren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/#help-ons-deze-pagina-te-verbeteren","title":"Help ons deze pagina te verbeteren","text":"<p>Deel je idee, suggestie of opmerking via GitHub of mail ons via algoritmes@minbzk.nl.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/","title":"Verboden AI mag niet worden gebruikt","text":"<p>aia-00OrganisatieverantwoordelijkhedenProbleemanalyseProjectleiderGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/#vereiste","title":"Vereiste","text":"<p>Verboden AI-systemen mogen niet worden gebruikt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/#toelichting","title":"Toelichting","text":"<p>Afgezien van de vele nuttige toepassingen van AI kan zij ook worden misbruikt en nieuwe en krachtige instrumenten voor manipulatie, uitbuiting en sociale controle opleveren. Dergelijke praktijken zijn bijzonder schadelijk en abusief en moeten worden verboden omdat zij in strijd zijn met de waarden van de Unie, namelijk eerbied voor de menselijke waardigheid, vrijheid, gelijkheid, democratie en de rechtsstaat, en met de grondrechten van de Unie die zijn vastgelegd in het Handvest, waaronder het recht op non-discriminatie, gegevensbescherming en privacy, en de rechten van het kind.</p> <p>In de volgende gevallen gaat het om een verboden toepassing op grond van de AI-verordening:</p> <ul> <li>gebruik kan gaan maken van subliminale technieken om mensen onbewust of bewust kunnen manipuleren, waardoor ze beslissingen nemen die ze anders niet zouden hebben genomen?</li> <li>gebruik kan gaan maken van kwetsbaarheden van individuen of specifieke groepen, zoals leeftijd, handicaps of sociale/economische omstandigheden, om het gedrag van die personen aanzienlijk te verstoren, wat kan leiden tot aanzienlijke schade bij henzelf of anderen?</li> <li>gebruikt kan worden om natuurlijke personen of groepen gedurende een periode te evalueren of te classificeren op basis van hun sociale gedrag of afgeleide persoonlijke kenmerken?</li> <li>gebruikt kan worden voor risicobeoordelingen van natuurlijke personen om het risico op crimineel gedrag te voorspellen, gebaseerd op profilering of persoonlijkheidskenmerken? (Dit geldt niet voor AI-systemen die worden gebruikt om menselijke beoordelingen te ondersteunen, gebaseerd op objectieve en verifieerbare feiten die rechtstreeks verband houden met criminele activiteiten)</li> <li>gebruikt kan worden om databanken voor gezichtsherkenning aan te leggen of aan te vullen door willekeurige gezichtsafbeeldingen van internet of CCTV-beelden te scrapen?</li> <li>gebruikt kan worden om emoties van een persoon op de werkplek of in het onderwijs af te leiden? (Dit is niet van toepassing als het gebruik van het AI-systeem is bedoeld voor medische- of veiligheidsdoeleinden)</li> <li>gebruikt kan worden om natuurlijke personen individueel in categorie\u00ebn in te delen op basis van biometrische gegevens om ras, politieke opvattingen, lidmaatschap van een vakbond, religieuze of levensbeschouwelijke overtuigingen, seksleven of seksuele geaardheid af te leiden? (Dit verbod geldt niet voor het labelen of filteren van rechtmatig verkregen biometrische datasets, zoals afbeeldingen, op basis van biometrische gegevens, of voor categorisering van biometrische gegevens op het gebied van rechtshandhaving)</li> <li>gebruikt kan worden als een biometrisch systeem in de publieke ruimte voor identificatie op afstand in real-time, met het oog op de rechtshandhaving?</li> </ul> <p>Er zijn een tweetal uitzonderingen voor het inzetten van verboden AI-systemen. Deze zijn:</p> <ul> <li>Er is sprake van een rechtshandhavingsactiviteit i.v.m. een specifiek misdrijf (terrorisme, mensenhandel, seksuele uitbuiting van kinderen en materiaal over seksueel misbruik van kinderen, illegale handel in verdovende middelen en psychotrope stoffen, illegale handel in wapens, munitie en explosieven, moord, zware mishandeling, illegale handel in menselijke organen en weefsels, illegale handel in nucleaire en radioactieve stoffen, ontvoering, wederrechtelijke vrijheidsberoving en gijzeling, misdrijven die onder de rechtsmacht van het Internationaal Strafhof vallen, kaping van vliegtuigen/schepen, verkrachting, milieucriminaliteit, georganiseerde of gewapende diefstal, sabotage, deelneming aan een criminele organisatie die betrokken is bij een of meer van de bovengenoemde misdrijven).</li> <li>Er is sprake van gerichte opsporing van specifieke slachtoffers, ontvoering, mensenhandel en seksuele uitbuiting van mensen, vermiste personen; of het voorkomen van bedreigingen voor het leven of de fysieke veiligheid van personen of het reageren op de huidige of voorzienbare dreiging van een terreuraanslag.</li> </ul> <p>Bepaal in een vroege fase en bij het onderbouwen van het gebruik van een AI-systeem of de beoogde toepassing is toegestaan.</p> <p>Richtsnoeren over verboden AI-praktijken vanuit de Europese Commissie</p> <p>De Europese Commissie heeft richtsnoeren inzake verboden praktijken op het gebied van AI, zoals gedefinieerd door de AI-verordening, gepubliceerd. Deze richtlijnen geven een overzicht van AI-praktijken die onacceptabel worden geacht vanwege hun mogelijke risico's voor Europese waarden en grondrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/#bronnen","title":"Bronnen","text":"<p>Artikel 5 Verordening Artifici\u00eble Intelligentie.</p> <p>Overweging 29 - 44 AI-Verordening.</p> <p>Handreiking identificatie verboden AI-systemen (Powerpoint-bestand)</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenAI-model voor algemene doeleindenVerboden AIAanbiederGebruiksverantwoordelijkeImporteurDistributeurSysteemrisicoGeen systeemrisicoGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-00-verboden-AI-praktijken/#risico","title":"Risico","text":"<p>Er ontstaat een onrechtmatige situatie voor een organisatie als deze AI inzet, die verboden is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/","title":"Personeel en gebruikers zijn voldoende AI-geletterd","text":"<p>aia-01OrganisatieverantwoordelijkhedenProjectleiderMenselijke controleGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/#vereiste","title":"Vereiste","text":"<p>Personeel en gebruikers zijn voldoende AI-geletterd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/#toelichting","title":"Toelichting","text":"<p>Aanbieders en gebruiksverantwoordelijken van AI-systemen nemen maatregelen om, zoveel als mogelijk, te zorgen voor een toereikend niveau van AI-geletterdheid bij hun personeel en andere personen die namens hen AI-systemen exploiteren en gebruiken.</p> <p>Zij houden daarbij rekening met hun technische kennis, ervaring, onderwijs en opleiding en de context waarin de AI-systemen zullen worden gebruikt, evenals met de personen of groepen personen ten aanzien van wie de AI-systemen zullen worden gebruikt.</p> <p>De AI-kennisplicht betekent bijvoorbeeld dat een HR-medewerker moet begrijpen dat een AI-systeem vooroordelen kan bevatten of essenti\u00eble informatie kan negeren, waardoor een sollicitant onterecht wel of juist niet wordt voorgedragen. En een baliemedewerker bij een gemeente die een AI-systemen gebruikt om de burgers te helpen, moet beseffen dat deze systemen vaak niet even goed werken voor iedereen. En dat diegene de uitkomsten van dit soort AI-systemen niet blindelings kan volgen.</p> <p>Het doel is om een adequaat niveau van begrip en vaardigheden te waarborgen, wat bijdraagt aan een verantwoord gebruik van AI en het minimaliseren van risico's.</p> <p>Vanaf februari 2025 treedt deze vereiste in werking.</p> <p>Tip</p> <p>De Rijksoverheid heeft een one-pager gemaakt om snel een overzicht te krijgen van wat AI-geletterdheid inhoudt.</p> <p>Tip</p> <p>De Autoriteit Persoonsgegevens schreef een document over hoe je aan de slag kan gaan met AI-geletterheid bij jouw organisatie.</p> <p>Tip</p> <p>Het AI-bureau van de EU heeft een aantal van de lopende best practices verzameld met als doel een levend archief aan te leggen met voorbeelden van lopende praktijken op het gebied van AI-geletterdheid.</p> <p>Tip</p> <p>Op de website van de Rijksacademie voor Digitalisering en Informatisering Overheid (RADIO) vind je een aantal links naar e-learnings en webinars over het gebruik van AI en generatieve AI. Zeker voor eindgebruikers die nog niet zo veel weten van AI bieden deze een goede basisopleiding.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 4 Verordening Artifici\u00eble Intelligentie</li> <li>One-pager AI-geletterdheid</li> <li>Aan de slag met AI-geletterdheid, Autoriteit Persoonsgegevens</li> <li>Living repository to foster learning and exchange on AI literacy - Europese Unie</li> <li>Verschillende e-learnings - RADIO</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenAI-model voor algemene doeleindenHoog risico AI-systeemVerboden AIGeen hoog risico AI-systeemAanbiederGebruiksverantwoordelijkeImporteurDistributeurSysteemrisicoGeen systeemrisicoGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-01-ai-geletterdheid/#risico","title":"Risico","text":"<p>Onvoldoende AI-geletterdheid kan leiden tot misbruik of onjuist gebruik van AI-systemen en tot situaties waarin AI-systemen verkeerd worden ingezet, onbedoeld gebruikt worden voor taken waar ze niet geschikt voor zijn, of dat de veiligheid en effectiviteit van de systemen in het gedrang komt.</p> <p>Dit kan leiden tot ineffici\u00ebntie, fouten, en mogelijk schade aan organisaties, gebruikers of betrokkenen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/","title":"Beoordeling als niet 'hoog-risico-AI-systeem' is gedocumenteerd","text":"<p>aia-02OntwerpProjectleiderGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#vereiste","title":"Vereiste","text":"<p>Beoordeling als niet 'hoog-risico-AI-systeem' is gedocumenteerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#toelichting","title":"Toelichting","text":"<p>Een aanbieder die van mening is dat er geen sprake is van een in bijlage III bedoeld AI-systeem, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld.</p> <p>Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2 AI-verordening. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.</p> <p>De aanbieder of in voorkomend geval de gemachtigd registreert zichzelf en het betreffende AI-systeem in de EU-databank (artikel 71 AI-verordening).</p> <p>AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III (kritieke infrastructuur) worden op nationaal niveau geregistreerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 6(4) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 49(2) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 71 Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage III Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenGeen hoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-02-documentatie-beoordeling-niet-hoog-risico-ai/#risico","title":"Risico","text":"<p>Gebrek aan transparantie en verantwoording bij risicobeoordeling kan leiden tot onrechtmatig in de markt brengen en onrechtmatig gebruik van (risicovolle) AI-systemen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-03-risicobeheersysteem/","title":"Hoog-risico-AI-systemen zijn voorzien van een risicobeheersysteem","text":"<p>aia-03OrganisatieverantwoordelijkhedenProjectleiderGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-03-risicobeheersysteem/#vereiste","title":"Vereiste","text":"<p>Voor AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-03-risicobeheersysteem/#toelichting","title":"Toelichting","text":"<p>Het systeem voor risicobeheer moet bestaan uit een gepland iteratief proces, dat tijdens de gehele levensduur van een hoog-risico AI-systeem wordt doorlopen. Een organisatie moet ervoor zorgen dat een risicobeheersysteem wordt ingericht in de organisatie.</p> <p>Het risicobeheersysteem moet gericht zijn op het vaststellen en beperken van de relevante risico\u2019s van AI-systemen voor de gezondheid, veiligheid en grondrechten met passende maatregelen.</p> <p>Het systeem voor risicobeheer moet periodiek worden ge\u00ebvalueerd en geactualiseerd om de blijvende doeltreffendheid ervan te waarborgen, alsook de motivering en de documentatie van eventuele significante besluiten en maatregelen die op grond van de AI-verordening zijn genomen.</p> <p>Dit proces moet ervoor zorgen dat de aanbieder de risico\u2019s of negatieve effecten vaststelt en risicobeperkende maatregelen uitvoert voor de bekende en de redelijkerwijs te voorziene risico\u2019s van AI-systemen voor de gezondheid, veiligheid en grondrechten.</p> <p>Hierin moeten ook maatregelen zitten voor redelijkerwijs te voorzien misbruik, met inbegrip van de mogelijke risico\u2019s die voortvloeien uit de wisselwerking tussen het AI-systeem en de omgeving waarin het werkt. De aanbieder moet aandacht hebben voor het gebruik van AI-systemen waarvan, hoewel zij niet rechtstreeks onder het beoogde doel vallen en niet in de gebruiksinstructies worden vermeld, mag worden verwacht dat zij kunnen voortvloeien uit gemakkelijk voorspelbaar menselijk gedrag.</p> <p>Bij het vaststellen van passende risicobeheersmaatregelen moet de aanbieder de gemaakte keuzes hebben gedocumenteerd en voorzien van een toelichting en, in voorkomend geval, deskundigen en externe belanghebbenden hierbij betrekken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-03-risicobeheersysteem/#bronnen","title":"Bronnen","text":"<p>Artikel 9(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-03-risicobeheersysteem/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-03-risicobeheersysteem/#risico","title":"Risico","text":"<p>Het ontbreken van risicobeheer kan leiden tot schade aan gebruikers of derden en wettelijke aansprakelijkheid voor de aanbieder.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/","title":"Hoog-risico-AI-systemen vormen geen risico voor kwetsbare groepen zoals kinderen","text":"<p>aia-04OntwerpMonitoring en beheerProjectleiderBeleid en adviesFundamentele rechtenBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#vereiste","title":"Vereiste","text":"<p>Bij het doorlopen, het periodieke systematische toetsen en actualiseren van het risicosysteem nemen aanbieders in overweging of het beoogde doel van het AI-systeem negatieve effecten zal hebben op personen jonger dan 18 jaar of andere kwetsbare groepen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#toelichting","title":"Toelichting","text":"<p>Bij de uitvoering van het in de leden 1 tot en met 7 van art. 9 AI-Verordening bedoelde systeem voor risicobeheer houden aanbieders rekening met de vraag of het beoogde doel van het AI-systeem met een hoog risico waarschijnlijk negatieve gevolgen zal hebben voor personen jonger dan 18 jaar en, in voorkomend geval, voor andere groepen kwetsbare personen.</p> <p>Er moet een grondige risicoanalyse plaatsvinden en worden vertaald naar mitigerende maatregelen om het risico te elimineren of te mitigeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#bronnen","title":"Bronnen","text":"<p>Artikel 9(9) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-04-risicobeoordeling-voor-jongeren-en-kwetsbaren/#risico","title":"Risico","text":"<p>Niet adequaat adresseren van risico's voor jongeren en kwetsbare groepen kan leiden tot ernstige ethische en maatschappelijke schade.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-05-data-kwaliteitscriteria/","title":"Datasets voor hoog-risico-AI-systemen voldoen aan kwaliteitscriteria","text":"<p>aia-05Dataverkenning en datapreparatieVerificatie en validatieProjectleiderOntwikkelaarData</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-05-data-kwaliteitscriteria/#vereiste","title":"Vereiste","text":"<p>AI-systemen met een hoog risico die technieken gebruiken die het trainen van AI-modellen met data omvatten, worden ontwikkeld op basis van datasets voor training, validatie en tests die voldoen aan de kwaliteitscriteria telkens wanneer dergelijke datasets worden gebruikt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-05-data-kwaliteitscriteria/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico die data gebruiken voor het trainen van AI-modellen, moeten gebaseerd zijn op datasets die voldoen aan specifieke kwaliteitscriteria.</p> <p>Deze criteria zorgen ervoor dat de data geschikt zijn voor training, validatie en tests, wat de betrouwbaarheid en nauwkeurigheid van het AI-systeem waarborgt. De kwaliteitscriteria zijn te vinden in leden 2 t/m 5 van artikel 10 van de AI-verordening. Bijvoorbeeld datasets moeten aan praktijken voor databeheer voldoen en moeten relevant, representatief, accuraat en volledig zijn.</p> <p>Deze vereiste houdt in dat de gebruikte datasets onder meer moeten voldoen aan:</p> <ul> <li>datasets voor training, validatie en tests worden onderworpen aan praktijken op het gebied van databeheer die stroken met het beoogde doel van het AI-systeem met een hoog risico. Dit heeft in het bijzonder betrekking op relevante ontwerpkeuzes, processen voor dataverzameling, verwerkingsactiviteiten voor datavoorbereiding, het opstellen van aannames met name betrekking tot de informatie die de data moeten meten en vertegenwoordigen, beschikbaarheid, kwantiteit en geschiktheid van de datasets en een beoordeling op mogelijke vooringenomenheid en passende maatregelen om deze vooringenomenheid op te sporen, te voorkomen en te beperken.</li> <li>datasets voor training, validatie en tests zijn relevant, voldoende representatief en zoveel mogelijk foutenvrij en volledig met het oog op het beoogde doel.</li> <li>Er wordt rekening gehouden met de eigenschappen of elementen die specifiek zijn voor een bepaalde geografische, contextuele, functionele of gedragsomgeving waarin het AI-systeem wordt gebruikt.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-05-data-kwaliteitscriteria/#bronnen","title":"Bronnen","text":"<p>Artikel 10(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-05-data-kwaliteitscriteria/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-05-data-kwaliteitscriteria/#risico","title":"Risico","text":"<p>Gebruik van laagkwalitatieve of bevooroordeelde datasets kan leiden tot onbetrouwbare en oneerlijke AI-besluitvorming. Onvoldoende kwaliteitsborging van testdata kan leiden tot vertekende resultaten en gebrekkige prestaties van het AI-systeem bij gebruik in de praktijk.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/","title":"Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie","text":"<p>aia-06Dataverkenning en datapreparatieOntwikkelenVerificatie en validatieProjectleiderOntwikkelaarTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn voorzien van voldoende technische documentatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/#toelichting","title":"Toelichting","text":"<p>De technische documentatie van een AI-systeem met een hoog risico wordt voorafgaand aan het in de handel brengen of in gebruik nemen opgesteld en regelmatig bijgewerkt.</p> <p>Deze documentatie moet duidelijk aantonen dat het systeem voldoet aan de vereisten van AI-Verordening (afdeling 2), zodat nationale autoriteiten en aangemelde instanties de naleving kunnen beoordelen. Daarvoor moet de informatie op een heldere en begrijpelijke wijze zijn opgesteld.</p> <p>De documentatie bevat ten minste de elementen zoals uiteengezet in bijlage IV AI-Verordening:</p> <ol> <li>Een algemene beschrijving van het AI-syseem.</li> <li>Een gedetailleerde beschrijving van de elementen van het AI-systeem en het proces voor de ontwikkeling ervan.</li> <li>Gedetailleerde informatie over de monitoring, werking en controle van het AI-systeem.</li> <li>Een beschrijving van de geschiktheid van de prestatiestatistieken.</li> <li>Een gedetailleerde beschrijving van het systeem voor risicobeheer overeenkomstig artikel 9 van de AI verordening.</li> <li>Een beschrijving van de wijzigingen die tijdens de levensduur worden aangebracht.</li> <li>Een lijst van normen die worden toegepast.</li> <li>Een exemplaar van de EU-conformiteitsverklaring.</li> <li>Een gedetailleerde beschrijving voor evaluatie van prestaties nadat het systeem in handel is gebracht, in overeenstemming met artikel 72 van de AI-verordening.</li> </ol> <p>De documentatie kan opgevraagd worden door een bevoegde autoriteit met een met redenen omkleed verzoek, zoals toegelicht in artikel 21 van de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 11 Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage IV Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/#risico","title":"Risico","text":"<p>Het ontbreken van de benodigde informatie over de algoritmische toepassing of AI-systeem kan ertoe leiden dat de technische functionering onduidelijk is. Dat kan tot problemen leiden bij de verantwoording, controle, beheer en conformiteit met regelgeving.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-06-technische-documentatie/#voorbeeld","title":"Voorbeeld","text":"<ul> <li>Gemeente Amsterdam - Onderzoekswaardigheid Algoritme \u2018Slimme check\u2019. (Een tool die de medewerkers helpt om te bepalen of een aanvraag levensonderhoud onderzoekswaardig is, niet meer in gebruik!): Technische documentatie.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-07-automatische-logregistratie/","title":"Hoog-risico-AI-systemen loggen automatisch bepaalde gegevens","text":"<p>aia-07OntwikkelenMonitoring en beheerOntwikkelaarProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-07-automatische-logregistratie/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen loggen automatisch bepaalde gegevens.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-07-automatische-logregistratie/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico zijn ontworpen met functionaliteiten die gebeurtenissen gedurende hun levenscyclus automatisch registreren. Dit wordt vaak aangeduid als \"logs\".</p> <p>Deze logs bieden een traceerbaarheidsmechanisme waarmee gebruiksverantwoordelijken en autoriteiten incidenten en fouten kunnen analyseren, naleving kunnen controleren en mogelijke risico's kunnen identificeren en aanpakken.</p> <p>Het doel van deze registratie is om de transparantie en verantwoordingsplicht van AI-systemen te vergroten, waardoor het beheer van risico's en incidenten verbetert. Voor AI-systemen met een hoog-risico voorziet de loggingcapaciteit ten minste in:</p> <ol> <li>de registratie van de duur van elk gebruik van het systeem;</li> <li>de referentiedatabank aan de hand waarvan de inputdata zijn gecontroleerd door het systeem;</li> <li>de inputdata ten aanzien waarvan de zoekopdracht een match heeft opgeleverd;</li> <li>de identificatie van natuurlijke personen die betrokken zijn bij de verificatie van de resultaten. Specifiek voor gebruiksverantwoordelijken</li> </ol> <p>Voor AI-systemen die door bestuursorganen worden gebruikt of AI-systmen die persoonsgegevens verwerken leveren de BIO en AVG vergelijkbare verplichingen op die ook van toepassing zijn op AI-systemen die niet gezien worden als een AI-systeem met hoog risico. Daarbij komen nog verplichtingen om de logs doorlopend of periodiek te monitoren op incidenten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-07-automatische-logregistratie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 12 Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 26(6) Verordening Artifici\u00eble Intelligentie, zie ook deze vereiste over logging door gebruiksverantwoordelijke.</li> <li>Hoofdstuk 12.4 Baseline Informatiebeveiliging Overheid </li> <li>Artikel 5 en 32 Algemene Verordening Gegevensbescherming</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-07-automatische-logregistratie/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-07-automatische-logregistratie/#risico","title":"Risico","text":"<p>Ontbreken van automatische logregistratie kan leiden tot een gebrek aan transparantie en traceerbaarheid van het AI-systeem, wat het vermogen om verantwoordelijkheid te nemen en eventuele problemen aan te pakken belemmert.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/","title":"Hoog-risico-AI-systemen zijn op een transparante manier ontwikkeld en ontworpen","text":"<p>aia-08OntwerpOntwikkelenMonitoring en beheerProjectleiderOntwikkelaarBeleid en adviesTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn op een transparante manier ontwikkeld en ontworpen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden ontworpen en ontwikkeld met een hoge mate van transparantie, zodat gebruikers de output van het systeem kunnen begrijpen en correct kunnen gebruiken.</p> <p>Dit zorgt ervoor dat de aanbieders en gebruikers kunnen voldoen aan de verplichtingen zoals uiteengezet in de relevante regelgeving, waardoor de betrouwbaarheid en verantwoordelijkheid van het gebruik van deze systemen worden verzekerd.</p> <p>In artikel 13 lid 3 is een overzicht gegeven van de informatie die gebruikersinstructies tenminste moeten bevatten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#bronnen","title":"Bronnen","text":"<p>Artikel 13(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-08-transparantie-aan-gebruiksverantwoordelijken/#risico","title":"Risico","text":"<p>Onvoldoende transparantie kan leiden tot een gebrek aan begrip over hoe het AI-systeem functioneert, wat de effectiviteit van de inzet ervan kan belemmeren en de naleving van wettelijke verplichtingen in gevaar kan brengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/","title":"Hoog-risico-AI-systemen staan onder menselijk toezicht","text":"<p>aia-09OntwerpOntwikkelenMonitoring en beheerProjectleiderMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen staan onder menselijk toezicht.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-hulpmiddelen, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.</p> <p>Het menselijk toezicht is gericht op het voorkomen of beperken van de risico\u2019s voor de gezondheid, veiligheid of grondrechten die zich kunnen voordoen wanneer een AI-systeem met een hoog risico wordt gebruikt in overeenstemming met het beoogde doel ervan of in een situatie van redelijkerwijs te voorzien misbruik, met name wanneer dergelijke risico\u2019s blijven bestaan ondanks de toepassing van andere eisen van deze afdeling.</p> <p>De te treffen toezichtmaatregelen staan in verhouding met de risico's, de mate van autonomie en de gebruikscontext van het AI-systeem met een hoog risico. Hierbij kan het gaan om:</p> <ol> <li>door de aanbieder bepaalde maatregelen die waar technisch haalbaar in het AI-systeem met een hoog risico worden ingebouwd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld;</li> <li>door de aanbieder bepaalde maatregelen voordat het AI-systeem met een hoog risico in de handel wordt gebracht of in gebruik wordt gesteld en die passend zijn om door de gebruiksverantwoordelijke te worden uitgevoerd.</li> </ol> <p>De natuurlijke personen die verantwoordelijk zijn voor het menselijk toezicht, moeten in staat worden gesteld om waar passend en in verhouding tot de omstandigheden het volgende te kunnen doen:</p> <ol> <li>Goed kunnen begrijpen van de relevante capaciteiten en beperkingen van het AI-systeem met een hoog risico. Met het oog op het opsporen en aanpakken van onregelmatigheden, storingen en onverwachte prestaties moet de werking van het AI-systeem goed kunnen worden begrepen;</li> <li>Bewust blijven van de mogelijke neiging om automatisch of te veel te vertrouwen op de output van een AI-systeem met hoog risico (automation bias). Dit geldt in het bijzonder voor het gebruik van een hoog risico AI-systeem dat wordt gebruikt om informatie of aanbevelingen te versterkken voor beslisisngen die door natuurlijke personen moeten worden genomen;</li> <li>De output juist kunnen interpreteren, bijvoorbeeld met behulp van de juiste hulpmiddelen en methoden voor interpretatie;</li> <li>In alle specifieke situaties kunnen besluiten om het hoog risico AI-systeem niet te gebruiken of de output op een andere wijze te negeren, door een andere beslissing te vervangen of terug te draaien;</li> <li>ingrijpen in de werking van het hoog risico AI-systeem of het systeem onderbreken door middel van een stopknop of een vergelijkbare procedure waarmee het systeem op een veilige wijze kan worden stopgezet.</li> </ol> <p>In het geval van een hoog risico systeem als bedoeld in bijlage III, punt 1, a  (systemen voor biometrische identificatie op afstand) geldt het vereiste dat twee natuurlijke personen met de nodige bekwaamheid, opleiding en bevoegdheid apart de indentificatie van het systeem verifici\u00ebren en bevestigen, tenzij het wordt gebruikt voor rechtshandhaving, migratie, grenstoezicht of asiel, in gevallen waarin het Unierecht of het nationale recht de toepassing van dit vereiste onevenredig acht.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/#bronnen","title":"Bronnen","text":"<p>Artikel 14 verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-09-menselijk-toezicht/#risico","title":"Risico","text":"<p>Ontbreken van betekenisvol menselijk toezicht kan leiden tot gebrek aan controle en begrip over het functioneren van het AI-systeem, wat kan resulteren in ongewenste of onvoorspelbare uitkomsten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/","title":"Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig","text":"<p>aia-10OntwerpOntwikkelenMonitoring en beheerProjectleiderBeleid en adviesOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn voldoende nauwkeurig, robuust en cyberveilig.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden zorgvuldig ontworpen en ontwikkeld om een hoog niveau van nauwkeurigheid, robuustheid en cyberbeveiliging te bieden.</p> <p>Dit garandeert consistente prestaties gedurende hun levensduur en minimaliseert risico's met betrekking tot deze aspecten, waardoor de betrouwbaarheid en veiligheid van het systeem worden gewaarborgd.</p> <p>Technische robuustheid is een essenti\u00eble eis voor AI-systemen met een hoog risico. Deze systemen moeten bestand zijn tegen schadelijk of anderszins ongewenst gedrag dat kan voortvloeien uit de beperkingen binnen de systemen of de omgeving waarin de systemen opereren (bijvoorbeeld fouten, onregelmatigheden, onverwachte situaties).</p> <p>Er moeten technische en organisatorische maatregelen worden getroffen om de robuustheid van AI-systemen met een hoog risico te waarborgen. Een technische oplossing kan bijvoorbeeld bestaan uit mechanismen die het systeem in staat stellen zijn werking veilig te onderbreken (storingsbeveiligingsplannen) wanneer zich bepaalde anomalie\u00ebn voordoen of wanneer de werking buiten bepaalde vooraf bepaalde grenzen plaatsvindt.</p> <p>Cyberbeveiliging is cruciaal om te waarborgen dat AI-systemen bestand zijn tegen pogingen van kwaadwillige derden die gebruikmaken van de kwetsbaarheden van het systeem om het gebruik, het gedrag of de prestaties ervan te wijzigen of de veiligheidskenmerken ervan in gevaar te brengen.</p> <p>Bij cyberaanvallen tegen AI-systemen kunnen AI-specifieke activa worden gebruikt, zoals trainingsdatasets (bv. datavervuiling) of getrainde modellen (bv. vijandige aanvallen of membership inference), of kwetsbaarheden in de digitale activa van het AI-systeem of de onderliggende ICT-infrastructuur worden benut.</p> <p>Om te zorgen voor een niveau van cyberbeveiliging dat aansluit op de risico\u2019s, moeten aanbieders van AI-systemen met een hoog risico passende maatregelen zoals veiligheidscontroles nemen, waarbij ook rekening wordt gehouden met de onderliggende ICT infrastructuur.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#bronnen","title":"Bronnen","text":"<p>Artikel 15 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-10-nauwkeurigheid-robuustheid-cyberbeveiliging/#risico","title":"Risico","text":"<p>Gebrek aan nauwkeurigheid, robuustheid of cyberbeveiliging kan leiden tot onbetrouwbare prestaties, kwetsbaarheid voor storingen en blootstelling aan beveiligingsrisico's, wat de effectiviteit en veiligheid van het AI-systeem in gevaar kan brengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-11-systeem-voor-kwaliteitsbeheer/","title":"Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteem","text":"<p>aia-11OrganisatieverantwoordelijkhedenProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn voorzien van een kwaliteitsbeheersysteem.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van de AI-Verordening waarborgt.</p> <p>Dit systeem omvat gedocumenteerde beleidslijnen, procedures en instructies, en omvat ten minste de aspecten vermeld in artikel 17 AI-verordening. Het behandelt beknopt de volgende aspecten:</p> <ol> <li>een strategie voor de naleving van de regelgeving, inclusief de naleving van de conformiteitsbeoordelingsprocedures en de procedures voor het beheer van de wijzigingen van het AI-systeem met een hoog risico;</li> <li>technieken, procedures en systematische maatregelen die moeten worden toegepast voor het ontwerp, de controle van het ontwerp en de verificatie van het ontwerp van het AI-systeem met een hoog risico;</li> <li>technieken, procedures en systematische maatregelen die moeten worden toegepast voor de ontwikkeling, de kwaliteitscontrole en de kwaliteitsborging van het AI-systeem met een hoog risico;</li> <li>procedures voor het inspecteren, testen en valideren die v\u00f3\u00f3r, tijdens en na de ontwikkeling van het AI-systeem met een hoog risico moeten worden uitgevoerd en de regelmaat waarmee zij moeten worden uitgevoerd;</li> <li>technische specificaties, met inbegrip van normen, die moeten worden toegepast en, wanneer de relevante geharmoniseerde normen niet volledig worden toegepast of geen betrekking hebben op alle relevante eisen van afdeling 2, de middelen die worden gebruikt om ervoor te zorgen dat het AI-systeem met een hoog risico in overeenstemming is met deze eisen;</li> <li>systemen en procedures voor databeheer, met inbegrip van dataverwerving, - verzameling, -analyse, -labeling, -opslag, -zuivering, -aggregatie en -behoud en datamining en eventuele andere operaties met betrekking tot de data die worden uitgevoerd voorafgaand aan en met het oog op het in de handel brengen of in gebruik stellen van AI-systemen met een hoog risico;</li> <li>het systeem voor risicobeheer zoals bedoeld in artikel 9 van de AI-verordening;</li> <li>het opzetten, toepassen en onderhouden van een systeem voor monitoring na het in de handel brengen, overeenkomstig artikel 72 AI-verordening;</li> <li>procedures in verband met het melden van een ernstig incident in overeenstemming met artikel 73 van de AI-verordening;</li> </ol> <p>Overheidsinstanties die AI-systemen met een hoog risico in gebruik stellen voor eigen gebruik, mogen de regels voor het systeem voor kwaliteitsbeheer goedkeuren en uitvoeren als onderdeel van het systeem voor kwaliteitsbeheer dat, naargelang het geval, op nationaal of regionaal niveau is goedgekeurd, rekening houdend met de specifieke kenmerken van de sector en de competenties en organisatie van de overheidsinstantie in kwestie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 17 Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(c) Verordening Artifici\u00eble Intelligentie</li> <li>Overweging 81 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-11-systeem-voor-kwaliteitsbeheer/#risico","title":"Risico","text":"<p>Zonder toepassing van een kwaliteitsbeheersysteem kunnen risico's ontstaan voor de veiligheid, betrouwbaarheid en naleving van het AI-systeem en conformiteit met wet- en regelgeving.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-12-bewaartermijn-voor-documentatie/","title":"Documentatie over hoog-risico-AI-systemen wordt 10 jaar bewaard door de aanbieder","text":"<p>aia-12OntwerpMonitoring en beheerUitfaserenProjectleiderTransparantieTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-12-bewaartermijn-voor-documentatie/#vereiste","title":"Vereiste","text":"<p>De aanbieder houdt gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld de volgende elementen ter beschikking van de nationale bevoegde autoriteiten:</p> <ol> <li>de technische documentatie als bedoeld in artikel 11 van de AI-verordening;</li> <li>de documentatie betreffende het in artikel 17 bedoelde systeem voor kwaliteitsbeheer;</li> <li>in voorkomend geval de documentatie betreffende de door aangemelde instanties goedgekeurde wijzigingen;</li> <li>in voorkomend geval de besluiten en andere documenten die door de aangemelde instanties zijn afgegeven;</li> <li>de EU-conformiteitsverklaring als bedoeld in artikel 47.</li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-12-bewaartermijn-voor-documentatie/#toelichting","title":"Toelichting","text":"<p>De aanbieder moet gedurende tien jaar na het op de markt brengen of in gebruik nemen van het AI-systeem met een hoog risico de vereiste documentatie beschikbaar houden voor de nationale autoriteiten.</p> <p>Dit houdt in dat technische documentatie, documentatie over het kwaliteitsbeheersysteem, eventuele documentatie over besluiten en goedgekeurde wijzigingen door aangemelde instanties en de EU-conformiteitsverklaring beschikbaar moet zijn.</p> <p>Dit waarborgt dat de autoriteiten toegang hebben tot relevante informatie voor controle en naleving van de voorschriften gedurende deze periode.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-12-bewaartermijn-voor-documentatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 18(1) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(d) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-12-bewaartermijn-voor-documentatie/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-12-bewaartermijn-voor-documentatie/#risico","title":"Risico","text":"<p>Niet voldoen aan de bewaartermijn kan leiden tot juridische consequenties en kan het vermogen van de autoriteiten om toezicht te houden op de naleving van de regelgeving belemmeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/","title":"Logs van hoog-risico-AI-systemen worden zes maanden bewaard door de aanbieder","text":"<p>aia-13OntwerpMonitoring en beheerUitfaserenProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#vereiste","title":"Vereiste","text":"<p>Logs van hoog-risico-AI-systemen worden zes maanden bewaard door de aanbieder.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten de automatisch gegenereerde logs bewaren volgens de voorschriften van artikel 12, lid 1, zolang deze logs onder hun controle vallen.</p> <p>Deze logs moeten ten minste zes maanden worden bewaard, tenzij anders bepaald door Unie- of nationale wetgeving met betrekking tot gegevensbescherming, om te voldoen aan de relevante voorschriften en verantwoordingsplicht.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 19(1) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(e) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 12(1) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-13-bewaartermijn-voor-gegenereerde-logs/#risico","title":"Risico","text":"<p>Het niet of onvoldoende bewaren van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-14-conformiteitsbeoordeling/","title":"Hoog-risico-AI-systemen worden pas geleverd of gebruikt na een conformiteitsbeoordelingsprocedure","text":"<p>aia-14Verificatie en validatieImplementatieJuristProjectleiderGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-14-conformiteitsbeoordeling/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat voor het AI-systeem met een hoog risico een conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-14-conformiteitsbeoordeling/#toelichting","title":"Toelichting","text":"<p>Conformiteitsbeoordelingen dragen bij aan het kunnen vertrouwen op de kwaliteit van producten en diensten. Aanbieders van AI-systemen met een hoog risico moeten ervoor zorgen dat de conformiteitsbeoordelingsprocedure wordt uitgevoerd v\u00f3\u00f3rdat het systeem op de markt wordt gebracht of in gebruik wordt genomen. Hiervoor moet worden beoordeeld of het ontwikkelde hoog risico AI-systeem voldoet aan de vereisten die gelden voor deze systemen. Denk hierbij aan de vereisten van risicobeheer, technische documentatie, data en datagovernance en transparantie en informatieverstrekking aan gebruiksverantwoordelijken (Afdeling 2, AI-Verordening).</p> <p>Een conformiteitbeoordeling kan in de meeste gevallen worden uitgevoerd door middel van een interne controle (als bedoeld in bijlage VI van de AI-verordening).</p> <p>In sommige gevallen dient de conformiteitsbeoordeling uitgevoerd te worden door een derde partij. De conformiteitsbeoordeling dient door een derde partij uitgevoerd te worden voor:</p> <ul> <li>Hoog-risico AI-systemen die veiligheidscomponent zijn van een producten die al worden gereguleerd via bestaande productregulering (Afdeling A van bijlage I).</li> <li>Hoog-risico AI-systemen die gebruik maken van biometrie (bijlage III punt 1). Let op! Indien het AI-systeem is bedoeld om door rechtshandhavingsinstanties, immigratie- of asielautoriteiten of door instellingen, organen of instanties van de Unie in gebruik te worden gesteld, dienst de conformiteitsbeoordeling uitgevoerd te worden door de markttoezichtautoriteit.</li> </ul> <p>Volg voor het uitvoeren van de conformiteitsbeoordeling de procedures die zijn voorgeschreven in de AI-verordening. Dit betekent dat er een conformiteitsverklaring opgesteld moet worden en de procedures uit bijlage VI en bijlage VII gevolgd dienen te worden.</p> <p>AI-systemen met een hoog risico die al aan een conformiteitsbeoordelingsprocedure zijn onderworpen, ondergaan een nieuwe conformiteitsbeoordelingsprocedure telkens wanneer zij substantieel zijn gewijzigd, ongeacht of het gewijzigde systeem bedoeld is om verder te worden gedistribueerd of door de huidige gebruiksverantwoordelijke gebruikt blijft worden.</p> <p></p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-14-conformiteitsbeoordeling/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(f), AI-verordening</li> <li>Artikel 43, AI-verordening</li> <li>Artikel 76, AI-verordening</li> <li>Bijlage VI, AI-verordening</li> <li>Bijlage VII, AI-verordening</li> <li>AI-wet</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-14-conformiteitsbeoordeling/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-14-conformiteitsbeoordeling/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-15-eu-conformiteitsverklaring/","title":"Hoog-risico-AI-systemen zijn voorzien van een EU-conformiteitsverklaring","text":"<p>aia-15Verificatie en validatieImplementatieJuristProjectleiderGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-15-eu-conformiteitsverklaring/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico stellen een EU-conformiteitsverklaring op.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-15-eu-conformiteitsverklaring/#toelichting","title":"Toelichting","text":"<p>Een EU-conformiteitsverklaring is een verplicht document dat een fabrikant of gemachtigde vertegenwoordiger moet ondertekenen, waarmee wordt verklaard dat het product aan de EU-eisen voldoet.</p> <p>De aanbieder stelt voor elk AI-systeem met een hoog risico een schriftelijke machineleesbare, fysieke of elektronisch ondertekende EU-conformiteitsverklaring op en houdt deze verklaring tot tien jaar na het in de handel brengen of het in gebruik stellen van het AI-systeem met een hoog risico ter beschikking van de nationale bevoegde autoriteiten.</p> <p>De conformiteitsverklaring bevat de informatie zoals genoemd in bijlage V van de AI-verordening.</p> <p>Voorbeelden hiervan zijn de naam en type van het AI-systeem, naam en adres van de aanbieder, dat de EU-conformiteitsverklaring wordt versterkt onder verantwoordelijkheid van de aanbieder en de vermelding van eventuele toegepaste relevante geharmoniseerde normen of van andere gemeenschappelijke specificaties waarop de conformiteitsverklaring betrekking heeft.</p> <p>Zorg dat je naast het opstellen van een verklaring een conformiteitsbeoordeling uitvoert op je AI-systeem volgens de procedures zoals die zijn voorgeschreven door de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-15-eu-conformiteitsverklaring/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(g) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 47(1) Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage V Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-15-eu-conformiteitsverklaring/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-15-eu-conformiteitsverklaring/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-16-ce-markering/","title":"Hoog-risico-AI-systemen zijn voorzien van een CE-markering","text":"<p>aia-16ImplementatieProjectleiderTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-16-ce-markering/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn voorzien van een CE-markering.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-16-ce-markering/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico moeten een CE-markering toevoegen aan het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan de AI-verordening is voldaan.</p> <p>Op AI-systemen met een hoog risico die in een product zijn ge\u00efntegreerd moet een fysieke CE-markering worden aangebracht, die kan worden aangevuld met een digitale CE-markering.</p> <p>Voor AI-systemen met een hoog risico die alleen digitaal worden verstrekt, moet een digitale CE-markering worden gebruikt.</p> <p>De lidstaten mogen het in de handel brengen en het in gebruik stellen van AI-systemen met een hoog risico die aan de in de AI-verordening vastgelegde eisen voldoen en waarop de CE-markering is aangebracht, niet op ongerechtvaardigde wijze belemmeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-16-ce-markering/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(h) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 48 Verordening Artifici\u00eble Intelligentie</li> <li>Overweging 129 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-16-ce-markering/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-16-ce-markering/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-17-registratieverplichtingen/","title":"Hoog-risico-AI-systemen zijn geregistreerd in de EU-databank","text":"<p>aia-17ImplementatieProjectleiderTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-17-registratieverplichtingen/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn geregistreerd in de EU-databank.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-17-registratieverplichtingen/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico registeren het systeem in de EU-databank voorafgaand aan ingebruikname van het AI-systeem.</p> <p>V\u00f3\u00f3r de distributie of inbedrijfstelling van een AI-systeem met een hoog risico van bijlage III, met uitzondering van specifieke gevallen zoals beschreven in punt 2 van bijlage III, is het vereist dat de aanbieder of gemachtigde zichzelf en het systeem registreert in de EU-databank zoals genoemd in art. 71 AI-verordening. Ook substanti\u00eble wijzigingen van AI-systemen met een hoog risico moeten in de EU-databank worden geregistreerd.</p> <p>Als een AI-systeem met een hoog risico wordt gebruikt zoals omschreven in bijlage III, moeten gebruiksverantwoordelijken die overheidsinstanties, -agentschappen of -organen zijn, zich bij een dergelijke databank registreren en het systeem selecteren dat zij voornemens zijn te gebruiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-17-registratieverplichtingen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(i) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 49(1) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-17-registratieverplichtingen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-17-registratieverplichtingen/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/","title":"Als een hoog-risico-AI-systeem niet voldoet aan de AI-verordening, grijpt de aanbieder in","text":"<p>aia-18OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderMenselijke controleTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI systeem met een hoog risico niet in overeenstemming is met de AI-verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die constateren dat hun systeem niet aan de verordening voldoet, moeten onmiddellijk corrigerende acties ondernemen, zoals het terugroepen of uit de handel nemen van het systeem.</p> <p>Ze moeten ook alle relevante partijen, zoals distributeurs, gebruiksverantwoordelijken en importeurs, op de hoogte stellen van deze maatregelen.</p> <p>Over AI-modellen voor algemene doeleinden met een systeemrisico wordt relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijgehouden, gedocumenteerd en onverwijld gerapporteerd aan het AI-bureau en, in voorkomende gevallen, aan de nationale bevoegde autoriteiten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 20 Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 16(j) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 55 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-18-corrigerende-maatregelen-voor-non-conforme-ai/#risico","title":"Risico","text":"<p>Niet reageren op non-conformiteit kan leiden tot risico's voor gebruikers en derden. Het kan leiden tot juridische procedures en reputatieschade voor organisaties.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/","title":"Hoog-risico-AI-systemen voldoen aan de toegankelijkheidseisen","text":"<p>aia-19OntwerpProjectleiderOntwikkelaarMenselijke controleTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-systemen met een hoog risico zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/#toelichting","title":"Toelichting","text":"<p>Gezien het toenemende belang en gebruik van AI-systemen moet de toepassing van universele ontwerpbeginselen op alle nieuwe technologie\u00ebn en diensten zorgen voor volledige en gelijke toegang voor iedereen die mogelijk gevolgen ondervindt van of gebruikmaakt van AI-technologie\u00ebn, met inbegrip van personen met een handicap, op een manier waarbij ten volle rekening wordt gehouden met hun inherente waardigheid en diversiteit.</p> <p>Aanbieders van AI-systemen met een hoog risico moeten daarom ervoor zorgen dat hun systeem toegankelijk is volgens de EU-richtlijnen 2016/2102 en 2019/882 en deze eisen onderdeel maken van het ontwerp. De nodige maatregelen moeten daarom zo goed mogelijk in het ontwerp van AI-systemen met een hoog risico worden ge\u00efntegreerd.</p> <p>In het kader van Richtlijn 2016/2102 moet onder toegankelijkheid worden verstaan het geheel van principes en technieken die in acht moeten worden genomen bij het ontwerpen, bouwen, beheren en bijwerken van websites en mobiele applicaties om hen voor gebruikers toegankelijker te maken, met name voor personen met een beperking.</p> <p>Bijlage 1 bevat de toegankelijkheidsvoorschriften voor producten en diensten die moeten worden toegepast op hoog-risico-AI-systemen.</p> <p>Richtlijn 2019/882 strekt ertoe een bijdrage te leveren tot het goed functioneren van de interne markt middels onderlinge aanpassing van de wettelijke en bestuursrechtelijke bepalingen van de lidstaten inzake de toegankelijkheidsvoorschriften voor bepaalde producten en diensten, in het bijzonder door het wegwerken en voorkomen van belemmeringen voor het vrije verkeer van onder deze richtlijn vallende producten en diensten ten gevolge van uiteenlopende toegankelijkheidsvoorschriften in de lidstaten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 16(l) Verordening Artifici\u00eble Intelligentie</li> <li>EU-richtlijn 2016/2102</li> <li>EU-richtlijn 2019/882</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-19-toegankelijkheidseisen/#risico","title":"Risico","text":"<p>Niet naleven van deze verplichtingen kan leiden tot juridische en operationele problemen, en kan de veiligheid en betrouwbaarheid van het AI-systeem in gevaar brengen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-20-gebruiksverantwoordelijken-maatregelen/","title":"Hoog-risico-AI-systemen worden gebruikt volgens de gebruiksaanwijzing","text":"<p>aia-20ImplementatieProjectleiderBeleid en adviesGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-20-gebruiksverantwoordelijken-maatregelen/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, in overeenstemming met de leden 3 en 6 van artikel 26 van de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-20-gebruiksverantwoordelijken-maatregelen/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico moeten vergezeld gaan van relevante documentatie in de vorm van gebruiksaanwijzingen.</p> <p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico moeten geschikte maatregelen nemen om ervoor te zorgen dat zij deze systemen gebruiken volgens de bijgevoegde instructies.</p> <p>De gebruiksverantwoordelijke zorgt ervoor dat de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico, voor zover hij daar controle over heeft.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-20-gebruiksverantwoordelijken-maatregelen/#bronnen","title":"Bronnen","text":"<p>Artikel 26(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-20-gebruiksverantwoordelijken-maatregelen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-20-gebruiksverantwoordelijken-maatregelen/#risico","title":"Risico","text":"<p>Het niet naleven van deze maatregelen kan leiden tot onjuist gebruik van de AI-systemen, wat de effectiviteit en veiligheid ervan kan verminderen, en kan resulteren in risico's voor gebruikers en derden.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/","title":"Menselijk toezicht van hoog-risico-AI-systemen wordt uitgevoerd door mensen met voldoende kennis en mogelijkheden","text":"<p>aia-21OrganisatieverantwoordelijkhedenProjectleiderGovernanceMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken dragen het menselijk toezicht over een hoog risico AI-systeem op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat natuurlijke personen die het menselijk toezicht moeten uitvoeren over het AI-systeem met een hoog risico, daarvoor over de nodige bekwaamheid, opleiding en autoriteit beschikt. Daarbij kan het van belang zijn dat deze natuurlijke personen ondersteuning krijgen bij het uitvoeren van deze taak.</p> <p>De gebruiksaanwijzing bij een hoog risico AI-systeem hoort informatie te bevatten over kenmerken, mogelijkheden en beperkingen van de prestaties van het AI-systeem bevatten. Deze informatie is relevant om te bepalen welke taken onder het bereik van menselijk toezicht kunnen worden gebracht.</p> <p>Deze informatie bestaat onder andere uit een beschrijving: - welke handelingen van de gebruiksverantwoordelijke van invloed kunnen zijn op het gedrag en de prestaties van het systeem, - op grond waarvan het AI-systeem risico\u2019s kan veroorzaken voor de gezondheid - veiligheid en grondrechten - over de wijzigingen die vooraf zijn bepaald en beoordeeld met het oog op conformiteit door de aanbieder - en over de relevante maatregelen voor menselijk toezicht, waaronder de maatregelen om de interpretatie van de output van het AI-systeem door de gebruiksverantwoordelijken te vergemakkelijken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 26(2) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 27(1 sub e) Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage IV (2 sub e en 3) Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-21-gebruiksverantwoordelijken-menselijk-toezicht/#risico","title":"Risico","text":"<p>Als de natuurlijke toezichthouder geen effectief toezicht kan houden op het hoog risico AI-systeem, kunnen ongewenste, negatieve effecten onstaan voor betrokkenen en de organisatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/","title":"De werking van hoog-risico-AI-systemen wordt gemonitord","text":"<p>aia-22Monitoring en beheerProjectleiderMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/#vereiste","title":"Vereiste","text":"<p>De werking van hoog-risico-AI-systemen wordt gemonitord.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/#toelichting","title":"Toelichting","text":"<p>Gebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72 AI Verordening.</p> <p>Dit is van belang om passende maatregelen te kunnen treffen als het systeem onbedoeld anders gaat functioneren.</p> <p>Als gebruiksverantwoordelijken redenen hebben om aan te nemen dat het gebruik overeenkomstig de gebruiksaanwijzingen ertoe kan leiden dat dat AI-systeem een risico vormt in de zin van artikel 79, lid 1, stellen zij de aanbieder of distributeur en de betreffende markttoezichtautoriteit hiervan zonder onnodige vertraging in kennis en onderbreken zij het gebruik van dat systeem.</p> <p>Wanneer gebruiksverantwoordelijke een ernstig incident vaststellen, stellen zij ook onmiddellijk eerst de aanbieder hiervan in kennis, en vervolgens de importeur of distributeur en de betreffende markttoezichtautoriteiten van dat incident.</p> <p>Als de gebruiksverantwoordelijke de aanbieder niet kan bereiken, is artikel 73 mutatis mutandis van toepassing. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijke van AI-systemen die de hoedanigheid van rechtshandhavingsinstanties hebben.</p> <p>Voor gebruiksverantwoordelijke die in de hoedanigheid van financi\u00eble instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financi\u00eble diensten, wordt de monitoringsverplichting overeenkomstig de eerste alinea geacht te zijn vervuld door te voldoen aan de regels inzake interne governance, regelingen of processen en -mechanismen uit hoofde van het desbetreffende recht inzake financi\u00eble diensten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/#bronnen","title":"Bronnen","text":"<p>Artikel 26(5) Verordening Artifici\u00eble Intelligentie.</p> <p>Artikel 72 Verordening Artifici\u00eble Intelligentie.</p> <p>Artikel 73 Verordening Artifici\u00eble Intelligentie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-22-gebruiksverantwoordelijken-monitoren-werking/#risico","title":"Risico","text":"<p>Zonder monitoring door gebruiksverantwoordelijken en (waar nodig) het informeren van aanbieder, distributeur of markttoezichtautoriteit, kan de foutieve werking van een hoog risico AI-systeem niet worden gesignaleerd en hersteld.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-23-gebruiksverantwoordelijken-bewaren-logs/","title":"Logs voor hoog-risico-AI-systemen worden bewaard door de gebruiksverantwoordelijke","text":"<p>aia-23OntwikkelenMonitoring en beheerProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-23-gebruiksverantwoordelijken-bewaren-logs/#vereiste","title":"Vereiste","text":"<p>Logs voor hoog-risico-AI-systemen worden bewaard door de gebruiksverantwoordelijke.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-23-gebruiksverantwoordelijken-bewaren-logs/#toelichting","title":"Toelichting","text":"<p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevens</p> <p>Anders dan in artikel 16(e) AI-verordening, waar een vergelijkbare vereiste geldt voor aanbieders, gaat het hier om een vereiste specifiek voor de gebruiksverantwoordelijken.</p> <p>Het is van belang dat de gebruiksverantwoordelijken een zelfstandige beoordeling maakt wat moet worden gelogd en voor welke periode gezien de doelstelling van de inzet van het AI-systeem.</p> <p>Daarbij is het van belang om te beoordelen in hoeverre een gebruiksverantwoordelijke hier 'controle' over heeft.</p> <p>De gebruiksverantwoordelijke zal, al dan niet samen met de aanbieder, (technische) maatregelen moeten treffen om dit te realiseren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-23-gebruiksverantwoordelijken-bewaren-logs/#bronnen","title":"Bronnen","text":"<p>Artikel 26(6) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-23-gebruiksverantwoordelijken-bewaren-logs/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-23-gebruiksverantwoordelijken-bewaren-logs/#risico","title":"Risico","text":"<p>Het niet of onvoldoende bewaren van logs kan het vermogen belemmeren om incidenten te analyseren, naleving te controleren en verantwoordelijkheid vast te stellen bij mogelijke problemen met het AI-systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-24-informeren-werknemers/","title":"Werknemers weten dat hun organisatie een hoog-risico AI-systeem gebruikt","text":"<p>aia-24ImplementatieProjectleiderTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-24-informeren-werknemers/#vereiste","title":"Vereiste","text":"<p>Werknemers weten dat hun organisatie een hoog-risico AI-systeem gebruikt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-24-informeren-werknemers/#toelichting","title":"Toelichting","text":"<p>Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico.</p> <p>Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.</p> <p>Dit vereiste benadrukt het belang van het informeren van werknemersvertegenwoordigers en betrokken werknemers over de inzet van een hoog risico AI-systeem op de werkplaats.</p> <p>De gebruiksverantwoordelijke als werknemer dient hier zorg voor te dragen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-24-informeren-werknemers/#bronnen","title":"Bronnen","text":"<p>Artikel 26(7) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-24-informeren-werknemers/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-24-informeren-werknemers/#risico","title":"Risico","text":"<p>Als werknemersvertegenwoordigers en werknemers niet worden ge\u00efnformeerd over de inzet van een hoog risico AI-systeem, kunnen zij zich niet weren tegen mogelijk ongewenste en negatieve effecten van de inzet van het hoog risico AI-systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-25-gebruiksverantwoordelijken-registratieverplichtingen/","title":"Gebruiksverantwoordelijken controleren de registratie van het hoog-risico AI-systeem in de EU-databank","text":"<p>aia-25OrganisatieverantwoordelijkhedenImplementatieMonitoring en beheerProjectleiderTransparantieGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-25-gebruiksverantwoordelijken-registratieverplichtingen/#vereiste","title":"Vereiste","text":"<p>Gebruiksverantwoordelijken controleren de registratie van het hoog-risico AI-systeem in de EU-databank.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-25-gebruiksverantwoordelijken-registratieverplichtingen/#toelichting","title":"Toelichting","text":"<p>Het is van belang dat gebruiksverantwoordelijken nagaan of het betreffende hoog risico AI-systeem door aanbieder is geregistreerd in de EU-databank (zoals omschreven in artikel 71 AI-verordening).</p> <p>Voordat het betreffende AI-systeem (bijlage III vermeld AI-systeem met een hoog risico) in gebruik te stellen of te gebruiken (met uitzondering van de in punt 2 van bijlage III vermelde AI-systemen met een hoog risico) registreren gebruiksverantwoordelijken die overheidsinstanties, instellingen, organen of instanties van de Unie, of personen die namens hen optreden, zichzelf en selecteren zij het systeem en registreren zij het gebruik ervan in de in artikel 71 bedoelde EU-databank.</p> <p>Heeft de aanbieder het betreffende hoog risico AI-systeem niet geregistreerd in de EU-Databank, dan mag het hoog risico AI-systeem niet worden gebruikt. De aanbieder of distributeur wordt door de gebruiksverantwoordelijke ge\u00efnformeerd dat het systeem niet is geregistreerd in de EU-databank.</p> <p>AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III (kritieke infrastructuur) worden op nationaal niveau geregistreerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-25-gebruiksverantwoordelijken-registratieverplichtingen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 26(8) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 49 (3) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 71 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-25-gebruiksverantwoordelijken-registratieverplichtingen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-25-gebruiksverantwoordelijken-registratieverplichtingen/#risico","title":"Risico","text":"<p>Zonder registratie van het hoog risico AI-systeem en het registreren welke organisaties of personen hier gebruik van maken, is het negatieve negatieve van het mogelijk onjuist of ongewenst functioneren van het AI-systeem niet te overzien en onduidelijk welke betrokken dit raakt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-26-recht-op-uitleg-ai-besluiten/","title":"Mensen over wie besluiten worden genomen door een hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluiten","text":"<p>aia-26OrganisatieverantwoordelijkhedenOntwerpMonitoring en beheerProjectleiderGovernanceFundamentele rechtenTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-26-recht-op-uitleg-ai-besluiten/#vereiste","title":"Vereiste","text":"<p>Mensen over wie besluiten worden genomen door een hoog-risico-AI-systemen, krijgen op verzoek informatie over deze besluiten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-26-recht-op-uitleg-ai-besluiten/#toelichting","title":"Toelichting","text":"<p>Elke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke toelichting te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.</p> <p>Die uitleg moet duidelijk en zinvol zijn en moet de grondslag zijn waarop de getroffen personen zich kunnen baseren om hun rechten uit te oefenen.</p> <p>Het recht om uitleg te krijgen mag niet van toepassing zijn op het gebruik van AI-systemen waarvoor uitzonderingen of beperkingen voortvloeien uit het Unierecht of het nationale recht en moet alleen van toepassing zijn voor zover het Unierecht niet reeds in dit recht voorziet.</p> <p>Dit vereiste geldt bijvoorbeeld niet als het gaat om AI-systemen die bedoeld zijn om te worden gebruikt als veiligheidscomponent bij het beheer of de exploitatie van kritieke digitale infrastructuur, wegverkeer of bij de levering van water, gas, verwerking en electriciteit (punt 2 bij Bijlage III van AI-verordening).</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-26-recht-op-uitleg-ai-besluiten/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 86(1) Verordening Artifici\u00eble Intelligentie</li> <li>Artikel 26(11) Verordening Artifici\u00eble Intelligentie</li> <li>Bijlage III Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-26-recht-op-uitleg-ai-besluiten/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-26-recht-op-uitleg-ai-besluiten/#risico","title":"Risico","text":"<p>Als gebruiksverantwoordelijke geen duidelijke, inhoudelijke toelichting geeft over de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen bij het genomen besluit, is het voor getroffen personen niet mogelijk zich te verdedigen tegen de rechtsgevolgen die hieruit voortkomen of de nadelige gevolgen voor gezondheid, veiligheid of diens grondrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-27-beoordelen-gevolgen-grondrechten/","title":"Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechten","text":"<p>aia-27OntwerpVerificatie en validatieProjectleiderBeleid en adviesFundamentele rechten</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-27-beoordelen-gevolgen-grondrechten/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen voor publieke taken worden beoordeeld op gevolgen voor grondrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-27-beoordelen-gevolgen-grondrechten/#toelichting","title":"Toelichting","text":"<p>Voordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2 AI-verordening, in gebruik wordt genomen, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren operatoren die publiekrechtelijke instellingen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en operatoren van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, onder b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren.</p> <p>Publieke instellingen of particuliere entiteiten die openbare diensten leveren, en operators van bepaalde AI-systemen, moeten dus een beoordeling uitvoeren van de impact op de grondrechten die het gebruik ervan kan hebben.</p> <p>Deze evaluatie is bedoeld om potenti\u00eble risico's te identificeren die kunnen voortvloeien uit het gebruik van dergelijke systemen en om passende maatregelen te nemen om deze risico's te beheersen.</p> <p>Het doel is om de bescherming van grondrechten te waarborgen bij het gebruik van AI-systemen met een hoog risico, met name in sectoren waar deze systemen cruciale diensten leveren aan het publiek.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-27-beoordelen-gevolgen-grondrechten/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 27, lid 1, AI-verordening</li> <li>Artikel 6, lid 2, AI-verordening</li> <li>Bijlage III, onderdeel 2 en 5, AI-verordening</li> <li>Impact Assessment Mensenrechten en Algoritmes (IAMA)</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-27-beoordelen-gevolgen-grondrechten/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGebruiksverantwoordelijkeGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-27-beoordelen-gevolgen-grondrechten/#risico","title":"Risico","text":"<p>Het niet uitvoeren van deze beoordeling kan leiden tot schendingen van de grondrechten, juridische complicaties en verlies van vertrouwen van het publiek in het gebruik van AI-systemen door overheids- en openbare dienstverlenende entiteiten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-27-beoordelen-gevolgen-grondrechten/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenImpact Assessment Mensenrechten en AlgoritmesStandaarden"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-28-transparantieverplichtingen/","title":"AI-systemen worden zo ontworpen en gebruikt, dat mensen begrijpen wanneer zij met een AI-systeem communiceren en welke content gemaakt is door een AI-systeem","text":"<p>aia-28OntwikkelenImplementatieProjectleiderOntwikkelaarTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-28-transparantieverplichtingen/#vereiste","title":"Vereiste","text":"<p>AI-systemen worden zo ontworpen en gebruikt, dat mensen begrijpen wanneer zij met een AI-systeem communiceren en welke content gemaakt is door een AI-systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-28-transparantieverplichtingen/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen zorgen dat AI-sytemen zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden ge\u00efnformeerd dat zij interacteren met een AI-systeem.</p> <p>Gebruiksverantwoordelijken moeten betrokkenen informeren over de werking van het systeem en in het geval van een AI-systeem dat content gegenereert duidelijk kenbaar maken dat de content kunstmatig is gegenereerd of gemanipuleerd.</p> <p>Dit geldt voor AI-systemen die:</p> <ul> <li>gebruikt worden voor directe interactie met natuurlijke personen (zoals chatbots).</li> <li>synthetische afbeeldingen, audio, video of tekst genereert en/of manipuleert (bijvoorbeeld deepfake).</li> <li>doen aan emotieherkenning of biometrische categorisatie.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-28-transparantieverplichtingen/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 50 Verordening Artifici\u00eble Intelligentie</li> <li>Overweging 132 Verordening Artifici\u00eble Intelligentie</li> <li>Overweging 134 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-28-transparantieverplichtingen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGeen hoog risico AI-systeemAanbiederTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-28-transparantieverplichtingen/#risico","title":"Risico","text":"<p>Bepaalde AI-systemen die bedoeld zijn om met natuurlijke personen te interageren of om content te genereren, kunnen specifieke risico\u2019s op imitatie of misleiding met zich meebrengen, ongeacht of zij als systeem met een hoog risico gelden.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-29-ai-modellen-algemene-doeleinden/","title":"AI-modellen voor algemene doeleinden zijn voorzien van voldoende technische documentatie en informatie","text":"<p>aia-29OntwerpOntwikkelenMonitoring en beheerProjectleiderTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-29-ai-modellen-algemene-doeleinden/#vereiste","title":"Vereiste","text":"<p>AI-modellen voor algemene doeleinden zijn voorzien van voldoende technische documentatie en informatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-29-ai-modellen-algemene-doeleinden/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden hebben een bijzondere rol en verantwoordelijkheid.</p> <p>Zij leveren modellen die de basis kunnen vormen voor weer andere systemen en algoritmen, die vaak weer door andere partijen worden aangeboden dan de ontwikkelaar van het algemene systeem. Dit vraagt om een goed inzicht in de modellen en hun capaciteiten, zowel qua integratie van de modellen in producten als qua naleving van verplichtingen.</p> <p>Er zijn daarom evenredige transparantiemaatregelen nodig, zoals het opstellen en bijwerken van documentatie en verstrekken van informatie over het AI-model voor algemeen gebruik door de aanbieders van systemen die de algemene modellen gebruiken in hun product. De minimaal in de documentatie op te nemen elementen moeten worden vastgelegd volgens bijlage XII van de AI-Verordening.</p> <p>De aanbieder van het AI-model voor algemene doeleinden dient technische documentatie op te stellen en bij te werken om deze op verzoek te kunnen overleggen aan het AI-bureau en de nationale bevoegde autoriteiten.</p> <p>Hierbij is het ook van belang dat de aanbieder van AI-modellen voor algemene doelstelling beleid opstellen voor naleving van auteursrechten en naburige rechten (artikel 4, lid 3 Richtlijn (EU) 2019/790).</p> <p>In art. 53 lid 2 wordt een uitzondering gemaakt op deze vereisten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-29-ai-modellen-algemene-doeleinden/#bronnen","title":"Bronnen","text":"<p>Artikel 53 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-29-ai-modellen-algemene-doeleinden/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-model voor algemene doeleindenAanbiederSysteemrisicoGeen systeemrisico</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-29-ai-modellen-algemene-doeleinden/#risico","title":"Risico","text":"<p>Het niet voldoen aan deze verplichtingen kan leiden tot juridische en ethische complicaties, inclusief schendingen van auteursrechten en gebrek aan transparantie in het gebruik van AI-modellen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-30-ai-modellen-algemene-doeleinden-systeemrisico/","title":"Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico treffen extra maatregelen","text":"<p>aia-30OntwerpVerificatie en validatieMonitoring en beheerProjectleiderOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-30-ai-modellen-algemene-doeleinden-systeemrisico/#vereiste","title":"Vereiste","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico treffen extra maatregelen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-30-ai-modellen-algemene-doeleinden-systeemrisico/#toelichting","title":"Toelichting","text":"<p>De aanbieders van AI-modellen voor algemene doeleinden die systeemrisico\u2019s inhouden, moeten, naast de verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden, onderworpen worden aan verplichtingen die gericht zijn op het identificeren en beperken van die systeemrisico\u2019s en op waarborging van een passend niveau van cyberbeveiliging, ongeacht of het model een op zichzelf staand model is of ingebed in een AI-systeem of in een product.</p> <p>Aanbieders van AI-modellen voor algemene doeleinden met een potentieel systeemrisico moeten modelevaluaties uitvoeren. Dit omvat het testen en documenteren van het model volgens de stand van de techniek, met specifieke aandacht voor het identificeren en beperken van kwetsbaarheden. Deze maatregelen zijn bedoeld om systematische risico's te adresseren en te verminderen. Deze vereiste is een aanvulling op de genoemde verplichtingen in artikel 53 van de AI-verordening.</p> <p>Systeemrisico betekent: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleienden, die aanzienlijke gevolgen hebben voor de markt van de Uniek vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid.</p> <p>Systeemrisico\u2019s nemen logischerwijs toe naargelang de capaciteiten en het bereik van een model groter zijn, kunnen zich voordoen gedurende de gehele levenscyclus van het model en worden be\u00efnvloed door elementen als misbruik van het model, de betrouwbaarheid, billijkheid, beveiliging en mate van autonomie ervan. Ook worden ze be\u00efnvloed door de toegang van het model tot instrumenten, nieuwe of gecombineerde modaliteiten, introductie- en distributiestrategie\u00ebn, en door het potentieel om waarborgen te omzeilen en andere factoren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-30-ai-modellen-algemene-doeleinden-systeemrisico/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 55 Verordening Artifici\u00eble Intelligentie</li> <li>Overweging 110 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-30-ai-modellen-algemene-doeleinden-systeemrisico/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-model voor algemene doeleindenAanbiederSysteemrisico</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-30-ai-modellen-algemene-doeleinden-systeemrisico/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot negatieve gevolgen voor de gezondheid, veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-31-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/","title":"Als AI-modellen voor algemene doeleinden met systeemrisico\u2019s ernstige incidenten veroorzaken, wordt dit gedocumenteerd en gerapporteerd","text":"<p>aia-31Monitoring en beheerProjectleiderGovernanceTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-31-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#vereiste","title":"Vereiste","text":"<p>Als AI-modellen voor algemene doeleinden met systeemrisico\u2019s ernstige incidenten veroorzaken, wordt dit gedocumenteerd en gerapporteerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-31-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico moeten ernstige incidenten documenteren en rapporteren. Deze informatie moet onmiddellijk worden gemeld aan het AI-bureau en eventueel aan nationale autoriteiten.</p> <p>Dit proces is cruciaal voor het waarborgen van de veiligheid en het nemen van passende corrigerende maatregelen. Dit vereiste is een aanvulling op de in artikel 53 AI-verordening genoemde verplichtingen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-31-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#bronnen","title":"Bronnen","text":"<p>Artikel 55(1c) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-31-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-model voor algemene doeleindenAanbiederSysteemrisico</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-31-ai-modellen-algemene-doeleinden-systeemrisico-ernstige-incidenten/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot risico's op veiligheidsincidenten, datalekken en schade aan de betrokken partijen en het publiek.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/","title":"AI-modellen voor algemene doeleinden met systeemrisico\u2019s zijn voldoende beveiligd tegen cyberaanvallen","text":"<p>aia-32OntwikkelenMonitoring en beheerOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#vereiste","title":"Vereiste","text":"<p>AI-modellen voor algemene doeleinden met systeemrisico\u2019s zijn voldoende beveiligd tegen cyberaanvallen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het model.</p> <p>Aanbieders van AI-modellen met systeemrisico moeten zorgen voor passende cyberbeveiligingsmaatregelen. Dit omvat het beschermen van zowel het AI-model als de fysieke infrastructuur tegen potenti\u00eble cyberdreigingen.</p> <p>Het doel is om de integriteit en veiligheid van het model en de infrastructuur te waarborgen. Dit vereiste is een aanvulling op de in artikel 53 AI-verordening genoemde verplichtingen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#bronnen","title":"Bronnen","text":"<p>Artikel 55(1d) Verordening Artifici\u00eble Intelligentie</p> <p>OWASP - top 10 meest kritieke kwetsbaarheden in generatieve AI-systemen</p> <p>AIVD - AI-systemen: ontwikkel ze veilig</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-model voor algemene doeleindenAanbiederSysteemrisico</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-32-ai-modellen-algemene-doeleinden-systeemrisico-cyberbeveiliging/#risico","title":"Risico","text":"<p>Niet voldoen aan deze verplichtingen kan leiden tot risico's op veiligheidsincidenten, datalekken en schade aan de betrokken partijen en het publiek.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-33-verwerking-in-testomgeving/","title":"AI-testomgevingen die persoonsgegevens verwerken, voldoen aan strenge voorwaarden","text":"<p>aia-33OrganisatieverantwoordelijkhedenOntwikkelenDataverkenning en datapreparatieJuristOntwikkelaarProjectleiderPrivacy en gegevensbeschermingData</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-33-verwerking-in-testomgeving/#vereiste","title":"Vereiste","text":"<p>AI-testomgevingen die persoonsgegevens verwerken, voldoen aan strenge voorwaarden.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-33-verwerking-in-testomgeving/#toelichting","title":"Toelichting","text":"<p>De rechtmatige verwerking van persoonsgegevens voor andere doeleinden voor het ontwikkelen, trainen en testen van AI-modellen is mogelijk, maar het moet voldoen aan strikte voorwaarden die zijn opgenomen in artikel 57 AI-Verordening. Hiervoor is een AI-testomgeving (ook wel regulatory sandbox genoemd) noodzakelijk, waarin maatregelen of kunnen worden getroffen om de data veilig te verwerken.</p> <p>Persoonsgegevens die in de testomgeving worden aangemaakt mogen niet buiten de testomgeving worden gedeeld en logbestanden worden bijgehouden voor de duur van de deelname aan de testomgeving. Wanneer in de testomgeving een LLM-model wordt (bij)getraind met privacygevoelige data mag dit model bovendien niet worden gebruikt in een niet-vertrouwelijke omgeving, omdat de trainingsdata, inclusief de persoonsgegevens, door het model zijn opgeslagen.</p> <p>Voor toepassingen voor het verder verwerken van gegevens kan worden gedacht aan het ontwikkelen van een AI-systeem zodat een overheidsinstantie of een andere natuurlijke of rechtspersoon een aanzienlijk openbaar belang kan waarborgen, bijvoorbeeld op het gebied van kwaliteit van milieu, duurzaamheid, openbare veiligheid en gezondheid.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-33-verwerking-in-testomgeving/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 57 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-33-verwerking-in-testomgeving/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-model voor algemene doeleindenAI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemGeen hoog risico AI-systeemAanbiederGebruiksverantwoordelijkeSysteemrisicoGeen systeemrisicoGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-33-verwerking-in-testomgeving/#risico","title":"Risico","text":"<p>Verdere verwerking van persoonsgegevens buiten een AI-testomgeving vergroot de kans op bijvoorbeeld het lekken van de persoonsgegevens, wat kan leiden tot een inbreuk op de privacyrechten van betrokken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-34-monitoring-na-het-in-de-handel-brengen/","title":"Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem","text":"<p>aia-34Monitoring en beheerProjectleiderTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-34-monitoring-na-het-in-de-handel-brengen/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn voorzien van een monitoringsysteem.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-34-monitoring-na-het-in-de-handel-brengen/#toelichting","title":"Toelichting","text":"<p>Aanbieders moeten een monitoringssysteem opzetten voor het monitoren na het in de handel brengen van het AI-systeem.</p> <p>Dit systeem moet documenteren op een wijze die passend is bij de aard van de AI-technologie\u00ebn en de risico's van het betreffende AI-systeem met een hoog risico. Dit monitoringssysteem moet proportioneel zijn aan de complexiteit en potenti\u00eble impact van het AI-systeem.</p> <p>Het systeem voor monitoring na het in de handel brengen verzamelt, documenteert en analyseert actief en systematisch relevante data die door gebruiksverantwoordelijken kunnen zijn verstrekt of via andere bronnen kunnen zijn verzameld, over de prestaties van AI-systemen met een hoog risico gedurende hun hele levensduur.</p> <p>Dit stelt de aanbieder in staat na te gaan of AI-systemen blijvend voldoen aan de in hoofdstuk III, afdeling 2, van de AI-verordening vermelde voorschriften. In voorkomend geval omvat de monitoring na het in de handel brengen een analyse van de interactie met andere AI-systemen. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijken die rechtshandhavingsinstanties zijn.</p> <p>Het systeem voor monitoring na het in de handel brengen is gebaseerd op een plan voor monitoring na het in de handel brengen. Het plan voor monitoring na het in de handel brengen maakt deel uit van de in bijlage IV bedoelde technische documentatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-34-monitoring-na-het-in-de-handel-brengen/#bronnen","title":"Bronnen","text":"<p>Artikel 72(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-34-monitoring-na-het-in-de-handel-brengen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-34-monitoring-na-het-in-de-handel-brengen/#risico","title":"Risico","text":"<p>Zonder monitoringssysteem voor na het in handel brengen is er een risico dat verminderde pestaties van een AI-systeem met hoog risico ongedeteceerd blijven. Een aanbieder kan niet nagaan of een AI-systeem blijvend voldoet aan voorschriften.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-35-melding-ernstige-incidenten/","title":"Ernstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouder","text":"<p>aia-35OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderGovernance</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-35-melding-ernstige-incidenten/#vereiste","title":"Vereiste","text":"<p>Ernstige incidenten door hoog-risico-AI-systemen worden gemeld aan de toezichthouder.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-35-melding-ernstige-incidenten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-systemen met een hoog risico die binnen de EU worden verhandeld, moeten ernstige incidenten melden bij de markttoezichtautoriteiten van de lidstaten waar het incident heeft plaatsgevonden. Het doel is om de veiligheid en betrouwbaarheid van AI-systemen te waarborgen en mogelijke risico's voor gebruikers te minimaliseren.</p> <p>Dit meldingsproces is bedoeld om snel en adequaat te reageren op ernstige incidenten die zich voordoen bij het gebruik van deze AI-systemen, en om passende maatregelen te nemen ter bescherming van de consumenten en het publiek. Een 'ernstig incident' wordt in artikel 3 van de AI-verordening gedefinieerd als: een incident of gebrekkig functioneren van een AI-systeem dat direct of indirect leidt tot:</p> <ol> <li>het overlijden van een persoon of ernstige schade voor de gezondheid van een persoon;</li> <li>een ernstige en onomkeerbare verstoring van het beheer of de exploitatie van kritieke infrastructuur;</li> <li>een schending van de uit het recht van de Unie voortvloeiende verplichtingen ter bescherming van de grondrechten;</li> <li>ernstige schade aan eigendommen of het milieu.</li> </ol>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-35-melding-ernstige-incidenten/#bronnen","title":"Bronnen","text":"<p>Artikel 73(1) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-35-melding-ernstige-incidenten/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-35-melding-ernstige-incidenten/#risico","title":"Risico","text":"<p>Het niet melden van ernstige incidenten kan leiden tot vertraagde reactie op potenti\u00eble gevaren voor gebruikers en kan het vertrouwen in AI-systemen ondermijnen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/","title":"Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordening","text":"<p>aia-36OrganisatieverantwoordelijkhedenMonitoring en beheerProjectleiderGovernanceMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/#vereiste","title":"Vereiste","text":"<p>Klokkenluiders kunnen veilig melden dat een organisatie zich niet houdt aan de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/#toelichting","title":"Toelichting","text":"<p>Inbreuken op de AI-Verordening moeten gemeld kunnen worden en melders moeten dit op een veilige en vertrouwelijke manier kunnen doen, zoals beschreven in Richtlijn (EU) 2019/1937.</p> <p>Personen die optreden als klokkenluiders bij inbreuken op de AI-verordening, moeten worden beschermd uit hoofde van het Unierecht. Richtlijn (EU) 2019/1937 (https://eur-lex.europa.eu/legal-content/NL/LSU/?uri=CELEX:32019L1937) van het Europees Parlement en de Raad moet daarom van toepassing zijn.</p> <p>De richtlijn biedt een kader voor het veilig en vertrouwelijk melden van schendingen van de verordening, terwijl het de melders (\"klokkenluiders\") beschermt tegen represailles of vervolging. Deze richtlijn bevordert transparantie en verantwoording binnen organisaties en draagt bij aan een cultuur van naleving en integriteit.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/#bronnen","title":"Bronnen","text":"<p>Artikel 87 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenAI-model voor algemene doeleindenHoog risico AI-systeemGeen hoog risico AI-systeemAanbiederGebruiksverantwoordelijkeImporteurDistributeurSysteemrisicoGeen systeemrisicoGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-36-melding-inbreuk-op-ai-verordening/#risico","title":"Risico","text":"<p>Gebrek aan een veilige omgeving kan ertoe leiden dat klokkenluiders geen melding maken van inbreuk op de AI-verordening. Dit schaadt het rapportagesysteem en heeft negatief effect op het maatschappelijk welzijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-37-recht-klacht-indienen-bij-ai-bureau/","title":"Aanbieders van AI-systemen kunnen een klacht indienen over de aanbieder van hun AI-model","text":"<p>aia-37OrganisatieverantwoordelijkhedenProjectleiderFundamentele rechten</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-37-recht-klacht-indienen-bij-ai-bureau/#vereiste","title":"Vereiste","text":"<p>Aanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op de AI verordening bij het AI-bureau.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-37-recht-klacht-indienen-bij-ai-bureau/#toelichting","title":"Toelichting","text":"<p>Aanbieders verder in de AI-waardeketen hebben het recht om een klacht in te dienen bij het AI-bureau in het geval van een inbreuk op de AI-verordening.</p> <p>Dit biedt hen een mechanisme om actie te ondernemen bij schendingen van de regels met betrekking tot AI-modellen voor algemene doeleinden die zij ge\u00efntrigeerd hebben in AI-systemen.</p> <p>Het AI-bureau kan dan passende maatregelen nemen om de naleving van de verordening te handhaven en eventuele geschillen tussen aanbieders op te lossen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-37-recht-klacht-indienen-bij-ai-bureau/#bronnen","title":"Bronnen","text":"<p>Artikel 89(2) Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-37-recht-klacht-indienen-bij-ai-bureau/#van-toepassing-op","title":"Van toepassing op","text":""},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-37-recht-klacht-indienen-bij-ai-bureau/#risico","title":"Risico","text":"<p>Gebrek aan klachtrecht verhindert het AI-bureau om tijdig en zorgvuldig te kunnen ingrijpen bij overtreding van de AI-verordening.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/","title":"Hoog-risico-AI-systemen zijn getest","text":"<p>aia-38OntwerpOntwikkelenMonitoring en beheerVerificatie en validatieProjectleiderOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/#vereiste","title":"Vereiste","text":"<p>Hoog-risico-AI-systemen zijn getest.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/#toelichting","title":"Toelichting","text":"<p>AI-systemen met een hoog risico worden getest met het oog op het vaststellen van passende en gerichte risicobeheersmaatregelen. De tests zorgen ervoor dat AI-systemen met een hoog risico consistent presteren ten aanzien van het doel ervan en in overeenstemming zijn met de geldende eisen.</p> <p>Het testen van AI-systemen met een hoog risico vindt, zoals passend, in de loop van het ontwikkelproces plaats en in ieder geval voordat het systeem in de handel wordt gebracht of in gebruik is gesteld.</p> <p>Er wordt getest aan de hand van vooraf vastgestelde beoordelingsmaatstaven en probabilistische drempels die passend zijn voor het beoogde doel van het AI-systeem met een hoog risico. De procedures voor testen zijn onderdeel van het kwaliteitsbeheer.</p> <p>Bij het verwerken van persoonsgegevens voor het ontwikkelen, trainen en testen van een AI-systeem in een AI-testomgeving, wordt een volledige en gedetailleerde beschrijving van het testproces en de testresultaten onderdeel van de technische documentatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/#testen-van-ai-systemen-met-een-hoog-risico-onder-reele-omstandigheden-buiten-ai-testomgevingen","title":"Testen van AI-systemen met een hoog risico onder re\u00eble omstandigheden buiten AI-testomgevingen","text":"<p>AI-systemen met een hoog risico kunnen onder re\u00eble omstandigheden buiten AI-testomgevingen voor regelgeving worden getest door aanbieders of potenti\u00eble aanbieders van in bijlage III vermelde AI-systemen met een hoog risico in overeenstemming met dit artikel en het in dit artikel bedoelde plan voor tests onder re\u00eble omstandigheden, onverminderd de verbodsbepalingen krachtens artikel 5 AI-Verordening.</p> <p>Aanbieders of potenti\u00eble aanbieders kunnen zelf of in samenwerking met een of meer gebruiksverantwoordelijken of potenti\u00eble gebruiksverantwoordelijken onder re\u00eble omstandigheden tests uitvoeren op in bijlage III bedoelde AI-systemen met een hoog risico op elk moment v\u00f3\u00f3r het in de handel brengen of in gebruik nemen van het AI-systeem.</p> <p>Aanbieders of potenti\u00eble aanbieders mogen alleen testen onder re\u00eble omstandigheden als is voldaan aan alle volgende voorwaarden:</p> <p>a. de aanbieder of potenti\u00eble aanbieder heeft een plan voor tests onder re\u00eble omstandigheden opgesteld en ingediend bij de markttoezichtautoriteit in de lidstaat waar onder re\u00eble omstandigheden moet worden getest;</p> <p>b. de markttoezichtautoriteit in de lidstaat waar onder re\u00eble omstandigheden moet worden getest, heeft het testen onder re\u00eble omstandigheden en het plan voor tests onder re\u00eble omstandigheden goedgekeurd; indien de markttoezichtautoriteit binnen dertig dagen geen antwoord heeft gegeven, worden het testen onder re\u00eble omstandigheden en het plan voor tests onder re\u00eble omstandigheden geacht te zijn goedgekeurd; indien het nationale recht niet voorziet in een stilzwijgende goedkeuring, blijft het testen onder re\u00eble omstandigheden onderworpen aan een toestemming;</p> <p>c. de aanbieder of potenti\u00eble aanbieder, met uitzondering van aanbieders of potenti\u00eble aanbieders van in de punten 1, 6 en 7 van bijlage III bedoelde AI-systemen met een hoog risico op de gebieden rechtshandhaving, migratie, asiel en grenstoezichtsbeheer en AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III, heeft het testen onder re\u00eble omstandigheden geregistreerd overeenkomstig artikel 71, lid 4, met een Uniebreed uniek identificatienummer en de in bijlage IX gespecificeerde informatie; de aanbieder of potenti\u00eble aanbieder van in de punten 1, 6 en 7 van bijlage III bedoelde AI-systemen met een hoog risico op de gebieden van rechtshandhaving, migratie, asiel en grenstoezichtsbeheer, heeft het testen onder re\u00eble omstandigheden geregistreerd in het beveiligde niet-openbare gedeelte van de EU-databank overeenkomstig artikel 49, lid 4, punt d), met een Uniebreed uniek identificatienummer en de daarin gespecificeerde informatie; de aanbieder of potenti\u00eble aanbieder van in punt 2 van bijlage III bedoelde AI-systemen met een hoog risico heeft het testen onder re\u00eble omstandigheden geregistreerd overeenkomstig artikel 49, lid 5;</p> <p>d. de aanbieder of potenti\u00eble aanbieder die onder re\u00eble omstandigheden test, is in de Unie gevestigd of heeft een in de Unie gevestigde wettelijke vertegenwoordiger aangewezen;</p> <p>e. gegevens die zijn verzameld en verwerkt met het oog op het testen onder re\u00eble omstandigheden mogen alleen aan derde landen worden doorgegeven mits er passende en toepasselijke waarborgen uit hoofde van het Unierecht worden toegepast;</p> <p>f. het testen onder re\u00eble omstandigheden duurt niet langer dan nodig is om de doelstellingen ervan te verwezenlijken en in geen geval langer dan zes maanden, met een mogelijke verlenging van nog eens zes maanden indien de aanbieder of potenti\u00eble aanbieder de markttoezichtautoriteit daar vooraf van in kennis stelt, met een uitleg waarom een dergelijke verlenging noodzakelijk is;</p> <p>g. proefpersonen die onder re\u00eble omstandigheden worden getest en die tot kwetsbare groepen behoren vanwege hun leeftijd of handicap, worden naar behoren beschermd;</p> <p>h. indien een aanbieder of potenti\u00eble aanbieder het testen onder re\u00eble omstandigheden organiseert in samenwerking met een of meer gebruiksverantwoordelijken of potenti\u00eble gebruiksverantwoordelijken, worden zij ge\u00efnformeerd over alle aspecten van het testen die relevant zijn voor hun beslissing om deel te nemen, en krijgen zij de relevante gebruiksinstructies van het AI-systeem als bedoeld in artikel 13; de aanbieder of potenti\u00eble aanbieder en de gebruiksverantwoordelijke of potenti\u00eble gebruiksverantwoordelijke sluiten een overeenkomst waarin hun taken en verantwoordelijkheden worden gespecificeerd teneinde te waarborgen dat de bepalingen voor het testen onder re\u00eble omstandigheden uit hoofde van deze verordening en ander toepasselijk Unie- en nationaal recht worden nageleefd;</p> <p>i. de proefpersonen die onder re\u00eble omstandigheden worden getest, hebben ge\u00efnformeerde toestemming gegeven overeenkomstig artikel 61, of, in het geval van rechtshandhaving, indien het vragen om ge\u00efnformeerde toestemming het testen van het AI-systeem onder re\u00eble omstandigheden onmogelijk zou maken, de test zelf en het resultaat van de test onder re\u00eble omstandigheden hebben geen negatieve gevolgen voor de proefpersonen en hun persoonsgegevens worden na de uitvoering van test gewist;</p> <p>j. op het testen onder re\u00eble omstandigheden wordt daadwerkelijk toezicht gehouden door de aanbieder of potenti\u00eble aanbieder, alsook door gebruiksverantwoordelijken of potenti\u00eble gebruiksverantwoordelijken via personen die voldoende zijn gekwalificeerd op het relevante gebied en beschikken over de nodige capaciteiten, opleiding en bevoegdheden om hun taken uit te voeren;</p> <p>k. de voorspellingen, aanbevelingen of beslissingen van het AI-systeem kunnen daadwerkelijk worden teruggedraaid en genegeerd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/#bronnen","title":"Bronnen","text":"<p>Artikel 9(6 en 8) Verordening Artifici\u00eble Intelligentie</p> <p>Artikel 17(1 sub d) Verordening Artifici\u00eble Intelligentie</p> <p>Artikel 59(1 sub i) Verordening Artifici\u00eble Intelligentie</p> <p>Artikel 60 Verordening Artifici\u00eble Intelligentie</p> <p>Overweging 138 - 141 Verordening Artifici\u00eble Intelligentie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-systeemAI-systeem voor algemene doeleindenHoog risico AI-systeemAanbiederGeen transparantieverplichtingTransparantieverplichting</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/#risico","title":"Risico","text":"<p>Zonder het testen van een AI-systeem, ontstaat het risico dat het AI-systeem inconsistent gaat presteren ten aanzien van het doel.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-38-testen/#maatregelen","title":"Maatregelen","text":"Maatregelen"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-39-beleid-naleven-auteurs-en-naburige-rechten/","title":"Er is beleid opgesteld ter naleving van auteursrechten en naburige rechten door aanbieders van AI-modellen voor algemene doeleinden","text":"<p>aia-39OntwerpOntwikkelenMonitoring en beheerProjectleiderTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-39-beleid-naleven-auteurs-en-naburige-rechten/#vereiste","title":"Vereiste","text":"<p>Er is beleid opgesteld ter naleving van auteursrechten en naburige rechten door aanbieders van AI-modellen voor algemene doeleinden.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-39-beleid-naleven-auteurs-en-naburige-rechten/#toelichting","title":"Toelichting","text":"<p>Aanbieders van AI-modellen voor algemene doeleinden stellen beleid op ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologie\u00ebn, van een op grond van artikel 4, lid 3, van Richtlijn (EU) 2019/790 tot uitdrukking gebracht voorbehoud van rechten.</p> <p>Hiervoor dient de rechthebbende van materialen die auteursrechtelijk zijn beschermd een uitdrukkelijk voorbehoud te hebben gemaakt voor het verder gebruik van deze materialen.</p> <p>Deze eis geldt ongeacht de jurisdictie waarin de auteursrechtelijke relevante handelingen plaatsvinden die helpen bij het trainen van die AI-modellen voor algemene doeleienden.</p> <p>Alleen op deze manier kan gezorgd worden voor een gelijk speelveld voor aanbieders van AI-modellen voor algemene doeleinden, waar geen enkele aanbieder zich een concurrentievoordeel op de Uniemarkt mag kunnen verschaffen met lagere auteursrechtelijke normen dan de in de Unie toepasselijke normen.</p> <p>Voor een grotere transparantie ten aanzien van de bij de pre-training en training van AI-modellen voor algemene doeleinden gebruikte data, met inbegrip van door het auteursrecht beschermde tekst en data, is het passend dat aanbieders van dergelijke modellen een voldoende gedetailleerde samenvatting maken en publiceren van de voor de training van het AI-model voor algemene doeleinden gebruikte content.</p> <p>Zo kan er bijvoorbeeld een opsomming worden gegeven van de belangrijkste gegevensverzamelingen of -reeksen waarmee het model is getraind, zoals grote particuliere of openbare databanken of gegevensarchieven, en kan een uitleg in de vorm van een relaas worden gegeven over andere gebruikte gegevensbronnen.</p> <p>Het AI-bureau moet kunnen controleren of de aanbieder aan deze eisen voldoet, zonder evenwel geval voor geval de trainingsdata te controleren of te beoordelen qua naleving van het auteursrecht.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-39-beleid-naleven-auteurs-en-naburige-rechten/#bronnen","title":"Bronnen","text":"<p>Artikel 53(1 sub c) Verordening Artifici\u00eble Intelligentie</p> <p>Artikel 4, lid 3, DSM-auteursrechtrichtlijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-39-beleid-naleven-auteurs-en-naburige-rechten/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste is van toepassing voor onderstaande (combinatie van) labels. Gebruik de beslishulp AI-verordening voor hulp bij wat er in jouw situatie van toepassing is.  AI-model voor algemene doeleindenAanbiederSysteemrisicoGeen systeemrisico</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aia-39-beleid-naleven-auteurs-en-naburige-rechten/#risico","title":"Risico","text":"<p>Door het niet voeren van een beleid voor het naleven van auteursrechten en naburige rechten, ontstaat het risico dat met het ontwikkeling, trainen en testen van AI-modellen een inbreuk wordt gemaakt op deze rechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/arc-01-archiefwet/","title":"Informatie over algoritmes wordt in goede, geordende en toegankelijke staat gebracht, bewaard en vernietigd wanneer nodig","text":"<p>arc-01UitfaserenMonitoring en beheerOntwikkelenProjectleiderOntwikkelaarTransparantieData</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/arc-01-archiefwet/#vereiste","title":"Vereiste","text":"<p>Informatie over algoritmes wordt in goede, geordende en toegankelijke staat gebracht, bewaard en vernietigd wanneer nodig.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/arc-01-archiefwet/#toelichting","title":"Toelichting","text":"<p>Overheden moeten informatie over algoritmes in goede, geordende en toegankelijke staat brengen en bewaren. Ook moeten ze zorgen voor de vernietiging van archiefbescheiden die daarvoor in aanmerking komen.</p> <p>Op basis van deze informatie moet bijvoorbeeld gereconstrueerd kunnen worden hoe besluiten, ook in de context van algoritmes, tot stand zijn gekomen. Informatie over algoritmes moet daarom op basis van de selectielijst bewaard en vernietigd worden.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/arc-01-archiefwet/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 3 Archiefwet 1995</li> <li>Artikel 15 lid 2 Archiefwet 1995</li> <li>Archiefbesluit 1995</li> <li>Archiefregeling</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/arc-01-archiefwet/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/arc-01-archiefwet/#risico","title":"Risico","text":"<p>Zonder goede het goede, geordende en toegankelijke staat brengen en bewaren van gegevens is het voor betrokkene(n) of derden niet mogelijk om achteraf te reconstrueren en te controleren hoe besluiten, waar algoritmes aan hebben bijgedragen, tot stand zijn gekomen.</p> <p>Het nalaten om archiefbescheiden na verloop van tijd te verwijderen brengt risico's met zich mee op het gebied van privacy en informatiebeveiliging.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aut-01-auteursrechten/","title":"Auteursrechten zijn beschermd","text":"<p>aut-01OntwerpDataverkenning en datapreparatieJuristData</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aut-01-auteursrechten/#vereiste","title":"Vereiste","text":"<p>Auteursrechten en naburige rechten mogen niet geschonden worden bij het ontwikkelen, testen en gebruiken van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aut-01-auteursrechten/#toelichting","title":"Toelichting","text":"<p>Bepaalde type algoritmes worden ontwikkeld op basis van grote hoeveelheden data. Deze data wordt gebruikt voor het trainen en testen van algoritmes. Het gebruiken van deze data mag geen inbreuk maken op auteursrechten van diegene die deze rechten heeft. Ook de gegenereerde output van algoritmes mag geen inbreuk maken op deze rechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aut-01-auteursrechten/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1 Auteurswet</li> <li>Artikel 4-9 Auteurswet</li> <li>Artikel 10 Auteurswet</li> <li>Artikel 13 Auteurswet</li> <li>Artikel 15n jo. 15o Auteurswet</li> <li>Artikel 3 en 4, DSM-auteursrechtrichtlijn</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aut-01-auteursrechten/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/aut-01-auteursrechten/#risico","title":"Risico","text":"<p>Het niet voldoen aan het auteursrecht of naburige rechten kan leiden tot onrechtmatig gebruik van auteursrechtelijk beschermde inhoud, wat kan resulteren in mogelijke juridische geschillen, boetes en schadevergoedingen voor inbreuk op het auteursrecht. Bovendien kan het niet naleven van het auteursrecht het vertrouwen van gebruikers en belanghebbenden ondermijnen, wat kan leiden tot reputatieschade en gebrek aan vertrouwen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/","title":"Persoonsgegevens worden op een rechtmatige manier verwerkt","text":"<p>avg-01OntwerpDataverkenning en datapreparatieProjectleiderJuristPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens worden op een rechtmatige manier verwerkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens moet rechtmatig plaatsvinden, wat betekent dat de verwerking gebaseerd moet zijn op \u00e9\u00e9n van de wettelijke grondslagen die zijn geformuleerd in artikel 6 Algemene Verordening Gegevensbescherming.</p> <p>Persoonsgegevens mogen alleen worden verzameld en verwerkt voor specifieke, duidelijk omschreven en gerechtvaardigde doeleinden. Het is niet toegestaan om deze gegevens verder te verwerken op een manier die niet verenigbaar is met deze oorspronkelijke doeleinden.</p> <p>Bij het verwerken van persoonsgegevens ten behoeve van de ontwikkeling en gebruik van algoritmes moet worden onderzocht of dit kan worden gebaseerd op \u00e9\u00e9n van de verwerkingsgrondslagen. Het is van belang dat wordt uitgewerkt welke persoonsgegevens waarvoor worden verwerkt en op basis van welke grondslag.</p> <p>Hierbij kan worden gedacht aan persoonsgegevens ten behoeve van trainingsdata, voor het genereren van output of, indien (juridisch) mogelijk, voor het uitvoeren van een onderzoek naar onbewuste vooringenomenheid.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5 lid 1 onder a en b Algemene Verordening Gegevensbescherming</li> <li>Artikel 6 lid 1 onder b Algemene Verordening Gegevensbescherming</li> <li>Artikel 6 Algemene Verordening Gegevensbescherming</li> <li>Overweging 39 en 45 Algemene Verordening Gegevensbescherming</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-01-persoonsgegevens-worden-rechtmatig-verwerkt/#risico","title":"Risico","text":"<p>Het risico wanneer persoonsgegevens niet op een rechtmatige manier worden verwerkt (verzamelen van gegevens valt hier ook onder), is dat er niet aan de AVG wordt voldaan. Er worden dan onrechtmatig persoonsgegevens verwerkt, waarmee privacy van personen in het geding komt. Ook kan het leiden tot hoge boetes voor organisaties, en kan een datalek plaatsvinden.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/","title":"Persoonsgegevens worden zo kort mogelijk bewaard","text":"<p>avg-02OntwerpDataverkenning en datapreparatieUitfaserenOntwikkelaarBeleid en adviesPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan nodig is voor de realisering van de doeleinden waarvoor de persoonsgegevens initieel worden verwerkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens dienen toereikend en ter zake dienend te zijn en beperkt te blijven tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt. Dit vereist dat ervoor wordt gezorgd dat de opslagperiode van de persoonsgegevens tot een strikt minimum wordt beperkt.</p> <p>Het beginsel van opslagbeperking betekent dat persoonsgegevens moeten worden bewaard in een vorm die het mogelijk maakt om de betrokkenen niet langer te identificeren dan voor de realisering van de doeleinden waarvoor de persoonsgegevens worden verwerkt.</p> <p>In de context van algoritmes is het belangrijk dat, wanneer persoonsgegevens worden verwerkt, er onderzocht wordt op welke manieren identificatie van betrokkenen tegen kan worden gegaan. Hierbij kan worden gedacht aan maatregelen als het pseudonomiseren, anonimiseren en aggregeren van de persoonsgegevens.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 5 lid 1 onder de AVG</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-02-beperkte-bewaartermijn-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Het onnodig lang bewaren van persoonsgegevens levert een onrechtmatige situatie op. De privacyrechten van betrokken worden hierdoor aangetast. Er ontstaan aanvullende risico's bij bijvoorbeeld een datalek.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/","title":"Persoonsgegevens worden zo min mogelijk verwerkt","text":"<p>avg-03OntwerpDataverkenning en datapreparatieOntwikkelenJuristOntwikkelaarPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens worden zo min mogelijk verwerkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>De verwerking van persoonsgegevens moet minimaal worden gehouden, dat wil zeggen dat die verwerking toereikend moet zijn, ter zake dienend en beperkt tot wat noodzakelijk is voor de doeleinden waarvoor zij worden verwerkt.</p> <p>Het is van belang dat \u00e9nkel persoonsgegevens worden verwerkt die noodzakelijk zijn gezien de doeleinden van die vewerking.</p> <p>Er moet een beoordeling worden gemaakt welke persoonsgegevens dit wel en eventueel niet zijn.</p> <p>Voor het ontwikkelen en gebruiken van algoritmes is het van belang om te beoordelen welke persoonsgegevens noodzakelijk zijn om het beoogde doel te bereiken.</p> <p>Afhankelijk van de toepassing vraagt dit om een intensieve toets. Er moet voor worden gezorgd dat persoonsgegevens die niet als noodzakelijk worden beschouwd, buiten de verwerking blijven.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 5 lid 1 onder c Algemene Verordening Gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-03-minimale-verwerking-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Het onnodig verwerken van persoonsgegevens kan een inbreuk maken op rechten van betrokkenen, en zou kunnen leiden tot een datalek.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-04-proportionaliteit-en-subsidiariteit/","title":"Persoonsgegevens en andere data verwerken gebeurt proportioneel en subsidiair","text":"<p>avg-04OntwerpDataverkenning en datapreparatieJuristOntwikkelaarFundamentele rechtenPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-04-proportionaliteit-en-subsidiariteit/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens en andere data verwerken gebeurt proportioneel en subsidiair.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-04-proportionaliteit-en-subsidiariteit/#toelichting","title":"Toelichting","text":"<p>Gegevensverwerking moet in verhouding staan tot het beoogde doel en persoonsgegevens mogen alleen verwerkt worden als er geen minder ingrijpende manier is om het doel te bereiken. Voor zover het gaat om de verwerking van persoonsgegevens moet dit vereiste aantoonbaar zijn.</p> <p>Proportionaliteit vereist dat de impact van gegevensverwerking op de persoonlijke levenssfeer voor de toepassing van een algoritme en voor het genereren van de benodigde output in balans is met het beoogde doel.</p> <p>Subsidiariteit vereist dat persoonsgegevens alleen moeten worden verwerkt als dit de minst inbreukmakende manier is om het doel te bereiken.</p> <p>Deze principes waarborgen dat de privacy van individuen wordt gerespecteerd en dat gegevensverwerking niet verder gaat dan noodzakelijk is voor legitieme doeleinden.</p> <p>Het is van belang om deze principes te hanteren om te bepalen of en in welke vorm een algoritmes moet worden toegepast en om tot een passende mate van gegevensverwerking te komen om het doel te bereiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-04-proportionaliteit-en-subsidiariteit/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5(1)(c) Algemene Verordening Gegevensbescherming</li> <li>Overweging 170 Algemene Verordening Gegevensbescherming</li> <li>Artikel 5(4) Verdrag betreffende de Europese Unie, Maastricht, 07-02-1992 |</li> <li>Artikel 52, Handvest van de grondrechten van de Europese Unie</li> <li>Protocol betreffende de toepassing van de beginselen van subsidiariteit en evenredigheid Verdrag betreffende de Europese Unie, Maastricht, 07-02-1992</li> <li>Artikel 1.10, 1.13 en 1.16 Aanbestedingswet 2012</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-04-proportionaliteit-en-subsidiariteit/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-04-proportionaliteit-en-subsidiariteit/#risico","title":"Risico","text":"<p>Zonder toetsing aan het proportinaliteits- en subsidiariteitsbeginsel ontstaat het risico dat er een onnodig zware en daardoor onrechtmatige inbreuk wordt gemaakt op de privacyrechten van betrokkenen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/","title":"Persoonsgegevens zijn juist en actueel","text":"<p>avg-05Dataverkenning en datapreparatieOntwikkelaarProjectleiderPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Persoonsgegevens zijn juist en actueel.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>De te verwerken persoonsgegevens moeten nauwkeurig, juist en zo nodig actueel zijn. Dit betekent dat alle maatregelen moeten worden genomen om ervoor te zorgen dat onjuiste persoonsgegevens worden gerectificeerd of gewist.</p> <p>Dat kan betekenen dat persoonsgegevens moeten worden geactualiseerd of verbeterd. In de context van algoritmes is het van belang dat ook daar wordt onderzocht welke maatregelen nodig zijn om die juistheid toe te passen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 5 lid 1 sub d Algemene Verordening Gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-05-juistheid-en-actualiteit-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Als er geen rekening wordt gehouden met de juistheid, nauwkeurigheid en volledigheid van persoonsgegevens, kunnen kwaliteit en integriteit van data niet voldoende worden gewaarborgd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/","title":"Organisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerken","text":"<p>avg-06OntwerpDataverkenning en datapreparatieJuristGovernancePrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#vereiste","title":"Vereiste","text":"<p>Organisaties kunnen bewijzen dat zij persoonsgegevens op de juiste manier verwerken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#toelichting","title":"Toelichting","text":"<p>De verantwoordelijken moeten bij de verwerking van persoonsgegevens door algoritmes kunnen aantonen dat de verwerkingen rechtmatig plaatsvinden. Dit betekent concreet dat de volgende punten aangetoond kunnen worden:</p> <ul> <li>Rechtmatigheid, behoorlijkheid en transparantie</li> <li>Doelbinding</li> <li>Minimale gegevensverwerking</li> <li>Juistheid</li> <li>Opslagbeperking</li> <li>Integriteit en vertrouwelijkheid</li> </ul> <p>Een aandachtpunt daarbij is dat de rechtmatigheid van de verwerking ten opzichte van andere gerelateerde wetgeving zoals de AI Act en de Algemene wet gelijke behandeling ook moeten kunnen worden aangetoond voor zover de rechtmatigheid van de verwerking onder de AVG daarvan afhankelijk is.</p> <p>Bij het verwerken van persoonsgegevens voor algoritmes moeten de verantwoordelijkheden duidelijk beschreven en toegewezen zijn.</p> <p>De verwerkingsverantwoordelijke is degene die ervoor zorgt dat deze verantwoordelijkheden worden nageleefd en kan dit aantonen, wat bekend staat als de verantwoordingsplicht.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5 lid 2 Algemene Verordening Gegevensbescherming</li> <li>Artikel 24 Algemene Verordening Gegevensbescherming</li> <li>Artikel 26 Algemene Verordening Gegevensbescherming</li> <li>Artikel 27 Algemene Verordening Gegevensbescherming</li> <li>Artikel 29 Algemene Verordening Gegevensbescherming</li> <li>Verantwoordingsplicht</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-06-verantwoordingsplicht-rechtmatigheid/#risico","title":"Risico","text":"<p>Het niet naleven van deze norm moet worden gekwalificeerd als een onrechtmatigheid, niet als een risico voor de rechten en vrijheden van betrokkenen onder de AVG. Maar het niet voldoen aan artikel 5 betekent in de praktijk vaak wel dat er onvoldoende zicht is op risico's voor de rechten en vrijheden van betrokkenen of dat er te grote risico's worden genomen. Deze gevolgen zijn echter indirect een gevolg van het niet naleven van artikel 5 AVG. Het moeten voldoen aan het aantoonbaarheidsvereiste kan wel risico's hebben voor de organisatie die een algortime inzet. Enkele risico's zijn:</p> <ul> <li>Aantoonbaarheidsvereisten vragen in de praktijk veel documentatie. Deze documentatie kan via de Woo opgevraagd worden. Het ontbreken van documentatie kan door externen vaak relatief makkelijk in verband worden gebracht met een overtreding van deze vereisten.</li> <li>Algoritmes die van nature slecht inzichtelijk en uitlegbaar zijn (zoals deep-learning) hebben een zeer hoge drempel om aan deze vereiste te voldoen. Aantonen van rechtmatigheid is voor een belangrijk deel afhankelijk van inzicht in de werking van het algoritme. De inzet van een algortime kan dus mogelijk tegengehouden worden door deze vereisten.</li> <li>Bij leveranciers die niet of gedeeltelijke transparant zijn over hun product of dienstverlening ontstaat een vergelijkbaar risico. Waar de Woo uitzonderingen heeft voor bedrijfsgeheimen heeft de AVG daar maar beperkte ruimte voor. Het is dus mogelijk dat leveranciers terughoudend zullen zijn met het delen van informatie die onder de AVG ook aan betrokkenen gecommuniceerd moeten worden.</li> <li>Samenwerkingsverbanden en externe leveranciers kunnen niet als argumenten worden gebruikt om de aantoonbaarheidsvereisten op af te schuiven. Onafhankelijk van de onderlinge afspraken daarover hebben alle verwerkingsverantwoordelijken de verplichting om aan deze vereisten te kunnen voldoen.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/","title":"Organisaties zijn transparant over het verwerken van persoonsgegevens","text":"<p>avg-07ImplementatieMonitoring en beheerOntwikkelaarProjectleiderPrivacy en gegevensbeschermingTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>De verwerking van persoonsgegevens moet transparant zijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Een betrokkene moet op de hoogte worden gesteld van het feit dat er verwerking plaatsvindt van diens persoonsgegevens en van de doeleinden daarvan (zoals ook is verwoord in het beginsel van transparante verwerking, artikel 5 AVG).</p> <p>Hierbij moeten de specifieke omstandigheden en de context waarin de persoonsgegevens worden verwerkt, worden meegenomen. In artikel 13 en 14 AVG wordt toegelicht welke informatie in welke gevallen moet worden verstrekt door de verwerkingsverantwoordelijke.</p> <p>Als persoonsgegevens worden verwerkt ten behoeve van het ontwikkelen of gebruiken van algoritmes, zal deze informatie moeten worden verstrekt.</p> <p>De Autoriteit Persoonsgegevens stelt in een advies over de inzet van geautomatiseerde risicoselectie bij de behandeling van aanvragen of toezicht dat zulke algoritmen zonder specifieke wettelijke voorziening slechts toegepast mogen worden onder bepaalde voorwaarden. Een van die voorwaarden is dat indien geautomatiseerde selectie voorafgaand aan de besluitvorming een rol heeft gespeeld, dit kenbaar wordt gemaakt aan betrokkene. Betrokkene moet uiterlijk bij bekendmaking van het besluit in kennis worden gesteld van de reden voor de selectie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 5 lid 1 Algemene Verordening Gegevensbescherming</li> <li>Artikel 12 Algemene Verordening Gegevensbescherming</li> <li>Artikel 13 Algemene Verordening Gegevensbescherming</li> <li>Artikel 14 Algemene Verordening Gegevensbescherming</li> <li>Overweging 58 Algemene Verordening Gegevensbescherming</li> <li>Advies artikel 22 AVG en geautomatiseerde selectie-instrumenten - Autoriteit Persoonsgegevens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt voor algoritmische toepassingen waarbij persoonsgegevens worden verwerkt. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-07-transparantie-bij-verwerken-persoonsgegevens/#risico","title":"Risico","text":"<p>Rechten van betrokken worden geschonden als er geen sprake is van transparantie over de verwerkingen van de persoonsgegevens.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/","title":"Gevoelige persoonsgegevens worden alleen gebruikt als hiervoor een wettelijke uitzondering geldt","text":"<p>avg-08OntwerpDataverkenning en datapreparatieProjectleiderJuristBeleid en adviesPrivacy en gegevensbeschermingBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#vereiste","title":"Vereiste","text":"<p>Bijzondere categorie\u00ebn van persoonsgegevens mogen alleen worden verwerkt op basis van een wettelijke uitzondering.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#toelichting","title":"Toelichting","text":"<p>Persoonsgegevens die door hun aard bijzonder gevoelig zijn wat betreft de grondrechten en fundamentele vrijheden, verdienen specifieke bescherming.</p> <p>Dit komt doordat de context van de verwerking ervan significante risico's kan meebrengen voor de grondrechten en de fundamentele vrijheden.</p> <p>Denk hierbij aan persoonsgegevens als ras, ethnische afkomst, politieke opvattingen of religieuze of levenschouwelijke overtuigingen.</p> <p>Bijzondere categorie\u00ebn persoonsgegevens mogen alleen worden verwerkt als er hier een wettelijke uitzondering voor is (artikel 9 AVG en artikel 30 UAVG).</p> <p>Deze vereiste is ook van toepassing bij het ontwikkelen en gebruiken van algoritmes en stelt daarmee beperkingen aan het mogen verwerken van deze categorie\u00ebn persoonsgegevens, bv. ten behoeve van trainingsdata of het genereren van de beoogde output.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 9 AVG</li> <li>Overweging 51 - 54 AVG</li> <li>Artikel 22 - 30 UAVG</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-08-wettelijke-verwerking-van-gevoelige-gegevens/#risico","title":"Risico","text":"<p>Het (onrechtmatige) verwerken van bijzondere categorie\u00ebn persoonsgegevens brengt risico's met zich mee op het gebied van respecteren van de persoonlijke levenssfeer en discriminatie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/","title":"Betrokkenen kunnen een beroep doen op hun privacyrechten","text":"<p>avg-09OrganisatieverantwoordelijkhedenOntwikkelenOntwikkelaarPrivacy en gegevensbeschermingData</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Betrokkenen kunnen een beroep doen op hun privacyrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Mensen hebben het recht om hun privacyrechten uit te oefenen door een beroep te doen op verschillende wettelijke bepalingen, zoals het recht op inzage, correctie, verwijdering en bezwaar tegen de verwerking van hun persoonsgegevens.</p> <p>Dit betekent dat individuen controle hebben over hoe hun gegevens worden gebruikt en kunnen verzoeken om toegang te krijgen tot hun gegevens of om wijzigingen aan te brengen indien nodig.</p> <p>Het kunnen uitoefenen van privacyrechten is essentieel voor het beschermen van de privacy van individuen, het waarborgen van transparantie en controle uitvoeren over persoonsgegevens.</p> <p>Als persoonsgegevens worden verwerkt voor het ontwikkelen en gebruiken van algoritmes, is het van belang dat maatregelen worden getroffen om deze rechten te eerbiedigen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#bronnen","title":"Bronnen","text":"<p>Artikel 15 - 21 Algemene Verordening Gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-09-inroepen-privacyrecht-bij-verwerking-persoonsgegevens/#risico","title":"Risico","text":"<p>Betrokkenen hebben geen controle over hun persoonsgegevens wanneer ze geen beroep kunnen doen op hun privacyrechten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/","title":"Besluiten met rechtsgevolgen of aanmerkelijke effecten zijn niet volledig geautomatiseerd","text":"<p>avg-10OntwerpImplementatieProjectleiderBeleid en adviesPrivacy en gegevensbeschermingMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#vereiste","title":"Vereiste","text":"<p>Betrokkenen hebben op grond van artikel 22 van de AVG het recht om niet onderworpen te worden aan een uitsluitend op geautomatiseerde verwerking, waaronder proflering, gebaseerd besluit waaraan voor hen rechtsgevolgen zijn verbonden of dat hen anderszins in aanmerkelijke mate treft. Op grond van artikel 40 UAVG geldt dit verbod niet indien de geautomatiseerde individuele besluitvorming, anders dan op basis van profilering, noodzakelijk is om te voldoen aan een wettelijke verplichting die op de verwerkingsverantwoordelijke rust of noodzakelijk is voor de vervulling van een taak van algemeen belang.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#toelichting","title":"Toelichting","text":"<p>Overheidsorganisaties zijn vaak belast met de uitvoering van wettelijke taken waarbij zij 'besluiten' moeten nemen, bijvoorbeeld als een burger vraagt om een uitkering, toeslag of een subsidie.</p> <p>Hiervoor moeten gegevens worden verwerkt om te kunnen bepalen of een burger hier ook recht op heeft. Om deze gegevens snel en accuraat te verwerken, zetten overheidsorganisaties vaak algoritmes in. Deze gegevens worden dan vaak 'geautomatiseerd' door deze algoritmes verwerkt, waarbij een ambtenaar deze verwerking niet altijd controleert.</p> <p>Soms wordt het proces voor het nemen van een besluit volledig geautomatiseerd ingericht. Denk hierbij aan het opleggen van een boete voor een snelheidsovertreding. Hierdoor kan in korte tijd en op een effici\u00ebnte wijze, een grote hoeveelheid besluiten worden genomen.</p> <p>Het geautomatiseerd verwerken van gegevens voor de totstandkoming van een besluit brengt risico's met zich mee. Zeker als hierbij persoonsgegevens van individuen worden verwerkt of als er sprake is van profilering. Daarom is in art. 22 AVG het recht voor betrokkenen vastgelegd om niet te worden onderworpen aan een uitsluitend op geautomatiseerde verwerking, waaronder profilering, gebaseerd besluit.</p> <p>Dit verbod geldt voor besluiten die 'rechtsgevolgen' hebben voor een betrokkene, bijvoorbeeld een burger die een boete ontvangt voor de snelheidsovertreding, of hem anderzijds in aanmerkelijke mate treft. Het besluit mag in die gevallen niet geautomatiseerd worden genomen. Een individu heeft namelijk recht op voldoende 'menselijke tussenkomst' bij de beoordeling van belangrijke beslissingen die deze persoon treffen.</p> <p>Bij het geautomatiseerd uitvoeren van processen dient altijd te worden voldaan aan de voorwaarden uit wetgeving, waaronder in het bijzonder de Algemene Verordening Gegevensbescherming (AVG) en de Algemene wet bestuursrecht(Awb). Bestuursorganen dienen dan ook te handelen conform de algemene beginselen van behoorlijk bestuur. Dit samenstel van regels moet de rechten van betrokkenen borgen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#algemene-eisen-aan-geautomatiseerde-besluitvorming-door-overheden","title":"Algemene eisen aan geautomatiseerde besluitvorming door overheden","text":"<p>De Nederlandse wetgever heeft in artikel 40 lid 1 UAVG gebruik gemaakt van de mogelijkheid een uitzondering te maken op het verbod van art. 22 lid 1 AVG. In Nederland is geautomatiseerde besluitvorming toegestaan, als het gaat om besluitvorming waarbij menselijke tussenkomst geen toegevoegde waarde heeft.</p> <p>Dit is het geval als er sprake is van een gebonden bevoegdheid waarbij weinig of geen beoordelingsruimte is waarin tot een andere conclusie kan worden gekomen. Hierbij kan worden gedacht aan het toekennen van kinderbijslag of de hoogte van het recht op studiefinanciering. Deze uitzondering geldt niet voor 'profilering', tenzij specifieke (sectorale) wetgeving het verbod opheft.</p> <p>Om deze uitzondering toe te kunnen passen, moet er op grond van artikel 22 AVG een 'passende maatregel' in de vorm van wetgeving zijn die personen voldoende bescherming biedt. In Nederland moet de Algemene wet bestuursrecht deze bescherming aan burgers bieden als bestuursorganen besluiten nemen. De Awb bevat vereisten en algemene beginselen waaraan besluitvorming moet voldoen.</p> <p>Bij het toepassen van geautomatiseerde besluitvorming, moet aan de hand van een DPIA wordt vastgesteld of er bij toepassing van de Awb daadwerkelijk voldoende bescherming wordt geboden. Een verwerkingsverantwoordelijke zal dus, naast het toepassen van vereisten uit de AVG en specifieke (sectorale) wetgeving, beginselen uit de Awb moeten vertalen naar concrete maatregelen om geautomatiseerde besluitvorming op een rechtmatige wijze toe te passen. Hierbij kan worden gedacht aan het toepassen van motiveringsbeginsel en het zorgvuldigheidsbeginsel.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#begrippen","title":"Begrippen","text":""},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#profilering","title":"Profilering","text":"<p>Profilering is bijzonder gevoelig. Bij profilering gaat het om elke vorm van een geautomatiseerde verwerking van persoonsgegevens, waarbij aan de hand van persoonsgegevens bepaalde persoonlijke aspecten van een natuurlijke persoon worden ge\u00ebvalueerd. Daarbij gaat het voornamelijk om het analyseren of voorspellen van zaken als beroepsprestaties, economische situatie, gezondheid, persoonlijke voorkeuren, interesses, betrouwbaarheid, gedrag, locatie of een verplaatsingen.</p> <p>Volgens deze definitie gaat het om een verwerking door een computersysteem waarbij het systeem algemene aanname(s) toegepast in een concreet geval. Dit doet het door een individu, met gebruikmaking van diens persoonsgegevens, in te delen in een categorie (profiel). Een dergelijk categorie (profiel) wordt vaak in verband gebracht met bepaalde risico's, bijvoorbeeld het risico op het misbruiken van bepaalde publieke voorzieningen.</p> <p>De gevoeligheid is dat nog niet is vastgesteld dat, in dit voorbeeld, de betreffende natuurlijke persoon ook daadwerkelijk misbruik heeft gemaakt van bepaalde voorzieningen. Als daar wel automatisch gevolgen aan worden verbonden, ontstaat het risico op een onrechtmatige behandeling van een natuurlijk persoon.</p> <p>Autoriteit Persoonsgegevens: handvatten voor het inrichten van betekenisvolle menselijke tussenkomst'</p> <p>De Autoriteit Persoonsgegevens heeft handvatten opgesteld die dienen als verduidelijking van het begrip 'betekenisvolle menselijke tussenkomst' en praktisch hulpmiddel bij het inrichten ervan.</p> <p>Bron: Autoriteit Persoonsgegevens - Betekenisvolle menselijke tussenkomst bij algoritmische besluitvorming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#besluit","title":"Besluit","text":"<p>In deze context moet het begrip 'besluit' worden gehanteerd zoals dit is bedoeld in artikel 22 AVG. Het begrip 'besluit' krijgt in de AVG een ruimere betekenis dan het geval is in artikel 1:3 Algemene wet bestuursrecht (Awb). In de Algemene wet bestuursrecht moet er sprake zijn van een 'rechtsgevolg', maar onder het besluitbegrip van de AVG kunnen ook situaties vallen waarin een individu \u2018slechts\u2019 feitelijke gevolgen ervaart als een besluit wordt genomen. Daarmee biedt de AVG dus bescherming voor meerdere situaties.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#rechtsgevolgen","title":"Rechtsgevolgen","text":"<p>Het begrip 'rechtsgevolg' duidt op wijziging in de rechtspositie van betrokkene. Het betekent, juridisch uitgedrukt, een verandering in het geheel van de rechten, aanspraken, bevoegdheden en verplichtingen van \u00e9\u00e9n of meer natuurlijke personen of rechtspersonen. In deze context wijzigt de rechtspositie van een individu door een keuze van het systeem, bijvoorbeeld doordat deze een boete ontvangt. Rechtsgevolgen kwalificeren altijd als relevant.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#aanmerkelijke-mate-treffen","title":"Aanmerkelijke mate treffen","text":"<p>De Europese wetgever heeft weinig richting gegeven aan hoe dit begrip moet worden ge\u00efnterpreteerd. Er zijn wel aanknopingspunten om te duiden wanneer hier sprake van is. De EDPB spreekt van ernstige, aanzienlijke effecten, groot of belangrijk genoeg zijn om aandacht te verdienen. Dat is in ieder geval zo als het besluit het potentieel heeft om de omstandigheden, het gedrag of de keuze van de betrokken personen in aanmerkelijke mate te treffen; een langdurig of blijvend effect op de betrokkene te hebben; of in het uiterste geval, tot uitsluiting of discriminatie te leiden.</p> <p>Dit vraagt per geval om een analyse welke 'keuzes' van het systeem welke gevolgen hebben voor een individu en of die gevolgen rechtsgevolgen zijn of alleen een feitelijk gevolg. Zie voor een nadere toelichting hiervoor het advies van de Autoriteit Persoonsgegevens inzake geautomatiseerde selectietechnieken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#toepassing","title":"Toepassing","text":"<p>Volledig geautomatiseerde vaststelling van een publiekrechtelijk besluit zoals een aanslag, een boete of een vergunning heeft rechtsgevolgen. Een beslissing dat een bepaalde aanvraag in aanmerking komt voor handmatige controle heeft op zichzelf geen rechtsgevolg - de rechtspositie van de betrokkene wijzigt (nog) niet. Wel moet beoordeeld worden of de betrokkene door dat besluit anderszins (dus feitelijk) in aanmerkelijke mate wordt getroffen.</p> <p>De Autoriteit Persoonsgegevens (AP) heeft in een advies over artikel 22 AVG en geautomatiseerde selectie-instrumenten toegelicht dat geautomatiseerde risicoselectie niet kwalificeert als geautomatiseerde besluitvorming indien de risicoselectie alleen gebruikt wordt om te beoordelen of acties jegens betrokkene nodig zijn, zoals navraag doen of informatie verzamelen, en eventuele rechtsgevolgen of aanmerkelijke effecten voor betrokkene pas tot stand komen na betekenisvolle menselijke tussenkomst. Een beslissing om iemand wel of niet te controleren op mogelijke fraude heeft op zichzelf immers nog geen rechtsgevolgen voor de burger en een voorzienbare reguliere controle zal een burger doorgaans niet in aanmerkelijke mate treffen. De AP adviseert dat bestuursorganen bij de inzet van geautomatiseerde risicoselectie moeten waarborgen dat eventuele gevolgen voor betrokkenen van de risicoselectie pas intreden na betekenisvolle menselijke tussenkomst en dat de risicoselectie niet automatisch andere aanmerkelijke effecten heeft.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 22 Algemene Verordening Gegevensbescherming</li> <li>Artikel 40 Uitvoeringswet AVG</li> <li>Artikel 1:3 Algemene wet bestuursrecht</li> <li>Advies landsadvocaat over geautomatiseerde selectietechnieken</li> <li>Advies artikel 22 AVG en geautomatiseerde selectie-instrumenten</li> <li>Kamerbrief met kabinetsreactie AP-advies over geautomatiseerde selectie-instrumenten</li> <li>Autoriteit Persoonsgegevens - Betekenisvolle menselijke tussenkomst bij algoritmische besluitvorming</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt voor algoritmische toepassingen die een rol spelen in de besluitvorming van bestuursorganen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-10-recht-op-niet-geautomatiseerde-besluitvorming/#risico","title":"Risico","text":"<p>Bij geautomatiseerde besluitvorming gebaseerd op profilering kan het risico ontstaan dat kenmerken van een bepaalde groep ten onrechte worden tegengeworpen aan een individu die deze kenmerken niet hoeft te bezitten.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/","title":"Ontwerp en standaardinstellingen (defaults) zijn zo gunstig mogelijk voor de privacy van betrokkenen","text":"<p>avg-11OntwerpDataverkenning en datapreparatieBeleid en adviesProjectleiderJuristOntwikkelaarPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#vereiste","title":"Vereiste","text":"<p>Privacy en gegevensbescherming door goed ontwerp en door standaardinstellingen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#toelichting","title":"Toelichting","text":"<p>Gegevensbescherming door ontwerp en standaardinstellingen houdt in dat privacy- en gegevensbescherming vanaf het begin worden ge\u00efntegreerd in de ontwikkeling van systemen en processen (ook wel privacy-by-design genoemd).</p> <p>Door al bij het ontwerp rekening te houden met privacyaspecten en door standaardinstellingen die privacy bevorderen, wordt de bescherming van persoonsgegevens versterkt. Hierbij kan worden gedacht een het pseudonimiseren van persoonsgegevens of dataminimalisatie.</p> <p>Deze aanpak zorgt ervoor dat privacy-overwegingen een integraal onderdeel zijn van alle aspecten van gegevensverwerking en draagt bij aan het vertrouwen van individuen in de veilige omgang met hun gegevens. Dit is eveneens van toepassing als persoonsgegevens worden verwerkt bij het ontwikkelen en gebruiken van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 25 Algemene Verordening Gegevensbescherming</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-11-privacy-bij-ontwerp-bij-verwerking-van-persoonsgegevens/#risico","title":"Risico","text":"<p>Door privacy en gegevensbescherming door ontwerp en standaardinstellingen niet toe te passen, kan een inbreuk op rechten van betrokkenen ontstaan.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-12-beveiliging-van-verwerking/","title":"Data zoals persoonsgegevens zijn voldoende beveiligd tegen ongelukken en cyberaanvallen","text":"<p>avg-12OrganisatieverantwoordelijkhedenJuristOntwikkelaarPrivacy en gegevensbeschermingTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-12-beveiliging-van-verwerking/#vereiste","title":"Vereiste","text":"<p>Rekening houdend met de stand van de techniek, de uitvoeringskosten, alsook met de aard, de omvang, de context en de verwerkingsdoeleinden en de qua waarschijnlijkheid en ernst uiteenlopende risico's voor de rechten en vrijheden van personen, treffen de verwerkingsverantwoordelijke en de verwerker passende technische en organisatorische maatregelen om een op het risico afgestemd beveiligingsniveau te waarborgen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-12-beveiliging-van-verwerking/#toelichting","title":"Toelichting","text":"<p>Voor de ontwikkeling en gebruik van algoritmes is data nodig. Deze data kan persoonsgegevens bevatten die moeten worden beschermd. De organisatie zal technische en organisatorische maatregelen moeten treffen om de data en het algoritme voldoende te beschermen. Hierbij kan worden gedacht aan dataminimalisatie, het pseudonimiseren of aggregeren van persoonsgegevens. Per toepassing moet worden onderzocht welke maatregelen hiervoor geschikt zijn.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-12-beveiliging-van-verwerking/#bronnen","title":"Bronnen","text":"<p>Artikel 32 Algemene Verordening Gegevensbescherming|</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-12-beveiliging-van-verwerking/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-12-beveiliging-van-verwerking/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals potenti\u00eble cyberaanvallen en datalekken. Dit kan leiden bijvoorbeeld tot verlies of diefstal van gevoelige gegevens, verstoring van organisatieprocessen,ongeautoriseerde toegang, vernietiging en onrechtmatige verwerking.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-13-dpia-verplicht/","title":"Een gegevensbeschermingseffectbeoordeling (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen","text":"<p>avg-13OntwerpDataverkenning en datapreparatieVerificatie en validatieJuristProjectleiderPrivacy en gegevensbescherming</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-13-dpia-verplicht/#vereiste","title":"Vereiste","text":"<p>Een gegevensbeschermingseffectbeoordeling (DPIA) is verplicht, indien een verwerking van persoonsgegevens waarschijnlijk een hoog risico inhoudt voor de rechten en vrijheden van natuurlijke personen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-13-dpia-verplicht/#toelichting","title":"Toelichting","text":"<p>Een Gegevensbeschermingseffectbeoordeling (GEB) of Data Protection Impact Assessment (DPIA) is verplicht wanneer de verwerking van persoonsgegevens waarschijnlijk een hoog risico met zich meebrengt voor de rechten en vrijheden van natuurlijke personen.</p> <p>Deze beoordeling identificeert en beperkt potenti\u00eble risico's en zorgt ervoor dat passende maatregelen worden genomen om de privacy van individuen te beschermen.</p> <p>Deze verplichting draagt bij aan een zorgvuldige en verantwoorde omgang met persoonsgegevens in algoritmes, waardoor de privacy van individuen wordt gewaarborgd.</p> <p>Let op: de DPIA verplichting is niet gebaseerd op de hoog-risico criteria uit de AI-act. Volgens Besluit lijst verwerkingen persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens moet voor het uitvoeren van een DPIA in ieder geval uitgegaan worden van een hoog risico als er sprake is van \u00e9\u00e9n van de volgende voorwaarden:</p> <ol> <li>Evaluatie of scoretoekenning</li> <li>Geautomatiseerde besluitvorming met rechtsgevolg of vergelijkbaar wezenlijk gevolg</li> <li>Stelselmatige monitoring</li> <li>Gevoelige gegevens of gegevens van zeer persoonlijke aard</li> <li>Op grote schaal verwerkte gegevens</li> <li>Matching of samenvoeging van datasets</li> <li>Gegevens met betrekking tot kwetsbare betrokkenen</li> <li>Innovatief gebruik of innovatieve toepassing van nieuwe technologische of organisatorische oplossingen</li> <li>de situatie waarin als gevolg van de verwerking zelf \"betrokkenen [...] een recht niet kunnen uitoefenen of geen beroep kunnen doen op een dienst of een overeenkomst\";</li> </ol> <p>Het is mogelijk dat algoritmes die niet aan \u00e9\u00e9n of meer van deze eigenschappen voldoen toch voor een potentieel hoog risico zorgen.</p> <p>Gebruiksverantwoordelijken van AI-systemen met een hoog risico gebruiken die informatie op grond van artikel 13 AI Verordening om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-13-dpia-verplicht/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 35 Algemene Verordening Gegevensbescherming</li> <li>Artikel 26, lid 9, AI-verordening</li> <li>Besluit lijst verwerkingen persoonsgegevens waarvoor een gegevensbeschermingseffectbeoordeling (DPIA) verplicht is, Autoriteit Persoonsgegevens</li> <li>Data protection impact assessment (DPIA), Autoriteit Persoonsgegevens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-13-dpia-verplicht/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-13-dpia-verplicht/#risico","title":"Risico","text":"<p>Het niet evalueren van de impact van het verwerking van persoonsgegevens in algoritmes kan resulteren in het niet onderkennen van de bijbehorende risico's  en het niet op tijd te mitigieren van deze risico's. Dit kan leiden tot potenti\u00eble schendingen van de rechten en vrijheden van betrokkenen en een onrechtmatige verwerking.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/avg-13-dpia-verplicht/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenData Protection Impact AssessmentToetsingskader Algoritmes Algemene Rekenkamer"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-01-zorgvuldigheidsbeginsel/","title":"Organisaties die algoritmes gebruiken voor publieke taken nemen besluiten zorgvuldig","text":"<p>awb-01OntwerpOntwikkelenVerificatie en validatieProjectleiderBeleid en adviesFundamentele rechtenMenselijke controle</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-01-zorgvuldigheidsbeginsel/#vereiste","title":"Vereiste","text":"<p>Organisaties die algoritmes gebruiken voor publieke taken nemen besluiten zorgvuldig.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-01-zorgvuldigheidsbeginsel/#toelichting","title":"Toelichting","text":"<p>Het zorgvuldigheidsvereiste eist dat een besluit met de nodige zorgvuldigheid wordt voorbereid en juist wordt genomen. Dit vraagt onder meer om een zorgvuldig onderzoek naar informatie, feiten, een zorgvuldige beslissingsprocedure en een deugdelijke besluitvorming.</p> <p>Dit betekent dat bij de ontwikkeling en gebruik van algoritmes informatie moet worden vastgelegd  over het algoritme. Hierbij kan worden gedacht aan:</p> <ul> <li>Dat het doel en eventuele subdoelen van het algoritme of AI-systeem helder zijn gedefinieerd, ook in relatie tot het maatschappelijke resultaat (outcome).</li> <li>Een bewuste afweging maken en vaststellen of het algoritme het juiste middel is om het probleem op doelmatige en doeltreffende wijze op te lossen.</li> <li>Dat de werking van het algoritme is onderzocht en is vastgesteld dat dit passend is om te gebruiken in een besluitvormingsproces.</li> <li>Dat de output van het algoritme kritisch ge\u00ebvalueerd wordt door natuurlijke personen en, zo nodig, niet bij de besluitvorming betrokken wordt.</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-01-zorgvuldigheidsbeginsel/#bronnen","title":"Bronnen","text":"<ul> <li>Afdeling 3.1 Algemene wet bestuursrecht</li> <li>Afdeling 3.2 Algemene wet bestuursrecht</li> <li>Afdeling 3.4 Algemene wet bestuursrecht</li> <li>Advies artikel 22 AVG en geautomatiseerde selectie-instrumenten</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-01-zorgvuldigheidsbeginsel/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-01-zorgvuldigheidsbeginsel/#risico","title":"Risico","text":"<p>De werking van het algoritme sluit niet of onvoldoende aan bij de juridische en ethische grenzen van de te ondersteunen wettelijke taak.</p> <p>Hierdoor kunnen ongewenste gevolgen ontstaan zoals een onjuist of onzorgvuldig genomen besluit. Het gevolg daarvan is dat burgers tegen het besluit bezwaar en/of beroep in zullen moeten stellen om hun rechten te effectueren.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-02-motiveringsbeginsel/","title":"Organisaties kunnen duidelijk uitleggen waarom en hoe algoritmes leiden tot een besluit","text":"<p>awb-02OntwerpImplementatieMonitoring en beheerProjectleiderOntwikkelaarTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-02-motiveringsbeginsel/#vereiste","title":"Vereiste","text":"<p>Een besluit berust op een deugdelijke en kenbare motivering.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-02-motiveringsbeginsel/#toelichting","title":"Toelichting","text":"<p>De Awb eist dat een besluit een deugdelijke en kenbare motivering heeft. Dit geldt ook als algoritmes worden ingezet. Een betrokkene moet in staat zijn om te controleren of de overheid een besluit correct heeft genomen. Het motiveringsbeginsel draagt bij aan doelen als verantwoording kunnen afleggen en het bieden van rechtsbescherming. Het kan in samenhang worden gezien met transparantieverplichtingen die voortkomen uit de AVG.</p> <p>Het is van belang dat inzichtelijk wordt gemaakt in het besluit welke gegevens zijn verwerkt en welke 'aannames' een algoritme bevat. Dit speelt in het bijzonder als gebruik wordt gemaakt van geautomatiseerde besluitvormingsprocessen. Hierbij kan worden gedacht aan:</p> <ul> <li> <p>Dat een besluit tot stand is gekomen met behulp van een algoritme.</p> </li> <li> <p>Van welke feiten het bestuursorgaan is uitgegaan.</p> </li> <li> <p>Welke gegevens zijn verwerkt.</p> </li> <li> <p>Welke relevante belangen tegen elkaar zijn afgewogen en hoe die afweging is verlopen.</p> </li> <li> <p>Welke regels zijn gebruikt.</p> </li> <li> <p>Wat de hierachter is (kenbaarheid).</p> </li> <li> <p>Welke analytische technieken zijn gebruikt.</p> </li> <li> <p>Waarom deze regels en logica relevant zijn (uitleg)?</p> </li> <li> <p>Op welke wijze de regels en logica tot stand zijn gekomen en hoe deze regels worden gevalideerd.</p> </li> </ul> <p>Een besluit moet informatie hierover bevatten om als om als voldoende draagkrachtig gemotiveerd te gelden. Het motiveringsbeginsel op grond van de Awb is beperkt tot besluiten in de zin van de Awb.</p> <p>De Autoriteit Persoonsgegevens stelt in een advies over de inzet van geautomatiseerde risicoselectie bij de behandeling van aanvragen of toezicht dat zulke algoritmen zonder specifieke wettelijke voorziening slechts toegepast mogen worden onder bepaalde voorwaarden. Een van die voorwaarden is dat indien geautomatiseerde selectie voorafgaand aan de besluitvorming een rol heeft gespeeld, dit kenbaar wordt gemaakt aan betrokkene. Betrokkene moet uiterlijk bij bekendmaking van het besluit in kennis worden gesteld van de reden voor de selectie.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-02-motiveringsbeginsel/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 3:46 en 3:47 Awb</li> <li>Jurisprudentie over AERIUS (ABRvS 18 juli 2018, ECLI:NL:RVS:2018:2454), Hof van Justitie C-274/18</li> <li>Advies artikel 22 AVG en geautomatiseerde selectie-instrumenten - Autoriteit Persoonsgegevens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-02-motiveringsbeginsel/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt voor algoritmische toepassingen die een rol spelen in de besluitvorming van bestuursorganen of, in het geval van geautomatiseerde risicoselectie, voor algoritmen die voorafgaand aan de besluitvorming een rol spelen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/awb-02-motiveringsbeginsel/#risico","title":"Risico","text":"<p>Het is onduidelijk op wat voor manier het algoritmes heeft bijgedragen aan de totstandkoming van een besluit.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/","title":"Computersystemen zijn voldoende beveiligd tegen ongelukken en cyberaanvallen","text":"<p>bio-01OrganisatieverantwoordelijkhedenBeleid en adviesOntwikkelaarTechnische robuustheid en veiligheid</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#vereiste","title":"Vereiste","text":"<p>Informatie en informatiesystemen moeten op de juiste manier worden beveiligd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#toelichting","title":"Toelichting","text":"<p>Informatiebeveiliging is het proces van vaststellen van de vereiste beveiliging van informatiesystemen in termen van vertrouwelijkheid, beschikbaarheid en integriteit alsmede het treffen, onderhouden en controleren van een samenhangend pakket van bijbehorende maatregelen.</p> <p>In Nederland is besloten dat overheidsinstellingen de Baseline Informatiebeveiliging Overheid (BIO) dienen toe te passen over hun informatie en informatiesystemen. De BIO beoogt de beveiliging van informatie(systemen) bij alle bestuurslagen en bestuursorganen van de overheid te bevorderen, zodat alle onderdelen erop kunnen vertrouwen dat onderling uitgewisselde gegevens, in lijn met wet- en regelgeving, passend beveiligd zijn.</p> <p>Algoritmes en hun output kunnen onderdeel worden van de informatie en informatiesystemen waar de BIO op van toepassing is. Het is van belang om algoritmische toepassingen en AI-systemen op de juiste manier te beveiligen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#bronnen","title":"Bronnen","text":"<ul> <li>Baseline Informatiebeveiliging Overheid</li> <li>Besluit voorschrift informatiebeveiliging rijksdienst 2007</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bio-01-beveiliging-informatie-en-informatiesystemen/#risico","title":"Risico","text":"<p>Er kunnen risico's ontstaan zoals ongeautoriseerde toegang, vernietiging, verlies, wijziging of niet-toegestane verwerking van gegevens als de informatie en informatiesystemen onvoldoende zijn beveiligd.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bzk-01-algoritmeregister/","title":"Impactvolle algoritmes en hoog-risico-AI-systemen staan in het Nederlandse Algoritmeregister","text":"<p>bzk-01ImplementatieMonitoring en beheerProjectleiderTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bzk-01-algoritmeregister/#vereiste","title":"Vereiste","text":"<p>Bestuursorganen publiceren algoritmes met impact en hoog-risico-AI-systemen in het Nederlandse Algoritmeregister.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bzk-01-algoritmeregister/#toelichting","title":"Toelichting","text":"<p>Het publiceren van algoritmes draagt bij aan transparantie voor belanghebbenden en derden over welke algoritmes worden gebruikt door de overheid. Het is vastgesteld beleid dat overheidsinstellingen, tenzij er uitsluitingsgronden zijn, de door hen gebruikte impactvolle algoritmes en hoogrisico AI-systemen publiceren in het algoritmeregister.</p> <p>De Autoriteit Persoonsgegevens heeft handvatten gepubliceerd om je te helpen bij het opzetten en invullen van registraties in het Algoritmeregister.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bzk-01-algoritmeregister/#bronnen","title":"Bronnen","text":"<ul> <li>Handreiking Algoritmeregister</li> <li>Geactualiseerde Werkagenda Waardengedreven Digitaliseren 2024</li> <li>Autoriteit Persoonsgegevens - Aan de slag met algoritmeregistratie: handvatten voor organisaties</li> <li>Kamerbrieven</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bzk-01-algoritmeregister/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bzk-01-algoritmeregister/#risico","title":"Risico","text":"<p>Door het niet publiceren van impactvolle algoritmes of hoog risico AI -systemen in het Algoritmeregister, is het voor betrokkenen of belanghebbenden minder goed mogelijk om de overheid kritisch te volgen, te bevragen en te controleren op de inzet van deze technologie\u00ebn die hen kunnen raken. Bij het onjuist of onvolledig publiceren in het Algortimeregister ontstaat er een risico dat betrokkenen en belanghebbenden onjuiste inschattingen maken over het gebruik van het algoritmes en daardoor in hun rechten worden beperkt.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/bzk-01-algoritmeregister/#hulpmiddelen","title":"hulpmiddelen","text":"HulpmiddelenAlgoritmeregisterHandreiking inventarisatie, identificatie en classificatie AI-systemen"},{"location":"voldoen-aan-wetten-en-regels/vereisten/dat-01-databankenwet/","title":"Databanken worden alleen gebruikt met toestemming van de databank-producent","text":"<p>dat-01Dataverkenning en datapreparatieJuristData</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/dat-01-databankenwet/#vereiste","title":"Vereiste","text":"<p>Het is verboden om zonder goedkeuring van de producent een databank op te vragen en/of te hergebruiken.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/dat-01-databankenwet/#toelichting","title":"Toelichting","text":"<p>De Databankrichtlijn en Databankenwet beschermt de producten/fabrikanten van databanken tegen onrechtmatige toe-eigening van een databank. Degene die een substanti\u00eble financi\u00eble en professionele investering heeft verricht om de inhoud van de databank te verkijgen en te verzamelen, krijgt een verbodsrecht en kan zo anderen verbieden de databank te gebruiken.</p> <p>Bij verkrijgen gaat het om \"het verzamelen van de werken, gegevens of andere zelfstandige elementen die tezamen de inhoud van de databank vormen\". Dit recht bestaat naast het recht op bescherming van de originele keuze of rangschikking van de inhoud van databanken (auteurswet).</p> <p>Voor het ontwikkelen van algoritme is data nodig. De data die hiervoor wordt gebruikt mag niet ongeoorloofd zijn verkregen uit een databank.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/dat-01-databankenwet/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1 en 2 Databankenwet</li> <li>Artikel 5a en 5b Databankenwet</li> <li>Artikel 7 Databankrichtlijn</li> <li>Overwegingen 39 - 41 Databankrichtlijn</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/dat-01-databankenwet/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/dat-01-databankenwet/#risico","title":"Risico","text":"<p>Als een ontwikkelaar onbevoegd gebruik heeft gemaakt van data uit een databank bij de ontwikkeling van algoritmes, wordt het databankenrecht geschonden van de eigenaar. De eigenaar van de databank kan bijvoorbeeld ontrekking van de data uit het handelsverkeer, vernietiging en onbruikbaarmaking  eisen, wat vergaande gevolgen kan hebben voor het gebruik kunnen maken van de algoritmische toepassing of AI-systeem.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-01-fundamentele-rechten/","title":"Algoritmes schenden geen grondrechten of mensenrechten","text":"<p>grw-01ProbleemanalyseOntwerpVerificatie en validatieMonitoring en beheerProjectleiderJuristFundamentele rechten</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-01-fundamentele-rechten/#vereiste","title":"Vereiste","text":"<p>Fundamentele vrijheden, mensenrechten en grondrechten worden beschermd bij de inzet van algoritmes.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-01-fundamentele-rechten/#toelichting","title":"Toelichting","text":"<p>De mensenrechten in Nederland zijn beschermd door nationale wetten en internationale verdragen. In Nederland staan veel mensenrechten in hoofdstuk 1 van de Grondwet. Deze rechten worden ook wel \u2019grondrechten\u2019 genoemd. Een bekend voorbeeld is artikel 1 van de Grondwet. Om mensenrechten te beschermen zijn ze op Europees en internationaal niveau in verschillende verklaringen en verdragen vastgelegd.</p> <p>Mensenrechten kunnen bij overheidshandelen en de inzet van algoritmes soms onder druk komen te staan. De inzet van algoritmes kan bijvoorbeeld een bedreiging vormen voor de privacy van burgers, voor het recht op gelijke behandeling en voor het recht op behoorlijk bestuur. Het is daarom belangrijk om tijdig te onderzoeken of er sprake is of kan zijn van een eventuele inbreuk op fundamentele rechten en vrijheden van burgers. Het is van belang dat maatregelen worden getroffen om een eventuele inbreuk te voorkomen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-01-fundamentele-rechten/#bronnen","title":"Bronnen","text":"<ul> <li>Grondwet</li> <li>Europees Verdrag voor de Rechten van de Mens (EVRM)</li> <li>Handvest van de grondrechten van de Europese Unie</li> <li>Universele Verklaring van de Rechten van de Mens (UVRM)</li> <li>Internationaal Statuut van de Rechten van de Mens</li> <li>Internationale Verdrag inzake burgerrechten en politieke rechten (IVBPR)</li> <li>Internationale Verdrag inzake economische, sociale en culturele rechten (IVESCR)</li> <li>Internationaal Verdrag inzake de uitbanning van alle vormen van rassendiscriminatie (CERD)</li> <li>Internationaal Verdrag voor de rechten van het kind (CRC)</li> <li>Internationaal Verdrag voor de Rechten van Mensen met een Handicap (VN-verdrag Handicap)</li> <li>Artikel 27 Verordening Artifici\u00eble Intelligentie</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-01-fundamentele-rechten/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-01-fundamentele-rechten/#risico","title":"Risico","text":"<p>Grondrechten kunnen worden geraakt door de inzet van algoritmes met eventuele schadelijke gevolgen voor betrokkenen.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-01-fundamentele-rechten/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenImpact Assessment Mensenrechten en AlgoritmesThe Fairness HandbookHandreiking non-discriminatie by designToetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-02-non-discriminatie/","title":"Algoritmes discrimineren niet","text":"<p>grw-02OntwerpOntwikkelenVerificatie en validatieMonitoring en beheerProjectleiderBias en non discriminatie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-02-non-discriminatie/#vereiste","title":"Vereiste","text":"<p>Allen die zich in Nederland bevinden, worden in gelijke gevallen gelijk behandeld. Directe en indirecte discriminatie wegens godsdienst, levensovertuiging, politieke gezindheid, ras, geslacht, handicap, seksuele gerichtheid of op welke grond dan ook, is niet toegestaan.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-02-non-discriminatie/#toelichting","title":"Toelichting","text":"<p>Overheidsinstanties moeten zich bij het uitvoeren van hun taken onthouden van discriminatie, ook wanneer er gebruik wordt gemaakt van algoritmes. Wanneer er algoritmes worden gebruikt om selecties te maken van burgers, dienen we te streven naar een gelijke behandeling van personen of groepen ten opzichte van andere personen in een vergelijkbare situatie.</p> <p>Hierbij is het belangrijk te beseffen dat discriminatie ook op indirecte wijze kan ontstaan. Hiervan is sprake wanneer een ogenschijnlijk neutrale bepaling, maatstaf of handelwijze personen met een beschermd persoonskenmerk in vergelijking met andere personen in het bijzonder benadeelt, tenzij hiervoor een objectieve rechtvaardiging bestaat.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-02-non-discriminatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1 Grondwet</li> <li>Artikel 14 Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden, Rome, 04-11-1950</li> <li>Artikel 21, Handvest van de grondrechten van de Europese Unie</li> <li>Artikel 1 Algemene wet gelijke behandeling</li> <li>Artikel 1 Protocol nr. 12 bij het Verdrag tot bescherming van de rechten van de mens en de fundamentele vrijheden, Rome, 04-11-2000</li> <li>Artikel 9 Algemene Verordening Gegevensbescherming</li> <li>Artikel 2:4 Algemene wet bestuursrecht</li> <li>Advies geautomatiseerde besluitvorming - Autoriteit Persoonsgegevens</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-02-non-discriminatie/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p> <p>Wanneer er geautomatiseerde risicoselectie plaatsvindt in je algoritme, volgt dit als een vereiste uit het AP-advies over geautomatiseerde besluitvorming.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-02-non-discriminatie/#risico","title":"Risico","text":"<p>Het risico bestaat dat het model onwenselijke systematische afwijkingen cre\u00ebert voor specifieke personen, groepen of andere eenheden, wat kan duiden op directe of indirecte discriminerende effecten van het algoritme.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/grw-02-non-discriminatie/#hulpmiddelen","title":"Hulpmiddelen","text":"HulpmiddelenThe Fairness HandbookHandreiking non-discriminatie by designToetsingskader risicoprofilering \u2013 Normen tegen discriminatie op grond van ras en nationaliteit"},{"location":"voldoen-aan-wetten-en-regels/vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/","title":"Iedereen kan openbare informatie over algoritmes vinden of aanvragen","text":"<p>woo-01OrganisatieverantwoordelijkhedenJuristProjectleiderTransparantie</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#vereiste","title":"Vereiste","text":"<p>Een bestuursorgaan draagt er zorg voor dat de documenten die het ontvangt, vervaardigt of anderszins onder zich heeft, zich in goede, geordende en toegankelijke staat bevinden. Een bestuursorgaan draagt er zoveel mogelijk zorg voor dat de informatie die het overeenkomstig deze wet verstrekt, actueel, nauwkeurig en vergelijkbaar is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#toelichting","title":"Toelichting","text":"<p>Bij het ontwikkelen en gebruiken van algoritmes kunnen documenten en publieke informatie ontstaan die (op verzoek) in aanmerking komen voor openbaarmaking. Het kunnen openbaren van publieke informatie is in het belang van een democratische rechtstaat. De Wet open overheid gaat uit van een recht op openbaarheid van publieke informatie. Iedereenkan een verzoek tot openbaarmaking van publieke informatie doen bij een bestuursorgaan zonder daarbij een belang te stellen (artikel 4.1 Woo). De aan een verzoeker verstrekte informatie wordt openbaar voor iedereen. De Woo is niet van toepassing op informatie die al openbaar is (uitspraken van de Afdeling bestuursrechtspraak van de Raad van State van 1 december 2010 (ECLI:NL:RVS:2010:BNS6990) en 20 oktober 2010 (ECLI:NL:RVS:2010:BO1165)). Er kunnen uitsluitingsgronden bestaan voor het openbaarmaken van documenten (artikel 5.1 Woo).</p> <p>In de context van het ontwikkelen en gebruiken van algoritmes is het van belang dat tijdig wordt vastgesteld welke documenten in aanmerking komen voor openbaarmaking. Dit moet worden bekeken in het licht van wat 'actief' moet worden geopenbaard, dus proactief vanuit overheidsinstanties zelf, of wat op 'verzoek' van iemand moet worden geopenbaard.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#bronnen","title":"Bronnen","text":"<ul> <li>Artikel 1.1 Wet open overheid</li> <li>Artikel 2.5 Wet open overheid</li> <li>Artikel 4.1 Wet open overheid</li> <li>Artikel 5 Wet open overheid</li> </ul>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#van-toepassing-op","title":"Van toepassing op","text":"<p>Deze vereiste geldt waarschijnlijk voor jouw algoritmische toepassingen. Bekijk de bronnen om te controleren of dit zo is.</p>"},{"location":"voldoen-aan-wetten-en-regels/vereisten/woo-01-recht-op-toegang-tot-publieke-informatie/#risico","title":"Risico","text":"<p>Zonder het openbaren van overheidsinformatie kan de overheid niet effectief worden gecontroleerd bij het uitvoeren van wettelijke taken.</p>"}]}